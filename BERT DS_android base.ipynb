{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfNydjdoLcvK"
   },
   "source": [
    "Based on \n",
    "\n",
    "\n",
    "\n",
    "1.   https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379\n",
    "2.   https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/\n",
    "3.   https://huggingface.co/transformers/training.html#fine-tuning-with-keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**problem statement:**\n",
    "\n",
    "\n",
    "*   a developer has to inspect an **artifact X**\n",
    "*   Within the artifact, only a portion of the text is relevant to **input task Y**\n",
    "*   We ought to build a model that establishes relationships between **Y** and **sentences x ∈ X** \n",
    "*  The model must determine: **is x relevant to task Y**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Example of a task and an annotated artifact:*\n",
    "\n",
    "<br>\n",
    "\n",
    "[<img src=\"https://i.imgur.com/Zj1317H.jpg\">](https://i.imgur.com/Zj1317H.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* The coloured sentences are sentences annotated as relevant to the input task. \n",
    "* The warmer the color, the more annotators selected that portion of the text. \n",
    "* For simplicity, we process the data and used sentences \n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Ultimately, our data is a tuple representing:*\n",
    "\n",
    "\n",
    "*   **text** = artifact sentence\n",
    "\n",
    "*   **question** = task description\n",
    "\n",
    "*   **source** = URL of the artifact\n",
    "\n",
    "*   **category_index** = whether sentence is relevant [or not] for the input task\n",
    "\n",
    "*   **weights** = number of participants who annotated sentence as relevant\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kudd2ZR8tKZ",
    "outputId": "2a38495e-b8e4-43b1-c126-ec92e98b07d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m39 \u001b[33m129 \u001b[0m https://developer.android.com/training/permissions/requesting\n",
      "\u001b[31m14 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/5233543\n",
      "\u001b[31m4 \u001b[33m34 \u001b[0m https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "\u001b[31m27 \u001b[33m63 \u001b[0m https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "\u001b[31m9 \u001b[33m161 \u001b[0m https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "\u001b[31m9 \u001b[33m15 \u001b[0m https://developer.android.com/training/volley/request\n",
      "\u001b[31m14 \u001b[33m65 \u001b[0m https://stackoverflow.com/questions/28504524\n",
      "\u001b[31m20 \u001b[33m59 \u001b[0m https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "\u001b[31m5 \u001b[33m97 \u001b[0m https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "\u001b[31m4 \u001b[33m12 \u001b[0m https://stackoverflow.com/questions/33241952\n",
      "\u001b[31m6 \u001b[33m33 \u001b[0m https://github.com/realm/realm-java/issues/776\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/8712652\n",
      "\u001b[31m8 \u001b[33m59 \u001b[0m https://dzone.com/articles/android-rotate-and-scale\n",
      "\u001b[31m5 \u001b[33m470 \u001b[0m https://developer.android.com/reference/android/widget/TextView\n",
      "\u001b[31m7 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/19025301\n",
      "\u001b[31m8 \u001b[33m95 \u001b[0m https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "\u001b[31m20 \u001b[33m145 \u001b[0m https://developer.android.com/training/dependency-injection/hilt-android\n",
      "\u001b[31m4 \u001b[33m8 \u001b[0m https://stackoverflow.com/questions/30648172\n",
      "\u001b[31m4 \u001b[33m81 \u001b[0m https://github.com/google/dagger/issues/1991\n",
      "\u001b[31m9 \u001b[33m48 \u001b[0m https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "\u001b[31m5 \u001b[33m47 \u001b[0m https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "\u001b[31m9 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/6442054\n",
      "\u001b[31m3 \u001b[33m22 \u001b[0m https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "\u001b[31m22 \u001b[33m211 \u001b[0m https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "\u001b[31m21 \u001b[33m59 \u001b[0m https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "\u001b[31m17 \u001b[33m33 \u001b[0m https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "\u001b[31m6 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/10108774\n",
      "\u001b[31m19 \u001b[33m250 \u001b[0m https://developer.android.com/guide/topics/media/camera\n",
      "\u001b[31m9 \u001b[33m32 \u001b[0m https://github.com/google/ExoPlayer/issues/8387\n",
      "\u001b[31m7 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/8184492\n",
      "\u001b[31m7 \u001b[33m58 \u001b[0m https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "\u001b[31m3 \u001b[33m50 \u001b[0m https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "\u001b[31m3 \u001b[33m56 \u001b[0m https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "\u001b[31m3 \u001b[33m5 \u001b[0m https://stackoverflow.com/questions/38980595\n",
      "\u001b[31m4 \u001b[33m38 \u001b[0m https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "\u001b[31m3 \u001b[33m36 \u001b[0m https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "\u001b[31m4 \u001b[33m131 \u001b[0m https://stackoverflow.com/questions/122105\n",
      "\u001b[31m3 \u001b[33m48 \u001b[0m https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "\u001b[31m8 \u001b[33m49 \u001b[0m https://developer.android.com/guide/topics/media/mediarecorder\n",
      "\u001b[31m4 \u001b[33m9 \u001b[0m https://stackoverflow.com/questions/6688444\n",
      "\u001b[31m4 \u001b[33m27 \u001b[0m https://stackoverflow.com/questions/24952513\n",
      "\u001b[31m18 \u001b[33m219 \u001b[0m https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "\u001b[31m3 \u001b[33m72 \u001b[0m https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "\u001b[31m5 \u001b[33m373 \u001b[0m https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "\u001b[31m12 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/35357919\n",
      "\u001b[31m11 \u001b[33m117 \u001b[0m https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "\u001b[31m8 \u001b[33m147 \u001b[0m https://developer.android.com/training/notify-user/build-notification\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/3059155\n",
      "\u001b[31m10 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/26838730\n",
      "\u001b[31m7 \u001b[33m283 \u001b[0m https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "\u001b[31m5 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/37096547\n",
      "\u001b[31m7 \u001b[33m179 \u001b[0m https://guides.codepath.com/android/using-the-recyclerview\n",
      "\u001b[31m3 \u001b[33m31 \u001b[0m https://stackoverflow.com/questions/47760861\n",
      "\u001b[31m13 \u001b[33m69 \u001b[0m https://developer.android.com/training/data-storage/sqlite\n",
      "\u001b[31m15 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/4015026\n",
      "\u001b[31m15 \u001b[33m81 \u001b[0m https://developer.android.com/guide/background/threading\n",
      "\u001b[31m6 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/2993085\n",
      "\u001b[31m11 \u001b[33m50 \u001b[0m https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "\u001b[31m5 \u001b[33m28 \u001b[0m https://stackoverflow.com/questions/23844667\n",
      "\u001b[31m5 \u001b[33m45 \u001b[0m https://github.com/flutter/flutter/issues/11392\n",
      "\u001b[31m4 \u001b[33m23 \u001b[0m https://stackoverflow.com/questions/29738510\n",
      "\u001b[31m5 \u001b[33m54 \u001b[0m https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "\u001b[31m7 \u001b[33m70 \u001b[0m https://guides.codepath.com/android/using-the-app-toolbar\n",
      "\u001b[31m4 \u001b[33m100 \u001b[0m https://stackoverflow.com/questions/2661536\n",
      "\u001b[31m9 \u001b[33m65 \u001b[0m https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "\u001b[31m5 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/24652078\n",
      "\u001b[31m8 \u001b[33m44 \u001b[0m https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/2883355\n",
      "\u001b[31m7 \u001b[33m24 \u001b[0m https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "\u001b[31m9 \u001b[33m51 \u001b[0m https://stackoverflow.com/questions/11064244\n",
      "\u001b[31m7 \u001b[33m138 \u001b[0m https://github.com/quarkusio/quarkus/issues/3954\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m16 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/29923376\n",
      "\u001b[31m4 \u001b[33m13 \u001b[0m https://github.com/google/dagger/issues/671\n",
      "\u001b[31m3 \u001b[33m19 \u001b[0m https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/36275986\n",
      "\u001b[31m42 \u001b[33m177 \u001b[0m https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "\u001b[31m9 \u001b[33m36 \u001b[0m https://developer.android.com/training/location/retrieve-current\n",
      "\u001b[31m5 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/46481789\n",
      "\u001b[31m22 \u001b[33m119 \u001b[0m https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "\u001b[31m15 \u001b[33m99 \u001b[0m https://javapapers.com/android/android-location-fused-provider\n",
      "\u001b[31m3 \u001b[33m14 \u001b[0m https://developer.android.com/training/keyboard-input/commands\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m3 \u001b[33m4 \u001b[0m https://stackoverflow.com/questions/40168601\n",
      "\u001b[31m20 \u001b[33m54 \u001b[0m https://developer.android.com/training/safetynet/recaptcha\n",
      "\u001b[31m11 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/27297067\n",
      "\u001b[31m8 \u001b[33m42 \u001b[0m https://stackoverflow.com/questions/30362446\n",
      "\u001b[31m10 \u001b[33m36 \u001b[0m https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "\u001b[31m5 \u001b[33m16 \u001b[0m https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "\u001b[31m5 \u001b[33m57 \u001b[0m https://github.com/signalapp/Signal-Android/issues/3376\n",
      "\u001b[31m5 \u001b[33m34 \u001b[0m https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "\u001b[31m22 \u001b[33m104 \u001b[0m https://developer.android.com/reference/org/json/JSONObject\n",
      "\u001b[31m8 \u001b[33m31 \u001b[0m https://guides.codepath.com/android/converting-json-to-models\n",
      "\u001b[31m7 \u001b[33m146 \u001b[0m https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "\u001b[31m5 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/24313539\n",
      "\u001b[31m12 \u001b[33m77 \u001b[0m https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "\u001b[31m6 \u001b[33m72 \u001b[0m https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "\u001b[31m5 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/14347588\n",
      "\u001b[31m31 \u001b[33m163 \u001b[0m https://guides.codepath.com/android/creating-and-using-fragments\n",
      "\u001b[31m4 \u001b[33m40 \u001b[0m https://developer.android.com/training/gestures/scale\n",
      "\u001b[31m6 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/10630373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m4 \u001b[33m54 \u001b[0m https://developer.android.com/training/gestures/scroll\n",
      "\u001b[31m4 \u001b[33m16 \u001b[0m https://stackoverflow.com/questions/39588322\n",
      "\u001b[31m20 \u001b[33m196 \u001b[0m https://developer.android.com/training/dependency-injection/dagger-android\n",
      "\u001b[31m6 \u001b[33m44 \u001b[0m https://stackoverflow.com/questions/57235136\n",
      "\u001b[31m24 \u001b[33m121 \u001b[0m https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "Sample entry from data:\n",
      "{\n",
      "    \"category_index\": 1,\n",
      "    \"question\": \"Permission Denial when trying to access contacts in Android\",\n",
      "    \"source\": \"https://developer.android.com/training/permissions/requesting\",\n",
      "    \"text\": \"Every Android app runs in a limited-access sandbox.\",\n",
      "    \"weights\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# @title Import data as JSON\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from Levenshtein import ratio\n",
    "from colorama import Fore, Style\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.level = logging.DEBUG\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "from ds_android import get_input_for_BERT\n",
    "\n",
    "raw_data = get_input_for_BERT()\n",
    "\n",
    "print('Sample entry from data:')\n",
    "print(json.dumps(raw_data[0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLoading data from cache\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# @title DICT that will store fold results\n",
    "# If there is a previous execution for the same configuration, we load it from disk\n",
    "\n",
    "# final results are the average of 3 distinct runs of this script.\n",
    "# reason: avoid phishing results when BERT training procedures were exceptionally good\n",
    "NUMBER_OF_RUNS = 3 \n",
    "config_output = 'output/bert_ds_android_base.json'\n",
    "# config_output = 'output/bert_ds_android_fe.json' # for frame-elements filter\n",
    "# config_output = 'output/bert_ds_android_fa.json' # for frame-association filters\n",
    "\n",
    "fold_results = dict()\n",
    "\n",
    "if os.path.isfile(config_output):\n",
    "    logger.info(Fore.YELLOW + \"Loading data from cache\" + Style.RESET_ALL)\n",
    "    with open(config_output) as input_file:\n",
    "        fold_results = json.load(input_file)\n",
    "        \n",
    "if 'venn_diagram_set' not in fold_results:\n",
    "    fold_results['venn_diagram_set'] = []     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1l5DIHP_FUb",
    "outputId": "7f1648d0-2582-43a8-c1fc-50095d78892b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n"
     ]
    }
   ],
   "source": [
    "# @title Set environment variables\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "USE_TPU = False\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "# @title Initialize TPU Strategy\n",
    "if USE_TPU:\n",
    "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
    "    tf.contrib.distribute.initialize_tpu_system(resolver)\n",
    "    strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
    "    \n",
    "from TFBertForTaskTextClassification import TFBertForTaskTextClassification\n",
    "from TFBertForTaskTextClassification import TFBertForAndroidTaskTextClassification\n",
    "from TFBertForTaskTextClassification import TFBertForSyntheticTaskTextClassification \n",
    "\n",
    "from metrics import MetricsAggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837,
     "referenced_widgets": [
      "8c7cf993674145ffb7bb876e5591f6ca",
      "67f208ba489343dfa195c1dd915f3efe",
      "35a9eeb0acdb44738a6ad7fbf6d99b2b",
      "153c3ed5c6314a49a5a37ad976417142",
      "82b7fc20b50c44b2bd84b3bf882cdd43",
      "16b6cfa829ad43778c079452df231a3d",
      "a2a36eb594654c65acd584d9d4ebea20",
      "3950e2a7832c4dce8fd8209d6322a1f7",
      "d32667132d604faeb419bbf9851c1bd8",
      "262cc50dd08f49f78b781c2ce96a4ad7",
      "f305b344487a4b598a7d41b007e49abd",
      "c18a3a9fc6d54b9f848e4454e1e36c21",
      "a8fd8b38a6b84be7b83b2f4df590fada",
      "5c6bfb038756422bb00be1349db7750b",
      "6cf29b5d508a4e2082751ccc7fa2f625",
      "c4c410ab0c994a229a49b8baee221de4",
      "9e99fb1211ba43459ee78dd64ab8c30e",
      "71a15c5a038f451f8ee64ce046488f71",
      "c586016d3b594c6299cab2384f4c10aa",
      "d03c894896ad4ed6b48f19a70fbdf2af",
      "3ccd384305c44ee3a86f47a2b994fbf9",
      "23531989ef014d7db16b220bb807c8fd",
      "e0e88103f9684ffdb957357222bbaaf7",
      "c5b9bf1f3ae343ce97982c7802cfdc94",
      "a66943be0fc0423880cb2bd63a1ea2d2",
      "8c2b37becdef45bba205dfb20f8e37b2",
      "baffabe6cabf48f5b0b6523ea92aee78",
      "997b8c940317448c9409a2dee15fc519",
      "b12b35cc52454a249c97f695409d24ce",
      "b6d9e21208294428a3f5572bbbd8b0b9",
      "d15e557fc621427a8295eecdc1e781a8",
      "b4276b6a5eac4023955218db6f78c84a",
      "c4b0a1b67d304afda6ee4e52095584cc",
      "901557318fb947dfa082f0cbf2d7365b",
      "0efe94b613f44c029f2e9bd05696ad32",
      "5a38bc7017d545e2b44ad6ab0b2d937b",
      "b3db733aacf94a3c94519d70a7a56d7a",
      "394b7988d36849b7b2c82872ae8d489d",
      "d3e13535de4b44bb9139c3911684cee8",
      "6ccdfb754c12418c9438ac218a172e63",
      "929799bd24fb411bb4686988f2ae8996",
      "4bd0f4c575714ad7848e818a576ee00a",
      "0466163ff4a945798423387d1ac900c8",
      "17cfaa41c53842618c728987a81a44da"
     ]
    },
    "id": "r_y7xwmxAT39",
    "outputId": "ba094ca3-4ef3-41c0-da55-0e07626c7fd2"
   },
   "outputs": [],
   "source": [
    "# Init the model\n",
    "model = TFBertForAndroidTaskTextClassification(model_id = 'bert-base-uncased')\n",
    "\n",
    "# Configure filters. All other values are as default\n",
    "model.target_output = 10\n",
    "model.use_frame_filtering = False\n",
    "model.match_frame_from_task = False\n",
    "model.n_undersampling = 3\n",
    "        \n",
    "# Load tokenizer\n",
    "model.tokenizer(cache_dir='/home/msarthur/scratch', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # base + frame-elements\n",
    "# model.use_frame_filtering = True\n",
    "# model.match_frame_from_task = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # base + frame-associations\n",
    "# model.use_frame_filtering = False\n",
    "# model.match_frame_from_task = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "03ddd131c9f0446eb83bb6dabee9a832",
      "3518f71b0e4540be8b17a3fe72182cb4",
      "a5ccb838d3704546937e925e456830be",
      "8181fd24b3624c1b9c6a9d0302f43a56",
      "f02cf8090f8d463eb7eeb59743a87276",
      "c9ef3ce0ace649c5a53e2244ba0dbb32",
      "702a74b6e6e44d6b8ad68347f1a4b5fb",
      "3d84c022c44141268ef2c8d5e0190404",
      "40c212c9b352401697860624a6c54b1c",
      "1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "911177bb86c749a0bd774cd3b7f9d302"
     ]
    },
    "id": "1oZGDUKnB1gw",
    "outputId": "21690a29-4add-4780-f87f-fa497b87d5e1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n",
      "Hide MarkerView when nothing selected\n",
      "How to check programmatically whether app is running in debug mode or not?\n",
      "JSONObject parse dictionary objects\n",
      "Want to add drawable icons insteadof colorful dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "100%|██████████| 7917/7917 [00:00<00:00, 718782.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    758\n",
      "1    253\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    708\n",
      "1     27\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 3.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2b23a9b733d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2b23a9b733d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1294 - sparse_categorical_accuracy: 0.6884The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66674, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 15s 913ms/step - loss: 1.1294 - sparse_categorical_accuracy: 0.6884 - val_loss: 0.6667 - val_sparse_categorical_accuracy: 0.6549\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0036 - sparse_categorical_accuracy: 0.5519\n",
      "Epoch 00002: val_loss did not improve from 0.66674\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 1.0036 - sparse_categorical_accuracy: 0.5519 - val_loss: 0.6993 - val_sparse_categorical_accuracy: 0.5398\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9498 - sparse_categorical_accuracy: 0.6548\n",
      "Epoch 00003: val_loss did not improve from 0.66674\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.9498 - sparse_categorical_accuracy: 0.6548 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6814\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8613 - sparse_categorical_accuracy: 0.7458\n",
      "Epoch 00004: val_loss improved from 0.66674 to 0.59313, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 458ms/step - loss: 0.8613 - sparse_categorical_accuracy: 0.7458 - val_loss: 0.5931 - val_sparse_categorical_accuracy: 0.7611\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7832 - sparse_categorical_accuracy: 0.7774\n",
      "Epoch 00005: val_loss improved from 0.59313 to 0.53691, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 434ms/step - loss: 0.7832 - sparse_categorical_accuracy: 0.7774 - val_loss: 0.5369 - val_sparse_categorical_accuracy: 0.7788\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6867 - sparse_categorical_accuracy: 0.8299\n",
      "Epoch 00006: val_loss did not improve from 0.53691\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.6867 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.5521 - val_sparse_categorical_accuracy: 0.7257\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5651 - sparse_categorical_accuracy: 0.8645\n",
      "Epoch 00007: val_loss improved from 0.53691 to 0.53049, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 431ms/step - loss: 0.5651 - sparse_categorical_accuracy: 0.8645 - val_loss: 0.5305 - val_sparse_categorical_accuracy: 0.7611\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4951 - sparse_categorical_accuracy: 0.8793\n",
      "Epoch 00008: val_loss did not improve from 0.53049\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.4951 - sparse_categorical_accuracy: 0.8793 - val_loss: 0.5811 - val_sparse_categorical_accuracy: 0.7611\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3903 - sparse_categorical_accuracy: 0.9120\n",
      "Epoch 00009: val_loss improved from 0.53049 to 0.52680, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 445ms/step - loss: 0.3903 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.5268 - val_sparse_categorical_accuracy: 0.7699\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3277 - sparse_categorical_accuracy: 0.9258\n",
      "Epoch 00010: val_loss did not improve from 0.52680\n",
      "16/16 [==============================] - 4s 249ms/step - loss: 0.3277 - sparse_categorical_accuracy: 0.9258 - val_loss: 0.5508 - val_sparse_categorical_accuracy: 0.7699\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "https://stackoverflow.com/questions/37096547\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 16 [1s] 1\n",
      "predicted\n",
      "[0s] 15 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.8235\n",
      "macro_f1: 0.4516\n",
      "Precision: 0.4667\n",
      "Recall: 0.4375\n",
      "F1: 0.4516\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 87 [1s] 17\n",
      "predicted\n",
      "[0s] 103 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.8269\n",
      "macro_f1: 0.4526\n",
      "Precision: 0.4175\n",
      "Recall: 0.4943\n",
      "F1: 0.4526\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 33 [1s] 3\n",
      "predicted\n",
      "[0s] 31 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.8333\n",
      "macro_f1: 0.5781\n",
      "Precision: 0.5677\n",
      "Recall: 0.6061\n",
      "F1: 0.5781\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/23844667\n",
      "--------------------\n",
      "Y\n",
      "[0s] 24 [1s] 4\n",
      "predicted\n",
      "[0s] 27 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.8929\n",
      "macro_f1: 0.6706\n",
      "Precision: 0.9444\n",
      "Recall: 0.6250\n",
      "F1: 0.6706\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/33241952\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 2\n",
      "predicted\n",
      "[0s] 26 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.7742\n",
      "macro_f1: 0.4364\n",
      "Precision: 0.4615\n",
      "Recall: 0.4138\n",
      "F1: 0.4364\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.572\u001b[0m\n",
      "recall:    \u001b[31m0.515\u001b[0m\n",
      "f1-score:  \u001b[31m0.518\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next 1\n",
      "\n",
      "\u001b[31mFold 1\u001b[0m\n",
      " height must be > 0\n",
      "Write and Read a json data to internal storage android\n",
      "Android PDF Rendering\n",
      "How can I hide a fragment on start of my MainActivity( or the application)?\n",
      "polymorphic deserialization of JSON with jackson, property type becomes &quot;null&quot;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7917/7917 [00:00<00:00, 771306.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    729\n",
      "1    243\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    722\n",
      "1     38\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 3.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0402 - sparse_categorical_accuracy: 0.6883The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64539, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 9s 588ms/step - loss: 1.0402 - sparse_categorical_accuracy: 0.6883 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.7130\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9455 - sparse_categorical_accuracy: 0.6770\n",
      "Epoch 00002: val_loss did not improve from 0.64539\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.9455 - sparse_categorical_accuracy: 0.6770 - val_loss: 0.7015 - val_sparse_categorical_accuracy: 0.5463\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8505 - sparse_categorical_accuracy: 0.7356\n",
      "Epoch 00003: val_loss did not improve from 0.64539\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.8505 - sparse_categorical_accuracy: 0.7356 - val_loss: 0.6552 - val_sparse_categorical_accuracy: 0.6111\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7699 - sparse_categorical_accuracy: 0.7449\n",
      "Epoch 00004: val_loss improved from 0.64539 to 0.60579, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 8s 512ms/step - loss: 0.7699 - sparse_categorical_accuracy: 0.7449 - val_loss: 0.6058 - val_sparse_categorical_accuracy: 0.6389\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7104 - sparse_categorical_accuracy: 0.7603\n",
      "Epoch 00005: val_loss did not improve from 0.60579\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.7104 - sparse_categorical_accuracy: 0.7603 - val_loss: 0.6131 - val_sparse_categorical_accuracy: 0.6481\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6369 - sparse_categorical_accuracy: 0.7963\n",
      "Epoch 00006: val_loss improved from 0.60579 to 0.52953, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 9s 535ms/step - loss: 0.6369 - sparse_categorical_accuracy: 0.7963 - val_loss: 0.5295 - val_sparse_categorical_accuracy: 0.6944\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5643 - sparse_categorical_accuracy: 0.8364\n",
      "Epoch 00007: val_loss did not improve from 0.52953\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.5643 - sparse_categorical_accuracy: 0.8364 - val_loss: 0.6204 - val_sparse_categorical_accuracy: 0.6852\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4949 - sparse_categorical_accuracy: 0.8447\n",
      "Epoch 00008: val_loss did not improve from 0.52953\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.4949 - sparse_categorical_accuracy: 0.8447 - val_loss: 0.6502 - val_sparse_categorical_accuracy: 0.6852\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4520 - sparse_categorical_accuracy: 0.8591\n",
      "Epoch 00009: val_loss did not improve from 0.52953\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.4520 - sparse_categorical_accuracy: 0.8591 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.6852\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3700 - sparse_categorical_accuracy: 0.8920Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.52953\n",
      "16/16 [==============================] - 4s 255ms/step - loss: 0.3700 - sparse_categorical_accuracy: 0.8920 - val_loss: 0.5453 - val_sparse_categorical_accuracy: 0.7407\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "https://stackoverflow.com/questions/38980595\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 3 [1s] 2\n",
      "predicted\n",
      "[0s] 5 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.6000\n",
      "macro_f1: 0.3750\n",
      "Precision: 0.3000\n",
      "Recall: 0.5000\n",
      "F1: 0.3750\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/creating-and-using-fragments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 153 [1s] 10\n",
      "predicted\n",
      "[0s] 163 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.9387\n",
      "macro_f1: 0.4842\n",
      "Precision: 0.4693\n",
      "Recall: 0.5000\n",
      "F1: 0.4842\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30362446\n",
      "--------------------\n",
      "Y\n",
      "[0s] 39 [1s] 3\n",
      "predicted\n",
      "[0s] 32 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7857\n",
      "macro_f1: 0.5905\n",
      "Precision: 0.5844\n",
      "Recall: 0.7308\n",
      "F1: 0.5905\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/14347588\n",
      "--------------------\n",
      "Y\n",
      "[0s] 21 [1s] 4\n",
      "predicted\n",
      "[0s] 24 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.8000\n",
      "macro_f1: 0.4444\n",
      "Precision: 0.4167\n",
      "Recall: 0.4762\n",
      "F1: 0.4444\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 8\n",
      "predicted\n",
      "[0s] 34 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8182\n",
      "macro_f1: 0.7206\n",
      "Precision: 0.7059\n",
      "Recall: 0.7431\n",
      "F1: 0.7206\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 22 [1s] 2\n",
      "predicted\n",
      "[0s] 14 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5833\n",
      "macro_f1: 0.4444\n",
      "Precision: 0.5143\n",
      "Recall: 0.5455\n",
      "F1: 0.4444\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2883355\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 22 [1s] 2\n",
      "predicted\n",
      "[0s] 15 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.6250\n",
      "macro_f1: 0.4693\n",
      "Precision: 0.5222\n",
      "Recall: 0.5682\n",
      "F1: 0.4693\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 2\n",
      "predicted\n",
      "[0s] 26 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7222\n",
      "macro_f1: 0.5000\n",
      "Precision: 0.5308\n",
      "Recall: 0.6176\n",
      "F1: 0.5000\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 3\n",
      "predicted\n",
      "[0s] 6 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.3125\n",
      "macro_f1: 0.2874\n",
      "Precision: 0.3833\n",
      "Recall: 0.3205\n",
      "F1: 0.2874\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/40168601\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 2 [1s] 2\n",
      "predicted\n",
      "[0s] 3 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.7500\n",
      "macro_f1: 0.7333\n",
      "Precision: 0.8333\n",
      "Recall: 0.7500\n",
      "F1: 0.7333\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.526\u001b[0m\n",
      "recall:    \u001b[31m0.575\u001b[0m\n",
      "f1-score:  \u001b[31m0.505\u001b[0m\n",
      "next 2\n",
      "\n",
      "\u001b[31mFold 2\u001b[0m\n",
      "How to Integrate reCAPTCHA 2.0 in Android\n",
      "How can I make this rxjava zip to run in parallel?\n",
      "Permission Denial when trying to access contacts in Android\n",
      "keyUp called when key is still pressed\n",
      "Don’t leak MockWebServer ports across tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7917/7917 [00:00<00:00, 721719.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    685\n",
      "1    229\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1304\n",
      "1      54\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 3.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.0678 - sparse_categorical_accuracy: 0.6455The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67346, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 10s 695ms/step - loss: 1.0678 - sparse_categorical_accuracy: 0.6455 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.7353\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.0384 - sparse_categorical_accuracy: 0.5274\n",
      "Epoch 00002: val_loss improved from 0.67346 to 0.66880, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 7s 471ms/step - loss: 1.0384 - sparse_categorical_accuracy: 0.5274 - val_loss: 0.6688 - val_sparse_categorical_accuracy: 0.6765\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.9965 - sparse_categorical_accuracy: 0.6740\n",
      "Epoch 00003: val_loss improved from 0.66880 to 0.56409, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 13s 896ms/step - loss: 0.9965 - sparse_categorical_accuracy: 0.6740 - val_loss: 0.5641 - val_sparse_categorical_accuracy: 0.7353\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.9001 - sparse_categorical_accuracy: 0.7462\n",
      "Epoch 00004: val_loss improved from 0.56409 to 0.55103, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 7s 445ms/step - loss: 0.9001 - sparse_categorical_accuracy: 0.7462 - val_loss: 0.5510 - val_sparse_categorical_accuracy: 0.7059\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7939 - sparse_categorical_accuracy: 0.7363\n",
      "Epoch 00005: val_loss improved from 0.55103 to 0.51592, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 7s 447ms/step - loss: 0.7939 - sparse_categorical_accuracy: 0.7363 - val_loss: 0.5159 - val_sparse_categorical_accuracy: 0.7255\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6726 - sparse_categorical_accuracy: 0.8020\n",
      "Epoch 00006: val_loss improved from 0.51592 to 0.48680, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 7s 459ms/step - loss: 0.6726 - sparse_categorical_accuracy: 0.8020 - val_loss: 0.4868 - val_sparse_categorical_accuracy: 0.7255\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6007 - sparse_categorical_accuracy: 0.8293\n",
      "Epoch 00007: val_loss improved from 0.48680 to 0.48257, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.6007 - sparse_categorical_accuracy: 0.8293 - val_loss: 0.4826 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4895 - sparse_categorical_accuracy: 0.8709\n",
      "Epoch 00008: val_loss did not improve from 0.48257\n",
      "15/15 [==============================] - 4s 239ms/step - loss: 0.4895 - sparse_categorical_accuracy: 0.8709 - val_loss: 0.4946 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4372 - sparse_categorical_accuracy: 0.8829\n",
      "Epoch 00009: val_loss did not improve from 0.48257\n",
      "15/15 [==============================] - 4s 239ms/step - loss: 0.4372 - sparse_categorical_accuracy: 0.8829 - val_loss: 0.5155 - val_sparse_categorical_accuracy: 0.7843\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3770 - sparse_categorical_accuracy: 0.9059\n",
      "Epoch 00010: val_loss did not improve from 0.48257\n",
      "15/15 [==============================] - 4s 240ms/step - loss: 0.3770 - sparse_categorical_accuracy: 0.9059 - val_loss: 0.5315 - val_sparse_categorical_accuracy: 0.7843\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 158 [1s] 3\n",
      "predicted\n",
      "[0s] 151 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.9441\n",
      "macro_f1: 0.6393\n",
      "Precision: 0.5967\n",
      "Recall: 0.8080\n",
      "F1: 0.6393\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "--------------------\n",
      "Y\n",
      "[0s] 70 [1s] 2\n",
      "predicted\n",
      "[0s] 62 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8333\n",
      "macro_f1: 0.4545\n",
      "Precision: 0.4839\n",
      "Recall: 0.4286\n",
      "F1: 0.4545\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 116 [1s] 1\n",
      "predicted\n",
      "[0s] 107 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.9060\n",
      "macro_f1: 0.4753\n",
      "Precision: 0.4953\n",
      "Recall: 0.4569\n",
      "F1: 0.4753\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/35357919\n",
      "--------------------\n",
      "Y\n",
      "[0s] 49 [1s] 4\n",
      "predicted\n",
      "[0s] 44 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.7925\n",
      "macro_f1: 0.5178\n",
      "Precision: 0.5215\n",
      "Recall: 0.5434\n",
      "F1: 0.5178\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "--------------------\n",
      "Y\n",
      "[0s] 59 [1s] 4\n",
      "predicted\n",
      "[0s] 53 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8095\n",
      "macro_f1: 0.5179\n",
      "Precision: 0.5217\n",
      "Recall: 0.5487\n",
      "F1: 0.5179\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/training/safetynet/recaptcha\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 6\n",
      "predicted\n",
      "[0s] 44 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7778\n",
      "macro_f1: 0.5598\n",
      "Precision: 0.5545\n",
      "Recall: 0.5833\n",
      "F1: 0.5598\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/5233543\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 8\n",
      "predicted\n",
      "[0s] 11 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7143\n",
      "macro_f1: 0.7083\n",
      "Precision: 0.7091\n",
      "Recall: 0.7212\n",
      "F1: 0.7083\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://developer.android.com/training/permissions/requesting\n",
      "--------------------\n",
      "Y\n",
      "[0s] 114 [1s] 15\n",
      "predicted\n",
      "[0s] 119 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8217\n",
      "macro_f1: 0.4906\n",
      "Precision: 0.4912\n",
      "Recall: 0.4939\n",
      "F1: 0.4906\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 3\n",
      "predicted\n",
      "[0s] 4 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5000\n",
      "macro_f1: 0.4974\n",
      "Precision: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.6818\n",
      "F1: 0.4974\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/27297067\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 8\n",
      "predicted\n",
      "[0s] 14 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.6370\n",
      "Precision: 0.6429\n",
      "Recall: 0.6346\n",
      "F1: 0.6370\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24952513\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.567\u001b[0m\n",
      "recall:    \u001b[31m0.590\u001b[0m\n",
      "f1-score:  \u001b[31m0.550\u001b[0m\n",
      "next 3\n",
      "\n",
      "\u001b[31mFold 3\u001b[0m\n",
      "Is there an accepted best-practice on making asynchronous HTTP requests in Android?\n",
      "How to set a minimum crop window ?\n",
      "Camera API: Cross device issues\n",
      "Quick Actions don't get displayed on Android 7.0\n",
      "Application icon doesn&#39;t show up in Android action bar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 7917/7917 [00:00<00:00, 743019.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    743\n",
      "1    247\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    737\n",
      "1     33\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 3.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0743 - sparse_categorical_accuracy: 0.7111The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68499, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 14s 897ms/step - loss: 1.0743 - sparse_categorical_accuracy: 0.7111 - val_loss: 0.6850 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0163 - sparse_categorical_accuracy: 0.4929\n",
      "Epoch 00002: val_loss did not improve from 0.68499\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 1.0163 - sparse_categorical_accuracy: 0.4929 - val_loss: 0.7088 - val_sparse_categorical_accuracy: 0.4909\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9546 - sparse_categorical_accuracy: 0.6434\n",
      "Epoch 00003: val_loss improved from 0.68499 to 0.64301, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 10s 601ms/step - loss: 0.9546 - sparse_categorical_accuracy: 0.6434 - val_loss: 0.6430 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8792 - sparse_categorical_accuracy: 0.7545\n",
      "Epoch 00004: val_loss improved from 0.64301 to 0.56816, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 435ms/step - loss: 0.8792 - sparse_categorical_accuracy: 0.7545 - val_loss: 0.5682 - val_sparse_categorical_accuracy: 0.7636\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8003 - sparse_categorical_accuracy: 0.8010\n",
      "Epoch 00005: val_loss improved from 0.56816 to 0.56397, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 440ms/step - loss: 0.8003 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.5640 - val_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7134 - sparse_categorical_accuracy: 0.8152\n",
      "Epoch 00006: val_loss improved from 0.56397 to 0.55311, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 424ms/step - loss: 0.7134 - sparse_categorical_accuracy: 0.8152 - val_loss: 0.5531 - val_sparse_categorical_accuracy: 0.7455\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6016 - sparse_categorical_accuracy: 0.8606\n",
      "Epoch 00007: val_loss improved from 0.55311 to 0.54882, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 421ms/step - loss: 0.6016 - sparse_categorical_accuracy: 0.8606 - val_loss: 0.5488 - val_sparse_categorical_accuracy: 0.7455\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5022 - sparse_categorical_accuracy: 0.9131\n",
      "Epoch 00008: val_loss did not improve from 0.54882\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.5022 - sparse_categorical_accuracy: 0.9131 - val_loss: 0.5674 - val_sparse_categorical_accuracy: 0.7455\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4488 - sparse_categorical_accuracy: 0.9121\n",
      "Epoch 00009: val_loss did not improve from 0.54882\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.4488 - sparse_categorical_accuracy: 0.9121 - val_loss: 0.6117 - val_sparse_categorical_accuracy: 0.7455\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4172 - sparse_categorical_accuracy: 0.9172\n",
      "Epoch 00010: val_loss did not improve from 0.54882\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.4172 - sparse_categorical_accuracy: 0.9172 - val_loss: 0.5799 - val_sparse_categorical_accuracy: 0.7545\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/3059155\n",
      "https://developer.android.com/training/notify-user/build-notification\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 145 [1s] 2\n",
      "predicted\n",
      "[0s] 138 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.9252\n",
      "macro_f1: 0.4806\n",
      "Precision: 0.4928\n",
      "Recall: 0.4690\n",
      "F1: 0.4806\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/media/camera\n",
      "--------------------\n",
      "Y\n",
      "[0s] 239 [1s] 11\n",
      "predicted\n",
      "[0s] 240 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.9400\n",
      "macro_f1: 0.6272\n",
      "Precision: 0.6333\n",
      "Recall: 0.6217\n",
      "F1: 0.6272\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "https://stackoverflow.com/questions/28504524\n",
      "--------------------\n",
      "Y\n",
      "[0s] 61 [1s] 4\n",
      "predicted\n",
      "[0s] 65 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.9385\n",
      "macro_f1: 0.4841\n",
      "Precision: 0.4692\n",
      "Recall: 0.5000\n",
      "F1: 0.4841\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 52 [1s] 7\n",
      "predicted\n",
      "[0s] 57 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.8475\n",
      "macro_f1: 0.4587\n",
      "Precision: 0.4386\n",
      "Recall: 0.4808\n",
      "F1: 0.4587\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/training/volley/request\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 2\n",
      "predicted\n",
      "[0s] 15 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.8667\n",
      "macro_f1: 0.4643\n",
      "Precision: 0.4333\n",
      "Recall: 0.5000\n",
      "F1: 0.4643\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/26838730\n",
      "--------------------\n",
      "Y\n",
      "[0s] 18 [1s] 7\n",
      "predicted\n",
      "[0s] 18 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.7600\n",
      "macro_f1: 0.7024\n",
      "Precision: 0.7024\n",
      "Recall: 0.7024\n",
      "F1: 0.7024\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.528\u001b[0m\n",
      "recall:    \u001b[31m0.546\u001b[0m\n",
      "f1-score:  \u001b[31m0.536\u001b[0m\n",
      "next 4\n",
      "\n",
      "\u001b[31mFold 4\u001b[0m\n",
      "Android: rotate canvas around the center of the screen\n",
      "TS shows numbers instead of contact names in notifications\n",
      "No lock screen controls ever\n",
      "Enums support with Realm?\n",
      "Sound panning should work for stereo files (and if not, add it to the docs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 7917/7917 [00:00<00:00, 531964.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    802\n",
      "1    267\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    265\n",
      "1     11\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 3.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0429 - sparse_categorical_accuracy: 0.4088The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63759, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 11s 642ms/step - loss: 1.0429 - sparse_categorical_accuracy: 0.4088 - val_loss: 0.6376 - val_sparse_categorical_accuracy: 0.6723\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9589 - sparse_categorical_accuracy: 0.6941\n",
      "Epoch 00002: val_loss improved from 0.63759 to 0.57164, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 8s 453ms/step - loss: 0.9589 - sparse_categorical_accuracy: 0.6941 - val_loss: 0.5716 - val_sparse_categorical_accuracy: 0.7227\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8712 - sparse_categorical_accuracy: 0.7362\n",
      "Epoch 00003: val_loss improved from 0.57164 to 0.53246, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 7s 427ms/step - loss: 0.8712 - sparse_categorical_accuracy: 0.7362 - val_loss: 0.5325 - val_sparse_categorical_accuracy: 0.7311\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7715 - sparse_categorical_accuracy: 0.7624\n",
      "Epoch 00004: val_loss improved from 0.53246 to 0.52652, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 9s 537ms/step - loss: 0.7715 - sparse_categorical_accuracy: 0.7624 - val_loss: 0.5265 - val_sparse_categorical_accuracy: 0.7311\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.6769 - sparse_categorical_accuracy: 0.7961\n",
      "Epoch 00005: val_loss improved from 0.52652 to 0.50256, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 7s 435ms/step - loss: 0.6769 - sparse_categorical_accuracy: 0.7961 - val_loss: 0.5026 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5812 - sparse_categorical_accuracy: 0.8513\n",
      "Epoch 00006: val_loss improved from 0.50256 to 0.49426, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 14s 794ms/step - loss: 0.5812 - sparse_categorical_accuracy: 0.8513 - val_loss: 0.4943 - val_sparse_categorical_accuracy: 0.7479\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4977 - sparse_categorical_accuracy: 0.8728\n",
      "Epoch 00007: val_loss improved from 0.49426 to 0.47577, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 7s 437ms/step - loss: 0.4977 - sparse_categorical_accuracy: 0.8728 - val_loss: 0.4758 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4473 - sparse_categorical_accuracy: 0.8812\n",
      "Epoch 00008: val_loss did not improve from 0.47577\n",
      "17/17 [==============================] - 4s 248ms/step - loss: 0.4473 - sparse_categorical_accuracy: 0.8812 - val_loss: 0.4890 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3886 - sparse_categorical_accuracy: 0.9046\n",
      "Epoch 00009: val_loss did not improve from 0.47577\n",
      "17/17 [==============================] - 4s 249ms/step - loss: 0.3886 - sparse_categorical_accuracy: 0.9046 - val_loss: 0.4938 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3707 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 00010: val_loss did not improve from 0.47577\n",
      "17/17 [==============================] - 4s 249ms/step - loss: 0.3707 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.5279 - val_sparse_categorical_accuracy: 0.7815\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "https://dzone.com/articles/android-rotate-and-scale\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 58 [1s] 1\n",
      "predicted\n",
      "[0s] 49 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8475\n",
      "macro_f1: 0.5489\n",
      "Precision: 0.5500\n",
      "Recall: 0.9224\n",
      "F1: 0.5489\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "https://github.com/signalapp/Signal-Android/issues/3376\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 54 [1s] 3\n",
      "predicted\n",
      "[0s] 47 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8070\n",
      "macro_f1: 0.5225\n",
      "Precision: 0.5287\n",
      "Recall: 0.5833\n",
      "F1: 0.5225\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/realm/realm-java/issues/776\n",
      "--------------------\n",
      "Y\n",
      "[0s] 31 [1s] 2\n",
      "predicted\n",
      "[0s] 23 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6970\n",
      "macro_f1: 0.4907\n",
      "Precision: 0.5283\n",
      "Recall: 0.6048\n",
      "F1: 0.4907\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24652078\n",
      "--------------------\n",
      "Y\n",
      "[0s] 8 [1s] 3\n",
      "predicted\n",
      "[0s] 7 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.5455\n",
      "macro_f1: 0.4762\n",
      "Precision: 0.4821\n",
      "Recall: 0.4792\n",
      "F1: 0.4762\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/8712652\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 15 [1s] 2\n",
      "predicted\n",
      "[0s] 8 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.5882\n",
      "macro_f1: 0.5296\n",
      "Precision: 0.6111\n",
      "Recall: 0.7667\n",
      "F1: 0.5296\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.540\u001b[0m\n",
      "recall:    \u001b[31m0.671\u001b[0m\n",
      "f1-score:  \u001b[31m0.514\u001b[0m\n",
      "next 5\n",
      "\n",
      "\u001b[31mFold 5\u001b[0m\n",
      "Different actions from contact info depending on whether hitting back key or back arrow in top left\n",
      "Unlimited/Dynamic ViewPager in both directions\n",
      "Java: Efficient ArrayList filtering?\n",
      "shouldn't snackbar DSL helpers take CharSequence?\n",
      "Not receiving notifications when phone is locked and connected through WIFI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 7917/7917 [00:00<00:00, 785056.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    742\n",
      "1    248\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    770\n",
      "1     33\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 3.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0431 - sparse_categorical_accuracy: 0.7253The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63738, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 12s 746ms/step - loss: 1.0431 - sparse_categorical_accuracy: 0.7253 - val_loss: 0.6374 - val_sparse_categorical_accuracy: 0.7455\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9700 - sparse_categorical_accuracy: 0.6980\n",
      "Epoch 00002: val_loss improved from 0.63738 to 0.58521, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 8s 470ms/step - loss: 0.9700 - sparse_categorical_accuracy: 0.6980 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.6636\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8668 - sparse_categorical_accuracy: 0.6960\n",
      "Epoch 00003: val_loss improved from 0.58521 to 0.56783, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 431ms/step - loss: 0.8668 - sparse_categorical_accuracy: 0.6960 - val_loss: 0.5678 - val_sparse_categorical_accuracy: 0.6818\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7394 - sparse_categorical_accuracy: 0.7505\n",
      "Epoch 00004: val_loss did not improve from 0.56783\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.7394 - sparse_categorical_accuracy: 0.7505 - val_loss: 0.6335 - val_sparse_categorical_accuracy: 0.6273\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6121 - sparse_categorical_accuracy: 0.8172\n",
      "Epoch 00005: val_loss did not improve from 0.56783\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.6121 - sparse_categorical_accuracy: 0.8172 - val_loss: 0.6682 - val_sparse_categorical_accuracy: 0.6364\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5204 - sparse_categorical_accuracy: 0.8394\n",
      "Epoch 00006: val_loss did not improve from 0.56783\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.5204 - sparse_categorical_accuracy: 0.8394 - val_loss: 0.5984 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4227 - sparse_categorical_accuracy: 0.8929Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.56783\n",
      "16/16 [==============================] - 4s 258ms/step - loss: 0.4227 - sparse_categorical_accuracy: 0.8929 - val_loss: 0.6266 - val_sparse_categorical_accuracy: 0.7091\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/122105\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 130 [1s] 1\n",
      "predicted\n",
      "[0s] 121 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.9160\n",
      "macro_f1: 0.4781\n",
      "Precision: 0.4959\n",
      "Recall: 0.4615\n",
      "F1: 0.4781\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 165 [1s] 12\n",
      "predicted\n",
      "[0s] 167 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8757\n",
      "macro_f1: 0.4669\n",
      "Precision: 0.4641\n",
      "Recall: 0.4697\n",
      "F1: 0.4669\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/36275986\n",
      "--------------------\n",
      "Y\n",
      "[0s] 22 [1s] 2\n",
      "predicted\n",
      "[0s] 18 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.8333\n",
      "macro_f1: 0.7000\n",
      "Precision: 0.6667\n",
      "Recall: 0.9091\n",
      "F1: 0.7000\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/10108774\n",
      "https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "--------------------\n",
      "Y\n",
      "[0s] 144 [1s] 2\n",
      "predicted\n",
      "[0s] 136 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.9178\n",
      "macro_f1: 0.4786\n",
      "Precision: 0.4926\n",
      "Recall: 0.4653\n",
      "F1: 0.4786\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 75 [1s] 2\n",
      "predicted\n",
      "[0s] 67 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8442\n",
      "macro_f1: 0.4577\n",
      "Precision: 0.4851\n",
      "Recall: 0.4333\n",
      "F1: 0.4577\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 2\n",
      "predicted\n",
      "[0s] 28 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6842\n",
      "macro_f1: 0.4063\n",
      "Precision: 0.4643\n",
      "Recall: 0.3611\n",
      "F1: 0.4063\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "--------------------\n",
      "Y\n",
      "[0s] 25 [1s] 8\n",
      "predicted\n",
      "[0s] 33 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.7576\n",
      "macro_f1: 0.4310\n",
      "Precision: 0.3788\n",
      "Recall: 0.5000\n",
      "F1: 0.4310\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24313539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 51 [1s] 4\n",
      "predicted\n",
      "[0s] 45 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7455\n",
      "macro_f1: 0.4271\n",
      "Precision: 0.4556\n",
      "Recall: 0.4020\n",
      "F1: 0.4271\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.488\u001b[0m\n",
      "recall:    \u001b[31m0.500\u001b[0m\n",
      "f1-score:  \u001b[31m0.481\u001b[0m\n",
      "next 6\n",
      "\n",
      "\u001b[31mFold 6\u001b[0m\n",
      "Generating an error when using Provider for scoped instances\n",
      "Why settings.xml layout is overlapping the ActionBar/Toolbar?\n",
      "Explanation of the getView() method of an ArrayAdapter\n",
      "Dagger 2 doesn't implement some of the component methods in Android project with custom annotation processor\n",
      "Android - Jackson JSON parser returns null value in &#39;release&#39; builds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 7917/7917 [00:00<00:00, 722866.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    699\n",
      "1    233\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1302\n",
      "1      49\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 3.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.0178 - sparse_categorical_accuracy: 0.5536The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61404, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 10s 642ms/step - loss: 1.0178 - sparse_categorical_accuracy: 0.5536 - val_loss: 0.6140 - val_sparse_categorical_accuracy: 0.6731\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.9346 - sparse_categorical_accuracy: 0.6481\n",
      "Epoch 00002: val_loss improved from 0.61404 to 0.58429, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 7s 478ms/step - loss: 0.9346 - sparse_categorical_accuracy: 0.6481 - val_loss: 0.5843 - val_sparse_categorical_accuracy: 0.6635\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.8373 - sparse_categorical_accuracy: 0.6921\n",
      "Epoch 00003: val_loss improved from 0.58429 to 0.52224, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 7s 440ms/step - loss: 0.8373 - sparse_categorical_accuracy: 0.6921 - val_loss: 0.5222 - val_sparse_categorical_accuracy: 0.7115\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7363 - sparse_categorical_accuracy: 0.7339\n",
      "Epoch 00004: val_loss improved from 0.52224 to 0.47431, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 8s 520ms/step - loss: 0.7363 - sparse_categorical_accuracy: 0.7339 - val_loss: 0.4743 - val_sparse_categorical_accuracy: 0.7404\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6248 - sparse_categorical_accuracy: 0.8079\n",
      "Epoch 00005: val_loss improved from 0.47431 to 0.46471, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 7s 455ms/step - loss: 0.6248 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.4647 - val_sparse_categorical_accuracy: 0.7692\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5435 - sparse_categorical_accuracy: 0.8423\n",
      "Epoch 00006: val_loss improved from 0.46471 to 0.43260, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 7s 445ms/step - loss: 0.5435 - sparse_categorical_accuracy: 0.8423 - val_loss: 0.4326 - val_sparse_categorical_accuracy: 0.7885\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4393 - sparse_categorical_accuracy: 0.8841\n",
      "Epoch 00007: val_loss did not improve from 0.43260\n",
      "15/15 [==============================] - 4s 244ms/step - loss: 0.4393 - sparse_categorical_accuracy: 0.8841 - val_loss: 0.4714 - val_sparse_categorical_accuracy: 0.8077\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3883 - sparse_categorical_accuracy: 0.8970\n",
      "Epoch 00008: val_loss improved from 0.43260 to 0.41728, saving model to /home/msarthur/scratch/best_model\n",
      "15/15 [==============================] - 7s 453ms/step - loss: 0.3883 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.4173 - val_sparse_categorical_accuracy: 0.8365\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3420 - sparse_categorical_accuracy: 0.9217\n",
      "Epoch 00009: val_loss did not improve from 0.41728\n",
      "15/15 [==============================] - 4s 244ms/step - loss: 0.3420 - sparse_categorical_accuracy: 0.9217 - val_loss: 0.4366 - val_sparse_categorical_accuracy: 0.8269\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2921 - sparse_categorical_accuracy: 0.9367\n",
      "Epoch 00010: val_loss did not improve from 0.41728\n",
      "15/15 [==============================] - 4s 245ms/step - loss: 0.2921 - sparse_categorical_accuracy: 0.9367 - val_loss: 0.4653 - val_sparse_categorical_accuracy: 0.8462\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/training/dependency-injection/dagger-android\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 195 [1s] 1\n",
      "predicted\n",
      "[0s] 186 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.9439\n",
      "macro_f1: 0.4856\n",
      "Precision: 0.4973\n",
      "Recall: 0.4744\n",
      "F1: 0.4856\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 203 [1s] 8\n",
      "predicted\n",
      "[0s] 201 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.9242\n",
      "macro_f1: 0.5358\n",
      "Precision: 0.5326\n",
      "Recall: 0.5403\n",
      "F1: 0.5358\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/google/dagger/issues/671\n",
      "https://stackoverflow.com/questions/29738510\n",
      "--------------------\n",
      "Y\n",
      "[0s] 21 [1s] 2\n",
      "predicted\n",
      "[0s] 23 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.9130\n",
      "macro_f1: 0.4773\n",
      "Precision: 0.4565\n",
      "Recall: 0.5000\n",
      "F1: 0.4773\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://github.com/quarkusio/quarkus/issues/3954\n",
      "https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "https://stackoverflow.com/questions/6442054\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 14 [1s] 7\n",
      "predicted\n",
      "[0s] 11 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.3810\n",
      "macro_f1: 0.3576\n",
      "Precision: 0.3727\n",
      "Recall: 0.3571\n",
      "F1: 0.3576\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/using-the-app-toolbar\n",
      "--------------------\n",
      "Y\n",
      "[0s] 65 [1s] 5\n",
      "predicted\n",
      "[0s] 60 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8143\n",
      "macro_f1: 0.5147\n",
      "Precision: 0.5167\n",
      "Recall: 0.5308\n",
      "F1: 0.5147\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/57235136\n",
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 3\n",
      "predicted\n",
      "[0s] 34 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7955\n",
      "macro_f1: 0.5938\n",
      "Precision: 0.5853\n",
      "Recall: 0.7358\n",
      "F1: 0.5938\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "--------------------\n",
      "Y\n",
      "[0s] 47 [1s] 12\n",
      "predicted\n",
      "[0s] 49 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6271\n",
      "macro_f1: 0.3854\n",
      "Precision: 0.3776\n",
      "Recall: 0.3936\n",
      "F1: 0.3854\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "--------------------\n",
      "Y\n",
      "[0s] 44 [1s] 3\n",
      "predicted\n",
      "[0s] 37 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7234\n",
      "macro_f1: 0.4198\n",
      "Precision: 0.4595\n",
      "Recall: 0.3864\n",
      "F1: 0.4198\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/29923376\n",
      "--------------------\n",
      "Y\n",
      "[0s] 28 [1s] 4\n",
      "predicted\n",
      "[0s] 22 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7500\n",
      "macro_f1: 0.6343\n",
      "Precision: 0.6273\n",
      "Recall: 0.7500\n",
      "F1: 0.6343\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "https://stackoverflow.com/questions/11064244\n",
      "--------------------\n",
      "Y\n",
      "[0s] 47 [1s] 4\n",
      "predicted\n",
      "[0s] 41 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8431\n",
      "macro_f1: 0.6688\n",
      "Precision: 0.6378\n",
      "Recall: 0.8005\n",
      "F1: 0.6688\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.506\u001b[0m\n",
      "recall:    \u001b[31m0.547\u001b[0m\n",
      "f1-score:  \u001b[31m0.507\u001b[0m\n",
      "next 7\n",
      "\n",
      "\u001b[31mFold 7\u001b[0m\n",
      "Doesn't scroll properly inside ViewPager\n",
      "The gravity is not working on the TextView in some situation.\n",
      "Support for GoogleApiClient and new FusedLocationProviderApi\n",
      "How to record phone calls in Android\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 7917/7917 [00:00<00:00, 741046.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    758\n",
      "1    253\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    871\n",
      "1     27\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 3.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0879 - sparse_categorical_accuracy: 0.6568The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67386, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 10s 647ms/step - loss: 1.0879 - sparse_categorical_accuracy: 0.6568 - val_loss: 0.6739 - val_sparse_categorical_accuracy: 0.6460\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0198 - sparse_categorical_accuracy: 0.5134\n",
      "Epoch 00002: val_loss did not improve from 0.67386\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 1.0198 - sparse_categorical_accuracy: 0.5134 - val_loss: 0.6804 - val_sparse_categorical_accuracy: 0.6018\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9742 - sparse_categorical_accuracy: 0.6231\n",
      "Epoch 00003: val_loss improved from 0.67386 to 0.63960, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 9s 571ms/step - loss: 0.9742 - sparse_categorical_accuracy: 0.6231 - val_loss: 0.6396 - val_sparse_categorical_accuracy: 0.7080\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9177 - sparse_categorical_accuracy: 0.6983\n",
      "Epoch 00004: val_loss did not improve from 0.63960\n",
      "16/16 [==============================] - 4s 249ms/step - loss: 0.9177 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.7051 - val_sparse_categorical_accuracy: 0.6195\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8389 - sparse_categorical_accuracy: 0.7488\n",
      "Epoch 00005: val_loss improved from 0.63960 to 0.62314, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 463ms/step - loss: 0.8389 - sparse_categorical_accuracy: 0.7488 - val_loss: 0.6231 - val_sparse_categorical_accuracy: 0.7345\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7365 - sparse_categorical_accuracy: 0.7824\n",
      "Epoch 00006: val_loss improved from 0.62314 to 0.58192, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 8s 518ms/step - loss: 0.7365 - sparse_categorical_accuracy: 0.7824 - val_loss: 0.5819 - val_sparse_categorical_accuracy: 0.7168\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6354 - sparse_categorical_accuracy: 0.8368\n",
      "Epoch 00007: val_loss did not improve from 0.58192\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.6354 - sparse_categorical_accuracy: 0.8368 - val_loss: 0.6370 - val_sparse_categorical_accuracy: 0.6903\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5467 - sparse_categorical_accuracy: 0.8586\n",
      "Epoch 00008: val_loss improved from 0.58192 to 0.55823, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 440ms/step - loss: 0.5467 - sparse_categorical_accuracy: 0.8586 - val_loss: 0.5582 - val_sparse_categorical_accuracy: 0.7788\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4304 - sparse_categorical_accuracy: 0.9169\n",
      "Epoch 00009: val_loss improved from 0.55823 to 0.55293, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 8s 505ms/step - loss: 0.4304 - sparse_categorical_accuracy: 0.9169 - val_loss: 0.5529 - val_sparse_categorical_accuracy: 0.7434\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3351 - sparse_categorical_accuracy: 0.9436\n",
      "Epoch 00010: val_loss did not improve from 0.55293\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.3351 - sparse_categorical_accuracy: 0.9436 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.7257\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/training/gestures/scroll\n",
      "https://developer.android.com/training/location/retrieve-current\n",
      "https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 113 [1s] 6\n",
      "predicted\n",
      "[0s] 109 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8824\n",
      "macro_f1: 0.5310\n",
      "Precision: 0.5271\n",
      "Recall: 0.5435\n",
      "F1: 0.5310\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/widget/TextView\n",
      "--------------------\n",
      "Y\n",
      "[0s] 468 [1s] 2\n",
      "predicted\n",
      "[0s] 466 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.9872\n",
      "macro_f1: 0.4968\n",
      "Precision: 0.4979\n",
      "Recall: 0.4957\n",
      "F1: 0.4968\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://javapapers.com/android/android-location-fused-provider\n",
      "--------------------\n",
      "Y\n",
      "[0s] 97 [1s] 2\n",
      "predicted\n",
      "[0s] 89 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8990\n",
      "macro_f1: 0.5565\n",
      "Precision: 0.5444\n",
      "Recall: 0.7036\n",
      "F1: 0.5565\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/6688444\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 5 [1s] 4\n",
      "predicted\n",
      "[0s] 7 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.3333\n",
      "macro_f1: 0.2500\n",
      "Precision: 0.2143\n",
      "Recall: 0.3000\n",
      "F1: 0.2500\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/media/mediarecorder\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 45 [1s] 4\n",
      "predicted\n",
      "[0s] 39 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7551\n",
      "macro_f1: 0.5000\n",
      "Precision: 0.5115\n",
      "Recall: 0.5250\n",
      "F1: 0.5000\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/46481789\n",
      "https://stackoverflow.com/questions/19025301\n",
      "--------------------\n",
      "Y\n",
      "[0s] 5 [1s] 6\n",
      "predicted\n",
      "[0s] 11 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.4545\n",
      "macro_f1: 0.3125\n",
      "Precision: 0.2273\n",
      "Recall: 0.5000\n",
      "F1: 0.3125\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/39588322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 3\n",
      "predicted\n",
      "[0s] 13 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.8750\n",
      "macro_f1: 0.7949\n",
      "Precision: 0.7949\n",
      "Recall: 0.7949\n",
      "F1: 0.7949\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.474\u001b[0m\n",
      "recall:    \u001b[31m0.552\u001b[0m\n",
      "f1-score:  \u001b[31m0.492\u001b[0m\n",
      "next 8\n",
      "\n",
      "\u001b[31mFold 8\u001b[0m\n",
      "SeekTo Position of cutted song not working\n",
      "Android Gallery with pinch zoom\n",
      "Wait for 2 async REST calls to result in success or error\n",
      "how  to set Screenshot frame size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 7917/7917 [00:00<00:00, 668363.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    802\n",
      "1    267\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    377\n",
      "1     11\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 3.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0433 - sparse_categorical_accuracy: 0.6155The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65631, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 10s 605ms/step - loss: 1.0433 - sparse_categorical_accuracy: 0.6155 - val_loss: 0.6563 - val_sparse_categorical_accuracy: 0.6891\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 1.0054 - sparse_categorical_accuracy: 0.6239\n",
      "Epoch 00002: val_loss improved from 0.65631 to 0.63689, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 8s 474ms/step - loss: 1.0054 - sparse_categorical_accuracy: 0.6239 - val_loss: 0.6369 - val_sparse_categorical_accuracy: 0.6471\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.9280 - sparse_categorical_accuracy: 0.6745\n",
      "Epoch 00003: val_loss improved from 0.63689 to 0.63351, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 10s 606ms/step - loss: 0.9280 - sparse_categorical_accuracy: 0.6745 - val_loss: 0.6335 - val_sparse_categorical_accuracy: 0.6050\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.8310 - sparse_categorical_accuracy: 0.7072\n",
      "Epoch 00004: val_loss improved from 0.63351 to 0.55003, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 7s 419ms/step - loss: 0.8310 - sparse_categorical_accuracy: 0.7072 - val_loss: 0.5500 - val_sparse_categorical_accuracy: 0.6807\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.7030 - sparse_categorical_accuracy: 0.7689\n",
      "Epoch 00005: val_loss improved from 0.55003 to 0.52956, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 7s 421ms/step - loss: 0.7030 - sparse_categorical_accuracy: 0.7689 - val_loss: 0.5296 - val_sparse_categorical_accuracy: 0.7311\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.5731 - sparse_categorical_accuracy: 0.8157\n",
      "Epoch 00006: val_loss improved from 0.52956 to 0.50822, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 8s 490ms/step - loss: 0.5731 - sparse_categorical_accuracy: 0.8157 - val_loss: 0.5082 - val_sparse_categorical_accuracy: 0.7563\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4706 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 00007: val_loss improved from 0.50822 to 0.48861, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 8s 465ms/step - loss: 0.4706 - sparse_categorical_accuracy: 0.8625 - val_loss: 0.4886 - val_sparse_categorical_accuracy: 0.7563\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.3487 - sparse_categorical_accuracy: 0.9158\n",
      "Epoch 00008: val_loss improved from 0.48861 to 0.48353, saving model to /home/msarthur/scratch/best_model\n",
      "17/17 [==============================] - 7s 427ms/step - loss: 0.3487 - sparse_categorical_accuracy: 0.9158 - val_loss: 0.4835 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2759 - sparse_categorical_accuracy: 0.9439\n",
      "Epoch 00009: val_loss did not improve from 0.48353\n",
      "17/17 [==============================] - 4s 249ms/step - loss: 0.2759 - sparse_categorical_accuracy: 0.9439 - val_loss: 0.5190 - val_sparse_categorical_accuracy: 0.7815\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2031 - sparse_categorical_accuracy: 0.9635\n",
      "Epoch 00010: val_loss did not improve from 0.48353\n",
      "17/17 [==============================] - 4s 248ms/step - loss: 0.2031 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.5749 - val_sparse_categorical_accuracy: 0.7731\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/2661536\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 99 [1s] 1\n",
      "predicted\n",
      "[0s] 90 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8900\n",
      "macro_f1: 0.4709\n",
      "Precision: 0.4944\n",
      "Recall: 0.4495\n",
      "F1: 0.4709\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://github.com/google/ExoPlayer/issues/8387\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 27 [1s] 5\n",
      "predicted\n",
      "[0s] 24 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.7188\n",
      "macro_f1: 0.5656\n",
      "Precision: 0.5625\n",
      "Recall: 0.5889\n",
      "F1: 0.5656\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/10630373\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 3\n",
      "predicted\n",
      "[0s] 22 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7188\n",
      "macro_f1: 0.5656\n",
      "Precision: 0.5773\n",
      "Recall: 0.6954\n",
      "F1: 0.5656\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2993085\n",
      "https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 2\n",
      "predicted\n",
      "[0s] 47 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.9000\n",
      "macro_f1: 0.4737\n",
      "Precision: 0.4787\n",
      "Recall: 0.4688\n",
      "F1: 0.4737\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/training/gestures/scale\n",
      "https://developer.android.com/guide/background/threading\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.528\u001b[0m\n",
      "recall:    \u001b[31m0.551\u001b[0m\n",
      "f1-score:  \u001b[31m0.519\u001b[0m\n",
      "next 9\n",
      "\n",
      "\u001b[31mFold 9\u001b[0m\n",
      "Android SQLite performance in complex queries\n",
      "Custom Annotations in Retrofit 2.0\n",
      "Android App Retrieve Data from Server but in a Secure way\n",
      "Hilt: How to prevent Hilt from picking dependency from a library?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 7917/7917 [00:00<00:00, 754260.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    763\n",
      "1    255\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    553\n",
      "1     25\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 3.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0201 - sparse_categorical_accuracy: 0.5943The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61028, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 11s 685ms/step - loss: 1.0201 - sparse_categorical_accuracy: 0.5943 - val_loss: 0.6103 - val_sparse_categorical_accuracy: 0.7632\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9537 - sparse_categorical_accuracy: 0.7053\n",
      "Epoch 00002: val_loss improved from 0.61028 to 0.56815, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 452ms/step - loss: 0.9537 - sparse_categorical_accuracy: 0.7053 - val_loss: 0.5682 - val_sparse_categorical_accuracy: 0.7544\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8360 - sparse_categorical_accuracy: 0.7633\n",
      "Epoch 00003: val_loss improved from 0.56815 to 0.53091, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 9s 558ms/step - loss: 0.8360 - sparse_categorical_accuracy: 0.7633 - val_loss: 0.5309 - val_sparse_categorical_accuracy: 0.7456\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7609 - sparse_categorical_accuracy: 0.7623\n",
      "Epoch 00004: val_loss improved from 0.53091 to 0.52042, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 454ms/step - loss: 0.7609 - sparse_categorical_accuracy: 0.7623 - val_loss: 0.5204 - val_sparse_categorical_accuracy: 0.7544\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6550 - sparse_categorical_accuracy: 0.7967\n",
      "Epoch 00005: val_loss improved from 0.52042 to 0.42423, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 7s 462ms/step - loss: 0.6550 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.4242 - val_sparse_categorical_accuracy: 0.8070\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5817 - sparse_categorical_accuracy: 0.8291\n",
      "Epoch 00006: val_loss did not improve from 0.42423\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.5817 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.4294 - val_sparse_categorical_accuracy: 0.8158\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5109 - sparse_categorical_accuracy: 0.8585\n",
      "Epoch 00007: val_loss improved from 0.42423 to 0.41193, saving model to /home/msarthur/scratch/best_model\n",
      "16/16 [==============================] - 8s 522ms/step - loss: 0.5109 - sparse_categorical_accuracy: 0.8585 - val_loss: 0.4119 - val_sparse_categorical_accuracy: 0.8246\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4495 - sparse_categorical_accuracy: 0.8841\n",
      "Epoch 00008: val_loss did not improve from 0.41193\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 0.4495 - sparse_categorical_accuracy: 0.8841 - val_loss: 0.4178 - val_sparse_categorical_accuracy: 0.8246\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3888 - sparse_categorical_accuracy: 0.8988\n",
      "Epoch 00009: val_loss did not improve from 0.41193\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.3888 - sparse_categorical_accuracy: 0.8988 - val_loss: 0.4494 - val_sparse_categorical_accuracy: 0.7895\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3620 - sparse_categorical_accuracy: 0.9057\n",
      "Epoch 00010: val_loss did not improve from 0.41193\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.3620 - sparse_categorical_accuracy: 0.9057 - val_loss: 0.4316 - val_sparse_categorical_accuracy: 0.8070\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://github.com/google/dagger/issues/1991\n",
      "https://developer.android.com/training/dependency-injection/hilt-android\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 141 [1s] 4\n",
      "predicted\n",
      "[0s] 135 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.9034\n",
      "macro_f1: 0.4746\n",
      "Precision: 0.4852\n",
      "Recall: 0.4645\n",
      "F1: 0.4746\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/8184492\n",
      "--------------------\n",
      "Y\n",
      "[0s] 50 [1s] 3\n",
      "predicted\n",
      "[0s] 43 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7925\n",
      "macro_f1: 0.5178\n",
      "Precision: 0.5267\n",
      "Recall: 0.5767\n",
      "F1: 0.5178\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/training/data-storage/sqlite\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 67 [1s] 2\n",
      "predicted\n",
      "[0s] 59 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8261\n",
      "macro_f1: 0.4524\n",
      "Precision: 0.4831\n",
      "Recall: 0.4254\n",
      "F1: 0.4524\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 2\n",
      "predicted\n",
      "[0s] 41 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.7800\n",
      "macro_f1: 0.4382\n",
      "Precision: 0.4756\n",
      "Recall: 0.4062\n",
      "F1: 0.4382\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/47760861\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 2\n",
      "predicted\n",
      "[0s] 21 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7419\n",
      "macro_f1: 0.5867\n",
      "Precision: 0.6000\n",
      "Recall: 0.8621\n",
      "F1: 0.5867\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/4015026\n",
      "--------------------\n",
      "Y\n",
      "[0s] 26 [1s] 9\n",
      "predicted\n",
      "[0s] 25 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7429\n",
      "macro_f1: 0.6749\n",
      "Precision: 0.6700\n",
      "Recall: 0.6816\n",
      "F1: 0.6749\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30648172\n",
      "https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 45 [1s] 3\n",
      "predicted\n",
      "[0s] 38 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7708\n",
      "macro_f1: 0.5107\n",
      "Precision: 0.5237\n",
      "Recall: 0.5667\n",
      "F1: 0.5107\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.538\u001b[0m\n",
      "recall:    \u001b[31m0.569\u001b[0m\n",
      "f1-score:  \u001b[31m0.522\u001b[0m\n",
      "next 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# @title 10-fold cross validation WIP\n",
    "CORPUS = raw_data\n",
    "\n",
    "all_tasks = sorted(list(set([d['question'] for d in raw_data])))\n",
    "rseed = 20210343\n",
    "random.seed(rseed)\n",
    "random.shuffle(all_tasks)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "file_handler = logging.FileHandler('/home/msarthur/scratch/LOG-bert_ds_android.ans')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, random_state=rseed)\n",
    "np_tasks_arr = np.array(all_tasks)\n",
    "\n",
    "\n",
    "idx_split = 0\n",
    "for train_index, test_index in kf.split(np_tasks_arr):\n",
    "\n",
    "    idx_split = str(idx_split)\n",
    "    eval_fold = True\n",
    "    # 10 runs per fold to avoid reporting peek results in a given fold\n",
    "    if idx_split in fold_results and fold_results[idx_split]['run_cnt'] >= NUMBER_OF_RUNS:\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split} FULLY TESTED\" + Style.RESET_ALL)\n",
    "        eval_fold = False\n",
    "\n",
    "\n",
    "    if eval_fold:\n",
    "        model.metrics.reset_aggregators()\n",
    "\n",
    "        test_tasks_lst = np_tasks_arr[test_index].tolist()\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split}\" + Style.RESET_ALL)\n",
    "        logger.info('\\n'.join(test_tasks_lst))\n",
    "\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "        df_train, df_val, df_test, weights = model.get_train_val_test(\n",
    "            CORPUS, test_tasks_lst\n",
    "        )\n",
    "        \n",
    "\n",
    "        logger.info('-' * 10)\n",
    "        logger.info(Fore.RED + 'train'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_train.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'test'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_test.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'weights'+ Style.RESET_ALL)\n",
    "        logger.info(str(weights))\n",
    "        logger.info('-' * 10)\n",
    "        \n",
    "        # <------------------------------------------------------------------------- TRAIN\n",
    "\n",
    "        # Encode X_train\n",
    "        train_encodings = model.encode(df_train)\n",
    "        train_labels = df_train['category_index'].tolist()\n",
    "\n",
    "        # Encode X_valid\n",
    "        val_encodings = model.encode(df_val)\n",
    "        val_labels = df_val['category_index'].tolist()\n",
    "\n",
    "\n",
    "        # https://huggingface.co/transformers/custom_datasets.html\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(train_encodings),\n",
    "            train_labels\n",
    "        ))\n",
    "\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(val_encodings),\n",
    "            val_labels\n",
    "        ))\n",
    "\n",
    "\n",
    "        fine_tunned_keras_model = model.build(\n",
    "            train_dataset, val_dataset, weights, \n",
    "            checkpoint_filepath='/home/msarthur/scratch/best_model', \n",
    "            cache_dir='/home/msarthur/scratch', \n",
    "            local_files_only=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        if model.match_frame_from_task:\n",
    "            __frame_pairs = model.fn_frame_pairs.get_most_common_frame_relationships(df_train)\n",
    "            model.sentence_task_frame_pairs = __frame_pairs\n",
    "\n",
    "        # <------------------------------------------------------------------------- TEST\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Testing model\" + Style.RESET_ALL)\n",
    "        for source in df_test[\"source\"].unique():\n",
    "            df_source = df_test[df_test[\"source\"] == source]   \n",
    "            logger.info(source)\n",
    "            \n",
    "            model.test(source, df_source, fine_tunned_keras_model)\n",
    "                        \n",
    "\n",
    "        # <------------------------------------------------------------------------- METRICS   \n",
    "        \n",
    "        prediction_metrics, api_metrics, so_metrics, git_metrics, misc_metrics = model.get_evaluation_metrics()\n",
    "        \n",
    "        MetricsAggregator.add_idx_fold_results(\n",
    "            idx_split, fold_results, prediction_metrics,\n",
    "            api_metrics, so_metrics, git_metrics, misc_metrics\n",
    "        )\n",
    "\n",
    "        fold_results['venn_diagram_set'] += model.metrics.venn_diagram_set\n",
    "        fold_results['venn_diagram_set'] = list(set(fold_results['venn_diagram_set']))\n",
    "\n",
    "\n",
    "        _precision, _recall, _f1score = MetricsAggregator.avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "        logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "        logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "        logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "    idx_split = int(idx_split)\n",
    "    idx_split += 1\n",
    "    logger.info(f\"next {idx_split}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mOutput successfully saved to: output/bert_ds_android_base.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with open(config_output, 'w') as outfile:\n",
    "    json.dump(fold_results, outfile, sort_keys=True, indent=4)\n",
    "    logger.info(Fore.RED + \"Output successfully saved to: {}\".format(config_output) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[31mAGGREGATED METRICS\u001b[0m\n",
      "\n",
      "precision: \u001b[31m0.530\u001b[0m\n",
      "recall:    \u001b[31m0.564\u001b[0m\n",
      "f1-score:  \u001b[31m0.513\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "__precision, __recall, __fscore = MetricsAggregator.get_full_exec_results(fold_results)\n",
    "\n",
    "logger.info(\"\\n\")\n",
    "logger.info(Fore.RED + \"AGGREGATED METRICS\" + Style.RESET_ALL)\n",
    "logger.info(\"\\nprecision: \" + Fore.RED + \"{:.3f}\".format(np.mean(__precision)) + Style.RESET_ALL)\n",
    "logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(np.mean(__recall)) + Style.RESET_ALL)\n",
    "logger.info(\"f1-score:  \" +  Fore.RED + \"{:.3f}\".format(np.mean(__fscore)) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Overflow results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[31mStack Overflow metrics\u001b[0m\n",
      "\n",
      "precision: \u001b[31m0.562\u001b[0m\n",
      "recall:    \u001b[31m0.616\u001b[0m\n",
      "f1-score:  \u001b[31m0.542\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "__precision, __recall, __fscore = MetricsAggregator.get_full_exec_results(fold_results, result_type=\"so\")\n",
    "\n",
    "logger.info(\"\\n\")\n",
    "logger.info(Fore.RED + \"Stack Overflow metrics\" + Style.RESET_ALL)\n",
    "logger.info(\"\\nprecision: \" + Fore.RED + \"{:.3f}\".format(np.mean(__precision)) + Style.RESET_ALL)\n",
    "logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(np.mean(__recall)) + Style.RESET_ALL)\n",
    "logger.info(\"f1-score:  \" +  Fore.RED + \"{:.3f}\".format(np.mean(__fscore)) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github issues results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[31mGithub issues metrics\u001b[0m\n",
      "\n",
      "precision: \u001b[31m0.536\u001b[0m\n",
      "recall:    \u001b[31m0.572\u001b[0m\n",
      "f1-score:  \u001b[31m0.511\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "__precision, __recall, __fscore = MetricsAggregator.get_full_exec_results(fold_results, result_type=\"git\")\n",
    "\n",
    "logger.info(\"\\n\")\n",
    "logger.info(Fore.RED + \"Github issues metrics\" + Style.RESET_ALL)\n",
    "logger.info(\"\\nprecision: \" + Fore.RED + \"{:.3f}\".format(np.mean(__precision)) + Style.RESET_ALL)\n",
    "logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(np.mean(__recall)) + Style.RESET_ALL)\n",
    "logger.info(\"f1-score:  \" +  Fore.RED + \"{:.3f}\".format(np.mean(__fscore)) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of text retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Fjg9kKaDM0fo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAPI\u001b[0m\n",
      "\n",
      "\u001b[31mAndroid PDF Rendering\u001b[0m\n",
      "https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8847]\u001b[0m If you want to render a PDF, you create a renderer and for every page you want to render, you open the page, render it, and close the page.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8840]\u001b[0m After you are done with rendering, you close the renderer.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8779]\u001b[0m This class represents a PDF document page for rendering.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8770]\u001b[0m If you are using this class to rasterize a PDF for printing or show a print preview, it is recommended that you respect the following contract in order to provide a consistent user experience when seeing a preview and printing, i.e. the user sees a preview that is the same as the printout.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8726]\u001b[0m A typical use of the APIs to render a PDF looks like this:\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8682]\u001b[0m This class enables rendering a PDF document.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8664]\u001b[0m You should take this info account if the document is rendered for printing and the target media size differs from the page size.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8609]\u001b[0m Opens a page for rendering.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8299]\u001b[0m Note that the pages are rendered one by one, i.e. you can have only a single page opened at any given time.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8268]\u001b[0m When scaling a document for printing the aspect ratio should be preserved.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mkeyUp called when key is still pressed\u001b[0m\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7788]\u001b[0m However, the simplest solution is to check whether the exact modifier key you care about is being pressed with methods such as isShiftPressed ( ) and isCtrlPressed ( ).\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7749]\u001b[0m To handle an individual key press, implement onKeyDown ( ) or onKeyUp ( ) as appropriate.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7717]\u001b[0m To respond to modifier key events such as when a key is combined with Shift or Control, you can query the KeyEvent that's passed to the callback method.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7491]\u001b[0m For example, here's the onKeyUp ( ) implementation again, with some extra handling for when the Shift key is held down with one of the keys:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7366]\u001b[0m You should never rely on receiving key events for any key on a soft input method ( an on-screen keyboard ).\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7023]\u001b[0m Note: When handling keyboard events with the KeyEvent class and related APIs, you should expect that such keyboard events come only from a hardware keyboard.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.6710]\u001b[0m If the user presses and holds the button, then onKeyDown ( ) is called multiple times.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6421]\u001b[0m If, however, you'd like to intercept or directly handle the keyboard input yourself, you can do so by implementing callback methods from the KeyEvent.Callback interface, such as onKeyDown ( ) and onKeyMultiple ( ).\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.5998]\u001b[0m Usually, you should use onKeyUp ( ) if you want to be sure that you receive only one event.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5837]\u001b[0m For example, this implementation responds to some keyboard keys to control a game:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mCamera API: Cross device issues\u001b[0m\n",
      "https://developer.android.com/guide/topics/media/camera\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8672]\u001b[0m Once you have built a preview class and a view layout in which to display it, you are ready to start capturing images with your application.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8607]\u001b[0m You obtain this object by first getting an instance of the Camera object, calling the getParameters ( ) method, changing the returned parameter object and then setting it back into the camera object, as demonstrated in the following example code:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8602]\u001b[0m If you use the preview class shown in Creating a preview class, add your startFaceDetection ( ) method to both the surfaceCreated ( ) and surfaceChanged ( ) methods in your preview class, as shown in the sample code below.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8579]\u001b[0m Prior to Android 2.2 ( API Level 8 ), you must set the output format and encoding formats parameters directly, instead of using CamcorderProfile.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8567]\u001b[0m Starting with Android 4.0 ( API Level 14 ), your camera application can provide additional controls to allow your app or users to specify areas in an image to use for determining focus or light level settings and pass these values to the camera hardware for use in capturing images or video.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8531]\u001b[0m A camera preview class is a SurfaceView that can display the live image data coming from a camera, so users can frame and capture a picture or video.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8487]\u001b[0m Starting in Android 2.2 ( API Level 8 ), you can use the setDisplayOrientation ( ) method to set the rotation of the preview image.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8458]\u001b[0m When setting preview size, you must use values from getSupportedPreviewSizes ( ).\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8420]\u001b[0m In your application code, you must set up listeners for your user interface controls to respond to a user action by taking a picture.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8388]\u001b[0m To record a time lapse video with MediaRecorder, you must configure the recorder object as if you are recording a normal video, setting the captured frames per second to a low number and using one of the time lapse quality settings, as shown in the code example below.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for API sources\n",
    "\n",
    "logger.info(Fore.RED + \"API\" + Style.RESET_ALL)\n",
    "model.metrics.examples_per_source_type(source_type='api', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FDBgOWQXNW1i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mGIT\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for GIT sources\n",
    "\n",
    "logger.info(Fore.RED + \"GIT\" + Style.RESET_ALL)\n",
    "model.metrics.examples_per_source_type(source_type='git', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "G4Bqx8AbNoV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSO\u001b[0m\n",
      "\n",
      "\u001b[31mAndroid - Jackson JSON parser returns null value in &#39;release&#39; builds\u001b[0m\n",
      "https://stackoverflow.com/questions/11064244\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8540]\u001b[0m The error message you are getting appears to be due to dubiously-legal JSON, particularly on the receiving side:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8534]\u001b[0m InputStream is, String json, JSONObject jObj are declared externally to your getJSONFromUrl -LRB- -RRB- method and there is a possibility that they are somehow affected differently by some other part of your code when running on one API compared to another.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8534]\u001b[0m And you can get the json object by passing index value like,\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8517]\u001b[0m Instead of that you directly create the json object from string buffer.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8516]\u001b[0m Have you tried the JSONParser ?\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8516]\u001b[0m If it is a JSONObject, change its type to String and your code will work perfectly.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8514]\u001b[0m It is possible that the JSONObject parser has been made more lenient in newer Android releases.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8508]\u001b[0m I think you missed to convert String Buffer -LRB- sb -RRB- into json array object.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8506]\u001b[0m Another remark is the handling of exceptions: It seems that if an exception is thrown in the first block when you building your String, the JSONObject initialization will be attempted with some faulty data.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8501]\u001b[0m I would suggest that you write your downloaded JSON out to a file and compare it with your original to see if there is a problem with the download logic.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mGenerating an error when using Provider for scoped instances\u001b[0m\n",
      "https://stackoverflow.com/questions/29923376\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8364]\u001b[0m So in order to get a scoped provider in a module, you need to specify the scope for your module's provider method.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8329]\u001b[0m First function of scopes is a way to tell Dagger compiler which scopes are allowed within scoped component.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8247]\u001b[0m A component can depend on only one other scoped component.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8058]\u001b[0m It is worth noting that apparently Dagger2 creates a single instance per scoped provider in a module per component.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7003]\u001b[0m Second function is to limit number of instances allowed within scoped component.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.6887]\u001b[0m Unscoped dependency will have simple Provider generated without any caching and any instance of that dependency created in component will be new for every new injection -LRB- as in constructor, or in module provision method, or just as a field -RRB-.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6640]\u001b[0m Reusable scope - declared with @dagger.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6467]\u001b[0m Define your scopes by the semantics of using them.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6385]\u001b[0m It is useful when dependency does not necessarily need to have single instance but may be shared for increased performance -LRB- less allocations -RRB- in single component or between components.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6028]\u001b[0m That's why using @ActivityScope dependency in non-@ActivityScope component will fire a compilation error.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mApplication icon doesn&#39;t show up in Android action bar\u001b[0m\n",
      "https://stackoverflow.com/questions/26838730\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8644]\u001b[0m A Toolbar is a generalization of action bars for use within application layouts.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8548]\u001b[0m Make sure you have the icon set in the manifest.xml file, in the application tag as:\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8135]\u001b[0m If you would like an application icon -LRB- but I discourage it -RRB-, you can use the method setLogo -LRB- -RRB-.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7696]\u001b[0m This is a common `` problem''.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7591]\u001b[0m In modern Android UIs developers should lean more on a visually distinct color scheme for toolbars than on their application icon.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6192]\u001b[0m You are using the AppCompat version 21 + and it is normal.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.6081]\u001b[0m Something like this:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mHow to Integrate reCAPTCHA 2.0 in Android\u001b[0m\n",
      "https://stackoverflow.com/questions/27297067\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8156]\u001b[0m The cool thing about the new Google Recaptcha is that the validation is now completely encapsulated in the widget.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8097]\u001b[0m That means, that the widget will take care of asking questions, validating responses all the way till it determines that a user is actually a human, only then you get a g-recaptcha-response value.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8086]\u001b[0m And replace the response_string with the value that you earlier got by the g-recaptcha-response field.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8081]\u001b[0m Hi curious you can validate your google recaptcha at client side also 100 % work for me to verify your google recaptcha just see below code This code at the html body:\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8063]\u001b[0m Anyone with HTTP POST knowledge could put random data inside of the g-recaptcha-response form field, and foll your site to make it think that this field was provided by the google widget.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7938]\u001b[0m A method I use in my login servlet to verify reCaptcha responses.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6115]\u001b[0m Here is complete demo code to understand client side and server side process.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mPermission Denial when trying to access contacts in Android\u001b[0m\n",
      "https://stackoverflow.com/questions/5233543\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7983]\u001b[0m The user can grant or deny each permission, and the app can continue to run with limited capabilities even if the user denies a permission request.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7934]\u001b[0m Hello Steven the debug log trace tells you that you need ... requires android.permission.READ _ CONTACTS\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7827]\u001b[0m If the device is running Android 6.0 or higher, and your app's target SDK is 23 or higher: The app has to list the permissions in the manifest, and it must request each dangerous permission it needs while the app is running.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7808]\u001b[0m Beginning in Android 6.0 -LRB- API level 23 -RRB-, users grant permissions to apps while the app is running, not when they install the app.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7710]\u001b[0m with the api 23, permission <uses-permission android:name=\"android.pemission.READ_CONTACTS\"/> dont work, change the api level in the emulator for api 22 -LRB- lollipop -RRB- or lower\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7688]\u001b[0m The first step when adding a `` Runtime Permission'' is to add it to the AndroidManifest:\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7652]\u001b[0m While developing for a target platform of 2.3.3 using Eclipse on Ubuntu, I had permission failures in the log file that indicated I needed this exact line while working on something similar.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7641]\u001b[0m If the permission you need to add isn't listed under the normal permissions, you'll need to deal with `` Runtime Permissions''.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7599]\u001b[0m It wasn't until I moved the * uses-permission ... READ_CONTACTS * line to outside the application tag that things worked.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7584]\u001b[0m These permissions will show a dialog to the user, similar to the following one:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mAndroid SQLite performance in complex queries\u001b[0m\n",
      "https://stackoverflow.com/questions/4015026\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8688]\u001b[0m Use EXPLAIN QUERY PLAN on your queries to see which index would be used or if the query requires a full table scan.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8616]\u001b[0m Here's a bit of code to get EXPLAIN QUERY PLAN results into Android logcat from a running Android app.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8609]\u001b[0m If you have more complex queries that can't make use of any indexes that you might create, you can de-normalize your schema, structuring your data in such a way that the queries are simpler and can be answered using indexes.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8600]\u001b[0m I dropped this into my ContentProvider.query -LRB- -RRB- and now I can see exactly how all the queries are getting performed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8576]\u001b[0m Using both WHERE predicates and ORDER BY both require an index and SQLite can only use one, so that can be a point where performance suffers.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8567]\u001b[0m Pin down exactly which queries you need to optimize.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8510]\u001b[0m Grab a copy of a typical database and use the REPL to time queries.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8477]\u001b[0m For SELECTs and UPDATEs, indexes can things up, but only if the indexes you create can actually be used by the queries that you need speeding up.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8458]\u001b[0m There is a LINK for optimizing SQLite in general in the SQLite documentation.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8452]\u001b[0m SQLite LINK using savepoints, but I'm not sure that you'll gain anything there performance-wise.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for SO sources\n",
    "\n",
    "logger.info(Fore.RED + \"SO\" + Style.RESET_ALL)\n",
    "model.metrics.examples_per_source_type(source_type='so', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2_mgLqe0N-hs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mMISC\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for MISC sources\n",
    "\n",
    "logger.info(Fore.RED + \"MISC\" + Style.RESET_ALL)\n",
    "model.metrics.examples_per_source_type(source_type='misc', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m135 entries VENN SET\u001b[0m\n",
      "That means, that the widget will take care of asking questions, validating responses all the way till it determines that a user is actually a human, only then you get a g-recaptcha-response value.\n",
      "Make a Snackbar to display a message\n",
      "During deserialization, you would want Jackson to deserialize the `` Vehicle'' JSON object to the appropriate `` Car'' or `` Plane'' class.\n",
      "Javac annotation processor uses rounds instead of defining processors order.\n",
      "with some custome code which simply draws a drawable icon.\n",
      "Do not inset the content with any margins from the PrintAttributes as the application is responsible to render it such that the margins are respected.\n",
      "In Android development, any time we want to show a vertical list of scrollable items we will use a ListView which has data populated using an Adapter.\n",
      "As getView is call many times inflating a new view every time is expensive so list view provides you one of the previously created view to re-use.\n",
      "Then inside of the interceptor, you can verify if the request is annotated or no.\n",
      "This document shows you how to use MediaRecorder to write an application that captures audio from a device microphone, save the audio, and play it back ( with MediaPlayer ).\n",
      "I created a ViewPager that supports infinite looping effect, smart auto-scroll, compatible with any indicators and easy to use.\n",
      "The error message you are getting appears to be due to dubiously-legal JSON, particularly on the receiving side:\n",
      "Although what you are doing is really not appropriate.\n",
      "To fix this issue, open MainActivity.kt and add the following line inside onCreate ( ) below the line where you connect the PageAdapter to the ViewPager:\n",
      "Below we place the toolbar at the top of a LinearLayout like the standard ActionBar:\n",
      "If your app needs to use resources or information outside of its own sandbox, you can declare a permission and set up a permission request that provides this access.\n",
      "But the easiest option is to generate java code directly and your generated java classes will be picked up by javac automatically, launching second round of annotation processing, where dagger will process them.\n",
      "reCAPTCHA is a free service that uses an advanced risk analysis engine to protect your app from spam and other abusive actions.\n",
      "You need to have implement a LINK and declare it in the AndroidManifest.xml.\n",
      "Java 8 -LRB- LINK -RRB- solves this problem using streams and lambdas in one line of code:\n",
      "We use a ScaleGestureDetector on the activity to listen to touch events.\n",
      "Try adding this piece of code before loading your viewPager\n",
      "After that override getView -LRB- -RRB- method and make sure to return your custom View there.\n",
      "When setting preview size, you must use values from getSupportedPreviewSizes ( ).\n",
      "Here's a bit of code to get EXPLAIN QUERY PLAN results into Android logcat from a running Android app.\n",
      "One thing that I ran across when I applied this approach to my production code is that you still need to keep the @JsonSubtypes annotation as part of the Base class.\n",
      "This line means: add a meta-property on serialization or read a meta-property on deserialization -LRB- include = JsonTypeInfo.As.PROPERTY -RRB- called'' @class'' -LRB- property ='' @class'' -RRB- that holds the fully-qualified Java class name -LRB- use = JsonTypeInfo.Id.CLASS -RRB-.\n",
      "Since the version of Retrofit 2.6.0, you can get the annotations in OkHttp Interceptor using the tag field like this:\n",
      "Try to check below FragmentPagerAdapter to get endless viewpager adapter:\n",
      "Listening for Location Updates After you invoke `` getLastLocation'', you might want to request periodic updates from the Fused Location Provider.\n",
      "I am using mic to record calls for better support and compatibility.\n",
      "GoogleApiClient FusedLocationProviderApi requires the GoogleApiClient instance to get the Location and it can be obtained as below.\n",
      "and in the LinearLayout, the default gravity -LRB- used here -RRB- is ` center'\n",
      "Basically you need to load a bitmap and pass to each event you want to draw.\n",
      "Those recording sources may only be used by system apps.\n",
      "When scaling a document for printing the aspect ratio should be preserved.\n",
      "While developing for a target platform of 2.3.3 using Eclipse on Ubuntu, I had permission failures in the log file that indicated I needed this exact line while working on something similar.\n",
      "A typical use of the APIs to render a PDF looks like this:\n",
      "First of all your Animal class with the Json Annotations for the subclasses.\n",
      "This class enables rendering a PDF document.\n",
      "Beginning in Android 6.0 -LRB- API level 23 -RRB-, users grant permissions to apps while the app is running, not when they install the app.\n",
      "inject.Scope annotation - Dependencies declared with that scope with have caching Provider with double-check lock generated and only single instance will be created for it within component declared with the same scope and its creation will be thread safe.\n",
      "The cool thing about the new Google Recaptcha is that the validation is now completely encapsulated in the widget.\n",
      "And replace the response_string with the value that you earlier got by the g-recaptcha-response field.\n",
      "Then in our `` onStart'' method we call the `` connect'' method and wait for `` onConnected'' callback method be invoked:\n",
      "Displaying ActionBar Icon In the new Android 5.0 material design guidelines, the style guidelines have changed to discourage the use of the icon in the ActionBar.\n",
      "I am using mic to record phone audio and also use the Telephony manager to find the calling state.\n",
      "The use of application icon plus title as a standard layout is discouraged on API 21 devices and newer.\n",
      "Starting in Android 2.2 ( API Level 8 ), you can use the setDisplayOrientation ( ) method to set the rotation of the preview image.\n",
      "This becomes a problem specifically when seeking, because dataSpec.position will not be 0 in this case, yet your implementation will nevertheless read from the start of the media.\n",
      "It is possible that the JSONObject parser has been made more lenient in newer Android releases.\n",
      "You don't need to use so many lists, just create a class that will contain all the data of single item, there is no need for buttons, use just text change listener instead.\n",
      "dataSpec.position is the position within the media that the caller wants to start reading from.\n",
      "Dangerous permission groups, however, can give apps access to things like your calling history, private messages, location, camera, microphone, and more.\n",
      "Returns the value mapped by name if it exists and is a JSONObject, or throws otherwise.\n",
      "Every android app has its own internal storage only that app can access, you can read from there or write to it.\n",
      "So in order to get a scoped provider in a module, you need to specify the scope for your module's provider method.\n",
      "Make a Snackbar to display a message.\n",
      "I'm still convinced that there are some security settings in the OS that deny the access to the contacts.\n",
      "The simplest, and best long-term solution, is to use BuildConfig.DEBUG.\n",
      "When GCM delivers a message to your device, BroadcastReceiver will receive the message and call the onReceive -LRB- -RRB- function, wherein you may start a service to actually perform the intended task for you.\n",
      "This is designed to prevent apps from eavesdropping on telephone conversations.\n",
      "I haven't tried recording phone call's but there is a option in LINK for:\n",
      "To handle an individual key press, implement onKeyDown ( ) or onKeyUp ( ) as appropriate.\n",
      "Something like this:\n",
      "For example, if you added three callbacks named one, two and three in order, they would be invoked in the order of three, two, and one, respectively.\n",
      "Anyone with HTTP POST knowledge could put random data inside of the g-recaptcha-response form field, and foll your site to make it think that this field was provided by the google widget.\n",
      "Now Android allows you to decide which permissions to accept on a case-by-case basis -- after the app is installed.\n",
      "Make sure you have the icon set in the manifest.xml file, in the application tag as:\n",
      "Use android: fillViewport = `` true'' in ScrollView\n",
      "It wasn't until I moved the * uses-permission ... READ_CONTACTS * line to outside the application tag that things worked.\n",
      "PdfRenderer -- This class enables rendering a PDF document.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you should try this:\n",
      "Usually, you should use onKeyUp ( ) if you want to be sure that you receive only one event.\n",
      "These are permissions that are requested while the app is running ( instead of before the app is installed ).\n",
      "Use android: fitsSystemWindows = `` true'' in the root view of your layout -LRB- LinearLayout in your case -RRB-.\n",
      "A Toolbar is a generalization of action bars for use within application layouts.\n",
      "I would suggest that you write your downloaded JSON out to a file and compare it with your original to see if there is a problem with the download logic.\n",
      "Use EXPLAIN QUERY PLAN on your queries to see which index would be used or if the query requires a full table scan.\n",
      "If the permission you need to add isn't listed under the normal permissions, you'll need to deal with `` Runtime Permissions''.\n",
      "Therefore, Android will always ask you to approve dangerous permissions.\n",
      "Using a Custom ArrayAdapter When we want to display a series of items from a list using a custom representation of the items, we need to use our own custom XML layout for each item.\n",
      "In the meantime I think that you will need to annotate your child classes with @JsonTypeInfo and @JsonSubTypes to override the inherited annotations.\n",
      "Consider the following below: If you have a JSON object for `` Vehicle'', it could be a `` Car'' or `` Plane'', each with its own fields, some unique to the other.\n",
      "Normally, the Android OS prohibits apps from accessing each other's files -LRB- i.e. databases, preference files, regular files stored in the app's private directory -RRB- through proven Linux file permissions.\n",
      "ComponentActivity, the base class for FragmentActivity and AppCompatActivity, allows you to control the behavior of the Back button by using its OnBackPressedDispatcher, which you can retrieve by calling getOnBackPressedDispatcher ( ).\n",
      "If the user presses and holds the button, then onKeyDown ( ) is called multiple times.\n",
      "So really you want to replace:\n",
      "Pin down exactly which queries you need to optimize.\n",
      "You can also do it by rotating the canvas before drawing:\n",
      "You set this text view a width of `` wrap_content'' it means, what ever the text is, the view take the size of the text.\n",
      "First, we will create an InputStreamReader that reads our request input.\n",
      "The TextView being in wrap_content this does nothing, as the TextView is exactly the size of the text.\n",
      "layout_gravity is the way the TextView will align itself in its parent, in your case in the vertical LinearLayout\n",
      "If you want to render a PDF, you create a renderer and for every page you want to render, you open the page, render it, and close the page.\n",
      "Due to the specifics of Android threading, we can not run network tasks on the same thread as the UI thread.\n",
      "Get a View that displays the data at the specified position in the data set.\n",
      "But these action buttons should not duplicate the action performed when the user taps the notification.\n",
      "If you have more complex queries that can't make use of any indexes that you might create, you can de-normalize your schema, structuring your data in such a way that the queries are simpler and can be answered using indexes.\n",
      "For SELECTs and UPDATEs, indexes can things up, but only if the indexes you create can actually be used by the queries that you need speeding up.\n",
      "How to make a dependency injectable To make an object embeddable in Hilt, you need to tell Hilt how to instantiate that object.\n",
      "This is a boolean value that will be true for a debug build, false otherwise:\n",
      "The first step when adding a `` Runtime Permission'' is to add it to the AndroidManifest:\n",
      "To overcome this, I have created a custom ViewPager -LRB- based on LINK -RRB- that calculates it's height in the required manner.\n",
      "The following example code demonstrates how to create a basic camera preview class that can be included in a View layout.\n",
      "To be able to record, your app must tell the user that it will access the device's audio input.\n",
      "Get the data item associated with the specified position in the data set.\n",
      "If you are using this class to rasterize a PDF for printing or show a print preview, it is recommended that you respect the following contract in order to provide a consistent user experience when seeing a preview and printing, i.e. the user sees a preview that is the same as the printout.\n",
      "Unscoped dependency will have simple Provider generated without any caching and any instance of that dependency created in component will be new for every new injection -LRB- as in constructor, or in module provision method, or just as a field -RRB-.\n",
      "To register a key pair for use with the SafetyNet reCAPTCHA API, navigate to the reCAPTCHA Android signup site, then complete the following sequence of steps:\n",
      "Here is a LINK on how to record audio using the LINK.\n",
      "that is done because rotation is around the top left point ( the origin ) of the view.\n",
      "You can either rotate your bitmap when you draw it by using a matrix:\n",
      "This bug incorrectly sets the drawable bounds to 0 -LRB- or negative in the case of an inset drawable -RRB-.\n",
      "basically I used a private string property taken as a string to construct a computed property with that enum correspondance.\n",
      "gravity is the way the text will align itself in the TextView.\n",
      "Use ANALYZE to allow SQLite's query planner to work more efficiently.\n",
      "If you would like an application icon -LRB- but I discourage it -RRB-, you can use the method setLogo -LRB- -RRB-.\n",
      "You can provide multiple callbacks via addCallback ( ).\n",
      "Note that in the zip function, the parameters have concrete types that correspond to the types of the observables being zipped.\n",
      "with the api 23, permission <uses-permission android:name=\"android.pemission.READ_CONTACTS\"/> dont work, change the api level in the emulator for api 22 -LRB- lollipop -RRB- or lower\n",
      "Finally, getView ( ) creates a view to be used as a row in the list.\n",
      "Before using the reCAPTCHA API, you need to add the SafetyNet API to your project.\n",
      "When doing so, the callbacks are invoked in the reverse order in which they are added - the callback added last is the first given a chance to handle the Back button event.\n",
      "A camera preview class is a SurfaceView that can display the live image data coming from a camera, so users can frame and capture a picture or video.\n",
      "it is used for the Android Music Remote control even if the App is in Lock mode.\n",
      "When a scale -LRB- ie, pinch -RRB- gesture is detected, then the scale factor is used to resize the ImageView.\n",
      "You use them following the same basic pattern you use for other types of requests.\n",
      "A notification can offer up to three action buttons that allow the user to respond quickly, such as snooze a reminder or even reply to a text message.\n",
      "get a seekable file descriptor from your pdf document:\n",
      "You can develop these things yourself, but if you would like to use a pre-made custom view, copy LINK into your project and use it like a normal ImageView.\n",
      "If you are using Android Studio, or if you are using Gradle from the command line, you can add your own stuff to BuildConfig or otherwise tweak the debug and release build types to help distinguish these situations at runtime.\n",
      "Returns the value mapped by name if it exists and is a JSONObject, or null otherwise.\n",
      "Values may be any mix of JSONObjects, JSONArrays, Strings, Booleans, Integers, Longs, Doubles or NULL.\n",
      "It is worth noting that apparently Dagger2 creates a single instance per scoped provider in a module per component.\n"
     ]
    }
   ],
   "source": [
    "logger.info(Fore.RED + f\"{len(fold_results['venn_diagram_set'])} entries VENN SET\" + Style.RESET_ALL)\n",
    "for _t in fold_results['venn_diagram_set']:\n",
    "    logger.info(_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM51gMzrDUJf4OiiaquqBe4",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hugging-face-keras-bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7 Arthur hugging",
   "language": "python",
   "name": "msarthur-hface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03ddd131c9f0446eb83bb6dabee9a832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3518f71b0e4540be8b17a3fe72182cb4",
       "IPY_MODEL_a5ccb838d3704546937e925e456830be",
       "IPY_MODEL_8181fd24b3624c1b9c6a9d0302f43a56"
      ],
      "layout": "IPY_MODEL_f02cf8090f8d463eb7eeb59743a87276"
     }
    },
    "0466163ff4a945798423387d1ac900c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0efe94b613f44c029f2e9bd05696ad32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3e13535de4b44bb9139c3911684cee8",
      "placeholder": "​",
      "style": "IPY_MODEL_6ccdfb754c12418c9438ac218a172e63",
      "value": "Downloading: 100%"
     }
    },
    "153c3ed5c6314a49a5a37ad976417142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_262cc50dd08f49f78b781c2ce96a4ad7",
      "placeholder": "​",
      "style": "IPY_MODEL_f305b344487a4b598a7d41b007e49abd",
      "value": " 232k/232k [00:00&lt;00:00, 286kB/s]"
     }
    },
    "16b6cfa829ad43778c079452df231a3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17cfaa41c53842618c728987a81a44da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fc2d9969ea34bb3bb6e9f0260c2a75c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23531989ef014d7db16b220bb807c8fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "262cc50dd08f49f78b781c2ce96a4ad7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3518f71b0e4540be8b17a3fe72182cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9ef3ce0ace649c5a53e2244ba0dbb32",
      "placeholder": "​",
      "style": "IPY_MODEL_702a74b6e6e44d6b8ad68347f1a4b5fb",
      "value": "Downloading: 100%"
     }
    },
    "35a9eeb0acdb44738a6ad7fbf6d99b2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3950e2a7832c4dce8fd8209d6322a1f7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d32667132d604faeb419bbf9851c1bd8",
      "value": 231508
     }
    },
    "394b7988d36849b7b2c82872ae8d489d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3950e2a7832c4dce8fd8209d6322a1f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ccd384305c44ee3a86f47a2b994fbf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d84c022c44141268ef2c8d5e0190404": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40c212c9b352401697860624a6c54b1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4bd0f4c575714ad7848e818a576ee00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a38bc7017d545e2b44ad6ab0b2d937b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_929799bd24fb411bb4686988f2ae8996",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bd0f4c575714ad7848e818a576ee00a",
      "value": 570
     }
    },
    "5c6bfb038756422bb00be1349db7750b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c586016d3b594c6299cab2384f4c10aa",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d03c894896ad4ed6b48f19a70fbdf2af",
      "value": 466062
     }
    },
    "67f208ba489343dfa195c1dd915f3efe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16b6cfa829ad43778c079452df231a3d",
      "placeholder": "​",
      "style": "IPY_MODEL_a2a36eb594654c65acd584d9d4ebea20",
      "value": "Downloading: 100%"
     }
    },
    "6ccdfb754c12418c9438ac218a172e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cf29b5d508a4e2082751ccc7fa2f625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ccd384305c44ee3a86f47a2b994fbf9",
      "placeholder": "​",
      "style": "IPY_MODEL_23531989ef014d7db16b220bb807c8fd",
      "value": " 466k/466k [00:00&lt;00:00, 637kB/s]"
     }
    },
    "702a74b6e6e44d6b8ad68347f1a4b5fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71a15c5a038f451f8ee64ce046488f71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8181fd24b3624c1b9c6a9d0302f43a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "placeholder": "​",
      "style": "IPY_MODEL_911177bb86c749a0bd774cd3b7f9d302",
      "value": " 536M/536M [00:12&lt;00:00, 40.9MB/s]"
     }
    },
    "82b7fc20b50c44b2bd84b3bf882cdd43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c2b37becdef45bba205dfb20f8e37b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4276b6a5eac4023955218db6f78c84a",
      "placeholder": "​",
      "style": "IPY_MODEL_c4b0a1b67d304afda6ee4e52095584cc",
      "value": " 28.0/28.0 [00:00&lt;00:00, 631B/s]"
     }
    },
    "8c7cf993674145ffb7bb876e5591f6ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67f208ba489343dfa195c1dd915f3efe",
       "IPY_MODEL_35a9eeb0acdb44738a6ad7fbf6d99b2b",
       "IPY_MODEL_153c3ed5c6314a49a5a37ad976417142"
      ],
      "layout": "IPY_MODEL_82b7fc20b50c44b2bd84b3bf882cdd43"
     }
    },
    "901557318fb947dfa082f0cbf2d7365b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0efe94b613f44c029f2e9bd05696ad32",
       "IPY_MODEL_5a38bc7017d545e2b44ad6ab0b2d937b",
       "IPY_MODEL_b3db733aacf94a3c94519d70a7a56d7a"
      ],
      "layout": "IPY_MODEL_394b7988d36849b7b2c82872ae8d489d"
     }
    },
    "911177bb86c749a0bd774cd3b7f9d302": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "929799bd24fb411bb4686988f2ae8996": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "997b8c940317448c9409a2dee15fc519": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e99fb1211ba43459ee78dd64ab8c30e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2a36eb594654c65acd584d9d4ebea20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5ccb838d3704546937e925e456830be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d84c022c44141268ef2c8d5e0190404",
      "max": 536063208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40c212c9b352401697860624a6c54b1c",
      "value": 536063208
     }
    },
    "a66943be0fc0423880cb2bd63a1ea2d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6d9e21208294428a3f5572bbbd8b0b9",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d15e557fc621427a8295eecdc1e781a8",
      "value": 28
     }
    },
    "a8fd8b38a6b84be7b83b2f4df590fada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e99fb1211ba43459ee78dd64ab8c30e",
      "placeholder": "​",
      "style": "IPY_MODEL_71a15c5a038f451f8ee64ce046488f71",
      "value": "Downloading: 100%"
     }
    },
    "b12b35cc52454a249c97f695409d24ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3db733aacf94a3c94519d70a7a56d7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0466163ff4a945798423387d1ac900c8",
      "placeholder": "​",
      "style": "IPY_MODEL_17cfaa41c53842618c728987a81a44da",
      "value": " 570/570 [00:00&lt;00:00, 17.0kB/s]"
     }
    },
    "b4276b6a5eac4023955218db6f78c84a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d9e21208294428a3f5572bbbd8b0b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baffabe6cabf48f5b0b6523ea92aee78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18a3a9fc6d54b9f848e4454e1e36c21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8fd8b38a6b84be7b83b2f4df590fada",
       "IPY_MODEL_5c6bfb038756422bb00be1349db7750b",
       "IPY_MODEL_6cf29b5d508a4e2082751ccc7fa2f625"
      ],
      "layout": "IPY_MODEL_c4c410ab0c994a229a49b8baee221de4"
     }
    },
    "c4b0a1b67d304afda6ee4e52095584cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4c410ab0c994a229a49b8baee221de4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c586016d3b594c6299cab2384f4c10aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5b9bf1f3ae343ce97982c7802cfdc94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_997b8c940317448c9409a2dee15fc519",
      "placeholder": "​",
      "style": "IPY_MODEL_b12b35cc52454a249c97f695409d24ce",
      "value": "Downloading: 100%"
     }
    },
    "c9ef3ce0ace649c5a53e2244ba0dbb32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d03c894896ad4ed6b48f19a70fbdf2af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d15e557fc621427a8295eecdc1e781a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d32667132d604faeb419bbf9851c1bd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3e13535de4b44bb9139c3911684cee8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0e88103f9684ffdb957357222bbaaf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5b9bf1f3ae343ce97982c7802cfdc94",
       "IPY_MODEL_a66943be0fc0423880cb2bd63a1ea2d2",
       "IPY_MODEL_8c2b37becdef45bba205dfb20f8e37b2"
      ],
      "layout": "IPY_MODEL_baffabe6cabf48f5b0b6523ea92aee78"
     }
    },
    "f02cf8090f8d463eb7eeb59743a87276": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f305b344487a4b598a7d41b007e49abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
