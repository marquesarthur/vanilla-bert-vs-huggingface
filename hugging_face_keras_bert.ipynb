{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hugging-face-keras-bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMonrEzg7YyVpjuFrl7fClw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marquesarthur/vanilla-bert-vs-huggingface/blob/main/hugging_face_keras_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfNydjdoLcvK"
      },
      "source": [
        "Based on \n",
        "\n",
        "\n",
        "\n",
        "1.   https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379\n",
        "2.   https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/\n",
        "3.   https://huggingface.co/transformers/training.html#fine-tuning-with-keras\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**problem statement:**\n",
        "\n",
        "\n",
        "*   a developer has to inspect an **artifact X**\n",
        "*   Within the artifact, only a portion of the text is relevant to **input task Y**\n",
        "*   We ought to build a model that establishes relationships between **Y** and **sentences x ∈ X** \n",
        "*  The model must determine: **is x relevant to task Y**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "___\n",
        "\n",
        "*Example of a task and an annotated artifact:*\n",
        "\n",
        "<br>\n",
        "\n",
        "[<img src=\"https://i.imgur.com/Zj1317H.jpg\">](https://i.imgur.com/Zj1317H.jpg)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* The coloured sentences are sentences annotated as relevant to the input task. \n",
        "* The warmer the color, the more annotators selected that portion of the text. \n",
        "* For simplicity, we process the data and used sentences \n",
        "\n",
        "<br>\n",
        "\n",
        "___\n",
        "\n",
        "*Ultimately, our data is a tuple representing:*\n",
        "\n",
        "\n",
        "*   **text** = artifact sentence\n",
        "\n",
        "*   **question** = task description\n",
        "\n",
        "*   **source** = URL of the artifact\n",
        "\n",
        "*   **category_index** = whether sentence is relevant [or not] for the input task\n",
        "\n",
        "*   **weights** = number of participants who annotated sentence as relevant\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "___\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtFJT5AK6RRc",
        "outputId": "e83fe8c3-9778-42e5-ac8a-71456894a446"
      },
      "source": [
        "# @title Install dependencies\n",
        "\n",
        "!pip install transformers\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y80jdm9S6wQA"
      },
      "source": [
        "!pip install -q scikit-learn tqdm pandas python-Levenshtein path colorama"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q38yIvW87NrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab80431d-8c49-4d15-9eb6-d8557dfced57"
      },
      "source": [
        "# @title Download git repo\n",
        "!git clone https://github.com/marquesarthur/vanilla-bert-vs-huggingface.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'vanilla-bert-vs-huggingface' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyrLR-tf8P4Q",
        "outputId": "be2989e3-ad95-41dc-9a47-0458d91eaf7d"
      },
      "source": [
        "%cd vanilla-bert-vs-huggingface\n",
        "!git pull\n",
        "!ls -l"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vanilla-bert-vs-huggingface\n",
            "Already up to date.\n",
            "total 5384\n",
            "-rw-r--r-- 1 root root    7988 Sep  6 18:42 ds_android.py\n",
            "drwxr-xr-x 7 root root    4096 Sep  6 18:42 expert_answers\n",
            "drwxr-xr-x 5 root root    4096 Sep  6 18:42 expert_tasks\n",
            "drwxr-xr-x 2 root root    4096 Sep  6 18:42 hugging\n",
            "drwxr-xr-x 2 root root    4096 Sep  6 18:42 __pycache__\n",
            "-rw-r--r-- 1 root root     356 Sep  6 18:42 README.md\n",
            "-rw-r--r-- 1 root root 5331079 Sep  6 18:42 relevance_corpus.json\n",
            "drwxr-xr-x 2 root root    4096 Sep  6 18:42 vanilla\n",
            "-rw-r--r-- 1 root root  145432 Sep  6 18:42 vanilla_keras_bert.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kudd2ZR8tKZ",
        "outputId": "89965646-d765-4546-b8dc-7aad447c40e6"
      },
      "source": [
        "# @title Import data as JSON\n",
        "import itertools\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "from Levenshtein import ratio\n",
        "from colorama import Fore, Style\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.level = logging.DEBUG\n",
        "stream_handler = logging.StreamHandler(sys.stdout)\n",
        "logger.addHandler(stream_handler)\n",
        "\n",
        "from ds_android import get_input_for_BERT\n",
        "\n",
        "raw_data = get_input_for_BERT()\n",
        "\n",
        "print('Sample entry from data:')\n",
        "print(json.dumps(raw_data[0], indent=4, sort_keys=True))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m4 \u001b[33m12 \u001b[0m https://stackoverflow.com/questions/33241952\n",
            "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/8712652\n",
            "\u001b[31m8 \u001b[33m59 \u001b[0m https://dzone.com/articles/android-rotate-and-scale\n",
            "\u001b[31m9 \u001b[33m15 \u001b[0m https://developer.android.com/training/volley/request\n",
            "\u001b[31m14 \u001b[33m65 \u001b[0m https://stackoverflow.com/questions/28504524\n",
            "\u001b[31m20 \u001b[33m59 \u001b[0m https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
            "\u001b[31m5 \u001b[33m97 \u001b[0m https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
            "\u001b[31m5 \u001b[33m47 \u001b[0m https://developer.android.com/reference/android/widget/ArrayAdapter\n",
            "\u001b[31m9 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/6442054\n",
            "\u001b[31m3 \u001b[33m22 \u001b[0m https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
            "\u001b[31m22 \u001b[33m211 \u001b[0m https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
            "\u001b[31m21 \u001b[33m59 \u001b[0m https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
            "\u001b[31m5 \u001b[33m470 \u001b[0m https://developer.android.com/reference/android/widget/TextView\n",
            "\u001b[31m7 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/19025301\n",
            "\u001b[31m8 \u001b[33m95 \u001b[0m https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
            "\u001b[31m39 \u001b[33m129 \u001b[0m https://developer.android.com/training/permissions/requesting\n",
            "\u001b[31m14 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/5233543\n",
            "\u001b[31m4 \u001b[33m34 \u001b[0m https://github.com/morenoh149/react-native-contacts/issues/516\n",
            "\u001b[31m27 \u001b[33m63 \u001b[0m https://guides.codepath.com/android/Understanding-App-Permissions\n",
            "\u001b[31m9 \u001b[33m161 \u001b[0m https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
            "\u001b[31m17 \u001b[33m33 \u001b[0m https://developer.android.com/guide/navigation/navigation-custom-back\n",
            "\u001b[31m6 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/10108774\n",
            "\u001b[31m20 \u001b[33m145 \u001b[0m https://developer.android.com/training/dependency-injection/hilt-android\n",
            "\u001b[31m4 \u001b[33m8 \u001b[0m https://stackoverflow.com/questions/30648172\n",
            "\u001b[31m4 \u001b[33m81 \u001b[0m https://github.com/google/dagger/issues/1991\n",
            "\u001b[31m9 \u001b[33m48 \u001b[0m https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
            "\u001b[31m6 \u001b[33m33 \u001b[0m https://github.com/realm/realm-java/issues/776\n",
            "\u001b[31m4 \u001b[33m38 \u001b[0m https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
            "\u001b[31m4 \u001b[33m131 \u001b[0m https://stackoverflow.com/questions/122105\n",
            "\u001b[31m3 \u001b[33m48 \u001b[0m https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
            "\u001b[31m8 \u001b[33m49 \u001b[0m https://developer.android.com/guide/topics/media/mediarecorder\n",
            "\u001b[31m4 \u001b[33m9 \u001b[0m https://stackoverflow.com/questions/6688444\n",
            "\u001b[31m3 \u001b[33m23 \u001b[0m https://github.com/google/oboe/issues/447\n",
            "\u001b[31m19 \u001b[33m250 \u001b[0m https://developer.android.com/guide/topics/media/camera\n",
            "\u001b[31m3 \u001b[33m36 \u001b[0m https://github.com/SundeepK/CompactCalendarView/issues/181\n",
            "\u001b[31m5 \u001b[33m373 \u001b[0m https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
            "\u001b[31m12 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/35357919\n",
            "\u001b[31m11 \u001b[33m117 \u001b[0m https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
            "\u001b[31m3 \u001b[33m56 \u001b[0m https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
            "\u001b[31m3 \u001b[33m5 \u001b[0m https://stackoverflow.com/questions/38980595\n",
            "\u001b[31m9 \u001b[33m32 \u001b[0m https://github.com/google/ExoPlayer/issues/8387\n",
            "\u001b[31m4 \u001b[33m27 \u001b[0m https://stackoverflow.com/questions/24952513\n",
            "\u001b[31m18 \u001b[33m219 \u001b[0m https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
            "\u001b[31m3 \u001b[33m72 \u001b[0m https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
            "\u001b[31m7 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/8184492\n",
            "\u001b[31m7 \u001b[33m58 \u001b[0m https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
            "\u001b[31m3 \u001b[33m50 \u001b[0m https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
            "\u001b[31m9 \u001b[33m65 \u001b[0m https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
            "\u001b[31m5 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/24652078\n",
            "\u001b[31m5 \u001b[33m28 \u001b[0m https://stackoverflow.com/questions/23844667\n",
            "\u001b[31m5 \u001b[33m45 \u001b[0m https://github.com/flutter/flutter/issues/11392\n",
            "\u001b[31m13 \u001b[33m69 \u001b[0m https://developer.android.com/training/data-storage/sqlite\n",
            "\u001b[31m15 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/4015026\n",
            "\u001b[31m3 \u001b[33m31 \u001b[0m https://stackoverflow.com/questions/47760861\n",
            "\u001b[31m4 \u001b[33m100 \u001b[0m https://stackoverflow.com/questions/2661536\n",
            "\u001b[31m4 \u001b[33m23 \u001b[0m https://stackoverflow.com/questions/29738510\n",
            "\u001b[31m5 \u001b[33m54 \u001b[0m https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
            "\u001b[31m7 \u001b[33m70 \u001b[0m https://guides.codepath.com/android/using-the-app-toolbar\n",
            "\u001b[31m15 \u001b[33m81 \u001b[0m https://developer.android.com/guide/background/threading\n",
            "\u001b[31m6 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/2993085\n",
            "\u001b[31m11 \u001b[33m50 \u001b[0m https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
            "\u001b[31m8 \u001b[33m147 \u001b[0m https://developer.android.com/training/notify-user/build-notification\n",
            "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/3059155\n",
            "\u001b[31m7 \u001b[33m283 \u001b[0m https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
            "\u001b[31m5 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/37096547\n",
            "\u001b[31m7 \u001b[33m179 \u001b[0m https://guides.codepath.com/android/using-the-recyclerview\n",
            "\u001b[31m10 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/26838730\n",
            "\u001b[31m9 \u001b[33m51 \u001b[0m https://stackoverflow.com/questions/11064244\n",
            "\u001b[31m7 \u001b[33m138 \u001b[0m https://github.com/quarkusio/quarkus/issues/3954\n",
            "\u001b[31m20 \u001b[33m54 \u001b[0m https://developer.android.com/training/safetynet/recaptcha\n",
            "\u001b[31m11 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/27297067\n",
            "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
            "\u001b[31m16 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/29923376\n",
            "\u001b[31m4 \u001b[33m13 \u001b[0m https://github.com/google/dagger/issues/671\n",
            "\u001b[31m8 \u001b[33m44 \u001b[0m https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
            "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/2883355\n",
            "\u001b[31m7 \u001b[33m24 \u001b[0m https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
            "\u001b[31m9 \u001b[33m36 \u001b[0m https://developer.android.com/training/location/retrieve-current\n",
            "\u001b[31m5 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/46481789\n",
            "\u001b[31m22 \u001b[33m119 \u001b[0m https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
            "\u001b[31m15 \u001b[33m99 \u001b[0m https://javapapers.com/android/android-location-fused-provider\n",
            "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
            "\u001b[31m3 \u001b[33m4 \u001b[0m https://stackoverflow.com/questions/40168601\n",
            "\u001b[31m3 \u001b[33m19 \u001b[0m https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
            "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/36275986\n",
            "\u001b[31m42 \u001b[33m177 \u001b[0m https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
            "\u001b[31m3 \u001b[33m14 \u001b[0m https://developer.android.com/training/keyboard-input/commands\n",
            "\u001b[31m7 \u001b[33m146 \u001b[0m https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
            "\u001b[31m5 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/24313539\n",
            "\u001b[31m12 \u001b[33m77 \u001b[0m https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
            "\u001b[31m5 \u001b[33m34 \u001b[0m https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
            "\u001b[31m4 \u001b[33m54 \u001b[0m https://developer.android.com/training/gestures/scroll\n",
            "\u001b[31m4 \u001b[33m16 \u001b[0m https://stackoverflow.com/questions/39588322\n",
            "\u001b[31m22 \u001b[33m104 \u001b[0m https://developer.android.com/reference/org/json/JSONObject\n",
            "\u001b[31m8 \u001b[33m31 \u001b[0m https://guides.codepath.com/android/converting-json-to-models\n",
            "\u001b[31m20 \u001b[33m196 \u001b[0m https://developer.android.com/training/dependency-injection/dagger-android\n",
            "\u001b[31m6 \u001b[33m44 \u001b[0m https://stackoverflow.com/questions/57235136\n",
            "\u001b[31m24 \u001b[33m121 \u001b[0m https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
            "\u001b[31m5 \u001b[33m57 \u001b[0m https://github.com/signalapp/Signal-Android/issues/3376\n",
            "\u001b[31m6 \u001b[33m72 \u001b[0m https://developer.android.com/training/basics/firstapp/starting-activity\n",
            "\u001b[31m5 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/14347588\n",
            "\u001b[31m31 \u001b[33m163 \u001b[0m https://guides.codepath.com/android/creating-and-using-fragments\n",
            "\u001b[31m4 \u001b[33m40 \u001b[0m https://developer.android.com/training/gestures/scale\n",
            "\u001b[31m6 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/10630373\n",
            "\u001b[31m8 \u001b[33m42 \u001b[0m https://stackoverflow.com/questions/30362446\n",
            "\u001b[31m10 \u001b[33m36 \u001b[0m https://github.com/FasterXML/jackson-databind/issues/1538\n",
            "\u001b[31m5 \u001b[33m16 \u001b[0m https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
            "Sample entry from data:\n",
            "{\n",
            "    \"category_index\": 1,\n",
            "    \"question\": \"Hide MarkerView when nothing selected\",\n",
            "    \"source\": \"https://stackoverflow.com/questions/33241952\",\n",
            "    \"text\": \"1 - Enable touch in the chart\",\n",
            "    \"weights\": 1\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b_GXczz9CGs",
        "outputId": "3ca4758b-1eac-48a3-c709-7916d494f1e0"
      },
      "source": [
        "from collections import Counter, defaultdict\n",
        "\n",
        "cnt = Counter([d['category_index'] for d in raw_data])\n",
        "\n",
        "total = sum(cnt.values())\n",
        "\n",
        "labels_cnt = [cnt[0] / float(total), cnt[1] / float(total)]\n",
        "print('label distribution')\n",
        "print('')\n",
        "print('not-relevant -- {:.0f}%'.format(labels_cnt[0] * 100))\n",
        "print('RELEVANT ------ {:.0f}%'.format(labels_cnt[1] * 100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label distribution\n",
            "\n",
            "not-relevant -- 88%\n",
            "RELEVANT ------ 12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1l5DIHP_FUb"
      },
      "source": [
        "# @title Set environment variables\n",
        "\n",
        "model_id = 'bert-base-uncased'\n",
        "# model_id = 'distilbert-base-uncased'\n",
        "\n",
        "import os\n",
        "import contextlib\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import codecs\n",
        "import numpy as np\n",
        "import math\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from collections import defaultdict, Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "USE_TPU = False\n",
        "os.environ['TF_KERAS'] = '1'\n",
        "\n",
        "# @title Initialize TPU Strategy\n",
        "if USE_TPU:\n",
        "  TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "  tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "  strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "# sklearn libs\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Tensorflow Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.python import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "\n",
        "# Hugging face imports\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TFDistilBertForSequenceClassification, TFBertForSequenceClassification\n",
        "from transformers import TFDistilBertModel, DistilBertConfig\n",
        "from transformers import DistilBertTokenizerFast, BertTokenizerFast\n",
        "\n",
        "\n",
        "\n",
        "# Bert Model Constants\n",
        "SEQ_LEN = 128\n",
        "BATCH_SIZE = 32 # larger batch size causes OOM errors\n",
        "EPOCHS = 3\n",
        "LR = 2e-5\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T9xPdXp_kt9"
      },
      "source": [
        "# @title JSON to dataframe helper functions\n",
        "def undersample_df(df, n_times=3):\n",
        "    class_0,class_1 = df.category_index.value_counts()\n",
        "    c0 = df[df['category_index'] == 0]\n",
        "    c1 = df[df['category_index'] == 1]\n",
        "    df_0 = c0.sample(int(n_times * class_1))\n",
        "    \n",
        "    undersampled_df = pd.concat([df_0, c1],axis=0)\n",
        "    return undersampled_df\n",
        "\n",
        "def get_ds_synthetic_data(min_w=3):\n",
        "  short_task = {\n",
        "      \"bugzilla\": \"\"\"How to query bugs using the custom fields with the Bugzilla REST API?\"\"\",\n",
        "      \"databases\": \"\"\"Which technology should be adopted for the database layer abstraction: Object/Relational Mapping (ORM) or a Java Database Connectivity API (JDBC)?\"\"\",\n",
        "      \"gpmdpu\": \"\"\"Can I bind the cmd key to the GPMDPU shortcuts?\"\"\",\n",
        "      \"lucene\": \"\"\"How does Lucene compute similarity scores for the BM25 similarity?\"\"\",\n",
        "      \"networking\": \"\"\"Which technology should be adopted for the notification system, Server-Sent Events (SSE) or WebSockets?\"\"\",\n",
        "  }\n",
        "\n",
        "  with open('relevance_corpus.json') as ipf:\n",
        "      aux = json.load(ipf)\n",
        "      raw_data = defaultdict(list)\n",
        "      for d in aux:\n",
        "          if d['task'] == 'yargs':\n",
        "              continue\n",
        "\n",
        "          raw_data['text'].append(d['text'])\n",
        "          raw_data['question'].append(short_task[d['task']])\n",
        "          raw_data['source'].append(d['source'])\n",
        "          raw_data['category_index'].append(1 if d['weight'] > min_w else 0)\n",
        "          raw_data['weights'].append(d['weight'] if d['weight'] > min_w else 0)\n",
        "\n",
        "      data = pd.DataFrame.from_dict(raw_data)\n",
        "      data = undersample_df(data, n_times=1)\n",
        "      data = data.sample(frac=1).reset_index(drop=True)\n",
        "      \n",
        "  return data\n",
        "\n",
        "def get_class_weights(y, smooth_factor=0, upper_bound=5.0):\n",
        "    \"\"\"\n",
        "    Returns the weights for each class based on the frequencies of the samples\n",
        "    :param smooth_factor: factor that smooths extremely uneven weights\n",
        "    :param y: list of true labels (the labels must be hashable)\n",
        "    :return: dictionary with the weight for each class\n",
        "    \"\"\"\n",
        "    counter = Counter(y)\n",
        "\n",
        "    if smooth_factor > 0:\n",
        "        p = max(counter.values()) * smooth_factor\n",
        "        for k in counter.keys():\n",
        "            counter[k] += p\n",
        "\n",
        "    majority = max(counter.values())\n",
        "\n",
        "    clazz = {cls: float(majority / count) for cls, count in counter.items()}\n",
        "    result = {}\n",
        "    for key, value in clazz.items():\n",
        "        if value > upper_bound:\n",
        "            value = upper_bound\n",
        "        \n",
        "        result[key] = value\n",
        "    return result\n",
        "\n",
        "def add_raw_data(result, data):\n",
        "    result['text'].append(data['text'])\n",
        "    result['question'].append(data['question'])\n",
        "    result['source'].append(data['source'])\n",
        "    result['category_index'].append(data['category_index'])\n",
        "    result['weights'].append(data['weights'])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_y7xwmxAT39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9399b0d8-60c6-4a44-fb97-05918adeb89e"
      },
      "source": [
        "# @title Tokenizer\n",
        "\n",
        "print(model_id)\n",
        "if model_id == 'distilbert-base-uncased':\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_id)\n",
        "else:\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(model_id)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert-base-uncased\n",
            "Starting new HTTPS connection (1): huggingface.co:443\n",
            "https://huggingface.co:443 \"GET /api/models/bert-base-uncased HTTP/1.1\" 200 918\n",
            "Starting new HTTPS connection (1): huggingface.co:443\n",
            "https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "Starting new HTTPS connection (1): huggingface.co:443\n",
            "https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n",
            "Starting new HTTPS connection (1): huggingface.co:443\n",
            "https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
            "Starting new HTTPS connection (1): huggingface.co:443\n",
            "https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/special_tokens_map.json HTTP/1.1\" 404 0\n",
            "Starting new HTTPS connection (1): huggingface.co:443\n",
            "https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "Starting new HTTPS connection (1): huggingface.co:443\n",
            "https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdAYw7lBAmlO"
      },
      "source": [
        "# @title data encoder\n",
        "\n",
        "def _encode(tokenizer, dataframe, max_length=SEQ_LEN):\n",
        "    \n",
        "    seq_a = dataframe['text'].tolist()\n",
        "    seq_b = dataframe['question'].tolist()\n",
        "    \n",
        "    return tokenizer(seq_a, seq_b, truncation=True, padding=True, max_length=max_length)\n",
        "\n",
        "def to_one_hot_encoding(data, nb_classes = 2):\n",
        "    targets = np.array([data]).reshape(-1)\n",
        "    one_hot_targets = np.eye(nb_classes)[targets]\n",
        "    return one_hot_targets    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-5ROuqDBU9X"
      },
      "source": [
        "# @title Metrics & Logging functions\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "recommendation_metrics = defaultdict(list)\n",
        "prediction_metrics = defaultdict(list)\n",
        "\n",
        "classification_report_lst = []\n",
        "log_examples_lst = []\n",
        "\n",
        "def aggregate_macro_metrics(store_at, precision, recall, fscore):   \n",
        "    store_at['precision'].append(precision)\n",
        "    store_at['recall'].append(recall)\n",
        "    store_at['fscore'].append(fscore)\n",
        "\n",
        "def aggregate_recommendation_metrics(store_at, k, precision_at_k, pyramid_precision_at_k):\n",
        "    store_at['k'].append(k)\n",
        "    store_at['precision'].append(precision_at_k)\n",
        "    store_at['∆ precision'].append(pyramid_precision_at_k)\n",
        "\n",
        "def log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10):\n",
        "    # get the predicted prob at every index\n",
        "    idx_probs = [(idx, y_predict[idx], y_probs[idx]) for idx, _ in enumerate(y_predict)]\n",
        "    \n",
        "    # filter probs for all indexes predicted as relevant  \n",
        "    idx_probs = list(filter(lambda k: k[1] == 1, idx_probs))\n",
        "    \n",
        "    most_probable = sorted(idx_probs, key=lambda i: i[2], reverse=True)\n",
        "    \n",
        "    result = [idx for idx, _, _ in most_probable][:k]\n",
        "    \n",
        "    for idx in result:\n",
        "        log_examples_lst.append((\n",
        "            source, \n",
        "            task_title,\n",
        "            pweights[idx],\n",
        "            y_predict[idx],\n",
        "            y_probs[idx],\n",
        "            text[idx]\n",
        "        ))\n",
        "\n",
        "def _precision_at_k(y_test, y_predict, y_prob, k=10):\n",
        "    # get the predicted prob at every index\n",
        "    idx_probs = [(idx, y_predict[idx], y_prob[idx]) for idx, _ in enumerate(y_test)]\n",
        "    \n",
        "    # filter probs for all indexes predicted as relevant  \n",
        "    idx_probs = list(filter(lambda k: k[1] == 1, idx_probs))\n",
        "    \n",
        "    most_probable = sorted(idx_probs, key=lambda i: i[2], reverse=True)\n",
        "    result = [y_test[idx] * y_predict[idx] for idx, _, _ in most_probable]   \n",
        "    y_predict = [y for _, y, _ in most_probable]\n",
        "    \n",
        "    result = result[:k]\n",
        "    y_predict = y_predict[:k]\n",
        "    ratio = sum(result) / float(len(y_predict) + 0.00001)\n",
        "    return ratio     \n",
        "\n",
        "\n",
        "def _pyramid_score(y_optimal, y_predicted, y_prob, k=10):\n",
        "\n",
        "    # create reference table for weights \n",
        "    # y_predicted = [i for i in y_optimal]\n",
        "    # get the predicted prob at every index\n",
        "    idx_probs = [(idx, y_optimal[idx], y_predicted[idx], y_prob[idx]) for idx, _ in enumerate(y_optimal)]\n",
        "    \n",
        "    # filter probs for all indexes predicted as relevant  \n",
        "    idx_probs = list(filter(lambda aux: aux[2] == 1, idx_probs))\n",
        "\n",
        "    # sort\n",
        "    most_probable = sorted(idx_probs, key=lambda i: i[3], reverse=True)\n",
        "\n",
        "    # compute predicted and optimal score up until K\n",
        "    predicted_score = [w for _, w, _, _ in most_probable][:k]\n",
        "    optimal_score = sorted(y_optimal, reverse=True)[:k]\n",
        "    \n",
        "    ratio = sum(predicted_score) / float(sum(optimal_score) + 0.00001)\n",
        "    return ratio           "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E1IN6UoPq96"
      },
      "source": [
        "#@title Training procedures\n",
        "\n",
        "def get_train_val_test(task_uid, size=0.9, undersample=False, aug=True, undersample_n=3):\n",
        "    if not isinstance(task_uid, list):\n",
        "        task_uid = [task_uid]\n",
        "        \n",
        "    train_data_raw = defaultdict(list)\n",
        "    test_data_raw = defaultdict(list)\n",
        "    \n",
        "    for _data in tqdm(CORPUS):\n",
        "        if _data['question'] in task_uid:\n",
        "            add_raw_data(test_data_raw, _data)\n",
        "        else:\n",
        "            add_raw_data(train_data_raw, _data)\n",
        "    \n",
        "    train_val = pd.DataFrame.from_dict(train_data_raw)\n",
        "    test = pd.DataFrame.from_dict(test_data_raw)\n",
        "    \n",
        "    # https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
        "    #  randomize rows....    \n",
        "    train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
        "    test = test.sample(frac=1).reset_index(drop=True)\n",
        "    \n",
        "    if undersample:\n",
        "        train_val = undersample_df(train_val, n_times=undersample_n)\n",
        "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
        "        \n",
        "    if aug:\n",
        "        train_val = pd.concat([train_val, get_ds_synthetic_data()],axis=0)\n",
        "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
        "    \n",
        "    weights = get_class_weights(train_val['category_index'].tolist())\n",
        "    \n",
        "    train, val = train_test_split(\n",
        "        train_val, \n",
        "        stratify=train_val['category_index'].tolist(), \n",
        "        train_size=size\n",
        "    )\n",
        "    \n",
        "    return train, val, test, weights        "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFePvH5vBVA7"
      },
      "source": [
        "# @title Testing procedures\n",
        "\n",
        "# https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7\n",
        "def eval_model(model, test_data):\n",
        "    preds = model.predict(test_data.batch(1)).logits  \n",
        "    \n",
        "    #transform to array with probabilities\n",
        "    res = tf.nn.softmax(preds, axis=1).numpy()      \n",
        "\n",
        "    return res.argmax(axis=-1), res[:, 1]\n",
        "\n",
        "def test_model(source, df_test, model, tokenizer):\n",
        "    \n",
        "    df_source = df_test[df_test[\"source\"] == source]   \n",
        "    task_title = df_source['question'].tolist()[0]\n",
        "    text = df_source['text'].tolist()\n",
        "    pweights = df_source['weights'].tolist()\n",
        "    \n",
        "    # Encode X_test\n",
        "    test_encodings = _encode(tokenizer, df_source)\n",
        "    test_labels = df_source['category_index'].tolist()\n",
        "    \n",
        "    test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "        dict(test_encodings),\n",
        "        test_labels\n",
        "    ))\n",
        "    \n",
        "    y_true = [y.numpy() for x, y in test_dataset]\n",
        "    y_predict, y_probs = eval_model(model, test_dataset)\n",
        "    \n",
        "    \n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_predict)\n",
        "    macro_f1 = f1_score(y_true, y_predict, average='macro')\n",
        "    \n",
        "    classification_report_lst.append(classification_report(y_true, y_predict))\n",
        "\n",
        "    logger.info(\"-\" * 20)    \n",
        "    \n",
        "    logger.info(\"Y\")\n",
        "    logger.info(\"[0s] {} [1s] {}\".format(\n",
        "        len(list(filter(lambda k: k== 0, y_true))),\n",
        "        len(list(filter(lambda k: k== 1, y_true)))\n",
        "    ))\n",
        "    \n",
        "        \n",
        "    logger.info(\"predicted\")\n",
        "    logger.info(\"[0s] {} [1s] {}\".format(\n",
        "        len(list(filter(lambda k: k== 0, y_predict))),\n",
        "        len(list(filter(lambda k: k== 1, y_predict)))\n",
        "    ))\n",
        "    \n",
        "    logger.info(\"-\" * 20)\n",
        "    \n",
        "    logger.info(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "    logger.info(\"macro_f1: {:.4f}\".format(macro_f1))\n",
        "\n",
        "    precision, recall, fscore, _ = precision_recall_fscore_support(y_true, y_predict, average='macro')\n",
        "    \n",
        "    aggregate_macro_metrics(prediction_metrics, precision, recall, fscore)\n",
        "    \n",
        "    logger.info(\"Precision: {:.4f}\".format(precision))\n",
        "    logger.info(\"Recall: {:.4f}\".format(recall))\n",
        "    logger.info(\"F1: {:.4f}\".format(fscore))\n",
        "    \n",
        "    logger.info(\"-\" * 20)\n",
        "    \n",
        "    for k in [3, 5, 10]:\n",
        "        p_at_k = _precision_at_k(y_true, y_predict, y_probs, k=k)\n",
        "        score_at_k = 0.0 #_pyramid_score(pweights, y_predict, y_probs, k=k)\n",
        "                                     \n",
        "        aggregate_recommendation_metrics(recommendation_metrics, k, p_at_k, score_at_k)\n",
        "        \n",
        "        logger.info(\"\")\n",
        "        logger.info(\"Precision_at_{}: {:.4f}\".format(k, p_at_k))\n",
        "        logger.info(\"Pyramid_at_{}: {:.4f}\".format(k, score_at_k))\n",
        "    logger.info(\"-\" * 20)\n",
        "    \n",
        "    log_examples(task_title, source, text, pweights, y_predict, y_probs, k=5)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oZGDUKnB1gw",
        "outputId": "b6bd5e74-4c20-4dca-a528-1aff12bbe090"
      },
      "source": [
        "# @title 10-fold cross validation WIP\n",
        "CORPUS = raw_data\n",
        "\n",
        "all_tasks = sorted(list(set([d['question'] for d in raw_data])))\n",
        "rseed = 20210343\n",
        "random.seed(rseed)\n",
        "random.shuffle(all_tasks)\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "n_splits = 10\n",
        "kf = KFold(n_splits=n_splits, random_state=rseed)\n",
        "np_tasks_arr = np.array(all_tasks)\n",
        "\n",
        "idx_split = 0\n",
        "for train_index, test_index in kf.split(np_tasks_arr):    \n",
        "    test_tasks_lst = np_tasks_arr[test_index].tolist()\n",
        "    \n",
        "    logger.info(\"\")\n",
        "    logger.info(Fore.RED + f\"Fold {idx_split}\" + Style.RESET_ALL)\n",
        "    logger.info('\\n'.join(test_tasks_lst))\n",
        "    \n",
        "    df_train, df_val, df_test, weights = get_train_val_test(test_tasks_lst, undersample=True, undersample_n=2) \n",
        "\n",
        "    logger.info('-' * 10)\n",
        "    logger.info(Fore.RED + 'train'+ Style.RESET_ALL)\n",
        "    logger.info(str(df_train.category_index.value_counts()))\n",
        "    logger.info(\"\")\n",
        "\n",
        "    logger.info(Fore.RED + 'val'+ Style.RESET_ALL)\n",
        "    logger.info(str(df_val.category_index.value_counts()))\n",
        "    logger.info(\"\")\n",
        "\n",
        "    logger.info(Fore.RED + 'test'+ Style.RESET_ALL)\n",
        "    logger.info(str(df_test.category_index.value_counts()))\n",
        "    logger.info(\"\")\n",
        "\n",
        "    logger.info(Fore.RED + 'weights'+ Style.RESET_ALL)\n",
        "    logger.info(str(weights))\n",
        "    logger.info('-' * 10)\n",
        "    \n",
        "    \n",
        "    # Encode X_train\n",
        "    train_encodings = _encode(tokenizer, df_train)\n",
        "    train_labels = df_train['category_index'].tolist()\n",
        "\n",
        "    # Encode X_valid\n",
        "    val_encodings = _encode(tokenizer, df_val)\n",
        "    val_labels = df_val['category_index'].tolist()\n",
        "\n",
        "\n",
        "    # https://huggingface.co/transformers/custom_datasets.html\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "        dict(train_encodings),\n",
        "        train_labels\n",
        "    ))\n",
        "\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "        dict(val_encodings),\n",
        "        val_labels\n",
        "    ))\n",
        "\n",
        "    \n",
        "    if model_id == 'distilbert-base-uncased':\n",
        "        model = TFDistilBertForSequenceClassification.from_pretrained(model_id)\n",
        "    else:\n",
        "        model = TFBertForSequenceClassification.from_pretrained(model_id)\n",
        "\n",
        "    # freeze all the parameters\n",
        "    # for param in model.parameters():\n",
        "    #   param.requires_grad = False\n",
        "        \n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    METRICS = [\n",
        "        tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    ]\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss_fn,\n",
        "        metrics=METRICS\n",
        "    )\n",
        "\n",
        "    # https://discuss.huggingface.co/t/how-to-dealing-with-data-imbalance/393/3\n",
        "    model.fit(\n",
        "        train_dataset.shuffle(1000).batch(BATCH_SIZE), \n",
        "        epochs=EPOCHS, \n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_weight=weights,\n",
        "        validation_data=val_dataset.shuffle(1000).batch(BATCH_SIZE)\n",
        "    )\n",
        "    \n",
        "    logger.info(\"\")\n",
        "    logger.info(Fore.RED + f\"Testing model\" + Style.RESET_ALL)\n",
        "    for source in df_test[\"source\"].unique():\n",
        "        df_source = df_test[df_test[\"source\"] == source]   \n",
        "        logger.info(source)\n",
        "        test_model(source, df_source, model, tokenizer)\n",
        "            \n",
        "    idx_split += 1\n",
        "    \n",
        "    break\n",
        "\n",
        "    "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[31mFold 0\u001b[0m\n",
            "how can i get the value of text view in recyclerview item?\n",
            "Hide MarkerView when nothing selected\n",
            "How to check programmatically whether app is running in debug mode or not?\n",
            "JSONObject parse dictionary objects\n",
            "Want to add drawable icons insteadof colorful dots\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "100%|██████████| 7940/7940 [00:00<00:00, 710974.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumExpr defaulting to 2 threads.\n",
            "----------\n",
            "\u001b[31mtrain\u001b[0m\n",
            "0    1823\n",
            "1     994\n",
            "Name: category_index, dtype: int64\n",
            "\n",
            "\u001b[31mval\u001b[0m\n",
            "0    203\n",
            "1    110\n",
            "Name: category_index, dtype: int64\n",
            "\n",
            "\u001b[31mtest\u001b[0m\n",
            "0    669\n",
            "1     66\n",
            "Name: category_index, dtype: int64\n",
            "\n",
            "\u001b[31mweights\u001b[0m\n",
            "{1: 1.835144927536232, 0: 1.0}\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting new HTTPS connection (1): huggingface.co:443\n",
            "https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "Starting new HTTPS connection (1): huggingface.co:443\n",
            "https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tf_model.h5 HTTP/1.1\" 302 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7faf483f0b40>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7faf483f0b40>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "AutoGraph could not transform <function wrap at 0x7faf63c879e0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7faf63c879e0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.8780 - sparse_categorical_accuracy: 0.5747The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "89/89 [==============================] - 193s 2s/step - loss: 0.8780 - sparse_categorical_accuracy: 0.5747 - val_loss: 0.6241 - val_sparse_categorical_accuracy: 0.6581\n",
            "Epoch 2/3\n",
            "89/89 [==============================] - 137s 2s/step - loss: 0.7614 - sparse_categorical_accuracy: 0.6933 - val_loss: 0.6233 - val_sparse_categorical_accuracy: 0.6294\n",
            "Epoch 3/3\n",
            "89/89 [==============================] - 137s 2s/step - loss: 0.6437 - sparse_categorical_accuracy: 0.7469 - val_loss: 0.6110 - val_sparse_categorical_accuracy: 0.6581\n",
            "\n",
            "\u001b[31mTesting model\u001b[0m\n",
            "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
            "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "--------------------\n",
            "Y\n",
            "[0s] 276 [1s] 7\n",
            "predicted\n",
            "[0s] 90 [1s] 193\n",
            "--------------------\n",
            "Accuracy: 0.3216\n",
            "macro_f1: 0.2577\n",
            "Precision: 0.4937\n",
            "Recall: 0.4433\n",
            "F1: 0.2577\n",
            "--------------------\n",
            "\n",
            "Precision_at_3: 0.3333\n",
            "Pyramid_at_3: 0.0000\n",
            "\n",
            "Precision_at_5: 0.2000\n",
            "Pyramid_at_5: 0.0000\n",
            "\n",
            "Precision_at_10: 0.1000\n",
            "Pyramid_at_10: 0.0000\n",
            "--------------------\n",
            "https://guides.codepath.com/android/using-the-recyclerview\n",
            "https://guides.codepath.com/android/using-the-recyclerview\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "--------------------\n",
            "Y\n",
            "[0s] 172 [1s] 7\n",
            "predicted\n",
            "[0s] 60 [1s] 119\n",
            "--------------------\n",
            "Accuracy: 0.3743\n",
            "macro_f1: 0.3142\n",
            "Precision: 0.5294\n",
            "Recall: 0.6744\n",
            "F1: 0.3142\n",
            "--------------------\n",
            "\n",
            "Precision_at_3: 0.6667\n",
            "Pyramid_at_3: 0.0000\n",
            "\n",
            "Precision_at_5: 0.6000\n",
            "Pyramid_at_5: 0.0000\n",
            "\n",
            "Precision_at_10: 0.3000\n",
            "Pyramid_at_10: 0.0000\n",
            "--------------------\n",
            "https://developer.android.com/reference/org/json/JSONObject\n",
            "https://developer.android.com/reference/org/json/JSONObject\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "--------------------\n",
            "Y\n",
            "[0s] 82 [1s] 22\n",
            "predicted\n",
            "[0s] 8 [1s] 96\n",
            "--------------------\n",
            "Accuracy: 0.2885\n",
            "macro_f1: 0.2753\n",
            "Precision: 0.6146\n",
            "Recall: 0.5488\n",
            "F1: 0.2753\n",
            "--------------------\n",
            "\n",
            "Precision_at_3: 0.0000\n",
            "Pyramid_at_3: 0.0000\n",
            "\n",
            "Precision_at_5: 0.0000\n",
            "Pyramid_at_5: 0.0000\n",
            "\n",
            "Precision_at_10: 0.1000\n",
            "Pyramid_at_10: 0.0000\n",
            "--------------------\n",
            "https://stackoverflow.com/questions/23844667\n",
            "https://stackoverflow.com/questions/23844667\n",
            "--------------------\n",
            "Y\n",
            "[0s] 23 [1s] 5\n",
            "predicted\n",
            "[0s] 17 [1s] 11\n",
            "--------------------\n",
            "Accuracy: 0.6429\n",
            "macro_f1: 0.5625\n",
            "Precision: 0.5775\n",
            "Recall: 0.6261\n",
            "F1: 0.5625\n",
            "--------------------\n",
            "\n",
            "Precision_at_3: 0.6667\n",
            "Pyramid_at_3: 0.0000\n",
            "\n",
            "Precision_at_5: 0.4000\n",
            "Pyramid_at_5: 0.0000\n",
            "\n",
            "Precision_at_10: 0.3000\n",
            "Pyramid_at_10: 0.0000\n",
            "--------------------\n",
            "https://github.com/flutter/flutter/issues/11392\n",
            "https://github.com/flutter/flutter/issues/11392\n",
            "--------------------\n",
            "Y\n",
            "[0s] 40 [1s] 5\n",
            "predicted\n",
            "[0s] 41 [1s] 4\n",
            "--------------------\n",
            "Accuracy: 0.8000\n",
            "macro_f1: 0.4444\n",
            "Precision: 0.4390\n",
            "Recall: 0.4500\n",
            "F1: 0.4444\n",
            "--------------------\n",
            "\n",
            "Precision_at_3: 0.0000\n",
            "Pyramid_at_3: 0.0000\n",
            "\n",
            "Precision_at_5: 0.0000\n",
            "Pyramid_at_5: 0.0000\n",
            "\n",
            "Precision_at_10: 0.0000\n",
            "Pyramid_at_10: 0.0000\n",
            "--------------------\n",
            "https://stackoverflow.com/questions/33241952\n",
            "https://stackoverflow.com/questions/33241952\n",
            "--------------------\n",
            "Y\n",
            "[0s] 8 [1s] 4\n",
            "predicted\n",
            "[0s] 7 [1s] 5\n",
            "--------------------\n",
            "Accuracy: 0.5833\n",
            "macro_f1: 0.5556\n",
            "Precision: 0.5571\n",
            "Recall: 0.5625\n",
            "F1: 0.5556\n",
            "--------------------\n",
            "\n",
            "Precision_at_3: 0.3333\n",
            "Pyramid_at_3: 0.0000\n",
            "\n",
            "Precision_at_5: 0.4000\n",
            "Pyramid_at_5: 0.0000\n",
            "\n",
            "Precision_at_10: 0.4000\n",
            "Pyramid_at_10: 0.0000\n",
            "--------------------\n",
            "https://guides.codepath.com/android/converting-json-to-models\n",
            "https://guides.codepath.com/android/converting-json-to-models\n",
            "--------------------\n",
            "Y\n",
            "[0s] 23 [1s] 8\n",
            "predicted\n",
            "[0s] 9 [1s] 22\n",
            "--------------------\n",
            "Accuracy: 0.4194\n",
            "macro_f1: 0.4188\n",
            "Precision: 0.5253\n",
            "Recall: 0.5272\n",
            "F1: 0.4188\n",
            "--------------------\n",
            "\n",
            "Precision_at_3: 0.6667\n",
            "Pyramid_at_3: 0.0000\n",
            "\n",
            "Precision_at_5: 0.6000\n",
            "Pyramid_at_5: 0.0000\n",
            "\n",
            "Precision_at_10: 0.4000\n",
            "Pyramid_at_10: 0.0000\n",
            "--------------------\n",
            "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
            "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
            "--------------------\n",
            "Y\n",
            "[0s] 33 [1s] 3\n",
            "predicted\n",
            "[0s] 9 [1s] 27\n",
            "--------------------\n",
            "Accuracy: 0.3333\n",
            "macro_f1: 0.3143\n",
            "Precision: 0.5556\n",
            "Recall: 0.6364\n",
            "F1: 0.3143\n",
            "--------------------\n",
            "\n",
            "Precision_at_3: 0.0000\n",
            "Pyramid_at_3: 0.0000\n",
            "\n",
            "Precision_at_5: 0.2000\n",
            "Pyramid_at_5: 0.0000\n",
            "\n",
            "Precision_at_10: 0.2000\n",
            "Pyramid_at_10: 0.0000\n",
            "--------------------\n",
            "https://stackoverflow.com/questions/37096547\n",
            "https://stackoverflow.com/questions/37096547\n",
            "--------------------\n",
            "Y\n",
            "[0s] 12 [1s] 5\n",
            "predicted\n",
            "[0s] 6 [1s] 11\n",
            "--------------------\n",
            "Accuracy: 0.2941\n",
            "macro_f1: 0.2917\n",
            "Precision: 0.3409\n",
            "Recall: 0.3250\n",
            "F1: 0.2917\n",
            "--------------------\n",
            "\n",
            "Precision_at_3: 0.0000\n",
            "Pyramid_at_3: 0.0000\n",
            "\n",
            "Precision_at_5: 0.2000\n",
            "Pyramid_at_5: 0.0000\n",
            "\n",
            "Precision_at_10: 0.2000\n",
            "Pyramid_at_10: 0.0000\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYVkKLe-B1j0"
      },
      "source": [
        "#@title Metrics report\n",
        "def avg_recommendation_metric_for(data, k=3, filter_outliers=True):\n",
        "    __precision = []\n",
        "    __pyramid = []\n",
        "    \n",
        "    total_len = len(data['k'])\n",
        "    \n",
        "    for idx in range(total_len):\n",
        "        \n",
        "        __value = data['k'][idx]\n",
        "        if __value  == k:\n",
        "            if filter_outliers:            \n",
        "                if data['precision'][idx] > 0.:\n",
        "                    __precision.append(data['precision'][idx])\n",
        "                if data['∆ precision'][idx] > 0.:\n",
        "                    __pyramid.append(data['∆ precision'][idx])\n",
        "            else:\n",
        "                __precision.append(data['precision'][idx])\n",
        "                __pyramid.append(data['∆ precision'][idx])\n",
        "                \n",
        "    r__precision = 0.\n",
        "    if __precision:\n",
        "      r__precision = np.mean(__precision)\n",
        "\n",
        "    r__pyramid = 0.\n",
        "    if __pyramid:\n",
        "      r__pyramid = np.mean(__pyramid)\n",
        "\n",
        "    return r__precision, r__pyramid\n",
        "\n",
        "def avg_macro_metric_for(data):\n",
        "    __precision = data['precision']\n",
        "    __recall = data['recall']\n",
        "    __fscore = data['fscore']\n",
        "\n",
        "    return np.mean(__precision), np.mean(__recall), np.mean(__fscore)    "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXAU79kUB1m_",
        "outputId": "91cd9b4e-cdfd-470a-89ce-b58a6e07f83c"
      },
      "source": [
        "_precision, __pyramid_score = avg_recommendation_metric_for(\n",
        "    recommendation_metrics, \n",
        "    k=3\n",
        ")\n",
        "\n",
        "logger.info(Fore.YELLOW + \"k=3\" + Style.RESET_ALL)\n",
        "logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mk=3\u001b[0m\n",
            "precision: \u001b[31m0.533\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0yBBd0lMHuI",
        "outputId": "7a0c48bb-13d3-45cc-a7c0-4ff140110f64"
      },
      "source": [
        "_precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
        "\n",
        "logger.info(\"\")\n",
        "logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
        "logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
        "logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
        "logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[33mModel metrics\u001b[0m\n",
            "precision: \u001b[31m0.515\u001b[0m\n",
            "recall:    \u001b[31m0.533\u001b[0m\n",
            "f1-score:  \u001b[31m0.382\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUOGnWgIMYLN"
      },
      "source": [
        "def examples_per_source_type(source_type='misc', n_samples=None):\n",
        "  _sources = list(set([x[0] for x in log_examples_lst]))\n",
        "\n",
        "  _template = \"[w={}]\" + Fore.RED + \"[y={}]\" + Fore.YELLOW + \"[p={:.4f}]\" + Style.RESET_ALL + \" {}\"\n",
        "\n",
        "  idx = 0\n",
        "  for s in _sources:\n",
        "      examples_in_source = []\n",
        "      if source_type == 'api' and ('docs.oracle' in s or 'developer.android' in s):\n",
        "          examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
        "          task_title = examples_in_source[0][1]\n",
        "          idx += 1\n",
        "      elif source_type == 'so' and ('stackoverflow.com' in s):\n",
        "          examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
        "          task_title = examples_in_source[0][1]            \n",
        "          idx += 1\n",
        "      elif source_type == 'git' and ('github.com' in s):\n",
        "          examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
        "          task_title = examples_in_source[0][1]\n",
        "          idx += 1\n",
        "      elif source_type == 'misc' and 'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
        "          examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
        "          task_title = examples_in_source[0][1]\n",
        "          idx += 1\n",
        "      if not examples_in_source:\n",
        "          continue\n",
        "      logger.info('')\n",
        "      logger.info(Fore.RED + f\"{task_title}\" + Style.RESET_ALL)    \n",
        "      logger.info(s)\n",
        "      logger.info('')\n",
        "\n",
        "      for _, _, pweights, y_predict, y_probs, text in examples_in_source:\n",
        "          logger.info(_template.format(pweights, y_predict, y_probs, text))\n",
        "          logger.info('')\n",
        "      logger.info('-' * 20)\n",
        "      \n",
        "      if n_samples and idx >= n_samples:\n",
        "        break\n",
        "    "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjg9kKaDM0fo",
        "outputId": "dba58771-3ba1-440b-a0af-0a637e619cee"
      },
      "source": [
        "#@title Sample prediction outputs for API sources\n",
        "\n",
        "logger.info(Fore.RED + \"API\" + Style.RESET_ALL)\n",
        "examples_per_source_type(source_type='api', n_samples=8)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mAPI\u001b[0m\n",
            "\n",
            "\u001b[31mJSONObject parse dictionary objects\u001b[0m\n",
            "https://developer.android.com/reference/org/json/JSONObject\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8441]\u001b[0m This fails with a JSONException if the requested name has no value or if the value can not be coerced to the requested type.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8362]\u001b[0m Creates a new JSONObject by copying mappings for the listed names from the given object.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8357]\u001b[0m Using accumulate will result in either a JSONArray or a mapping whose type is the type of value depending on the number of calls to it.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8346]\u001b[0m Although null can not be coerced, the sentinel value JSONObject #NULL is coerced to the string `` null''.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8327]\u001b[0m Creates a new JSONObject by copying all name/value mappings from the given map.\n",
            "\n",
            "--------------------\n",
            "\n",
            "\u001b[31mhow can i get the value of text view in recyclerview item?\u001b[0m\n",
            "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8450]\u001b[0m In this case, you need an adapter that takes an Affirmation instance from the list returned by loadAffirmations ( ), and turns it into a list item view, so that it can be displayed in the RecyclerView.\n",
            "\n",
            "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8271]\u001b[0m RecyclerView is designed to be very efficient, even with large lists, by reusing, or recycling, the views that have scrolled off the screen.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8213]\u001b[0m Create a Datasource, call loadAffirmations ( ), get the size of the returned list, convert it to a string, and assign it as the text of textView.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8195]\u001b[0m The onCreateViewHolder ( ) method is called by the layout manager to create new view holders for the RecyclerView ( when there are no existing view holders that can be reused ).\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8181]\u001b[0m Add the code to extend your ItemAdapter from the abstract class RecyclerView.Adapter.\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDBgOWQXNW1i",
        "outputId": "013b5938-1f8d-45b5-814c-9260fee16bef"
      },
      "source": [
        "#@title Sample prediction outputs for GIT sources\n",
        "\n",
        "logger.info(Fore.RED + \"GIT\" + Style.RESET_ALL)\n",
        "examples_per_source_type(source_type='git', n_samples=4)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mGIT\u001b[0m\n",
            "\n",
            "\u001b[31mHow to check programmatically whether app is running in debug mode or not?\u001b[0m\n",
            "https://github.com/flutter/flutter/issues/11392\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7858]\u001b[0m Please add the option to check what mode ( slow, profile or release ) the Flutter app is running in.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5824]\u001b[0m Document how to check if profile/release/debug mode in dart\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5718]\u001b[0m The only way that works reliably has been posted above in # 11392 ( comment ).\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5657]\u001b[0m But we should document that somewhere, or configure a variable accordingly or something.\n",
            "\n",
            "--------------------\n",
            "\n",
            "\u001b[31mWant to add drawable icons insteadof colorful dots\u001b[0m\n",
            "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8472]\u001b[0m You will need to load your icon probably in the init ( ) method of that class and draw using the that bitmap method.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8422]\u001b[0m You can tweak the code on how you want to draw the icons:\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8208]\u001b[0m Then change CompactCalendarController.java by removing those lines I mentioned and replacing with a call to draw your icon.\n",
            "\n",
            "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8162]\u001b[0m with some custome code which simply draws a drawable icon.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8117]\u001b[0m Want to add drawable icons insteadof colorful dots\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4Bqx8AbNoV_",
        "outputId": "cde9a402-d2b8-4c41-a044-175f2dd6d8ca"
      },
      "source": [
        "#@title Sample prediction outputs for SO sources\n",
        "\n",
        "logger.info(Fore.RED + \"SO\" + Style.RESET_ALL)\n",
        "examples_per_source_type(source_type='so', n_samples=4)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mSO\u001b[0m\n",
            "\n",
            "\u001b[31mHow to check programmatically whether app is running in debug mode or not?\u001b[0m\n",
            "https://stackoverflow.com/questions/23844667\n",
            "\n",
            "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7903]\u001b[0m If you are using Android Studio, or if you are using Gradle from the command line, you can add your own stuff to BuildConfig or otherwise tweak the debug and release build types to help distinguish these situations at runtime.\n",
            "\n",
            "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7619]\u001b[0m This is a boolean value that will be true for a debug build, false otherwise:\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7347]\u001b[0m then, in your code you detect the ENABLE_CRASHLYTICS flag as follows:\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6986]\u001b[0m I am using this solution in case to find out that my app is running on debug version.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6962]\u001b[0m Alternatively, you could differentiate using BuildConfig.BUILD _ TYPE ;\n",
            "\n",
            "--------------------\n",
            "\n",
            "\u001b[31mhow can i get the value of text view in recyclerview item?\u001b[0m\n",
            "https://stackoverflow.com/questions/37096547\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7484]\u001b[0m I had a similar problem.My Recyclerview contained one Textview, two EditTexts and one remove Button to remove the item from the Recyclerview.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7197]\u001b[0m In the adapter I am using two arraylists rtyArray and qtyArray to hold the position of the Edittext data in the model class.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7074]\u001b[0m I am getting the data from both the Edittexts, from a model class using a button from my activity.\n",
            "\n",
            "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7069]\u001b[0m You don't need to use so many lists, just create a class that will contain all the data of single item, there is no need for buttons, use just text change listener instead.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7019]\u001b[0m Above class holds the three Strings one is the titile and the two hold the edittext data.\n",
            "\n",
            "--------------------\n",
            "\n",
            "\u001b[31mHide MarkerView when nothing selected\u001b[0m\n",
            "https://stackoverflow.com/questions/33241952\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7878]\u001b[0m set your marker to the chart\n",
            "\n",
            "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7862]\u001b[0m Set the view Marker in the chart\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7512]\u001b[0m Use IMarker Interface -LRB- MarkerView has been deprecated since release 3.0.0 -RRB-\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7512]\u001b[0m Create a new class that implements the IMarker interface\n",
            "\n",
            "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.5310]\u001b[0m 2 - Create MarkerView\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_mgLqe0N-hs",
        "outputId": "3bbf6fb1-2479-4189-ec36-ae598429a27c"
      },
      "source": [
        "#@title Sample prediction outputs for MISC sources\n",
        "\n",
        "logger.info(Fore.RED + \"MISC\" + Style.RESET_ALL)\n",
        "examples_per_source_type(source_type='misc', n_samples=4)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mMISC\u001b[0m\n",
            "\n",
            "\u001b[31mhow can i get the value of text view in recyclerview item?\u001b[0m\n",
            "https://guides.codepath.com/android/using-the-recyclerview\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8247]\u001b[0m Unlike the ListView adapter, a RecyclerView adapter should not rely on notifyDataSetChanged ( ) since the more granular actions should be used.\n",
            "\n",
            "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8239]\u001b[0m However, with a RecyclerView the adapter requires the existence of a `` ViewHolder'' object which describes and provides access to all the views within each item row.\n",
            "\n",
            "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8238]\u001b[0m If you create enough items and scroll through the list, the views will be recycled and far smoother by default than the ListView widget:\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8119]\u001b[0m You may notice an error that says `` There is no default constructor available in androidx.recyclerview.widget.ListAdapter''.\n",
            "\n",
            "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8076]\u001b[0m Every adapter has three primary methods: onCreateViewHolder to inflate the item layout and create the holder, onBindViewHolder to set the view attributes based on the data and getItemCount to determine the number of items.\n",
            "\n",
            "--------------------\n",
            "\n",
            "\u001b[31mJSONObject parse dictionary objects\u001b[0m\n",
            "https://guides.codepath.com/android/converting-json-to-models\n",
            "\n",
            "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8503]\u001b[0m Next, we need to add method that would manage the deserialization of a JSON dictionary into a populated Business object:\n",
            "\n",
            "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8247]\u001b[0m With this method in place, we could take a single business JSON dictionary such as:\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8188]\u001b[0m This search method will take care of executing our JSON request to the Yelp API.\n",
            "\n",
            "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8183]\u001b[0m We could now run the app and verify that the JSON array of business has the format we expect from the provided sample response in the documentation.\n",
            "\n",
            "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8126]\u001b[0m However, in the API response, we actually get a collection of business JSON in an array.\n",
            "\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Aqy_IvONch"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}