{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marquesarthur/vanilla-bert-vs-huggingface/blob/main/hugging_face_keras_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfNydjdoLcvK"
   },
   "source": [
    "Based on \n",
    "\n",
    "\n",
    "\n",
    "1.   https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379\n",
    "2.   https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/\n",
    "3.   https://huggingface.co/transformers/training.html#fine-tuning-with-keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**problem statement:**\n",
    "\n",
    "\n",
    "*   a developer has to inspect an **artifact X**\n",
    "*   Within the artifact, only a portion of the text is relevant to **input task Y**\n",
    "*   We ought to build a model that establishes relationships between **Y** and **sentences x ∈ X** \n",
    "*  The model must determine: **is x relevant to task Y**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Example of a task and an annotated artifact:*\n",
    "\n",
    "<br>\n",
    "\n",
    "[<img src=\"https://i.imgur.com/Zj1317H.jpg\">](https://i.imgur.com/Zj1317H.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* The coloured sentences are sentences annotated as relevant to the input task. \n",
    "* The warmer the color, the more annotators selected that portion of the text. \n",
    "* For simplicity, we process the data and used sentences \n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Ultimately, our data is a tuple representing:*\n",
    "\n",
    "\n",
    "*   **text** = artifact sentence\n",
    "\n",
    "*   **question** = task description\n",
    "\n",
    "*   **source** = URL of the artifact\n",
    "\n",
    "*   **category_index** = whether sentence is relevant [or not] for the input task\n",
    "\n",
    "*   **weights** = number of participants who annotated sentence as relevant\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtFJT5AK6RRc",
    "outputId": "f3eaf1c3-63c2-455e-eaa5-5eb9955afe4b"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "\n",
    "# !pip install transformers\n",
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y80jdm9S6wQA",
    "outputId": "de6caa10-19da-42af-958f-bf19fe70903d"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn tqdm pandas python-Levenshtein path colorama matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q38yIvW87NrN",
    "outputId": "425ff20e-e16f-475a-93fe-221008e32fdc"
   },
   "outputs": [],
   "source": [
    "# @title Download git repo\n",
    "# !git clone https://github.com/marquesarthur/vanilla-bert-vs-huggingface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyrLR-tf8P4Q",
    "outputId": "a2cc52fc-f3e9-4cf0-ce6d-c11cee304c39"
   },
   "outputs": [],
   "source": [
    "# %cd vanilla-bert-vs-huggingface\n",
    "# !git pull\n",
    "# !ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kudd2ZR8tKZ",
    "outputId": "2a38495e-b8e4-43b1-c126-ec92e98b07d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m39 \u001b[33m129 \u001b[0m https://developer.android.com/training/permissions/requesting\n",
      "\u001b[31m14 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/5233543\n",
      "\u001b[31m4 \u001b[33m34 \u001b[0m https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "\u001b[31m27 \u001b[33m63 \u001b[0m https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "\u001b[31m9 \u001b[33m161 \u001b[0m https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "\u001b[31m9 \u001b[33m15 \u001b[0m https://developer.android.com/training/volley/request\n",
      "\u001b[31m14 \u001b[33m65 \u001b[0m https://stackoverflow.com/questions/28504524\n",
      "\u001b[31m20 \u001b[33m59 \u001b[0m https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "\u001b[31m5 \u001b[33m97 \u001b[0m https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "\u001b[31m4 \u001b[33m12 \u001b[0m https://stackoverflow.com/questions/33241952\n",
      "\u001b[31m6 \u001b[33m33 \u001b[0m https://github.com/realm/realm-java/issues/776\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/8712652\n",
      "\u001b[31m8 \u001b[33m59 \u001b[0m https://dzone.com/articles/android-rotate-and-scale\n",
      "\u001b[31m5 \u001b[33m470 \u001b[0m https://developer.android.com/reference/android/widget/TextView\n",
      "\u001b[31m7 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/19025301\n",
      "\u001b[31m8 \u001b[33m95 \u001b[0m https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "\u001b[31m20 \u001b[33m145 \u001b[0m https://developer.android.com/training/dependency-injection/hilt-android\n",
      "\u001b[31m4 \u001b[33m8 \u001b[0m https://stackoverflow.com/questions/30648172\n",
      "\u001b[31m4 \u001b[33m81 \u001b[0m https://github.com/google/dagger/issues/1991\n",
      "\u001b[31m9 \u001b[33m48 \u001b[0m https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "\u001b[31m5 \u001b[33m47 \u001b[0m https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "\u001b[31m9 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/6442054\n",
      "\u001b[31m3 \u001b[33m22 \u001b[0m https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "\u001b[31m22 \u001b[33m211 \u001b[0m https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "\u001b[31m21 \u001b[33m59 \u001b[0m https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "\u001b[31m17 \u001b[33m33 \u001b[0m https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "\u001b[31m6 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/10108774\n",
      "\u001b[31m19 \u001b[33m250 \u001b[0m https://developer.android.com/guide/topics/media/camera\n",
      "\u001b[31m9 \u001b[33m32 \u001b[0m https://github.com/google/ExoPlayer/issues/8387\n",
      "\u001b[31m7 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/8184492\n",
      "\u001b[31m7 \u001b[33m58 \u001b[0m https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "\u001b[31m3 \u001b[33m50 \u001b[0m https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "\u001b[31m3 \u001b[33m56 \u001b[0m https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "\u001b[31m3 \u001b[33m5 \u001b[0m https://stackoverflow.com/questions/38980595\n",
      "\u001b[31m4 \u001b[33m38 \u001b[0m https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "\u001b[31m8 \u001b[33m36 \u001b[0m https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "\u001b[31m4 \u001b[33m131 \u001b[0m https://stackoverflow.com/questions/122105\n",
      "\u001b[31m3 \u001b[33m48 \u001b[0m https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "\u001b[31m8 \u001b[33m49 \u001b[0m https://developer.android.com/guide/topics/media/mediarecorder\n",
      "\u001b[31m4 \u001b[33m9 \u001b[0m https://stackoverflow.com/questions/6688444\n",
      "\u001b[31m3 \u001b[33m23 \u001b[0m https://github.com/google/oboe/issues/447\n",
      "\u001b[31m4 \u001b[33m27 \u001b[0m https://stackoverflow.com/questions/24952513\n",
      "\u001b[31m18 \u001b[33m219 \u001b[0m https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "\u001b[31m3 \u001b[33m72 \u001b[0m https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "\u001b[31m5 \u001b[33m373 \u001b[0m https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "\u001b[31m12 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/35357919\n",
      "\u001b[31m11 \u001b[33m117 \u001b[0m https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "\u001b[31m8 \u001b[33m147 \u001b[0m https://developer.android.com/training/notify-user/build-notification\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/3059155\n",
      "\u001b[31m10 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/26838730\n",
      "\u001b[31m7 \u001b[33m48 \u001b[0m https://guides.codepath.com/android/Defining-The-ActionBar\n",
      "\u001b[31m7 \u001b[33m283 \u001b[0m https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "\u001b[31m5 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/37096547\n",
      "\u001b[31m7 \u001b[33m179 \u001b[0m https://guides.codepath.com/android/using-the-recyclerview\n",
      "\u001b[31m3 \u001b[33m31 \u001b[0m https://stackoverflow.com/questions/47760861\n",
      "\u001b[31m13 \u001b[33m69 \u001b[0m https://developer.android.com/training/data-storage/sqlite\n",
      "\u001b[31m15 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/4015026\n",
      "\u001b[31m15 \u001b[33m81 \u001b[0m https://developer.android.com/guide/background/threading\n",
      "\u001b[31m6 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/2993085\n",
      "\u001b[31m11 \u001b[33m50 \u001b[0m https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "\u001b[31m5 \u001b[33m28 \u001b[0m https://stackoverflow.com/questions/23844667\n",
      "\u001b[31m5 \u001b[33m45 \u001b[0m https://github.com/flutter/flutter/issues/11392\n",
      "\u001b[31m4 \u001b[33m23 \u001b[0m https://stackoverflow.com/questions/29738510\n",
      "\u001b[31m5 \u001b[33m54 \u001b[0m https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "\u001b[31m4 \u001b[33m100 \u001b[0m https://stackoverflow.com/questions/2661536\n",
      "\u001b[31m9 \u001b[33m65 \u001b[0m https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "\u001b[31m5 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/24652078\n",
      "\u001b[31m8 \u001b[33m44 \u001b[0m https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/2883355\n",
      "\u001b[31m7 \u001b[33m24 \u001b[0m https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "\u001b[31m9 \u001b[33m51 \u001b[0m https://stackoverflow.com/questions/11064244\n",
      "\u001b[31m7 \u001b[33m138 \u001b[0m https://github.com/quarkusio/quarkus/issues/3954\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m16 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/29923376\n",
      "\u001b[31m4 \u001b[33m13 \u001b[0m https://github.com/google/dagger/issues/671\n",
      "\u001b[31m3 \u001b[33m19 \u001b[0m https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/36275986\n",
      "\u001b[31m42 \u001b[33m177 \u001b[0m https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "\u001b[31m9 \u001b[33m36 \u001b[0m https://developer.android.com/training/location/retrieve-current\n",
      "\u001b[31m5 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/46481789\n",
      "\u001b[31m22 \u001b[33m119 \u001b[0m https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "\u001b[31m15 \u001b[33m99 \u001b[0m https://javapapers.com/android/android-location-fused-provider\n",
      "\u001b[31m3 \u001b[33m14 \u001b[0m https://developer.android.com/training/keyboard-input/commands\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m3 \u001b[33m4 \u001b[0m https://stackoverflow.com/questions/40168601\n",
      "\u001b[31m20 \u001b[33m54 \u001b[0m https://developer.android.com/training/safetynet/recaptcha\n",
      "\u001b[31m11 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/27297067\n",
      "\u001b[31m8 \u001b[33m42 \u001b[0m https://stackoverflow.com/questions/30362446\n",
      "\u001b[31m10 \u001b[33m36 \u001b[0m https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "\u001b[31m5 \u001b[33m16 \u001b[0m https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "\u001b[31m5 \u001b[33m57 \u001b[0m https://github.com/signalapp/Signal-Android/issues/3376\n",
      "\u001b[31m5 \u001b[33m34 \u001b[0m https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "\u001b[31m22 \u001b[33m104 \u001b[0m https://developer.android.com/reference/org/json/JSONObject\n",
      "\u001b[31m8 \u001b[33m31 \u001b[0m https://guides.codepath.com/android/converting-json-to-models\n",
      "\u001b[31m7 \u001b[33m146 \u001b[0m https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "\u001b[31m5 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/24313539\n",
      "\u001b[31m12 \u001b[33m77 \u001b[0m https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "\u001b[31m6 \u001b[33m72 \u001b[0m https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "\u001b[31m5 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/14347588\n",
      "\u001b[31m31 \u001b[33m163 \u001b[0m https://guides.codepath.com/android/creating-and-using-fragments\n",
      "\u001b[31m4 \u001b[33m40 \u001b[0m https://developer.android.com/training/gestures/scale\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m6 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/10630373\n",
      "\u001b[31m4 \u001b[33m54 \u001b[0m https://developer.android.com/training/gestures/scroll\n",
      "\u001b[31m4 \u001b[33m16 \u001b[0m https://stackoverflow.com/questions/39588322\n",
      "\u001b[31m20 \u001b[33m196 \u001b[0m https://developer.android.com/training/dependency-injection/dagger-android\n",
      "\u001b[31m6 \u001b[33m44 \u001b[0m https://stackoverflow.com/questions/57235136\n",
      "\u001b[31m24 \u001b[33m121 \u001b[0m https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "Sample entry from data:\n",
      "{\n",
      "    \"category_index\": 1,\n",
      "    \"question\": \"Permission Denial when trying to access contacts in Android\",\n",
      "    \"source\": \"https://developer.android.com/training/permissions/requesting\",\n",
      "    \"text\": \"Every Android app runs in a limited-access sandbox.\",\n",
      "    \"weights\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# @title Import data as JSON\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from Levenshtein import ratio\n",
    "from colorama import Fore, Style\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.level = logging.DEBUG\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "from ds_android import get_input_for_BERT\n",
    "\n",
    "raw_data = get_input_for_BERT()\n",
    "\n",
    "print('Sample entry from data:')\n",
    "print(json.dumps(raw_data[0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b_GXczz9CGs",
    "outputId": "2f6b91cb-8396-41af-e299-61360817d8b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution\n",
      "\n",
      "not-relevant -- 87%\n",
      "RELEVANT ------ 13%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "cnt = Counter([d['category_index'] for d in raw_data])\n",
    "\n",
    "total = sum(cnt.values())\n",
    "\n",
    "labels_cnt = [cnt[0] / float(total), cnt[1] / float(total)]\n",
    "print('label distribution')\n",
    "print('')\n",
    "print('not-relevant -- {:.0f}%'.format(labels_cnt[0] * 100))\n",
    "print('RELEVANT ------ {:.0f}%'.format(labels_cnt[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seframes = {}\n",
    "with open('seframes.json') as input_file:\n",
    "    seframes = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_meaningful_frame(text):    \n",
    "    meaning_frames = [\n",
    "        'Temporal_collocation', 'Execution', 'Using', 'Intentionally_act',\n",
    "        'Being_obligated', 'Likelihood', 'Causation', 'Required_event',\n",
    "        'Desiring', 'Awareness', 'Grasp', 'Attempt'\n",
    "    ]\n",
    "    \n",
    "    if text in seframes:\n",
    "        text_labels = seframes[text]\n",
    "        if any([elem in meaning_frames for elem in text_labels]):\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLoading data from cache\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fold_results = dict()\n",
    "if os.path.isfile('bert_ds_android.json'):\n",
    "    logger.info(Fore.YELLOW + \"Loading data from cache\" + Style.RESET_ALL)\n",
    "    with open('bert_ds_android.json') as input_file:\n",
    "        fold_results = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1l5DIHP_FUb",
    "outputId": "7f1648d0-2582-43a8-c1fc-50095d78892b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n"
     ]
    }
   ],
   "source": [
    "# @title Set environment variables\n",
    "\n",
    "model_id = 'bert-base-uncased'\n",
    "# model_id = 'distilbert-base-uncased'\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "USE_TPU = False\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "# @title Initialize TPU Strategy\n",
    "if USE_TPU:\n",
    "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
    "    tf.contrib.distribute.initialize_tpu_system(resolver)\n",
    "    strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
    "\n",
    "# sklearn libs\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "# Hugging face imports\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification, TFBertForSequenceClassification\n",
    "from transformers import TFDistilBertModel, DistilBertConfig\n",
    "from transformers import DistilBertTokenizerFast, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Model parameters\n",
    "\n",
    "# Bert Model Constants\n",
    "SEQ_LEN = 64 # 128\n",
    "BATCH_SIZE = 64 # 64 32 larger batch size causes OOM errors\n",
    "EPOCHS = 10 # 3 4\n",
    "LR = 1e-5 # 2e-5\n",
    "\n",
    "# 3e-4, 1e-4, 5e-5, 3e-5\n",
    "# My own constants\n",
    "# USE_FRAME_FILTERING = False\n",
    "# UNDERSAMPLING = True\n",
    "# N_UNDERSAMPLING = 2 # ratio of how many samples from 0-class, to 1-class, e.g.: 2:1\n",
    "# USE_DS_SYNTHETIC = False\n",
    "\n",
    "USE_FRAME_FILTERING = False\n",
    "UNDERSAMPLING = True\n",
    "N_UNDERSAMPLING = 2 # ratio of how many samples from 0-class, to 1-class, e.g.: 2:1\n",
    "USE_DS_SYNTHETIC = False\n",
    "MIN_W = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1T9xPdXp_kt9"
   },
   "outputs": [],
   "source": [
    "# @title JSON to dataframe helper functions\n",
    "def undersample_df(df, n_times=3):\n",
    "    class_0,class_1 = df.category_index.value_counts()\n",
    "    c0 = df[df['category_index'] == 0]\n",
    "    c1 = df[df['category_index'] == 1]\n",
    "    df_0 = c0.sample(int(n_times * class_1))\n",
    "    \n",
    "    undersampled_df = pd.concat([df_0, c1],axis=0)\n",
    "    return undersampled_df\n",
    "\n",
    "def get_ds_synthetic_data(min_w=MIN_W):\n",
    "    short_task = {\n",
    "      \"bugzilla\": \"\"\"How to query bugs using the custom fields with the Bugzilla REST API?\"\"\",\n",
    "      \"databases\": \"\"\"Which technology should be adopted for the database layer abstraction: Object/Relational Mapping (ORM) or a Java Database Connectivity API (JDBC)?\"\"\",\n",
    "      \"gpmdpu\": \"\"\"Can I bind the cmd key to the GPMDPU shortcuts?\"\"\",\n",
    "      \"lucene\": \"\"\"How does Lucene compute similarity scores for the BM25 similarity?\"\"\",\n",
    "      \"networking\": \"\"\"Which technology should be adopted for the notification system, Server-Sent Events (SSE) or WebSockets?\"\"\",\n",
    "    }\n",
    "\n",
    "    with open('relevance_corpus.json') as ipf:\n",
    "        aux = json.load(ipf)\n",
    "        raw_data = defaultdict(list)\n",
    "        for d in aux:\n",
    "            if d['task'] == 'yargs':\n",
    "                continue\n",
    "\n",
    "            raw_data['text'].append(d['text'])\n",
    "            raw_data['question'].append(short_task[d['task']])\n",
    "            raw_data['source'].append(d['source'])\n",
    "            raw_data['category_index'].append(1 if d['weight'] > min_w else 0)\n",
    "            raw_data['weights'].append(d['weight'] if d['weight'] > min_w else 0)\n",
    " \n",
    "        data = pd.DataFrame.from_dict(raw_data)\n",
    "        data = undersample_df(data, n_times=1)\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "      \n",
    "    return data\n",
    "\n",
    "def get_class_weights(y, smooth_factor=0, upper_bound=5.0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    clazz = {cls: float(majority / count) for cls, count in counter.items()}\n",
    "    result = {}\n",
    "    for key, value in clazz.items():\n",
    "        if value > upper_bound:\n",
    "            value = upper_bound\n",
    "        \n",
    "        result[key] = value\n",
    "    return result\n",
    "\n",
    "def add_raw_data(result, data):\n",
    "    s = data['source']\n",
    "    if 'docs.oracle' in s or 'developer.android' in s:\n",
    "        source_type = 'api'\n",
    "    elif 'stackoverflow.com' in s:\n",
    "        source_type = 'so'\n",
    "    elif 'github.com' in s:\n",
    "        source_type = 'git'\n",
    "    else:\n",
    "        source_type = 'misc'\n",
    "    \n",
    "    result['text'].append(data['text'])\n",
    "    result['question'].append(data['question'])\n",
    "    result['source'].append(data['source'])\n",
    "    result['category_index'].append(data['category_index'])\n",
    "    result['weights'].append(data['weights'])\n",
    "    result['source_type'].append(source_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837,
     "referenced_widgets": [
      "8c7cf993674145ffb7bb876e5591f6ca",
      "67f208ba489343dfa195c1dd915f3efe",
      "35a9eeb0acdb44738a6ad7fbf6d99b2b",
      "153c3ed5c6314a49a5a37ad976417142",
      "82b7fc20b50c44b2bd84b3bf882cdd43",
      "16b6cfa829ad43778c079452df231a3d",
      "a2a36eb594654c65acd584d9d4ebea20",
      "3950e2a7832c4dce8fd8209d6322a1f7",
      "d32667132d604faeb419bbf9851c1bd8",
      "262cc50dd08f49f78b781c2ce96a4ad7",
      "f305b344487a4b598a7d41b007e49abd",
      "c18a3a9fc6d54b9f848e4454e1e36c21",
      "a8fd8b38a6b84be7b83b2f4df590fada",
      "5c6bfb038756422bb00be1349db7750b",
      "6cf29b5d508a4e2082751ccc7fa2f625",
      "c4c410ab0c994a229a49b8baee221de4",
      "9e99fb1211ba43459ee78dd64ab8c30e",
      "71a15c5a038f451f8ee64ce046488f71",
      "c586016d3b594c6299cab2384f4c10aa",
      "d03c894896ad4ed6b48f19a70fbdf2af",
      "3ccd384305c44ee3a86f47a2b994fbf9",
      "23531989ef014d7db16b220bb807c8fd",
      "e0e88103f9684ffdb957357222bbaaf7",
      "c5b9bf1f3ae343ce97982c7802cfdc94",
      "a66943be0fc0423880cb2bd63a1ea2d2",
      "8c2b37becdef45bba205dfb20f8e37b2",
      "baffabe6cabf48f5b0b6523ea92aee78",
      "997b8c940317448c9409a2dee15fc519",
      "b12b35cc52454a249c97f695409d24ce",
      "b6d9e21208294428a3f5572bbbd8b0b9",
      "d15e557fc621427a8295eecdc1e781a8",
      "b4276b6a5eac4023955218db6f78c84a",
      "c4b0a1b67d304afda6ee4e52095584cc",
      "901557318fb947dfa082f0cbf2d7365b",
      "0efe94b613f44c029f2e9bd05696ad32",
      "5a38bc7017d545e2b44ad6ab0b2d937b",
      "b3db733aacf94a3c94519d70a7a56d7a",
      "394b7988d36849b7b2c82872ae8d489d",
      "d3e13535de4b44bb9139c3911684cee8",
      "6ccdfb754c12418c9438ac218a172e63",
      "929799bd24fb411bb4686988f2ae8996",
      "4bd0f4c575714ad7848e818a576ee00a",
      "0466163ff4a945798423387d1ac900c8",
      "17cfaa41c53842618c728987a81a44da"
     ]
    },
    "id": "r_y7xwmxAT39",
    "outputId": "ba094ca3-4ef3-41c0-da55-0e07626c7fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# @title Tokenizer\n",
    "\n",
    "print(model_id)\n",
    "if model_id == 'distilbert-base-uncased':\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)\n",
    "else:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HdAYw7lBAmlO"
   },
   "outputs": [],
   "source": [
    "# @title data encoder\n",
    "\n",
    "def _encode(tokenizer, dataframe, max_length=SEQ_LEN):\n",
    "    \n",
    "    seq_a = dataframe['text'].tolist()\n",
    "    seq_b = dataframe['question'].tolist()\n",
    "    \n",
    "    return tokenizer(seq_a, seq_b, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "def to_one_hot_encoding(data, nb_classes = 2):\n",
    "    targets = np.array([data]).reshape(-1)\n",
    "    one_hot_targets = np.eye(nb_classes)[targets]\n",
    "    return one_hot_targets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "y-5ROuqDBU9X"
   },
   "outputs": [],
   "source": [
    "# @title Metrics & Logging functions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "recommendation_metrics = defaultdict(list)\n",
    "prediction_metrics = defaultdict(list)\n",
    "api_metrics = defaultdict(list)\n",
    "so_metrics = defaultdict(list)\n",
    "git_metrics = defaultdict(list)\n",
    "misc_metrics = defaultdict(list)\n",
    "\n",
    "classification_report_lst = []\n",
    "log_examples_lst = []\n",
    "source_lst = []\n",
    "venn_diagram_set = []\n",
    "\n",
    "def aggregate_macro_metrics(store_at, precision, recall, fscore):   \n",
    "    store_at['precision'].append(precision)\n",
    "    store_at['recall'].append(recall)\n",
    "    store_at['fscore'].append(fscore)\n",
    "    \n",
    "    \n",
    "def aggregate_macro_source_metrics(precision, recall, fscore, source):\n",
    "    s = source\n",
    "    if 'docs.oracle' in s or 'developer.android' in s:\n",
    "        aggregate_macro_metrics(api_metrics, precision, recall, fscore)\n",
    "    elif 'stackoverflow.com' in s:\n",
    "        aggregate_macro_metrics(so_metrics, precision, recall, fscore)\n",
    "    elif 'github.com' in s:\n",
    "        aggregate_macro_metrics(git_metrics, precision, recall, fscore)        \n",
    "    elif  'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
    "        aggregate_macro_metrics(misc_metrics, precision, recall, fscore)\n",
    "    \n",
    "\n",
    "def aggregate_recommendation_metrics(store_at, k, precision_at_k, pyramid_precision_at_k):\n",
    "    store_at['k'].append(k)\n",
    "    store_at['precision'].append(precision_at_k)\n",
    "    store_at['∆ precision'].append(pyramid_precision_at_k)\n",
    "    \n",
    "def aggregate_report_metrics(clz_report):\n",
    "    relevant_label = str(1)\n",
    "    if relevant_label in clz_report:\n",
    "        for _key in ['precision', 'recall']:\n",
    "            if _key in clz_report[relevant_label]:\n",
    "                clz_report_lst[_key].append(clz_report[relevant_label][_key])    \n",
    "                \n",
    "def log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10):\n",
    "    # get the predicted prob at every index\n",
    "    idx_probs = [(idx, y_predict[idx], y_probs[idx]) for idx, _ in enumerate(y_predict)]\n",
    "    \n",
    "    # filter probs for all indexes predicted as relevant  \n",
    "    idx_probs = list(filter(lambda k: k[1] == 1, idx_probs))\n",
    "    \n",
    "    most_probable = sorted(idx_probs, key=lambda i: i[2], reverse=True)\n",
    "    \n",
    "    result = [idx for idx, _, _ in most_probable][:k]\n",
    "    \n",
    "    for idx in result:\n",
    "        log_examples_lst.append((\n",
    "            source, \n",
    "            task_title,\n",
    "            pweights[idx],\n",
    "            y_predict[idx],\n",
    "            y_probs[idx],\n",
    "            text[idx]\n",
    "        ))\n",
    "        \n",
    "def log_venn_diagram(y_true, y_predicted, text):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        for _true, _predict, _t in zip(y_true, y_predicted, text):\n",
    "            if _true == 1 and _predict == 1:\n",
    "                cnt += 1\n",
    "                venn_diagram_set.append(_t)\n",
    "    except Exception as ex:\n",
    "        logger.info(str(ex))\n",
    "    logger.info(Fore.RED + str(cnt) + Style.RESET_ALL + \" entries logged\")\n",
    "\n",
    "    \n",
    "def avg_macro_metric_for(data):\n",
    "    __precision = data['precision']\n",
    "    __recall = data['recall']\n",
    "    __fscore = data['fscore']\n",
    "\n",
    "    return np.mean(__precision), np.mean(__recall), np.mean(__fscore)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4E1IN6UoPq96"
   },
   "outputs": [],
   "source": [
    "#@title Training procedures\n",
    "\n",
    "def get_train_val_test(task_uid, size=0.9, undersample=False, aug=True, undersample_n=3):\n",
    "    if not isinstance(task_uid, list):\n",
    "        task_uid = [task_uid]\n",
    "        \n",
    "    train_data_raw = defaultdict(list)\n",
    "    test_data_raw = defaultdict(list)\n",
    "    \n",
    "    for _data in tqdm(CORPUS):\n",
    "        if _data['question'] in task_uid:\n",
    "            add_raw_data(test_data_raw, _data)\n",
    "        else:\n",
    "            add_raw_data(train_data_raw, _data)\n",
    "    \n",
    "    train_val = pd.DataFrame.from_dict(train_data_raw)\n",
    "    test = pd.DataFrame.from_dict(test_data_raw)\n",
    "    \n",
    "    # https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "    #  randomize rows....    \n",
    "    train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "    test = test.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    if undersample:\n",
    "        train_val = undersample_df(train_val, n_times=undersample_n)\n",
    "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    if aug:\n",
    "        train_val = pd.concat([train_val, get_ds_synthetic_data()],axis=0)\n",
    "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    weights = get_class_weights(train_val['category_index'].tolist())\n",
    "    \n",
    "    train, val = train_test_split(\n",
    "        train_val, \n",
    "        stratify=train_val['category_index'].tolist(), \n",
    "        train_size=size\n",
    "    )\n",
    "    \n",
    "    return train, val, test, weights        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_predictions(task_title, text, y_predict, y_probs, relevant_class=1):\n",
    "    result = []\n",
    "    \n",
    "    for _t, _y, _prob in zip(text, y_predict, y_probs):\n",
    "        if _y == relevant_class:\n",
    "            if has_meaningful_frame(_t):\n",
    "                result.append(_y)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        else:\n",
    "            result.append(_y)\n",
    "    \n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vFePvH5vBVA7"
   },
   "outputs": [],
   "source": [
    "# @title Testing procedures\n",
    "\n",
    "# https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7\n",
    "def eval_model(model, test_data):\n",
    "    preds = model.predict(test_data.batch(1)).logits  \n",
    "    \n",
    "    #transform to array with probabilities\n",
    "    res = tf.nn.softmax(preds, axis=1).numpy()      \n",
    "\n",
    "    return res.argmax(axis=-1), res[:, 1]\n",
    "\n",
    "def test_model(source, df_test, model, tokenizer, pos_filter=False):\n",
    "    \n",
    "    df_source = df_test[df_test[\"source\"] == source]   \n",
    "    task_title = df_source['question'].tolist()[0]\n",
    "    text = df_source['text'].tolist()\n",
    "    pweights = df_source['weights'].tolist()\n",
    "    \n",
    "    # Encode X_test\n",
    "    test_encodings = _encode(tokenizer, df_source)\n",
    "    test_labels = df_source['category_index'].tolist()\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        dict(test_encodings),\n",
    "        test_labels\n",
    "    ))\n",
    "    \n",
    "    y_true = [y.numpy() for x, y in test_dataset]\n",
    "    y_predict, y_probs = eval_model(model, test_dataset)\n",
    "    \n",
    "    if pos_filter:\n",
    "        y_predict = update_predictions(task_title, text, y_predict, y_probs)\n",
    "    \n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_predict)\n",
    "    macro_f1 = f1_score(y_true, y_predict, average='macro')\n",
    "    \n",
    "    classification_report_lst.append(classification_report(y_true, y_predict))\n",
    "    aggregate_report_metrics(classification_report(y_true, y_predict, output_dict=True))\n",
    "    \n",
    "\n",
    "    logger.info(\"-\" * 20)    \n",
    "    \n",
    "    logger.info(\"Y\")\n",
    "    logger.info(\"[0s] {} [1s] {}\".format(\n",
    "        len(list(filter(lambda k: k== 0, y_true))),\n",
    "        len(list(filter(lambda k: k== 1, y_true)))\n",
    "    ))\n",
    "    \n",
    "        \n",
    "    logger.info(\"predicted\")\n",
    "    logger.info(\"[0s] {} [1s] {}\".format(\n",
    "        len(list(filter(lambda k: k== 0, y_predict))),\n",
    "        len(list(filter(lambda k: k== 1, y_predict)))\n",
    "    ))\n",
    "    \n",
    "    logger.info(\"-\" * 20)\n",
    "    \n",
    "    logger.info(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "    logger.info(\"macro_f1: {:.4f}\".format(macro_f1))\n",
    "\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(y_true, y_predict, average='macro')\n",
    "    \n",
    "    aggregate_macro_metrics(prediction_metrics, precision, recall, fscore)\n",
    "    aggregate_macro_source_metrics(precision, recall, fscore, source)\n",
    "    \n",
    "    logger.info(\"Precision: {:.4f}\".format(precision))\n",
    "    logger.info(\"Recall: {:.4f}\".format(recall))\n",
    "    logger.info(\"F1: {:.4f}\".format(fscore))\n",
    "    \n",
    "    log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10)\n",
    "    log_venn_diagram(y_true, y_predict, text)\n",
    "    source_lst.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_idx_fold_results(idx_split, store_at):\n",
    "    if idx_split not in store_at:\n",
    "        store_at[idx_split] = dict()\n",
    "        store_at[idx_split]['run_cnt'] = 0\n",
    "        store_at[idx_split]['overall'] = defaultdict(list)\n",
    "        store_at[idx_split]['api'] = defaultdict(list)\n",
    "        store_at[idx_split]['so'] = defaultdict(list)\n",
    "        store_at[idx_split]['git'] = defaultdict(list)\n",
    "        store_at[idx_split]['misc'] = defaultdict(list)\n",
    "    \n",
    "    store_at[idx_split]['run_cnt'] += 1\n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "    store_at[idx_split]['overall']['precision'].append(_precision)\n",
    "    store_at[idx_split]['overall']['recall'].append(_recall)\n",
    "    store_at[idx_split]['overall']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(api_metrics)\n",
    "    store_at[idx_split]['api']['precision'].append(_precision)\n",
    "    store_at[idx_split]['api']['recall'].append(_recall)\n",
    "    store_at[idx_split]['api']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(so_metrics)\n",
    "    store_at[idx_split]['so']['precision'].append(_precision)\n",
    "    store_at[idx_split]['so']['recall'].append(_recall)\n",
    "    store_at[idx_split]['so']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(git_metrics)\n",
    "    store_at[idx_split]['git']['precision'].append(_precision)\n",
    "    store_at[idx_split]['git']['recall'].append(_recall)\n",
    "    store_at[idx_split]['git']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(misc_metrics)\n",
    "    store_at[idx_split]['misc']['precision'].append(_precision)\n",
    "    store_at[idx_split]['misc']['recall'].append(_recall)\n",
    "    store_at[idx_split]['misc']['fscore'].append(_f1score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TFBertForSequenceClassification.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "03ddd131c9f0446eb83bb6dabee9a832",
      "3518f71b0e4540be8b17a3fe72182cb4",
      "a5ccb838d3704546937e925e456830be",
      "8181fd24b3624c1b9c6a9d0302f43a56",
      "f02cf8090f8d463eb7eeb59743a87276",
      "c9ef3ce0ace649c5a53e2244ba0dbb32",
      "702a74b6e6e44d6b8ad68347f1a4b5fb",
      "3d84c022c44141268ef2c8d5e0190404",
      "40c212c9b352401697860624a6c54b1c",
      "1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "911177bb86c749a0bd774cd3b7f9d302"
     ]
    },
    "id": "1oZGDUKnB1gw",
    "outputId": "21690a29-4add-4780-f87f-fa497b87d5e1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mi=0\u001b[0m\n",
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n",
      "Hide MarkerView when nothing selected\n",
      "How to check programmatically whether app is running in debug mode or not?\n",
      "JSONObject parse dictionary objects\n",
      "Want to add drawable icons insteadof colorful dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "100%|██████████| 7918/7918 [00:00<00:00, 860331.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1659\n",
      "1     830\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    664\n",
      "1     71\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2b2ffb0193d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2b2ffb0193d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9392 - sparse_categorical_accuracy: 0.5882The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63149, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 18s 464ms/step - loss: 0.9392 - sparse_categorical_accuracy: 0.5882 - val_loss: 0.6315 - val_sparse_categorical_accuracy: 0.6462\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8502 - sparse_categorical_accuracy: 0.6501\n",
      "Epoch 00002: val_loss did not improve from 0.63149\n",
      "39/39 [==============================] - 10s 261ms/step - loss: 0.8502 - sparse_categorical_accuracy: 0.6501 - val_loss: 0.6376 - val_sparse_categorical_accuracy: 0.6426\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7856 - sparse_categorical_accuracy: 0.6975\n",
      "Epoch 00003: val_loss improved from 0.63149 to 0.60136, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 15s 374ms/step - loss: 0.7856 - sparse_categorical_accuracy: 0.6975 - val_loss: 0.6014 - val_sparse_categorical_accuracy: 0.6606\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7345 - sparse_categorical_accuracy: 0.7360\n",
      "Epoch 00004: val_loss did not improve from 0.60136\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.7345 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.6147 - val_sparse_categorical_accuracy: 0.6679\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6716 - sparse_categorical_accuracy: 0.7630\n",
      "Epoch 00005: val_loss did not improve from 0.60136\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.6716 - sparse_categorical_accuracy: 0.7630 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.6318\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5926 - sparse_categorical_accuracy: 0.7979\n",
      "Epoch 00006: val_loss did not improve from 0.60136\n",
      "39/39 [==============================] - 10s 263ms/step - loss: 0.5926 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.6338 - val_sparse_categorical_accuracy: 0.7076\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4957 - sparse_categorical_accuracy: 0.8453Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.60136\n",
      "39/39 [==============================] - 11s 269ms/step - loss: 0.4957 - sparse_categorical_accuracy: 0.8453 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.6643\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 276 [1s] 7\n",
      "predicted\n",
      "[0s] 168 [1s] 115\n",
      "--------------------\n",
      "Accuracy: 0.5830\n",
      "macro_f1: 0.3835\n",
      "Precision: 0.4938\n",
      "Recall: 0.4381\n",
      "F1: 0.3835\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "--------------------\n",
      "Y\n",
      "[0s] 28 [1s] 8\n",
      "predicted\n",
      "[0s] 20 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.5556\n",
      "macro_f1: 0.5000\n",
      "Precision: 0.5250\n",
      "Recall: 0.5357\n",
      "F1: 0.5000\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "--------------------\n",
      "Y\n",
      "[0s] 172 [1s] 7\n",
      "predicted\n",
      "[0s] 91 [1s] 88\n",
      "--------------------\n",
      "Accuracy: 0.5251\n",
      "macro_f1: 0.3910\n",
      "Precision: 0.5174\n",
      "Recall: 0.6159\n",
      "F1: 0.3910\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 82 [1s] 22\n",
      "predicted\n",
      "[0s] 47 [1s] 57\n",
      "--------------------\n",
      "Accuracy: 0.5288\n",
      "macro_f1: 0.5000\n",
      "Precision: 0.5571\n",
      "Recall: 0.5848\n",
      "F1: 0.5000\n",
      "\u001b[31m15\u001b[0m entries logged\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "--------------------\n",
      "Y\n",
      "[0s] 40 [1s] 5\n",
      "predicted\n",
      "[0s] 38 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.7333\n",
      "macro_f1: 0.4231\n",
      "Precision: 0.4342\n",
      "Recall: 0.4125\n",
      "F1: 0.4231\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 8\n",
      "predicted\n",
      "[0s] 15 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.6129\n",
      "macro_f1: 0.5921\n",
      "Precision: 0.6208\n",
      "Recall: 0.6576\n",
      "F1: 0.5921\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/23844667\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 5\n",
      "predicted\n",
      "[0s] 16 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.6071\n",
      "macro_f1: 0.5354\n",
      "Precision: 0.5625\n",
      "Recall: 0.6043\n",
      "F1: 0.5354\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/33241952\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 8 [1s] 4\n",
      "predicted\n",
      "[0s] 10 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.8333\n",
      "macro_f1: 0.7778\n",
      "Precision: 0.9000\n",
      "Recall: 0.7500\n",
      "F1: 0.7778\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/37096547\n",
      "--------------------\n",
      "Y\n",
      "[0s] 12 [1s] 5\n",
      "predicted\n",
      "[0s] 14 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.7647\n",
      "macro_f1: 0.6731\n",
      "Precision: 0.7262\n",
      "Recall: 0.6583\n",
      "F1: 0.6731\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.593\u001b[0m\n",
      "recall:    \u001b[31m0.584\u001b[0m\n",
      "f1-score:  \u001b[31m0.531\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.525\u001b[0m\n",
      "recall:    \u001b[31m0.511\u001b[0m\n",
      "f1-score:  \u001b[31m0.442\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.730\u001b[0m\n",
      "recall:    \u001b[31m0.671\u001b[0m\n",
      "f1-score:  \u001b[31m0.662\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.480\u001b[0m\n",
      "recall:    \u001b[31m0.474\u001b[0m\n",
      "f1-score:  \u001b[31m0.462\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.569\u001b[0m\n",
      "recall:    \u001b[31m0.637\u001b[0m\n",
      "f1-score:  \u001b[31m0.492\u001b[0m\n",
      "\n",
      "\u001b[31mFold 1\u001b[0m\n",
      " height must be > 0\n",
      "Write and Read a json data to internal storage android\n",
      "Android PDF Rendering\n",
      "How can I hide a fragment on start of my MainActivity( or the application)?\n",
      "polymorphic deserialization of JSON with jackson, property type becomes &quot;null&quot;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 856006.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1605\n",
      "1     803\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    659\n",
      "1    101\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.9287 - sparse_categorical_accuracy: 0.5901The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66488, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 16s 429ms/step - loss: 0.9287 - sparse_categorical_accuracy: 0.5901 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.6082\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.8090 - sparse_categorical_accuracy: 0.6827\n",
      "Epoch 00002: val_loss improved from 0.66488 to 0.60778, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 15s 391ms/step - loss: 0.8090 - sparse_categorical_accuracy: 0.6827 - val_loss: 0.6078 - val_sparse_categorical_accuracy: 0.6791\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.7323 - sparse_categorical_accuracy: 0.7338\n",
      "Epoch 00003: val_loss did not improve from 0.60778\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.7323 - sparse_categorical_accuracy: 0.7338 - val_loss: 0.6157 - val_sparse_categorical_accuracy: 0.6828\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6643 - sparse_categorical_accuracy: 0.7782\n",
      "Epoch 00004: val_loss did not improve from 0.60778\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.6643 - sparse_categorical_accuracy: 0.7782 - val_loss: 0.6220 - val_sparse_categorical_accuracy: 0.6903\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5674 - sparse_categorical_accuracy: 0.8301\n",
      "Epoch 00005: val_loss improved from 0.60778 to 0.58711, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 20s 532ms/step - loss: 0.5674 - sparse_categorical_accuracy: 0.8301 - val_loss: 0.5871 - val_sparse_categorical_accuracy: 0.7127\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4764 - sparse_categorical_accuracy: 0.8650\n",
      "Epoch 00006: val_loss did not improve from 0.58711\n",
      "38/38 [==============================] - 10s 259ms/step - loss: 0.4764 - sparse_categorical_accuracy: 0.8650 - val_loss: 0.6375 - val_sparse_categorical_accuracy: 0.6978\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3906 - sparse_categorical_accuracy: 0.8941\n",
      "Epoch 00007: val_loss did not improve from 0.58711\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.3906 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.6397 - val_sparse_categorical_accuracy: 0.7201\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3139 - sparse_categorical_accuracy: 0.9252\n",
      "Epoch 00008: val_loss did not improve from 0.58711\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.3139 - sparse_categorical_accuracy: 0.9252 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.7276\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2562 - sparse_categorical_accuracy: 0.9406Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.58711\n",
      "38/38 [==============================] - 10s 266ms/step - loss: 0.2562 - sparse_categorical_accuracy: 0.9406 - val_loss: 0.7149 - val_sparse_categorical_accuracy: 0.7201\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/2883355\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 19 [1s] 5\n",
      "predicted\n",
      "[0s] 14 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5417\n",
      "macro_f1: 0.4667\n",
      "Precision: 0.4929\n",
      "Recall: 0.4895\n",
      "F1: 0.4667\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/creating-and-using-fragments\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 132 [1s] 31\n",
      "predicted\n",
      "[0s] 127 [1s] 36\n",
      "--------------------\n",
      "Accuracy: 0.6871\n",
      "macro_f1: 0.5209\n",
      "Precision: 0.5206\n",
      "Recall: 0.5230\n",
      "F1: 0.5209\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "--------------------\n",
      "Y\n",
      "[0s] 242 [1s] 7\n",
      "predicted\n",
      "[0s] 84 [1s] 165\n",
      "--------------------\n",
      "Accuracy: 0.3574\n",
      "macro_f1: 0.2895\n",
      "Precision: 0.5122\n",
      "Recall: 0.6001\n",
      "F1: 0.2895\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "--------------------\n",
      "Y\n",
      "[0s] 66 [1s] 6\n",
      "predicted\n",
      "[0s] 68 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.8611\n",
      "macro_f1: 0.4627\n",
      "Precision: 0.4559\n",
      "Recall: 0.4697\n",
      "F1: 0.4627\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 8\n",
      "predicted\n",
      "[0s] 15 [1s] 29\n",
      "--------------------\n",
      "Accuracy: 0.3864\n",
      "macro_f1: 0.3704\n",
      "Precision: 0.4862\n",
      "Recall: 0.4792\n",
      "F1: 0.3704\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 5\n",
      "predicted\n",
      "[0s] 6 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6875\n",
      "macro_f1: 0.6863\n",
      "Precision: 0.7500\n",
      "Recall: 0.7727\n",
      "F1: 0.6863\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30362446\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 8\n",
      "predicted\n",
      "[0s] 28 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.7143\n",
      "macro_f1: 0.6305\n",
      "Precision: 0.6250\n",
      "Recall: 0.6801\n",
      "F1: 0.6305\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "--------------------\n",
      "Y\n",
      "[0s] 53 [1s] 3\n",
      "predicted\n",
      "[0s] 28 [1s] 28\n",
      "--------------------\n",
      "Accuracy: 0.5179\n",
      "macro_f1: 0.3978\n",
      "Precision: 0.5179\n",
      "Recall: 0.5881\n",
      "F1: 0.3978\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 17 [1s] 7\n",
      "predicted\n",
      "[0s] 14 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6250\n",
      "macro_f1: 0.5901\n",
      "Precision: 0.5929\n",
      "Recall: 0.6092\n",
      "F1: 0.5901\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/14347588\n",
      "--------------------\n",
      "Y\n",
      "[0s] 20 [1s] 5\n",
      "predicted\n",
      "[0s] 21 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.7200\n",
      "macro_f1: 0.5257\n",
      "Precision: 0.5298\n",
      "Recall: 0.5250\n",
      "F1: 0.5257\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "--------------------\n",
      "Y\n",
      "[0s] 26 [1s] 10\n",
      "predicted\n",
      "[0s] 24 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.7778\n",
      "macro_f1: 0.7382\n",
      "Precision: 0.7292\n",
      "Recall: 0.7538\n",
      "F1: 0.7382\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/38980595\n",
      "--------------------\n",
      "Y\n",
      "[0s] 2 [1s] 3\n",
      "predicted\n",
      "[0s] 3 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.4000\n",
      "macro_f1: 0.4000\n",
      "Precision: 0.4167\n",
      "Recall: 0.4167\n",
      "F1: 0.4000\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/40168601\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 1 [1s] 3\n",
      "predicted\n",
      "[0s] 2 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.7500\n",
      "macro_f1: 0.7333\n",
      "Precision: 0.7500\n",
      "Recall: 0.8333\n",
      "F1: 0.7333\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.568\u001b[0m\n",
      "recall:    \u001b[31m0.595\u001b[0m\n",
      "f1-score:  \u001b[31m0.524\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.493\u001b[0m\n",
      "recall:    \u001b[31m0.534\u001b[0m\n",
      "f1-score:  \u001b[31m0.380\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.563\u001b[0m\n",
      "recall:    \u001b[31m0.589\u001b[0m\n",
      "f1-score:  \u001b[31m0.551\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.729\u001b[0m\n",
      "recall:    \u001b[31m0.754\u001b[0m\n",
      "f1-score:  \u001b[31m0.738\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.621\u001b[0m\n",
      "recall:    \u001b[31m0.635\u001b[0m\n",
      "f1-score:  \u001b[31m0.599\u001b[0m\n",
      "\n",
      "\u001b[31mFold 2\u001b[0m\n",
      "How to Integrate reCAPTCHA 2.0 in Android\n",
      "How can I make this rxjava zip to run in parallel?\n",
      "Permission Denial when trying to access contacts in Android\n",
      "keyUp called when key is still pressed\n",
      "Don’t leak MockWebServer ports across tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 848440.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1463\n",
      "1     732\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1178\n",
      "1     180\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9235 - sparse_categorical_accuracy: 0.6009The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67841, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 18s 504ms/step - loss: 0.9235 - sparse_categorical_accuracy: 0.6009 - val_loss: 0.6784 - val_sparse_categorical_accuracy: 0.5246\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8553 - sparse_categorical_accuracy: 0.6228\n",
      "Epoch 00002: val_loss improved from 0.67841 to 0.61994, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 13s 378ms/step - loss: 0.8553 - sparse_categorical_accuracy: 0.6228 - val_loss: 0.6199 - val_sparse_categorical_accuracy: 0.6844\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7724 - sparse_categorical_accuracy: 0.7048\n",
      "Epoch 00003: val_loss did not improve from 0.61994\n",
      "35/35 [==============================] - 9s 256ms/step - loss: 0.7724 - sparse_categorical_accuracy: 0.7048 - val_loss: 0.6280 - val_sparse_categorical_accuracy: 0.6844\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6965 - sparse_categorical_accuracy: 0.7499\n",
      "Epoch 00004: val_loss did not improve from 0.61994\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.6965 - sparse_categorical_accuracy: 0.7499 - val_loss: 0.6299 - val_sparse_categorical_accuracy: 0.6762\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6287 - sparse_categorical_accuracy: 0.7886\n",
      "Epoch 00005: val_loss did not improve from 0.61994\n",
      "35/35 [==============================] - 9s 256ms/step - loss: 0.6287 - sparse_categorical_accuracy: 0.7886 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.6189\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.5336 - sparse_categorical_accuracy: 0.8351Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.61994\n",
      "35/35 [==============================] - 9s 262ms/step - loss: 0.5336 - sparse_categorical_accuracy: 0.8351 - val_loss: 0.6588 - val_sparse_categorical_accuracy: 0.7049\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 69 [1s] 3\n",
      "predicted\n",
      "[0s] 59 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.8611\n",
      "macro_f1: 0.6484\n",
      "Precision: 0.6154\n",
      "Recall: 0.9275\n",
      "F1: 0.6484\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "--------------------\n",
      "Y\n",
      "[0s] 152 [1s] 9\n",
      "predicted\n",
      "[0s] 94 [1s] 67\n",
      "--------------------\n",
      "Accuracy: 0.6398\n",
      "macro_f1: 0.5005\n",
      "Precision: 0.5672\n",
      "Recall: 0.8092\n",
      "F1: 0.5005\n",
      "\u001b[31m9\u001b[0m entries logged\n",
      "https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "--------------------\n",
      "Y\n",
      "[0s] 368 [1s] 5\n",
      "predicted\n",
      "[0s] 371 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.9812\n",
      "macro_f1: 0.4953\n",
      "Precision: 0.4933\n",
      "Recall: 0.4973\n",
      "F1: 0.4953\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "--------------------\n",
      "Y\n",
      "[0s] 201 [1s] 18\n",
      "predicted\n",
      "[0s] 154 [1s] 65\n",
      "--------------------\n",
      "Accuracy: 0.7123\n",
      "macro_f1: 0.5317\n",
      "Precision: 0.5509\n",
      "Recall: 0.6410\n",
      "F1: 0.5317\n",
      "\u001b[31m10\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/35357919\n",
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 12\n",
      "predicted\n",
      "[0s] 52 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.7925\n",
      "macro_f1: 0.5178\n",
      "Precision: 0.8942\n",
      "Recall: 0.5417\n",
      "F1: 0.5178\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/training/permissions/requesting\n",
      "--------------------\n",
      "Y\n",
      "[0s] 90 [1s] 39\n",
      "predicted\n",
      "[0s] 38 [1s] 91\n",
      "--------------------\n",
      "Accuracy: 0.5039\n",
      "macro_f1: 0.5038\n",
      "Precision: 0.6024\n",
      "Recall: 0.6009\n",
      "F1: 0.5038\n",
      "\u001b[31m33\u001b[0m entries logged\n",
      "https://developer.android.com/training/safetynet/recaptcha\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 20\n",
      "predicted\n",
      "[0s] 34 [1s] 20\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.6426\n",
      "Precision: 0.6426\n",
      "Recall: 0.6426\n",
      "F1: 0.6426\n",
      "\u001b[31m11\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/27297067\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 10 [1s] 11\n",
      "predicted\n",
      "[0s] 15 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.5714\n",
      "macro_f1: 0.5553\n",
      "Precision: 0.6000\n",
      "Recall: 0.5818\n",
      "F1: 0.5553\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 3\n",
      "predicted\n",
      "[0s] 3 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.4286\n",
      "macro_f1: 0.4286\n",
      "Precision: 0.6364\n",
      "Recall: 0.6364\n",
      "F1: 0.4286\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "--------------------\n",
      "Y\n",
      "[0s] 106 [1s] 11\n",
      "predicted\n",
      "[0s] 109 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.8376\n",
      "macro_f1: 0.4558\n",
      "Precision: 0.4495\n",
      "Recall: 0.4623\n",
      "F1: 0.4558\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/5233543\n",
      "--------------------\n",
      "Y\n",
      "[0s] 7 [1s] 14\n",
      "predicted\n",
      "[0s] 7 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.7143\n",
      "macro_f1: 0.6786\n",
      "Precision: 0.6786\n",
      "Recall: 0.6786\n",
      "F1: 0.6786\n",
      "\u001b[31m11\u001b[0m entries logged\n",
      "https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "--------------------\n",
      "Y\n",
      "[0s] 30 [1s] 4\n",
      "predicted\n",
      "[0s] 20 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.5882\n",
      "macro_f1: 0.4711\n",
      "Precision: 0.5214\n",
      "Recall: 0.5500\n",
      "F1: 0.4711\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 27\n",
      "predicted\n",
      "[0s] 8 [1s] 55\n",
      "--------------------\n",
      "Accuracy: 0.4921\n",
      "macro_f1: 0.4412\n",
      "Precision: 0.6023\n",
      "Recall: 0.5463\n",
      "F1: 0.4412\n",
      "\u001b[31m25\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24952513\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 4\n",
      "predicted\n",
      "[0s] 16 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.5846\n",
      "Precision: 0.6051\n",
      "Recall: 0.7011\n",
      "F1: 0.5846\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.604\u001b[0m\n",
      "recall:    \u001b[31m0.630\u001b[0m\n",
      "f1-score:  \u001b[31m0.533\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.594\u001b[0m\n",
      "recall:    \u001b[31m0.594\u001b[0m\n",
      "f1-score:  \u001b[31m0.518\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.694\u001b[0m\n",
      "recall:    \u001b[31m0.626\u001b[0m\n",
      "f1-score:  \u001b[31m0.584\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.521\u001b[0m\n",
      "recall:    \u001b[31m0.550\u001b[0m\n",
      "f1-score:  \u001b[31m0.471\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.557\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:    \u001b[31m0.677\u001b[0m\n",
      "f1-score:  \u001b[31m0.516\u001b[0m\n",
      "\u001b[33mi=1\u001b[0m\n",
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n",
      "Hide MarkerView when nothing selected\n",
      "How to check programmatically whether app is running in debug mode or not?\n",
      "JSONObject parse dictionary objects\n",
      "Want to add drawable icons insteadof colorful dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 824122.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1659\n",
      "1     830\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    664\n",
      "1     71\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9114 - sparse_categorical_accuracy: 0.5958The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62363, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 19s 495ms/step - loss: 0.9114 - sparse_categorical_accuracy: 0.5958 - val_loss: 0.6236 - val_sparse_categorical_accuracy: 0.6931\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8248 - sparse_categorical_accuracy: 0.6609\n",
      "Epoch 00002: val_loss improved from 0.62363 to 0.55935, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 343ms/step - loss: 0.8248 - sparse_categorical_accuracy: 0.6609 - val_loss: 0.5594 - val_sparse_categorical_accuracy: 0.7256\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7368 - sparse_categorical_accuracy: 0.7107\n",
      "Epoch 00003: val_loss improved from 0.55935 to 0.55786, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 21s 531ms/step - loss: 0.7368 - sparse_categorical_accuracy: 0.7107 - val_loss: 0.5579 - val_sparse_categorical_accuracy: 0.7220\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6484 - sparse_categorical_accuracy: 0.7549\n",
      "Epoch 00004: val_loss improved from 0.55786 to 0.54992, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 346ms/step - loss: 0.6484 - sparse_categorical_accuracy: 0.7549 - val_loss: 0.5499 - val_sparse_categorical_accuracy: 0.7220\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5634 - sparse_categorical_accuracy: 0.8059\n",
      "Epoch 00005: val_loss did not improve from 0.54992\n",
      "39/39 [==============================] - 10s 261ms/step - loss: 0.5634 - sparse_categorical_accuracy: 0.8059 - val_loss: 0.5504 - val_sparse_categorical_accuracy: 0.7473\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4514 - sparse_categorical_accuracy: 0.8546\n",
      "Epoch 00006: val_loss did not improve from 0.54992\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.4514 - sparse_categorical_accuracy: 0.8546 - val_loss: 0.6349 - val_sparse_categorical_accuracy: 0.7004\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.3665 - sparse_categorical_accuracy: 0.8947\n",
      "Epoch 00007: val_loss did not improve from 0.54992\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.3665 - sparse_categorical_accuracy: 0.8947 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.7076\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.2965 - sparse_categorical_accuracy: 0.9213Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.54992\n",
      "39/39 [==============================] - 11s 269ms/step - loss: 0.2965 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.7292\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 28 [1s] 8\n",
      "predicted\n",
      "[0s] 18 [1s] 18\n",
      "--------------------\n",
      "Accuracy: 0.6111\n",
      "macro_f1: 0.5786\n",
      "Precision: 0.6111\n",
      "Recall: 0.6607\n",
      "F1: 0.5786\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 82 [1s] 22\n",
      "predicted\n",
      "[0s] 17 [1s] 87\n",
      "--------------------\n",
      "Accuracy: 0.3750\n",
      "macro_f1: 0.3736\n",
      "Precision: 0.6264\n",
      "Recall: 0.6037\n",
      "F1: 0.3736\n",
      "\u001b[31m22\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 8\n",
      "predicted\n",
      "[0s] 22 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.7097\n",
      "macro_f1: 0.6353\n",
      "Precision: 0.6313\n",
      "Recall: 0.6413\n",
      "F1: 0.6353\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "--------------------\n",
      "Y\n",
      "[0s] 276 [1s] 7\n",
      "predicted\n",
      "[0s] 202 [1s] 81\n",
      "--------------------\n",
      "Accuracy: 0.6961\n",
      "macro_f1: 0.4214\n",
      "Precision: 0.4913\n",
      "Recall: 0.4265\n",
      "F1: 0.4214\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "--------------------\n",
      "Y\n",
      "[0s] 40 [1s] 5\n",
      "predicted\n",
      "[0s] 38 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.7333\n",
      "macro_f1: 0.4231\n",
      "Precision: 0.4342\n",
      "Recall: 0.4125\n",
      "F1: 0.4231\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "--------------------\n",
      "Y\n",
      "[0s] 172 [1s] 7\n",
      "predicted\n",
      "[0s] 128 [1s] 51\n",
      "--------------------\n",
      "Accuracy: 0.6983\n",
      "macro_f1: 0.4445\n",
      "Precision: 0.5001\n",
      "Recall: 0.5004\n",
      "F1: 0.4445\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/23844667\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 5\n",
      "predicted\n",
      "[0s] 12 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.5357\n",
      "macro_f1: 0.5048\n",
      "Precision: 0.5833\n",
      "Recall: 0.6391\n",
      "F1: 0.5048\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/37096547\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 12 [1s] 5\n",
      "predicted\n",
      "[0s] 14 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.7647\n",
      "macro_f1: 0.6731\n",
      "Precision: 0.7262\n",
      "Recall: 0.6583\n",
      "F1: 0.6731\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/33241952\n",
      "--------------------\n",
      "Y\n",
      "[0s] 8 [1s] 4\n",
      "predicted\n",
      "[0s] 8 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.6250\n",
      "Precision: 0.6250\n",
      "Recall: 0.6250\n",
      "F1: 0.6250\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.581\u001b[0m\n",
      "recall:    \u001b[31m0.574\u001b[0m\n",
      "f1-score:  \u001b[31m0.520\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.559\u001b[0m\n",
      "recall:    \u001b[31m0.515\u001b[0m\n",
      "f1-score:  \u001b[31m0.397\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.645\u001b[0m\n",
      "recall:    \u001b[31m0.641\u001b[0m\n",
      "f1-score:  \u001b[31m0.601\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.523\u001b[0m\n",
      "recall:    \u001b[31m0.537\u001b[0m\n",
      "f1-score:  \u001b[31m0.501\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.566\u001b[0m\n",
      "recall:    \u001b[31m0.571\u001b[0m\n",
      "f1-score:  \u001b[31m0.540\u001b[0m\n",
      "\n",
      "\u001b[31mFold 1\u001b[0m\n",
      " height must be > 0\n",
      "Write and Read a json data to internal storage android\n",
      "Android PDF Rendering\n",
      "How can I hide a fragment on start of my MainActivity( or the application)?\n",
      "polymorphic deserialization of JSON with jackson, property type becomes &quot;null&quot;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 817207.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1605\n",
      "1     803\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    659\n",
      "1    101\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.9304 - sparse_categorical_accuracy: 0.5208The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68739, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 15s 408ms/step - loss: 0.9304 - sparse_categorical_accuracy: 0.5208 - val_loss: 0.6874 - val_sparse_categorical_accuracy: 0.5485\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.9033 - sparse_categorical_accuracy: 0.6167\n",
      "Epoch 00002: val_loss improved from 0.68739 to 0.65358, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 13s 339ms/step - loss: 0.9033 - sparse_categorical_accuracy: 0.6167 - val_loss: 0.6536 - val_sparse_categorical_accuracy: 0.6119\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.8243 - sparse_categorical_accuracy: 0.6690\n",
      "Epoch 00003: val_loss improved from 0.65358 to 0.58870, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 13s 331ms/step - loss: 0.8243 - sparse_categorical_accuracy: 0.6690 - val_loss: 0.5887 - val_sparse_categorical_accuracy: 0.6828\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.7537 - sparse_categorical_accuracy: 0.7263\n",
      "Epoch 00004: val_loss improved from 0.58870 to 0.54187, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 13s 353ms/step - loss: 0.7537 - sparse_categorical_accuracy: 0.7263 - val_loss: 0.5419 - val_sparse_categorical_accuracy: 0.7164\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6906 - sparse_categorical_accuracy: 0.7488\n",
      "Epoch 00005: val_loss improved from 0.54187 to 0.53147, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 19s 497ms/step - loss: 0.6906 - sparse_categorical_accuracy: 0.7488 - val_loss: 0.5315 - val_sparse_categorical_accuracy: 0.7388\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5872 - sparse_categorical_accuracy: 0.8015\n",
      "Epoch 00006: val_loss improved from 0.53147 to 0.52896, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 0.5872 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.5290 - val_sparse_categorical_accuracy: 0.7575\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5158 - sparse_categorical_accuracy: 0.8277\n",
      "Epoch 00007: val_loss did not improve from 0.52896\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.5158 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.5391 - val_sparse_categorical_accuracy: 0.7612\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4188 - sparse_categorical_accuracy: 0.8746\n",
      "Epoch 00008: val_loss did not improve from 0.52896\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.4188 - sparse_categorical_accuracy: 0.8746 - val_loss: 0.5910 - val_sparse_categorical_accuracy: 0.7388\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3480 - sparse_categorical_accuracy: 0.8978\n",
      "Epoch 00009: val_loss did not improve from 0.52896\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.3480 - sparse_categorical_accuracy: 0.8978 - val_loss: 0.6442 - val_sparse_categorical_accuracy: 0.7351\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2557 - sparse_categorical_accuracy: 0.9306Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.52896\n",
      "38/38 [==============================] - 10s 267ms/step - loss: 0.2557 - sparse_categorical_accuracy: 0.9306 - val_loss: 0.6983 - val_sparse_categorical_accuracy: 0.7500\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 242 [1s] 7\n",
      "predicted\n",
      "[0s] 170 [1s] 79\n",
      "--------------------\n",
      "Accuracy: 0.6867\n",
      "macro_f1: 0.4519\n",
      "Precision: 0.5165\n",
      "Recall: 0.6308\n",
      "F1: 0.4519\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/creating-and-using-fragments\n",
      "--------------------\n",
      "Y\n",
      "[0s] 132 [1s] 31\n",
      "predicted\n",
      "[0s] 53 [1s] 110\n",
      "--------------------\n",
      "Accuracy: 0.4172\n",
      "macro_f1: 0.4064\n",
      "Precision: 0.5291\n",
      "Recall: 0.5414\n",
      "F1: 0.4064\n",
      "\u001b[31m23\u001b[0m entries logged\n",
      "https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 17 [1s] 7\n",
      "predicted\n",
      "[0s] 5 [1s] 19\n",
      "--------------------\n",
      "Accuracy: 0.5000\n",
      "macro_f1: 0.4965\n",
      "Precision: 0.6842\n",
      "Recall: 0.6471\n",
      "F1: 0.4965\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/14347588\n",
      "--------------------\n",
      "Y\n",
      "[0s] 20 [1s] 5\n",
      "predicted\n",
      "[0s] 15 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6400\n",
      "macro_f1: 0.5714\n",
      "Precision: 0.5833\n",
      "Recall: 0.6250\n",
      "F1: 0.5714\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 8\n",
      "predicted\n",
      "[0s] 24 [1s] 20\n",
      "--------------------\n",
      "Accuracy: 0.7273\n",
      "macro_f1: 0.6857\n",
      "Precision: 0.7000\n",
      "Recall: 0.8333\n",
      "F1: 0.6857\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "--------------------\n",
      "Y\n",
      "[0s] 66 [1s] 6\n",
      "predicted\n",
      "[0s] 63 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.8472\n",
      "macro_f1: 0.5907\n",
      "Precision: 0.5794\n",
      "Recall: 0.6136\n",
      "F1: 0.5907\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30362446\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 8\n",
      "predicted\n",
      "[0s] 19 [1s] 23\n",
      "--------------------\n",
      "Accuracy: 0.5476\n",
      "macro_f1: 0.5143\n",
      "Precision: 0.5778\n",
      "Recall: 0.6250\n",
      "F1: 0.5143\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2883355\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 19 [1s] 5\n",
      "predicted\n",
      "[0s] 11 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.5833\n",
      "macro_f1: 0.5556\n",
      "Precision: 0.6084\n",
      "Recall: 0.6632\n",
      "F1: 0.5556\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 5\n",
      "predicted\n",
      "[0s] 4 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.4375\n",
      "macro_f1: 0.4353\n",
      "Precision: 0.5417\n",
      "Recall: 0.5364\n",
      "F1: 0.4353\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "--------------------\n",
      "Y\n",
      "[0s] 53 [1s] 3\n",
      "predicted\n",
      "[0s] 19 [1s] 37\n",
      "--------------------\n",
      "Accuracy: 0.3929\n",
      "macro_f1: 0.3389\n",
      "Precision: 0.5405\n",
      "Recall: 0.6792\n",
      "F1: 0.3389\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/38980595\n",
      "--------------------\n",
      "Y\n",
      "[0s] 2 [1s] 3\n",
      "predicted\n",
      "[0s] 4 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.6000\n",
      "macro_f1: 0.5833\n",
      "Precision: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.6667\n",
      "F1: 0.5833\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "--------------------\n",
      "Y\n",
      "[0s] 26 [1s] 10\n",
      "predicted\n",
      "[0s] 25 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.6944\n",
      "macro_f1: 0.6303\n",
      "Precision: 0.6273\n",
      "Recall: 0.6346\n",
      "F1: 0.6303\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/40168601\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 1 [1s] 3\n",
      "predicted\n",
      "[0s] 2 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.7500\n",
      "macro_f1: 0.7333\n",
      "Precision: 0.7500\n",
      "Recall: 0.8333\n",
      "F1: 0.7333\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.614\u001b[0m\n",
      "recall:    \u001b[31m0.656\u001b[0m\n",
      "f1-score:  \u001b[31m0.538\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.584\u001b[0m\n",
      "recall:    \u001b[31m0.689\u001b[0m\n",
      "f1-score:  \u001b[31m0.517\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.654\u001b[0m\n",
      "recall:    \u001b[31m0.683\u001b[0m\n",
      "f1-score:  \u001b[31m0.592\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.627\u001b[0m\n",
      "recall:    \u001b[31m0.635\u001b[0m\n",
      "f1-score:  \u001b[31m0.630\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.585\u001b[0m\n",
      "recall:    \u001b[31m0.575\u001b[0m\n",
      "f1-score:  \u001b[31m0.446\u001b[0m\n",
      "\n",
      "\u001b[31mFold 2\u001b[0m\n",
      "How to Integrate reCAPTCHA 2.0 in Android\n",
      "How can I make this rxjava zip to run in parallel?\n",
      "Permission Denial when trying to access contacts in Android\n",
      "keyUp called when key is still pressed\n",
      "Don’t leak MockWebServer ports across tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 855411.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1463\n",
      "1     732\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1178\n",
      "1     180\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9145 - sparse_categorical_accuracy: 0.5157The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61150, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 17s 491ms/step - loss: 0.9145 - sparse_categorical_accuracy: 0.5157 - val_loss: 0.6115 - val_sparse_categorical_accuracy: 0.6516\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8034 - sparse_categorical_accuracy: 0.6565\n",
      "Epoch 00002: val_loss improved from 0.61150 to 0.60043, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 12s 332ms/step - loss: 0.8034 - sparse_categorical_accuracy: 0.6565 - val_loss: 0.6004 - val_sparse_categorical_accuracy: 0.6557\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7104 - sparse_categorical_accuracy: 0.7121\n",
      "Epoch 00003: val_loss improved from 0.60043 to 0.58775, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 14s 410ms/step - loss: 0.7104 - sparse_categorical_accuracy: 0.7121 - val_loss: 0.5878 - val_sparse_categorical_accuracy: 0.6926\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6171 - sparse_categorical_accuracy: 0.7636\n",
      "Epoch 00004: val_loss improved from 0.58775 to 0.57889, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.6171 - sparse_categorical_accuracy: 0.7636 - val_loss: 0.5789 - val_sparse_categorical_accuracy: 0.7172\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.5161 - sparse_categorical_accuracy: 0.8123\n",
      "Epoch 00005: val_loss did not improve from 0.57889\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.5161 - sparse_categorical_accuracy: 0.8123 - val_loss: 0.6180 - val_sparse_categorical_accuracy: 0.7008\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4404 - sparse_categorical_accuracy: 0.8547\n",
      "Epoch 00006: val_loss did not improve from 0.57889\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.4404 - sparse_categorical_accuracy: 0.8547 - val_loss: 0.6447 - val_sparse_categorical_accuracy: 0.7418\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.3701 - sparse_categorical_accuracy: 0.8756\n",
      "Epoch 00007: val_loss did not improve from 0.57889\n",
      "35/35 [==============================] - 9s 258ms/step - loss: 0.3701 - sparse_categorical_accuracy: 0.8756 - val_loss: 0.7364 - val_sparse_categorical_accuracy: 0.7295\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.3207 - sparse_categorical_accuracy: 0.9030Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.57889\n",
      "35/35 [==============================] - 9s 263ms/step - loss: 0.3207 - sparse_categorical_accuracy: 0.9030 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.7541\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/training/permissions/requesting\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 90 [1s] 39\n",
      "predicted\n",
      "[0s] 29 [1s] 100\n",
      "--------------------\n",
      "Accuracy: 0.4806\n",
      "macro_f1: 0.4775\n",
      "Precision: 0.6283\n",
      "Recall: 0.6060\n",
      "F1: 0.4775\n",
      "\u001b[31m36\u001b[0m entries logged\n",
      "https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "--------------------\n",
      "Y\n",
      "[0s] 30 [1s] 4\n",
      "predicted\n",
      "[0s] 20 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.5882\n",
      "macro_f1: 0.4711\n",
      "Precision: 0.5214\n",
      "Recall: 0.5500\n",
      "F1: 0.4711\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "--------------------\n",
      "Y\n",
      "[0s] 152 [1s] 9\n",
      "predicted\n",
      "[0s] 69 [1s] 92\n",
      "--------------------\n",
      "Accuracy: 0.4720\n",
      "macro_f1: 0.3869\n",
      "Precision: 0.5362\n",
      "Recall: 0.6681\n",
      "F1: 0.3869\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "--------------------\n",
      "Y\n",
      "[0s] 368 [1s] 5\n",
      "predicted\n",
      "[0s] 176 [1s] 197\n",
      "--------------------\n",
      "Accuracy: 0.4692\n",
      "macro_f1: 0.3279\n",
      "Precision: 0.4966\n",
      "Recall: 0.4351\n",
      "F1: 0.3279\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "--------------------\n",
      "Y\n",
      "[0s] 201 [1s] 18\n",
      "predicted\n",
      "[0s] 117 [1s] 102\n",
      "--------------------\n",
      "Accuracy: 0.5708\n",
      "macro_f1: 0.4605\n",
      "Precision: 0.5424\n",
      "Recall: 0.6397\n",
      "F1: 0.4605\n",
      "\u001b[31m13\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/35357919\n",
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 12\n",
      "predicted\n",
      "[0s] 10 [1s] 43\n",
      "--------------------\n",
      "Accuracy: 0.2642\n",
      "macro_f1: 0.2631\n",
      "Precision: 0.3930\n",
      "Recall: 0.4065\n",
      "F1: 0.2631\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 106 [1s] 11\n",
      "predicted\n",
      "[0s] 39 [1s] 78\n",
      "--------------------\n",
      "Accuracy: 0.3761\n",
      "macro_f1: 0.3382\n",
      "Precision: 0.5128\n",
      "Recall: 0.5334\n",
      "F1: 0.3382\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://developer.android.com/training/safetynet/recaptcha\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 20\n",
      "predicted\n",
      "[0s] 14 [1s] 40\n",
      "--------------------\n",
      "Accuracy: 0.5926\n",
      "macro_f1: 0.5875\n",
      "Precision: 0.7018\n",
      "Recall: 0.6662\n",
      "F1: 0.5875\n",
      "\u001b[31m19\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/5233543\n",
      "--------------------\n",
      "Y\n",
      "[0s] 7 [1s] 14\n",
      "predicted\n",
      "[0s] 5 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.7143\n",
      "macro_f1: 0.6500\n",
      "Precision: 0.6750\n",
      "Recall: 0.6429\n",
      "F1: 0.6500\n",
      "\u001b[31m12\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 27\n",
      "predicted\n",
      "[0s] 18 [1s] 45\n",
      "--------------------\n",
      "Accuracy: 0.4921\n",
      "macro_f1: 0.4815\n",
      "Precision: 0.5278\n",
      "Recall: 0.5231\n",
      "F1: 0.4815\n",
      "\u001b[31m20\u001b[0m entries logged\n",
      "https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "--------------------\n",
      "Y\n",
      "[0s] 69 [1s] 3\n",
      "predicted\n",
      "[0s] 39 [1s] 33\n",
      "--------------------\n",
      "Accuracy: 0.5833\n",
      "macro_f1: 0.4444\n",
      "Precision: 0.5455\n",
      "Recall: 0.7826\n",
      "F1: 0.4444\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 3\n",
      "predicted\n",
      "[0s] 4 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.3571\n",
      "macro_f1: 0.3538\n",
      "Precision: 0.4750\n",
      "Recall: 0.4697\n",
      "F1: 0.3538\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24952513\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 4\n",
      "predicted\n",
      "[0s] 13 [1s] 14\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5556\n",
      "macro_f1: 0.5000\n",
      "Precision: 0.5687\n",
      "Recall: 0.6359\n",
      "F1: 0.5000\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/27297067\n",
      "--------------------\n",
      "Y\n",
      "[0s] 10 [1s] 11\n",
      "predicted\n",
      "[0s] 5 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.3810\n",
      "macro_f1: 0.3259\n",
      "Precision: 0.3187\n",
      "Recall: 0.3682\n",
      "F1: 0.3259\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.532\u001b[0m\n",
      "recall:    \u001b[31m0.566\u001b[0m\n",
      "f1-score:  \u001b[31m0.433\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.575\u001b[0m\n",
      "recall:    \u001b[31m0.544\u001b[0m\n",
      "f1-score:  \u001b[31m0.437\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.489\u001b[0m\n",
      "recall:    \u001b[31m0.513\u001b[0m\n",
      "f1-score:  \u001b[31m0.435\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.521\u001b[0m\n",
      "recall:    \u001b[31m0.550\u001b[0m\n",
      "f1-score:  \u001b[31m0.471\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.533\u001b[0m\n",
      "recall:    \u001b[31m0.629\u001b[0m\n",
      "f1-score:  \u001b[31m0.422\u001b[0m\n",
      "\u001b[33mi=2\u001b[0m\n",
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n",
      "Hide MarkerView when nothing selected\n",
      "How to check programmatically whether app is running in debug mode or not?\n",
      "JSONObject parse dictionary objects\n",
      "Want to add drawable icons insteadof colorful dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 710536.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1659\n",
      "1     830\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    664\n",
      "1     71\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9016 - sparse_categorical_accuracy: 0.6203The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64738, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 15s 394ms/step - loss: 0.9016 - sparse_categorical_accuracy: 0.6203 - val_loss: 0.6474 - val_sparse_categorical_accuracy: 0.6534\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8478 - sparse_categorical_accuracy: 0.6424\n",
      "Epoch 00002: val_loss improved from 0.64738 to 0.60657, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 0.8478 - sparse_categorical_accuracy: 0.6424 - val_loss: 0.6066 - val_sparse_categorical_accuracy: 0.6787\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7782 - sparse_categorical_accuracy: 0.6983\n",
      "Epoch 00003: val_loss improved from 0.60657 to 0.59946, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 0.7782 - sparse_categorical_accuracy: 0.6983 - val_loss: 0.5995 - val_sparse_categorical_accuracy: 0.6931\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7159 - sparse_categorical_accuracy: 0.7372\n",
      "Epoch 00004: val_loss improved from 0.59946 to 0.58786, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.7159 - sparse_categorical_accuracy: 0.7372 - val_loss: 0.5879 - val_sparse_categorical_accuracy: 0.7112\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6338 - sparse_categorical_accuracy: 0.7830\n",
      "Epoch 00005: val_loss did not improve from 0.58786\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.6338 - sparse_categorical_accuracy: 0.7830 - val_loss: 0.6974 - val_sparse_categorical_accuracy: 0.6209\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5769 - sparse_categorical_accuracy: 0.8120\n",
      "Epoch 00006: val_loss improved from 0.58786 to 0.56995, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 17s 447ms/step - loss: 0.5769 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.5699 - val_sparse_categorical_accuracy: 0.7220\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4811 - sparse_categorical_accuracy: 0.8485\n",
      "Epoch 00007: val_loss did not improve from 0.56995\n",
      "39/39 [==============================] - 10s 261ms/step - loss: 0.4811 - sparse_categorical_accuracy: 0.8485 - val_loss: 0.6208 - val_sparse_categorical_accuracy: 0.7004\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.3919 - sparse_categorical_accuracy: 0.8827\n",
      "Epoch 00008: val_loss did not improve from 0.56995\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.3919 - sparse_categorical_accuracy: 0.8827 - val_loss: 0.6146 - val_sparse_categorical_accuracy: 0.7184\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.2983 - sparse_categorical_accuracy: 0.9200\n",
      "Epoch 00009: val_loss did not improve from 0.56995\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.2983 - sparse_categorical_accuracy: 0.9200 - val_loss: 0.6622 - val_sparse_categorical_accuracy: 0.7184\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.2485 - sparse_categorical_accuracy: 0.9337Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.56995\n",
      "39/39 [==============================] - 11s 270ms/step - loss: 0.2485 - sparse_categorical_accuracy: 0.9337 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.7184\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 276 [1s] 7\n",
      "predicted\n",
      "[0s] 217 [1s] 66\n",
      "--------------------\n",
      "Accuracy: 0.7491\n",
      "macro_f1: 0.4417\n",
      "Precision: 0.4938\n",
      "Recall: 0.4537\n",
      "F1: 0.4417\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "--------------------\n",
      "Y\n",
      "[0s] 28 [1s] 8\n",
      "predicted\n",
      "[0s] 24 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.7222\n",
      "macro_f1: 0.6538\n",
      "Precision: 0.6458\n",
      "Recall: 0.6875\n",
      "F1: 0.6538\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/23844667\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 5\n",
      "predicted\n",
      "[0s] 20 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.7500\n",
      "macro_f1: 0.6494\n",
      "Precision: 0.6375\n",
      "Recall: 0.6913\n",
      "F1: 0.6494\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 82 [1s] 22\n",
      "predicted\n",
      "[0s] 81 [1s] 23\n",
      "--------------------\n",
      "Accuracy: 0.6250\n",
      "macro_f1: 0.4470\n",
      "Precision: 0.4479\n",
      "Recall: 0.4462\n",
      "F1: 0.4470\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "--------------------\n",
      "Y\n",
      "[0s] 172 [1s] 7\n",
      "predicted\n",
      "[0s] 131 [1s] 48\n",
      "--------------------\n",
      "Accuracy: 0.7374\n",
      "macro_f1: 0.4952\n",
      "Precision: 0.5302\n",
      "Recall: 0.6578\n",
      "F1: 0.4952\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "--------------------\n",
      "Y\n",
      "[0s] 40 [1s] 5\n",
      "predicted\n",
      "[0s] 42 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.8222\n",
      "macro_f1: 0.4512\n",
      "Precision: 0.4405\n",
      "Recall: 0.4625\n",
      "F1: 0.4512\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 8\n",
      "predicted\n",
      "[0s] 24 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.7742\n",
      "macro_f1: 0.6922\n",
      "Precision: 0.7024\n",
      "Recall: 0.6848\n",
      "F1: 0.6922\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/37096547\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 12 [1s] 5\n",
      "predicted\n",
      "[0s] 15 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.5882\n",
      "macro_f1: 0.3704\n",
      "Precision: 0.3333\n",
      "Recall: 0.4167\n",
      "F1: 0.3704\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/33241952\n",
      "--------------------\n",
      "Y\n",
      "[0s] 8 [1s] 4\n",
      "predicted\n",
      "[0s] 10 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.5556\n",
      "Precision: 0.6000\n",
      "Recall: 0.5625\n",
      "F1: 0.5556\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.537\u001b[0m\n",
      "recall:    \u001b[31m0.563\u001b[0m\n",
      "f1-score:  \u001b[31m0.528\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.471\u001b[0m\n",
      "recall:    \u001b[31m0.450\u001b[0m\n",
      "f1-score:  \u001b[31m0.444\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.524\u001b[0m\n",
      "recall:    \u001b[31m0.557\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score:  \u001b[31m0.525\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.543\u001b[0m\n",
      "recall:    \u001b[31m0.575\u001b[0m\n",
      "f1-score:  \u001b[31m0.553\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.616\u001b[0m\n",
      "recall:    \u001b[31m0.671\u001b[0m\n",
      "f1-score:  \u001b[31m0.594\u001b[0m\n",
      "\n",
      "\u001b[31mFold 1\u001b[0m\n",
      " height must be > 0\n",
      "Write and Read a json data to internal storage android\n",
      "Android PDF Rendering\n",
      "How can I hide a fragment on start of my MainActivity( or the application)?\n",
      "polymorphic deserialization of JSON with jackson, property type becomes &quot;null&quot;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 418320.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1605\n",
      "1     803\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    659\n",
      "1    101\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.9409 - sparse_categorical_accuracy: 0.5249The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68938, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 15s 400ms/step - loss: 0.9409 - sparse_categorical_accuracy: 0.5249 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.5709\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.8892 - sparse_categorical_accuracy: 0.6117\n",
      "Epoch 00002: val_loss improved from 0.68938 to 0.65312, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 13s 337ms/step - loss: 0.8892 - sparse_categorical_accuracy: 0.6117 - val_loss: 0.6531 - val_sparse_categorical_accuracy: 0.6604\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.8326 - sparse_categorical_accuracy: 0.6761\n",
      "Epoch 00003: val_loss improved from 0.65312 to 0.59603, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.8326 - sparse_categorical_accuracy: 0.6761 - val_loss: 0.5960 - val_sparse_categorical_accuracy: 0.7090\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.7776 - sparse_categorical_accuracy: 0.7213\n",
      "Epoch 00004: val_loss did not improve from 0.59603\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.7776 - sparse_categorical_accuracy: 0.7213 - val_loss: 0.6000 - val_sparse_categorical_accuracy: 0.7276\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.7328 - sparse_categorical_accuracy: 0.7471\n",
      "Epoch 00005: val_loss improved from 0.59603 to 0.58149, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 13s 347ms/step - loss: 0.7328 - sparse_categorical_accuracy: 0.7471 - val_loss: 0.5815 - val_sparse_categorical_accuracy: 0.7351\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6450 - sparse_categorical_accuracy: 0.7890\n",
      "Epoch 00006: val_loss did not improve from 0.58149\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.6450 - sparse_categorical_accuracy: 0.7890 - val_loss: 0.5876 - val_sparse_categorical_accuracy: 0.7239\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5817 - sparse_categorical_accuracy: 0.8194\n",
      "Epoch 00007: val_loss did not improve from 0.58149\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.5817 - sparse_categorical_accuracy: 0.8194 - val_loss: 0.6461 - val_sparse_categorical_accuracy: 0.7052\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4816 - sparse_categorical_accuracy: 0.8571\n",
      "Epoch 00008: val_loss did not improve from 0.58149\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.4816 - sparse_categorical_accuracy: 0.8571 - val_loss: 0.6271 - val_sparse_categorical_accuracy: 0.7201\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3942 - sparse_categorical_accuracy: 0.8904Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.58149\n",
      "38/38 [==============================] - 10s 266ms/step - loss: 0.3942 - sparse_categorical_accuracy: 0.8904 - val_loss: 0.6977 - val_sparse_categorical_accuracy: 0.7052\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 242 [1s] 7\n",
      "predicted\n",
      "[0s] 27 [1s] 222\n",
      "--------------------\n",
      "Accuracy: 0.1365\n",
      "macro_f1: 0.1309\n",
      "Precision: 0.5158\n",
      "Recall: 0.5558\n",
      "F1: 0.1309\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "--------------------\n",
      "Y\n",
      "[0s] 53 [1s] 3\n",
      "predicted\n",
      "[0s] 27 [1s] 29\n",
      "--------------------\n",
      "Accuracy: 0.4286\n",
      "macro_f1: 0.3000\n",
      "Precision: 0.4444\n",
      "Recall: 0.2264\n",
      "F1: 0.3000\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "--------------------\n",
      "Y\n",
      "[0s] 66 [1s] 6\n",
      "predicted\n",
      "[0s] 69 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.8750\n",
      "macro_f1: 0.4667\n",
      "Precision: 0.4565\n",
      "Recall: 0.4773\n",
      "F1: 0.4667\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/creating-and-using-fragments\n",
      "--------------------\n",
      "Y\n",
      "[0s] 132 [1s] 31\n",
      "predicted\n",
      "[0s] 163 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.8098\n",
      "macro_f1: 0.4475\n",
      "Precision: 0.4049\n",
      "Recall: 0.5000\n",
      "F1: 0.4475\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://github.com/FasterXML/jackson-databind/issues/1538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 26 [1s] 10\n",
      "predicted\n",
      "[0s] 32 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.7222\n",
      "macro_f1: 0.5567\n",
      "Precision: 0.6250\n",
      "Recall: 0.5615\n",
      "F1: 0.5567\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 8\n",
      "predicted\n",
      "[0s] 12 [1s] 32\n",
      "--------------------\n",
      "Accuracy: 0.3182\n",
      "macro_f1: 0.3125\n",
      "Precision: 0.4531\n",
      "Recall: 0.4375\n",
      "F1: 0.3125\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/14347588\n",
      "--------------------\n",
      "Y\n",
      "[0s] 20 [1s] 5\n",
      "predicted\n",
      "[0s] 25 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.8000\n",
      "macro_f1: 0.4444\n",
      "Precision: 0.4000\n",
      "Recall: 0.5000\n",
      "F1: 0.4444\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2883355\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 19 [1s] 5\n",
      "predicted\n",
      "[0s] 10 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.5417\n",
      "macro_f1: 0.5209\n",
      "Precision: 0.5929\n",
      "Recall: 0.6368\n",
      "F1: 0.5209\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30362446\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 8\n",
      "predicted\n",
      "[0s] 38 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.7619\n",
      "macro_f1: 0.5139\n",
      "Precision: 0.5329\n",
      "Recall: 0.5184\n",
      "F1: 0.5139\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 17 [1s] 7\n",
      "predicted\n",
      "[0s] 14 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5417\n",
      "macro_f1: 0.4991\n",
      "Precision: 0.5071\n",
      "Recall: 0.5084\n",
      "F1: 0.4991\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/38980595\n",
      "--------------------\n",
      "Y\n",
      "[0s] 2 [1s] 3\n",
      "predicted\n",
      "[0s] 2 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.6000\n",
      "macro_f1: 0.5833\n",
      "Precision: 0.5833\n",
      "Recall: 0.5833\n",
      "F1: 0.5833\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/40168601\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 1 [1s] 3\n",
      "predicted\n",
      "[0s] 1 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 1.0000\n",
      "macro_f1: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1: 1.0000\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 5\n",
      "predicted\n",
      "[0s] 16 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.6875\n",
      "macro_f1: 0.4074\n",
      "Precision: 0.3438\n",
      "Recall: 0.5000\n",
      "F1: 0.4074\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.528\u001b[0m\n",
      "recall:    \u001b[31m0.539\u001b[0m\n",
      "f1-score:  \u001b[31m0.476\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.467\u001b[0m\n",
      "recall:    \u001b[31m0.424\u001b[0m\n",
      "f1-score:  \u001b[31m0.303\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.622\u001b[0m\n",
      "recall:    \u001b[31m0.648\u001b[0m\n",
      "f1-score:  \u001b[31m0.613\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.625\u001b[0m\n",
      "recall:    \u001b[31m0.562\u001b[0m\n",
      "f1-score:  \u001b[31m0.557\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.419\u001b[0m\n",
      "recall:    \u001b[31m0.503\u001b[0m\n",
      "f1-score:  \u001b[31m0.451\u001b[0m\n",
      "\n",
      "\u001b[31mFold 2\u001b[0m\n",
      "How to Integrate reCAPTCHA 2.0 in Android\n",
      "How can I make this rxjava zip to run in parallel?\n",
      "Permission Denial when trying to access contacts in Android\n",
      "keyUp called when key is still pressed\n",
      "Don’t leak MockWebServer ports across tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 818577.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1463\n",
      "1     732\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1178\n",
      "1     180\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8879 - sparse_categorical_accuracy: 0.5895The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64538, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 17s 478ms/step - loss: 0.8879 - sparse_categorical_accuracy: 0.5895 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.5943\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8061 - sparse_categorical_accuracy: 0.6679\n",
      "Epoch 00002: val_loss improved from 0.64538 to 0.60769, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 12s 341ms/step - loss: 0.8061 - sparse_categorical_accuracy: 0.6679 - val_loss: 0.6077 - val_sparse_categorical_accuracy: 0.6475\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7066 - sparse_categorical_accuracy: 0.7194\n",
      "Epoch 00003: val_loss improved from 0.60769 to 0.60556, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 14s 392ms/step - loss: 0.7066 - sparse_categorical_accuracy: 0.7194 - val_loss: 0.6056 - val_sparse_categorical_accuracy: 0.6680\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6061 - sparse_categorical_accuracy: 0.7777\n",
      "Epoch 00004: val_loss did not improve from 0.60556\n",
      "35/35 [==============================] - 9s 256ms/step - loss: 0.6061 - sparse_categorical_accuracy: 0.7777 - val_loss: 0.7015 - val_sparse_categorical_accuracy: 0.6352\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.5123 - sparse_categorical_accuracy: 0.8159\n",
      "Epoch 00005: val_loss did not improve from 0.60556\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.5123 - sparse_categorical_accuracy: 0.8159 - val_loss: 0.6573 - val_sparse_categorical_accuracy: 0.6885\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4427 - sparse_categorical_accuracy: 0.8446\n",
      "Epoch 00006: val_loss did not improve from 0.60556\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.4427 - sparse_categorical_accuracy: 0.8446 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.7008\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.3819 - sparse_categorical_accuracy: 0.8815Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.60556\n",
      "35/35 [==============================] - 9s 265ms/step - loss: 0.3819 - sparse_categorical_accuracy: 0.8815 - val_loss: 0.7577 - val_sparse_categorical_accuracy: 0.6926\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 106 [1s] 11\n",
      "predicted\n",
      "[0s] 76 [1s] 41\n",
      "--------------------\n",
      "Accuracy: 0.6410\n",
      "macro_f1: 0.4808\n",
      "Precision: 0.5215\n",
      "Recall: 0.5575\n",
      "F1: 0.4808\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 368 [1s] 5\n",
      "predicted\n",
      "[0s] 285 [1s] 88\n",
      "--------------------\n",
      "Accuracy: 0.7614\n",
      "macro_f1: 0.4534\n",
      "Precision: 0.5061\n",
      "Recall: 0.5832\n",
      "F1: 0.4534\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "--------------------\n",
      "Y\n",
      "[0s] 69 [1s] 3\n",
      "predicted\n",
      "[0s] 58 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.8194\n",
      "macro_f1: 0.5665\n",
      "Precision: 0.5628\n",
      "Recall: 0.7464\n",
      "F1: 0.5665\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "--------------------\n",
      "Y\n",
      "[0s] 152 [1s] 9\n",
      "predicted\n",
      "[0s] 85 [1s] 76\n",
      "--------------------\n",
      "Accuracy: 0.5839\n",
      "macro_f1: 0.4645\n",
      "Precision: 0.5592\n",
      "Recall: 0.7796\n",
      "F1: 0.4645\n",
      "\u001b[31m9\u001b[0m entries logged\n",
      "https://developer.android.com/training/safetynet/recaptcha\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 20\n",
      "predicted\n",
      "[0s] 34 [1s] 20\n",
      "--------------------\n",
      "Accuracy: 0.7037\n",
      "macro_f1: 0.6824\n",
      "Precision: 0.6824\n",
      "Recall: 0.6824\n",
      "F1: 0.6824\n",
      "\u001b[31m12\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 27\n",
      "predicted\n",
      "[0s] 18 [1s] 45\n",
      "--------------------\n",
      "Accuracy: 0.5238\n",
      "macro_f1: 0.5139\n",
      "Precision: 0.5667\n",
      "Recall: 0.5556\n",
      "F1: 0.5139\n",
      "\u001b[31m21\u001b[0m entries logged\n",
      "https://developer.android.com/training/permissions/requesting\n",
      "--------------------\n",
      "Y\n",
      "[0s] 90 [1s] 39\n",
      "predicted\n",
      "[0s] 36 [1s] 93\n",
      "--------------------\n",
      "Accuracy: 0.5039\n",
      "macro_f1: 0.5036\n",
      "Precision: 0.6134\n",
      "Recall: 0.6081\n",
      "F1: 0.5036\n",
      "\u001b[31m34\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "--------------------\n",
      "Y\n",
      "[0s] 201 [1s] 18\n",
      "predicted\n",
      "[0s] 154 [1s] 65\n",
      "--------------------\n",
      "Accuracy: 0.7123\n",
      "macro_f1: 0.5317\n",
      "Precision: 0.5509\n",
      "Recall: 0.6410\n",
      "F1: 0.5317\n",
      "\u001b[31m10\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/5233543\n",
      "--------------------\n",
      "Y\n",
      "[0s] 7 [1s] 14\n",
      "predicted\n",
      "[0s] 5 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.8095\n",
      "macro_f1: 0.7667\n",
      "Precision: 0.8063\n",
      "Recall: 0.7500\n",
      "F1: 0.7667\n",
      "\u001b[31m13\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/35357919\n",
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 12\n",
      "predicted\n",
      "[0s] 29 [1s] 24\n",
      "--------------------\n",
      "Accuracy: 0.4717\n",
      "macro_f1: 0.4111\n",
      "Precision: 0.4454\n",
      "Recall: 0.4228\n",
      "F1: 0.4111\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24952513\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 4\n",
      "predicted\n",
      "[0s] 16 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.5846\n",
      "Precision: 0.6051\n",
      "Recall: 0.7011\n",
      "F1: 0.5846\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "--------------------\n",
      "Y\n",
      "[0s] 30 [1s] 4\n",
      "predicted\n",
      "[0s] 23 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.6176\n",
      "macro_f1: 0.4440\n",
      "Precision: 0.4802\n",
      "Recall: 0.4583\n",
      "F1: 0.4440\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/27297067\n",
      "--------------------\n",
      "Y\n",
      "[0s] 10 [1s] 11\n",
      "predicted\n",
      "[0s] 13 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.4762\n",
      "macro_f1: 0.4714\n",
      "Precision: 0.4808\n",
      "Recall: 0.4818\n",
      "F1: 0.4714\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 3\n",
      "predicted\n",
      "[0s] 6 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.6429\n",
      "macro_f1: 0.6257\n",
      "Precision: 0.6875\n",
      "Recall: 0.7727\n",
      "F1: 0.6257\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.576\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:    \u001b[31m0.624\u001b[0m\n",
      "f1-score:  \u001b[31m0.536\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.622\u001b[0m\n",
      "recall:    \u001b[31m0.662\u001b[0m\n",
      "f1-score:  \u001b[31m0.566\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.584\u001b[0m\n",
      "recall:    \u001b[31m0.589\u001b[0m\n",
      "f1-score:  \u001b[31m0.558\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.480\u001b[0m\n",
      "recall:    \u001b[31m0.458\u001b[0m\n",
      "f1-score:  \u001b[31m0.444\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.552\u001b[0m\n",
      "recall:    \u001b[31m0.656\u001b[0m\n",
      "f1-score:  \u001b[31m0.511\u001b[0m\n",
      "\u001b[33mi=3\u001b[0m\n",
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n",
      "Hide MarkerView when nothing selected\n",
      "How to check programmatically whether app is running in debug mode or not?\n",
      "JSONObject parse dictionary objects\n",
      "Want to add drawable icons insteadof colorful dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 778894.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1659\n",
      "1     830\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    664\n",
      "1     71\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9253 - sparse_categorical_accuracy: 0.5376The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67419, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 32s 824ms/step - loss: 0.9253 - sparse_categorical_accuracy: 0.5376 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6498\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8695 - sparse_categorical_accuracy: 0.6079\n",
      "Epoch 00002: val_loss improved from 0.67419 to 0.62809, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 0.8695 - sparse_categorical_accuracy: 0.6079 - val_loss: 0.6281 - val_sparse_categorical_accuracy: 0.6751\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7931 - sparse_categorical_accuracy: 0.6947\n",
      "Epoch 00003: val_loss improved from 0.62809 to 0.60328, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 14s 357ms/step - loss: 0.7931 - sparse_categorical_accuracy: 0.6947 - val_loss: 0.6033 - val_sparse_categorical_accuracy: 0.6895\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7199 - sparse_categorical_accuracy: 0.7429\n",
      "Epoch 00004: val_loss did not improve from 0.60328\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.7199 - sparse_categorical_accuracy: 0.7429 - val_loss: 0.6154 - val_sparse_categorical_accuracy: 0.6823\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6215 - sparse_categorical_accuracy: 0.7995\n",
      "Epoch 00005: val_loss improved from 0.60328 to 0.59879, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 18s 464ms/step - loss: 0.6215 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.5988 - val_sparse_categorical_accuracy: 0.7112\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5271 - sparse_categorical_accuracy: 0.8401\n",
      "Epoch 00006: val_loss did not improve from 0.59879\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.5271 - sparse_categorical_accuracy: 0.8401 - val_loss: 0.6787 - val_sparse_categorical_accuracy: 0.6787\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4220 - sparse_categorical_accuracy: 0.8815\n",
      "Epoch 00007: val_loss did not improve from 0.59879\n",
      "39/39 [==============================] - 10s 263ms/step - loss: 0.4220 - sparse_categorical_accuracy: 0.8815 - val_loss: 0.6308 - val_sparse_categorical_accuracy: 0.7004\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.3214 - sparse_categorical_accuracy: 0.9152\n",
      "Epoch 00008: val_loss did not improve from 0.59879\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.3214 - sparse_categorical_accuracy: 0.9152 - val_loss: 0.6383 - val_sparse_categorical_accuracy: 0.7401\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.2280 - sparse_categorical_accuracy: 0.9446Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.59879\n",
      "39/39 [==============================] - 10s 268ms/step - loss: 0.2280 - sparse_categorical_accuracy: 0.9446 - val_loss: 0.6647 - val_sparse_categorical_accuracy: 0.7509\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 276 [1s] 7\n",
      "predicted\n",
      "[0s] 151 [1s] 132\n",
      "--------------------\n",
      "Accuracy: 0.5230\n",
      "macro_f1: 0.3563\n",
      "Precision: 0.4910\n",
      "Recall: 0.4073\n",
      "F1: 0.3563\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "--------------------\n",
      "Y\n",
      "[0s] 172 [1s] 7\n",
      "predicted\n",
      "[0s] 94 [1s] 85\n",
      "--------------------\n",
      "Accuracy: 0.5531\n",
      "macro_f1: 0.4148\n",
      "Precision: 0.5300\n",
      "Recall: 0.6989\n",
      "F1: 0.4148\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 82 [1s] 22\n",
      "predicted\n",
      "[0s] 43 [1s] 61\n",
      "--------------------\n",
      "Accuracy: 0.5096\n",
      "macro_f1: 0.4888\n",
      "Precision: 0.5614\n",
      "Recall: 0.5892\n",
      "F1: 0.4888\n",
      "\u001b[31m16\u001b[0m entries logged\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "--------------------\n",
      "Y\n",
      "[0s] 28 [1s] 8\n",
      "predicted\n",
      "[0s] 26 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7222\n",
      "macro_f1: 0.6296\n",
      "Precision: 0.6231\n",
      "Recall: 0.6429\n",
      "F1: 0.6296\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "--------------------\n",
      "Y\n",
      "[0s] 40 [1s] 5\n",
      "predicted\n",
      "[0s] 41 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.8889\n",
      "macro_f1: 0.6914\n",
      "Precision: 0.7134\n",
      "Recall: 0.6750\n",
      "F1: 0.6914\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 8\n",
      "predicted\n",
      "[0s] 19 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.8065\n",
      "macro_f1: 0.7786\n",
      "Precision: 0.7654\n",
      "Recall: 0.8288\n",
      "F1: 0.7786\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/23844667\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 5\n",
      "predicted\n",
      "[0s] 19 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.7143\n",
      "macro_f1: 0.6190\n",
      "Precision: 0.6140\n",
      "Recall: 0.6696\n",
      "F1: 0.6190\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/33241952\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 8 [1s] 4\n",
      "predicted\n",
      "[0s] 11 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.5833\n",
      "macro_f1: 0.3684\n",
      "Precision: 0.3182\n",
      "Recall: 0.4375\n",
      "F1: 0.3684\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/37096547\n",
      "--------------------\n",
      "Y\n",
      "[0s] 12 [1s] 5\n",
      "predicted\n",
      "[0s] 14 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.6471\n",
      "macro_f1: 0.5096\n",
      "Precision: 0.5238\n",
      "Recall: 0.5167\n",
      "F1: 0.5096\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.571\u001b[0m\n",
      "recall:    \u001b[31m0.607\u001b[0m\n",
      "f1-score:  \u001b[31m0.540\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.526\u001b[0m\n",
      "recall:    \u001b[31m0.498\u001b[0m\n",
      "f1-score:  \u001b[31m0.423\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.485\u001b[0m\n",
      "recall:    \u001b[31m0.541\u001b[0m\n",
      "f1-score:  \u001b[31m0.499\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.668\u001b[0m\n",
      "recall:    \u001b[31m0.659\u001b[0m\n",
      "f1-score:  \u001b[31m0.660\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.648\u001b[0m\n",
      "recall:    \u001b[31m0.764\u001b[0m\n",
      "f1-score:  \u001b[31m0.597\u001b[0m\n",
      "\n",
      "\u001b[31mFold 1\u001b[0m\n",
      " height must be > 0\n",
      "Write and Read a json data to internal storage android\n",
      "Android PDF Rendering\n",
      "How can I hide a fragment on start of my MainActivity( or the application)?\n",
      "polymorphic deserialization of JSON with jackson, property type becomes &quot;null&quot;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 785396.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1605\n",
      "1     803\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    659\n",
      "1    101\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.9369 - sparse_categorical_accuracy: 0.5640The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67348, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 18s 481ms/step - loss: 0.9369 - sparse_categorical_accuracy: 0.5640 - val_loss: 0.6735 - val_sparse_categorical_accuracy: 0.5933\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.8418 - sparse_categorical_accuracy: 0.6711\n",
      "Epoch 00002: val_loss improved from 0.67348 to 0.60028, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 0.8418 - sparse_categorical_accuracy: 0.6711 - val_loss: 0.6003 - val_sparse_categorical_accuracy: 0.7201\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.7781 - sparse_categorical_accuracy: 0.7147\n",
      "Epoch 00003: val_loss did not improve from 0.60028\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.7781 - sparse_categorical_accuracy: 0.7147 - val_loss: 0.6135 - val_sparse_categorical_accuracy: 0.7015\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.7073 - sparse_categorical_accuracy: 0.7616\n",
      "Epoch 00004: val_loss improved from 0.60028 to 0.57179, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 14s 356ms/step - loss: 0.7073 - sparse_categorical_accuracy: 0.7616 - val_loss: 0.5718 - val_sparse_categorical_accuracy: 0.7201\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6125 - sparse_categorical_accuracy: 0.8135\n",
      "Epoch 00005: val_loss did not improve from 0.57179\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.6125 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5888 - val_sparse_categorical_accuracy: 0.7239\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5258 - sparse_categorical_accuracy: 0.8501\n",
      "Epoch 00006: val_loss did not improve from 0.57179\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.5258 - sparse_categorical_accuracy: 0.8501 - val_loss: 0.6066 - val_sparse_categorical_accuracy: 0.7276\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4430 - sparse_categorical_accuracy: 0.8841\n",
      "Epoch 00007: val_loss did not improve from 0.57179\n",
      "38/38 [==============================] - 10s 262ms/step - loss: 0.4430 - sparse_categorical_accuracy: 0.8841 - val_loss: 0.6278 - val_sparse_categorical_accuracy: 0.7425\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3652 - sparse_categorical_accuracy: 0.9128Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.57179\n",
      "38/38 [==============================] - 10s 266ms/step - loss: 0.3652 - sparse_categorical_accuracy: 0.9128 - val_loss: 0.6302 - val_sparse_categorical_accuracy: 0.7500\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 242 [1s] 7\n",
      "predicted\n",
      "[0s] 59 [1s] 190\n",
      "--------------------\n",
      "Accuracy: 0.2651\n",
      "macro_f1: 0.2315\n",
      "Precision: 0.5184\n",
      "Recall: 0.6219\n",
      "F1: 0.2315\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30362446\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 8\n",
      "predicted\n",
      "[0s] 42 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.8095\n",
      "macro_f1: 0.4474\n",
      "Precision: 0.4048\n",
      "Recall: 0.5000\n",
      "F1: 0.4474\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/creating-and-using-fragments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 132 [1s] 31\n",
      "predicted\n",
      "[0s] 159 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.7853\n",
      "macro_f1: 0.4399\n",
      "Precision: 0.4025\n",
      "Recall: 0.4848\n",
      "F1: 0.4399\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 8\n",
      "predicted\n",
      "[0s] 12 [1s] 32\n",
      "--------------------\n",
      "Accuracy: 0.4545\n",
      "macro_f1: 0.4500\n",
      "Precision: 0.6250\n",
      "Recall: 0.6667\n",
      "F1: 0.4500\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "--------------------\n",
      "Y\n",
      "[0s] 66 [1s] 6\n",
      "predicted\n",
      "[0s] 66 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.8889\n",
      "macro_f1: 0.6364\n",
      "Precision: 0.6364\n",
      "Recall: 0.6364\n",
      "F1: 0.6364\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "--------------------\n",
      "Y\n",
      "[0s] 53 [1s] 3\n",
      "predicted\n",
      "[0s] 19 [1s] 37\n",
      "--------------------\n",
      "Accuracy: 0.3571\n",
      "macro_f1: 0.3000\n",
      "Precision: 0.5007\n",
      "Recall: 0.5031\n",
      "F1: 0.3000\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 17 [1s] 7\n",
      "predicted\n",
      "[0s] 18 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.7083\n",
      "macro_f1: 0.6308\n",
      "Precision: 0.6389\n",
      "Recall: 0.6261\n",
      "F1: 0.6308\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "--------------------\n",
      "Y\n",
      "[0s] 26 [1s] 10\n",
      "predicted\n",
      "[0s] 35 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.6944\n",
      "macro_f1: 0.4098\n",
      "Precision: 0.3571\n",
      "Recall: 0.4808\n",
      "F1: 0.4098\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/14347588\n",
      "--------------------\n",
      "Y\n",
      "[0s] 20 [1s] 5\n",
      "predicted\n",
      "[0s] 25 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.8000\n",
      "macro_f1: 0.4444\n",
      "Precision: 0.4000\n",
      "Recall: 0.5000\n",
      "F1: 0.4444\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2883355\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 19 [1s] 5\n",
      "predicted\n",
      "[0s] 17 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.5000\n",
      "macro_f1: 0.3333\n",
      "Precision: 0.3529\n",
      "Recall: 0.3158\n",
      "F1: 0.3333\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 5\n",
      "predicted\n",
      "[0s] 16 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.6875\n",
      "macro_f1: 0.4074\n",
      "Precision: 0.3438\n",
      "Recall: 0.5000\n",
      "F1: 0.4074\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/38980595\n",
      "--------------------\n",
      "Y\n",
      "[0s] 2 [1s] 3\n",
      "predicted\n",
      "[0s] 4 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.6000\n",
      "macro_f1: 0.5833\n",
      "Precision: 0.7500\n",
      "Recall: 0.6667\n",
      "F1: 0.5833\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/40168601\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 1 [1s] 3\n",
      "predicted\n",
      "[0s] 2 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.7500\n",
      "macro_f1: 0.7333\n",
      "Precision: 0.7500\n",
      "Recall: 0.8333\n",
      "F1: 0.7333\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.514\u001b[0m\n",
      "recall:    \u001b[31m0.564\u001b[0m\n",
      "f1-score:  \u001b[31m0.465\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.570\u001b[0m\n",
      "recall:    \u001b[31m0.607\u001b[0m\n",
      "f1-score:  \u001b[31m0.404\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.532\u001b[0m\n",
      "recall:    \u001b[31m0.563\u001b[0m\n",
      "f1-score:  \u001b[31m0.508\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.357\u001b[0m\n",
      "recall:    \u001b[31m0.481\u001b[0m\n",
      "f1-score:  \u001b[31m0.410\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.462\u001b[0m\n",
      "recall:    \u001b[31m0.537\u001b[0m\n",
      "f1-score:  \u001b[31m0.493\u001b[0m\n",
      "\n",
      "\u001b[31mFold 2\u001b[0m\n",
      "How to Integrate reCAPTCHA 2.0 in Android\n",
      "How can I make this rxjava zip to run in parallel?\n",
      "Permission Denial when trying to access contacts in Android\n",
      "keyUp called when key is still pressed\n",
      "Don’t leak MockWebServer ports across tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 775511.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1463\n",
      "1     732\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1178\n",
      "1     180\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9423 - sparse_categorical_accuracy: 0.5699The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69001, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 18s 514ms/step - loss: 0.9423 - sparse_categorical_accuracy: 0.5699 - val_loss: 0.6900 - val_sparse_categorical_accuracy: 0.4959\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9092 - sparse_categorical_accuracy: 0.5950\n",
      "Epoch 00002: val_loss improved from 0.69001 to 0.68811, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 15s 422ms/step - loss: 0.9092 - sparse_categorical_accuracy: 0.5950 - val_loss: 0.6881 - val_sparse_categorical_accuracy: 0.4918\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8690 - sparse_categorical_accuracy: 0.6369\n",
      "Epoch 00003: val_loss improved from 0.68811 to 0.64809, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 12s 332ms/step - loss: 0.8690 - sparse_categorical_accuracy: 0.6369 - val_loss: 0.6481 - val_sparse_categorical_accuracy: 0.5984\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7997 - sparse_categorical_accuracy: 0.6747\n",
      "Epoch 00004: val_loss improved from 0.64809 to 0.59539, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 13s 385ms/step - loss: 0.7997 - sparse_categorical_accuracy: 0.6747 - val_loss: 0.5954 - val_sparse_categorical_accuracy: 0.6639\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7268 - sparse_categorical_accuracy: 0.7212\n",
      "Epoch 00005: val_loss did not improve from 0.59539\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.7268 - sparse_categorical_accuracy: 0.7212 - val_loss: 0.6212 - val_sparse_categorical_accuracy: 0.6639\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6401 - sparse_categorical_accuracy: 0.7768\n",
      "Epoch 00006: val_loss did not improve from 0.59539\n",
      "35/35 [==============================] - 9s 258ms/step - loss: 0.6401 - sparse_categorical_accuracy: 0.7768 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6516\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.5560 - sparse_categorical_accuracy: 0.8118\n",
      "Epoch 00007: val_loss did not improve from 0.59539\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.5560 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.6077 - val_sparse_categorical_accuracy: 0.6967\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4741 - sparse_categorical_accuracy: 0.8492Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.59539\n",
      "35/35 [==============================] - 9s 263ms/step - loss: 0.4741 - sparse_categorical_accuracy: 0.8492 - val_loss: 0.6592 - val_sparse_categorical_accuracy: 0.6885\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/training/permissions/requesting\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 90 [1s] 39\n",
      "predicted\n",
      "[0s] 48 [1s] 81\n",
      "--------------------\n",
      "Accuracy: 0.5349\n",
      "macro_f1: 0.5326\n",
      "Precision: 0.5914\n",
      "Recall: 0.6013\n",
      "F1: 0.5326\n",
      "\u001b[31m30\u001b[0m entries logged\n",
      "https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "--------------------\n",
      "Y\n",
      "[0s] 30 [1s] 4\n",
      "predicted\n",
      "[0s] 23 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.6765\n",
      "macro_f1: 0.5296\n",
      "Precision: 0.5474\n",
      "Recall: 0.6000\n",
      "F1: 0.5296\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "--------------------\n",
      "Y\n",
      "[0s] 152 [1s] 9\n",
      "predicted\n",
      "[0s] 115 [1s] 46\n",
      "--------------------\n",
      "Accuracy: 0.7578\n",
      "macro_f1: 0.5724\n",
      "Precision: 0.5826\n",
      "Recall: 0.8194\n",
      "F1: 0.5724\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "--------------------\n",
      "Y\n",
      "[0s] 201 [1s] 18\n",
      "predicted\n",
      "[0s] 162 [1s] 57\n",
      "--------------------\n",
      "Accuracy: 0.7306\n",
      "macro_f1: 0.5254\n",
      "Precision: 0.5393\n",
      "Recall: 0.6003\n",
      "F1: 0.5254\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 106 [1s] 11\n",
      "predicted\n",
      "[0s] 100 [1s] 17\n",
      "--------------------\n",
      "Accuracy: 0.7607\n",
      "macro_f1: 0.4320\n",
      "Precision: 0.4450\n",
      "Recall: 0.4198\n",
      "F1: 0.4320\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "--------------------\n",
      "Y\n",
      "[0s] 368 [1s] 5\n",
      "predicted\n",
      "[0s] 360 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.9517\n",
      "macro_f1: 0.4876\n",
      "Precision: 0.4931\n",
      "Recall: 0.4823\n",
      "F1: 0.4876\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "--------------------\n",
      "Y\n",
      "[0s] 69 [1s] 3\n",
      "predicted\n",
      "[0s] 59 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.8333\n",
      "macro_f1: 0.5781\n",
      "Precision: 0.5684\n",
      "Recall: 0.7536\n",
      "F1: 0.5781\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/training/safetynet/recaptcha\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 20\n",
      "predicted\n",
      "[0s] 37 [1s] 17\n",
      "--------------------\n",
      "Accuracy: 0.6852\n",
      "macro_f1: 0.6506\n",
      "Precision: 0.6590\n",
      "Recall: 0.6471\n",
      "F1: 0.6506\n",
      "\u001b[31m10\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 27\n",
      "predicted\n",
      "[0s] 20 [1s] 43\n",
      "--------------------\n",
      "Accuracy: 0.5873\n",
      "macro_f1: 0.5821\n",
      "Precision: 0.6308\n",
      "Recall: 0.6157\n",
      "F1: 0.5821\n",
      "\u001b[31m22\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24952513\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 4\n",
      "predicted\n",
      "[0s] 18 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.7407\n",
      "macro_f1: 0.6454\n",
      "Precision: 0.6389\n",
      "Recall: 0.7446\n",
      "F1: 0.6454\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/27297067\n",
      "--------------------\n",
      "Y\n",
      "[0s] 10 [1s] 11\n",
      "predicted\n",
      "[0s] 15 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.5714\n",
      "macro_f1: 0.5553\n",
      "Precision: 0.6000\n",
      "Recall: 0.5818\n",
      "F1: 0.5553\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/35357919\n",
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 12\n",
      "predicted\n",
      "[0s] 42 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.6415\n",
      "macro_f1: 0.4725\n",
      "Precision: 0.4719\n",
      "Recall: 0.4736\n",
      "F1: 0.4725\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/5233543\n",
      "--------------------\n",
      "Y\n",
      "[0s] 7 [1s] 14\n",
      "predicted\n",
      "[0s] 7 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro_f1: 0.6786\n",
      "Precision: 0.6786\n",
      "Recall: 0.6786\n",
      "F1: 0.6786\n",
      "\u001b[31m11\u001b[0m entries logged\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 3\n",
      "predicted\n",
      "[0s] 7 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.7143\n",
      "macro_f1: 0.6889\n",
      "Precision: 0.7143\n",
      "Recall: 0.8182\n",
      "F1: 0.6889\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.583\u001b[0m\n",
      "recall:    \u001b[31m0.631\u001b[0m\n",
      "f1-score:  \u001b[31m0.567\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.614\u001b[0m\n",
      "recall:    \u001b[31m0.637\u001b[0m\n",
      "f1-score:  \u001b[31m0.590\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.597\u001b[0m\n",
      "recall:    \u001b[31m0.620\u001b[0m\n",
      "f1-score:  \u001b[31m0.588\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.547\u001b[0m\n",
      "recall:    \u001b[31m0.600\u001b[0m\n",
      "f1-score:  \u001b[31m0.530\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.553\u001b[0m\n",
      "recall:    \u001b[31m0.642\u001b[0m\n",
      "f1-score:  \u001b[31m0.538\u001b[0m\n",
      "\u001b[33mi=4\u001b[0m\n",
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n",
      "Hide MarkerView when nothing selected\n",
      "How to check programmatically whether app is running in debug mode or not?\n",
      "JSONObject parse dictionary objects\n",
      "Want to add drawable icons insteadof colorful dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 408478.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1659\n",
      "1     830\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    664\n",
      "1     71\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9155 - sparse_categorical_accuracy: 0.6043The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68193, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 20s 501ms/step - loss: 0.9155 - sparse_categorical_accuracy: 0.6043 - val_loss: 0.6819 - val_sparse_categorical_accuracy: 0.5704\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8470 - sparse_categorical_accuracy: 0.6324\n",
      "Epoch 00002: val_loss improved from 0.68193 to 0.59190, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 14s 361ms/step - loss: 0.8470 - sparse_categorical_accuracy: 0.6324 - val_loss: 0.5919 - val_sparse_categorical_accuracy: 0.6859\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7942 - sparse_categorical_accuracy: 0.6866\n",
      "Epoch 00003: val_loss improved from 0.59190 to 0.54055, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 15s 373ms/step - loss: 0.7942 - sparse_categorical_accuracy: 0.6866 - val_loss: 0.5406 - val_sparse_categorical_accuracy: 0.7365\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7430 - sparse_categorical_accuracy: 0.7095\n",
      "Epoch 00004: val_loss improved from 0.54055 to 0.54054, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 15s 389ms/step - loss: 0.7430 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.5405 - val_sparse_categorical_accuracy: 0.7473\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6863 - sparse_categorical_accuracy: 0.7405\n",
      "Epoch 00005: val_loss improved from 0.54054 to 0.49625, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 339ms/step - loss: 0.6863 - sparse_categorical_accuracy: 0.7405 - val_loss: 0.4963 - val_sparse_categorical_accuracy: 0.7690\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6246 - sparse_categorical_accuracy: 0.7654\n",
      "Epoch 00006: val_loss improved from 0.49625 to 0.45850, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.6246 - sparse_categorical_accuracy: 0.7654 - val_loss: 0.4585 - val_sparse_categorical_accuracy: 0.8123\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5526 - sparse_categorical_accuracy: 0.8067\n",
      "Epoch 00007: val_loss did not improve from 0.45850\n",
      "39/39 [==============================] - 10s 263ms/step - loss: 0.5526 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.4655 - val_sparse_categorical_accuracy: 0.7942\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4793 - sparse_categorical_accuracy: 0.8313\n",
      "Epoch 00008: val_loss improved from 0.45850 to 0.45089, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 332ms/step - loss: 0.4793 - sparse_categorical_accuracy: 0.8313 - val_loss: 0.4509 - val_sparse_categorical_accuracy: 0.8087\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4070 - sparse_categorical_accuracy: 0.8646\n",
      "Epoch 00009: val_loss did not improve from 0.45089\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.4070 - sparse_categorical_accuracy: 0.8646 - val_loss: 0.4879 - val_sparse_categorical_accuracy: 0.8014\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.3355 - sparse_categorical_accuracy: 0.9024\n",
      "Epoch 00010: val_loss did not improve from 0.45089\n",
      "39/39 [==============================] - 10s 263ms/step - loss: 0.3355 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.8014\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 8\n",
      "predicted\n",
      "[0s] 21 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7419\n",
      "macro_f1: 0.6869\n",
      "Precision: 0.6786\n",
      "Recall: 0.7038\n",
      "F1: 0.6869\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "--------------------\n",
      "Y\n",
      "[0s] 172 [1s] 7\n",
      "predicted\n",
      "[0s] 106 [1s] 73\n",
      "--------------------\n",
      "Accuracy: 0.5978\n",
      "macro_f1: 0.4205\n",
      "Precision: 0.5132\n",
      "Recall: 0.5851\n",
      "F1: 0.4205\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 82 [1s] 22\n",
      "predicted\n",
      "[0s] 12 [1s] 92\n",
      "--------------------\n",
      "Accuracy: 0.3077\n",
      "macro_f1: 0.3012\n",
      "Precision: 0.5725\n",
      "Recall: 0.5443\n",
      "F1: 0.3012\n",
      "\u001b[31m21\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/23844667\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 5\n",
      "predicted\n",
      "[0s] 16 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.6786\n",
      "macro_f1: 0.6199\n",
      "Precision: 0.6354\n",
      "Recall: 0.7261\n",
      "F1: 0.6199\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "--------------------\n",
      "Y\n",
      "[0s] 276 [1s] 7\n",
      "predicted\n",
      "[0s] 177 [1s] 106\n",
      "--------------------\n",
      "Accuracy: 0.6148\n",
      "macro_f1: 0.3974\n",
      "Precision: 0.4953\n",
      "Recall: 0.4545\n",
      "F1: 0.3974\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "--------------------\n",
      "Y\n",
      "[0s] 28 [1s] 8\n",
      "predicted\n",
      "[0s] 20 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.6111\n",
      "macro_f1: 0.5625\n",
      "Precision: 0.5813\n",
      "Recall: 0.6161\n",
      "F1: 0.5625\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/37096547\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 12 [1s] 5\n",
      "predicted\n",
      "[0s] 15 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.7059\n",
      "macro_f1: 0.5503\n",
      "Precision: 0.6167\n",
      "Recall: 0.5583\n",
      "F1: 0.5503\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "--------------------\n",
      "Y\n",
      "[0s] 40 [1s] 5\n",
      "predicted\n",
      "[0s] 39 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.7556\n",
      "macro_f1: 0.4304\n",
      "Precision: 0.4359\n",
      "Recall: 0.4250\n",
      "F1: 0.4304\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/33241952\n",
      "--------------------\n",
      "Y\n",
      "[0s] 8 [1s] 4\n",
      "predicted\n",
      "[0s] 8 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.6250\n",
      "Precision: 0.6250\n",
      "Recall: 0.6250\n",
      "F1: 0.6250\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.573\u001b[0m\n",
      "recall:    \u001b[31m0.582\u001b[0m\n",
      "f1-score:  \u001b[31m0.510\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.534\u001b[0m\n",
      "recall:    \u001b[31m0.499\u001b[0m\n",
      "f1-score:  \u001b[31m0.349\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.626\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:    \u001b[31m0.636\u001b[0m\n",
      "f1-score:  \u001b[31m0.598\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.509\u001b[0m\n",
      "recall:    \u001b[31m0.521\u001b[0m\n",
      "f1-score:  \u001b[31m0.496\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.596\u001b[0m\n",
      "recall:    \u001b[31m0.644\u001b[0m\n",
      "f1-score:  \u001b[31m0.554\u001b[0m\n",
      "\n",
      "\u001b[31mFold 1\u001b[0m\n",
      " height must be > 0\n",
      "Write and Read a json data to internal storage android\n",
      "Android PDF Rendering\n",
      "How can I hide a fragment on start of my MainActivity( or the application)?\n",
      "polymorphic deserialization of JSON with jackson, property type becomes &quot;null&quot;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 753619.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1605\n",
      "1     803\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    659\n",
      "1    101\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.9177 - sparse_categorical_accuracy: 0.5345The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64965, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 20s 524ms/step - loss: 0.9177 - sparse_categorical_accuracy: 0.5345 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.6194\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.8593 - sparse_categorical_accuracy: 0.6329\n",
      "Epoch 00002: val_loss improved from 0.64965 to 0.61753, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 15s 390ms/step - loss: 0.8593 - sparse_categorical_accuracy: 0.6329 - val_loss: 0.6175 - val_sparse_categorical_accuracy: 0.6231\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.7651 - sparse_categorical_accuracy: 0.6873\n",
      "Epoch 00003: val_loss improved from 0.61753 to 0.60159, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 13s 338ms/step - loss: 0.7651 - sparse_categorical_accuracy: 0.6873 - val_loss: 0.6016 - val_sparse_categorical_accuracy: 0.6567\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6835 - sparse_categorical_accuracy: 0.7392\n",
      "Epoch 00004: val_loss did not improve from 0.60159\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.6835 - sparse_categorical_accuracy: 0.7392 - val_loss: 0.6236 - val_sparse_categorical_accuracy: 0.6455\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6100 - sparse_categorical_accuracy: 0.7811\n",
      "Epoch 00005: val_loss did not improve from 0.60159\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.6100 - sparse_categorical_accuracy: 0.7811 - val_loss: 0.6105 - val_sparse_categorical_accuracy: 0.6716\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5120 - sparse_categorical_accuracy: 0.8293\n",
      "Epoch 00006: val_loss improved from 0.60159 to 0.58237, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 15s 406ms/step - loss: 0.5120 - sparse_categorical_accuracy: 0.8293 - val_loss: 0.5824 - val_sparse_categorical_accuracy: 0.7388\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4345 - sparse_categorical_accuracy: 0.8638\n",
      "Epoch 00007: val_loss did not improve from 0.58237\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.4345 - sparse_categorical_accuracy: 0.8638 - val_loss: 0.6007 - val_sparse_categorical_accuracy: 0.7463\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3909 - sparse_categorical_accuracy: 0.8796\n",
      "Epoch 00008: val_loss did not improve from 0.58237\n",
      "38/38 [==============================] - 10s 261ms/step - loss: 0.3909 - sparse_categorical_accuracy: 0.8796 - val_loss: 0.6298 - val_sparse_categorical_accuracy: 0.7388\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3333 - sparse_categorical_accuracy: 0.9024\n",
      "Epoch 00009: val_loss did not improve from 0.58237\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.3333 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.6285 - val_sparse_categorical_accuracy: 0.7612\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2984 - sparse_categorical_accuracy: 0.9132Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.58237\n",
      "38/38 [==============================] - 10s 265ms/step - loss: 0.2984 - sparse_categorical_accuracy: 0.9132 - val_loss: 0.6579 - val_sparse_categorical_accuracy: 0.7575\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 26 [1s] 10\n",
      "predicted\n",
      "[0s] 23 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.7500\n",
      "macro_f1: 0.7125\n",
      "Precision: 0.7040\n",
      "Recall: 0.7346\n",
      "F1: 0.7125\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "--------------------\n",
      "Y\n",
      "[0s] 242 [1s] 7\n",
      "predicted\n",
      "[0s] 207 [1s] 42\n",
      "--------------------\n",
      "Accuracy: 0.8193\n",
      "macro_f1: 0.4907\n",
      "Precision: 0.5117\n",
      "Recall: 0.5602\n",
      "F1: 0.4907\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "--------------------\n",
      "Y\n",
      "[0s] 66 [1s] 6\n",
      "predicted\n",
      "[0s] 61 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.8472\n",
      "macro_f1: 0.6332\n",
      "Precision: 0.6118\n",
      "Recall: 0.6894\n",
      "F1: 0.6332\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/creating-and-using-fragments\n",
      "--------------------\n",
      "Y\n",
      "[0s] 132 [1s] 31\n",
      "predicted\n",
      "[0s] 51 [1s] 112\n",
      "--------------------\n",
      "Accuracy: 0.4172\n",
      "macro_f1: 0.4083\n",
      "Precision: 0.5385\n",
      "Recall: 0.5538\n",
      "F1: 0.4083\n",
      "\u001b[31m24\u001b[0m entries logged\n",
      "https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 17 [1s] 7\n",
      "predicted\n",
      "[0s] 3 [1s] 21\n",
      "--------------------\n",
      "Accuracy: 0.4167\n",
      "macro_f1: 0.4000\n",
      "Precision: 0.6667\n",
      "Recall: 0.5882\n",
      "F1: 0.4000\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "--------------------\n",
      "Y\n",
      "[0s] 53 [1s] 3\n",
      "predicted\n",
      "[0s] 6 [1s] 50\n",
      "--------------------\n",
      "Accuracy: 0.1607\n",
      "macro_f1: 0.1583\n",
      "Precision: 0.5300\n",
      "Recall: 0.5566\n",
      "F1: 0.1583\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/38980595\n",
      "--------------------\n",
      "Y\n",
      "[0s] 2 [1s] 3\n",
      "predicted\n",
      "[0s] 4 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.6000\n",
      "macro_f1: 0.5833\n",
      "Precision: 0.7500\n",
      "Recall: 0.6667\n",
      "F1: 0.5833\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 8\n",
      "predicted\n",
      "[0s] 22 [1s] 22\n",
      "--------------------\n",
      "Accuracy: 0.6818\n",
      "macro_f1: 0.6460\n",
      "Precision: 0.6818\n",
      "Recall: 0.8056\n",
      "F1: 0.6460\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30362446\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 8\n",
      "predicted\n",
      "[0s] 23 [1s] 19\n",
      "--------------------\n",
      "Accuracy: 0.5952\n",
      "macro_f1: 0.5361\n",
      "Precision: 0.5664\n",
      "Recall: 0.6066\n",
      "F1: 0.5361\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/14347588\n",
      "--------------------\n",
      "Y\n",
      "[0s] 20 [1s] 5\n",
      "predicted\n",
      "[0s] 12 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.5200\n",
      "macro_f1: 0.4792\n",
      "Precision: 0.5321\n",
      "Recall: 0.5500\n",
      "F1: 0.4792\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2883355\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 19 [1s] 5\n",
      "predicted\n",
      "[0s] 8 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.4583\n",
      "macro_f1: 0.4497\n",
      "Precision: 0.5625\n",
      "Recall: 0.5842\n",
      "F1: 0.4497\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 5\n",
      "predicted\n",
      "[0s] 3 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.5000\n",
      "macro_f1: 0.4921\n",
      "Precision: 0.6923\n",
      "Recall: 0.6364\n",
      "F1: 0.4921\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/40168601\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 1 [1s] 3\n",
      "predicted\n",
      "[0s] 3 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.5000\n",
      "macro_f1: 0.5000\n",
      "Precision: 0.6667\n",
      "Recall: 0.6667\n",
      "F1: 0.5000\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.616\u001b[0m\n",
      "recall:    \u001b[31m0.631\u001b[0m\n",
      "f1-score:  \u001b[31m0.499\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.584\u001b[0m\n",
      "recall:    \u001b[31m0.653\u001b[0m\n",
      "f1-score:  \u001b[31m0.482\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.616\u001b[0m\n",
      "recall:    \u001b[31m0.615\u001b[0m\n",
      "f1-score:  \u001b[31m0.510\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.704\u001b[0m\n",
      "recall:    \u001b[31m0.735\u001b[0m\n",
      "f1-score:  \u001b[31m0.713\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.632\u001b[0m\n",
      "recall:    \u001b[31m0.593\u001b[0m\n",
      "f1-score:  \u001b[31m0.433\u001b[0m\n",
      "\n",
      "\u001b[31mFold 2\u001b[0m\n",
      "How to Integrate reCAPTCHA 2.0 in Android\n",
      "How can I make this rxjava zip to run in parallel?\n",
      "Permission Denial when trying to access contacts in Android\n",
      "keyUp called when key is still pressed\n",
      "Don’t leak MockWebServer ports across tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7918/7918 [00:00<00:00, 858573.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1463\n",
      "1     732\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1178\n",
      "1     180\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9175 - sparse_categorical_accuracy: 0.5298The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64753, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 18s 501ms/step - loss: 0.9175 - sparse_categorical_accuracy: 0.5298 - val_loss: 0.6475 - val_sparse_categorical_accuracy: 0.6475\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8455 - sparse_categorical_accuracy: 0.6506\n",
      "Epoch 00002: val_loss improved from 0.64753 to 0.60221, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 12s 352ms/step - loss: 0.8455 - sparse_categorical_accuracy: 0.6506 - val_loss: 0.6022 - val_sparse_categorical_accuracy: 0.6721\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7425 - sparse_categorical_accuracy: 0.7075\n",
      "Epoch 00003: val_loss improved from 0.60221 to 0.58234, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 12s 352ms/step - loss: 0.7425 - sparse_categorical_accuracy: 0.7075 - val_loss: 0.5823 - val_sparse_categorical_accuracy: 0.6926\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6414 - sparse_categorical_accuracy: 0.7654\n",
      "Epoch 00004: val_loss did not improve from 0.58234\n",
      "35/35 [==============================] - 9s 256ms/step - loss: 0.6414 - sparse_categorical_accuracy: 0.7654 - val_loss: 0.5832 - val_sparse_categorical_accuracy: 0.7090\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.5555 - sparse_categorical_accuracy: 0.8118\n",
      "Epoch 00005: val_loss did not improve from 0.58234\n",
      "35/35 [==============================] - 9s 258ms/step - loss: 0.5555 - sparse_categorical_accuracy: 0.8118 - val_loss: 0.5913 - val_sparse_categorical_accuracy: 0.7131\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4707 - sparse_categorical_accuracy: 0.8483\n",
      "Epoch 00006: val_loss did not improve from 0.58234\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.4707 - sparse_categorical_accuracy: 0.8483 - val_loss: 0.6375 - val_sparse_categorical_accuracy: 0.7213\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4014 - sparse_categorical_accuracy: 0.8747Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.58234\n",
      "35/35 [==============================] - 9s 262ms/step - loss: 0.4014 - sparse_categorical_accuracy: 0.8747 - val_loss: 0.6086 - val_sparse_categorical_accuracy: 0.7500\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 201 [1s] 18\n",
      "predicted\n",
      "[0s] 126 [1s] 93\n",
      "--------------------\n",
      "Accuracy: 0.6027\n",
      "macro_f1: 0.4751\n",
      "Precision: 0.5407\n",
      "Recall: 0.6318\n",
      "F1: 0.4751\n",
      "\u001b[31m12\u001b[0m entries logged\n",
      "https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "--------------------\n",
      "Y\n",
      "[0s] 30 [1s] 4\n",
      "predicted\n",
      "[0s] 23 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.6765\n",
      "macro_f1: 0.5296\n",
      "Precision: 0.5474\n",
      "Recall: 0.6000\n",
      "F1: 0.5296\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/training/safetynet/recaptcha\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 20\n",
      "predicted\n",
      "[0s] 28 [1s] 26\n",
      "--------------------\n",
      "Accuracy: 0.6296\n",
      "macro_f1: 0.6213\n",
      "Precision: 0.6250\n",
      "Recall: 0.6338\n",
      "F1: 0.6213\n",
      "\u001b[31m13\u001b[0m entries logged\n",
      "https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 106 [1s] 11\n",
      "predicted\n",
      "[0s] 63 [1s] 54\n",
      "--------------------\n",
      "Accuracy: 0.5128\n",
      "macro_f1: 0.3929\n",
      "Precision: 0.4815\n",
      "Recall: 0.4460\n",
      "F1: 0.3929\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "--------------------\n",
      "Y\n",
      "[0s] 69 [1s] 3\n",
      "predicted\n",
      "[0s] 48 [1s] 24\n",
      "--------------------\n",
      "Accuracy: 0.6806\n",
      "macro_f1: 0.4758\n",
      "Precision: 0.5312\n",
      "Recall: 0.6739\n",
      "F1: 0.4758\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "--------------------\n",
      "Y\n",
      "[0s] 368 [1s] 5\n",
      "predicted\n",
      "[0s] 276 [1s] 97\n",
      "--------------------\n",
      "Accuracy: 0.7319\n",
      "macro_f1: 0.4322\n",
      "Precision: 0.4979\n",
      "Recall: 0.4696\n",
      "F1: 0.4322\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "--------------------\n",
      "Y\n",
      "[0s] 152 [1s] 9\n",
      "predicted\n",
      "[0s] 93 [1s] 68\n",
      "--------------------\n",
      "Accuracy: 0.6335\n",
      "macro_f1: 0.4965\n",
      "Precision: 0.5662\n",
      "Recall: 0.8059\n",
      "F1: 0.4965\n",
      "\u001b[31m9\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 27\n",
      "predicted\n",
      "[0s] 11 [1s] 52\n",
      "--------------------\n",
      "Accuracy: 0.5079\n",
      "macro_f1: 0.4740\n",
      "Precision: 0.5944\n",
      "Recall: 0.5556\n",
      "F1: 0.4740\n",
      "\u001b[31m24\u001b[0m entries logged\n",
      "https://developer.android.com/training/permissions/requesting\n",
      "--------------------\n",
      "Y\n",
      "[0s] 90 [1s] 39\n",
      "predicted\n",
      "[0s] 38 [1s] 91\n",
      "--------------------\n",
      "Accuracy: 0.4884\n",
      "macro_f1: 0.4883\n",
      "Precision: 0.5837\n",
      "Recall: 0.5825\n",
      "F1: 0.4883\n",
      "\u001b[31m32\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/35357919\n",
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 12\n",
      "predicted\n",
      "[0s] 26 [1s] 27\n",
      "--------------------\n",
      "Accuracy: 0.4906\n",
      "macro_f1: 0.4524\n",
      "Precision: 0.4957\n",
      "Recall: 0.4939\n",
      "F1: 0.4524\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24952513\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 4\n",
      "predicted\n",
      "[0s] 15 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.6296\n",
      "macro_f1: 0.5559\n",
      "Precision: 0.5917\n",
      "Recall: 0.6793\n",
      "F1: 0.5559\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/5233543\n",
      "--------------------\n",
      "Y\n",
      "[0s] 7 [1s] 14\n",
      "predicted\n",
      "[0s] 5 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.7143\n",
      "macro_f1: 0.6500\n",
      "Precision: 0.6750\n",
      "Recall: 0.6429\n",
      "F1: 0.6500\n",
      "\u001b[31m12\u001b[0m entries logged\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 3\n",
      "predicted\n",
      "[0s] 3 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.4286\n",
      "macro_f1: 0.4286\n",
      "Precision: 0.6364\n",
      "Recall: 0.6364\n",
      "F1: 0.4286\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/27297067\n",
      "--------------------\n",
      "Y\n",
      "[0s] 10 [1s] 11\n",
      "predicted\n",
      "[0s] 11 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.4762\n",
      "macro_f1: 0.4762\n",
      "Precision: 0.4773\n",
      "Recall: 0.4773\n",
      "F1: 0.4762\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.560\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:    \u001b[31m0.595\u001b[0m\n",
      "f1-score:  \u001b[31m0.496\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.586\u001b[0m\n",
      "recall:    \u001b[31m0.581\u001b[0m\n",
      "f1-score:  \u001b[31m0.493\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.560\u001b[0m\n",
      "recall:    \u001b[31m0.573\u001b[0m\n",
      "f1-score:  \u001b[31m0.534\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.547\u001b[0m\n",
      "recall:    \u001b[31m0.600\u001b[0m\n",
      "f1-score:  \u001b[31m0.530\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.543\u001b[0m\n",
      "recall:    \u001b[31m0.623\u001b[0m\n",
      "f1-score:  \u001b[31m0.463\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# @title 10-fold cross validation WIP\n",
    "CORPUS = raw_data\n",
    "\n",
    "all_tasks = sorted(list(set([d['question'] for d in raw_data])))\n",
    "rseed = 20210343\n",
    "random.seed(rseed)\n",
    "random.shuffle(all_tasks)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "file_handler = logging.FileHandler('/home/msarthur/scratch/LOG-bert_ds_android.ans')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, random_state=rseed)\n",
    "np_tasks_arr = np.array(all_tasks)\n",
    "\n",
    "\n",
    "for _iterations in range(5):\n",
    "    logger.info(Fore.YELLOW + f\"i={_iterations}\" + Style.RESET_ALL)\n",
    "    idx_split = 0\n",
    "    for train_index, test_index in kf.split(np_tasks_arr):\n",
    "        idx_split = str(idx_split)\n",
    "        # 10 runs per fold to avoid reporting peek results in a given fold\n",
    "        if idx_split in fold_results and fold_results[idx_split]['run_cnt'] >= 10:\n",
    "            logger.info(Fore.RED + f\"Fold {idx_split} FULLY TESTED\" + Style.RESET_ALL)\n",
    "            continue\n",
    "\n",
    "\n",
    "        # <------------------------------------------------------------------------- EVAL VARIABLES\n",
    "        recommendation_metrics = defaultdict(list)\n",
    "        prediction_metrics = defaultdict(list)\n",
    "        api_metrics = defaultdict(list)\n",
    "        so_metrics = defaultdict(list)\n",
    "        git_metrics = defaultdict(list)\n",
    "        misc_metrics = defaultdict(list)\n",
    "        random_prediction_metrics = defaultdict(list)\n",
    "        clz_report_lst = defaultdict(list)\n",
    "\n",
    "        classification_report_lst = []\n",
    "        log_examples_lst = []\n",
    "        source_lst = []\n",
    "        venn_diagram_set = []\n",
    "        # <------------------------------------------------------------------------- EVAL VARIABLES\n",
    "\n",
    "\n",
    "        test_tasks_lst = np_tasks_arr[test_index].tolist()\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split}\" + Style.RESET_ALL)\n",
    "        logger.info('\\n'.join(test_tasks_lst))\n",
    "\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "        df_train, df_val, df_test, weights = get_train_val_test(\n",
    "            test_tasks_lst,\n",
    "            aug=USE_DS_SYNTHETIC,\n",
    "            undersample=UNDERSAMPLING, \n",
    "            undersample_n=N_UNDERSAMPLING\n",
    "        )\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "\n",
    "        logger.info('-' * 10)\n",
    "        logger.info(Fore.RED + 'train'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_train.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'test'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_test.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'weights'+ Style.RESET_ALL)\n",
    "        logger.info(str(weights))\n",
    "        logger.info('-' * 10)\n",
    "\n",
    "\n",
    "        # Encode X_train\n",
    "        train_encodings = _encode(tokenizer, df_train)\n",
    "        train_labels = df_train['category_index'].tolist()\n",
    "\n",
    "        # Encode X_valid\n",
    "        val_encodings = _encode(tokenizer, df_val)\n",
    "        val_labels = df_val['category_index'].tolist()\n",
    "\n",
    "\n",
    "        # https://huggingface.co/transformers/custom_datasets.html\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(train_encodings),\n",
    "            train_labels\n",
    "        ))\n",
    "\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(val_encodings),\n",
    "            val_labels\n",
    "        ))\n",
    "\n",
    "\n",
    "        if model_id == 'distilbert-base-uncased':\n",
    "            model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "                model_id, cache_dir='/home/msarthur/scratch'\n",
    "            )\n",
    "        else:\n",
    "            model = TFBertForSequenceClassification.from_pretrained(\n",
    "                model_id, cache_dir='/home/msarthur/scratch', local_files_only=True\n",
    "            )\n",
    "\n",
    "        # freeze all the parameters\n",
    "        # for param in model.parameters():\n",
    "        #   param.requires_grad = False\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "        METRICS = [\n",
    "            tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        ]\n",
    "\n",
    "        early_stopper = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', mode='min', patience=4, \n",
    "            verbose=1, restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
    "        checkpoint_filepath = '/home/msarthur/scratch/best_model'\n",
    "\n",
    "        mc = tf.keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath, \n",
    "            monitor='val_loss', mode='min', verbose=1, \n",
    "            save_best_only=True,\n",
    "            save_weights_only=True\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_fn,\n",
    "            metrics=METRICS\n",
    "        )\n",
    "\n",
    "        # https://discuss.huggingface.co/t/how-to-dealing-with-data-imbalance/393/3\n",
    "        # https://wandb.ai/ayush-thakur/huggingface/reports/Early-Stopping-in-HuggingFace-Examples--Vmlldzo0MzE2MTM\n",
    "        model.fit(\n",
    "            train_dataset.shuffle(1000).batch(BATCH_SIZE), \n",
    "            epochs=EPOCHS, \n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_weight=weights,\n",
    "            validation_data=val_dataset.shuffle(1000).batch(BATCH_SIZE),\n",
    "            callbacks=[early_stopper, mc]\n",
    "        )\n",
    "\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Testing model\" + Style.RESET_ALL)\n",
    "        for source in df_test[\"source\"].unique():\n",
    "            df_source = df_test[df_test[\"source\"] == source]   \n",
    "            logger.info(source)\n",
    "            test_model(source, df_source, model, tokenizer, pos_filter=USE_FRAME_FILTERING)\n",
    "\n",
    "        add_idx_fold_results(idx_split, fold_results)\n",
    "        if 'venn_diagram_set' not in fold_results:\n",
    "            fold_results['venn_diagram_set'] = []\n",
    "\n",
    "        fold_results['venn_diagram_set'] += venn_diagram_set\n",
    "        fold_results['venn_diagram_set'] = list(set(fold_results['venn_diagram_set']))\n",
    "\n",
    "\n",
    "        _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "        logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "        logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "        logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "        idx_split = int(idx_split)\n",
    "\n",
    "        idx_split += 1\n",
    "\n",
    "\n",
    "        log_sources_data = [api_metrics, so_metrics, git_metrics, misc_metrics]\n",
    "        log_sources_ids = ['api_metrics', 'so_metrics', 'git_metrics', 'misc_metrics']\n",
    "\n",
    "        for _id, __data in zip(log_sources_ids, log_sources_data):\n",
    "            _precision, _recall, _f1score = avg_macro_metric_for(__data)\n",
    "\n",
    "            logger.info(\"\")\n",
    "            logger.info(Fore.YELLOW + f\"{_id}\" + Style.RESET_ALL)\n",
    "            logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "            logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "            logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "    #     break\n",
    "        if idx_split >= 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m0\u001b[0m\n",
      "precision: \u001b[31m0.565\u001b[0m [0.57, 0.54, 0.55, 0.59, 0.58, 0.54, 0.57, 0.57]\n",
      "recall:    \u001b[31m0.573\u001b[0m [0.59, 0.54, 0.56, 0.58, 0.57, 0.56, 0.61, 0.58]\n",
      "f1-score:  \u001b[31m0.507\u001b[0m [0.5, 0.45, 0.48, 0.53, 0.52, 0.53, 0.54, 0.51]\n",
      "\u001b[33m1\u001b[0m\n",
      "precision: \u001b[31m0.576\u001b[0m [0.65, 0.54, 0.57, 0.61, 0.53, 0.51, 0.62]\n",
      "recall:    \u001b[31m0.606\u001b[0m [0.67, 0.59, 0.6, 0.66, 0.54, 0.56, 0.63]\n",
      "f1-score:  \u001b[31m0.505\u001b[0m [0.54, 0.5, 0.52, 0.54, 0.48, 0.47, 0.5]\n",
      "\u001b[33m2\u001b[0m\n",
      "precision: \u001b[31m0.563\u001b[0m [0.55, 0.54, 0.6, 0.53, 0.58, 0.58, 0.56]\n",
      "recall:    \u001b[31m0.597\u001b[0m [0.57, 0.57, 0.63, 0.57, 0.62, 0.63, 0.59]\n",
      "f1-score:  \u001b[31m0.501\u001b[0m [0.44, 0.5, 0.53, 0.43, 0.54, 0.57, 0.5]\n"
     ]
    }
   ],
   "source": [
    "for key_i, value in fold_results.items():\n",
    "    if isinstance(value, dict):\n",
    "        for key_j, __data in value.items():\n",
    "            if key_j == 'overall':\n",
    "                logger.info(Fore.YELLOW + f\"{key_i}\" + Style.RESET_ALL)\n",
    "                logger.info(\"precision: \" + Fore.RED +\n",
    "                            \"{:.3f}\".format(np.mean(__data['precision'])) + Style.RESET_ALL +\n",
    "                           f\" {str([round(x, 2) for x in __data['precision']])}\")\n",
    "                logger.info(\"recall:    \" + Fore.RED +\n",
    "                            \"{:.3f}\".format(np.mean(__data['recall'])) + Style.RESET_ALL+\n",
    "                           f\" {str([round(x, 2) for x in __data['recall']])}\")\n",
    "                logger.info(\"f1-score:  \" + \n",
    "                            Fore.RED + \"{:.3f}\".format(np.mean(__data['fscore'])) + Style.RESET_ALL+\n",
    "                           f\" {str([round(x, 2) for x in __data['fscore']])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCaching results\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(Fore.YELLOW + \"Caching results\" + Style.RESET_ALL)\n",
    "with open('bert_ds_android.json', 'w') as fo:\n",
    "    json.dump(fold_results, fo, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', 'venn_diagram_set', '1', '2'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for source in df_test[\"source\"].unique():\n",
    "#     df_source = df_test[df_test[\"source\"] == source]   \n",
    "#     logger.info(source)\n",
    "#     test_model(source, df_source, model, tokenizer, pos_filter=True)\n",
    "#     cnt += 1\n",
    "#     if cnt >= 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cYVkKLe-B1j0"
   },
   "outputs": [],
   "source": [
    "#@title Metrics report\n",
    "# logger.info(json.dumps(fold_results, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(api_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"API metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(so_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"SO metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(git_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"GIT metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(misc_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"MISC metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "zUOGnWgIMYLN"
   },
   "outputs": [],
   "source": [
    "def examples_per_source_type(source_type='misc', n_samples=None):\n",
    "    _sources = list(set([x[0] for x in log_examples_lst]))\n",
    "\n",
    "    _template = \"[w={}]\" + Fore.RED + \"[y={}]\" + Fore.YELLOW + \"[p={:.4f}]\" + Style.RESET_ALL + \" {}\"\n",
    "\n",
    "    idx = 0\n",
    "    for s in _sources:\n",
    "        examples_in_source = []\n",
    "        if source_type == 'api' and ('docs.oracle' in s or 'developer.android' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'so' and ('stackoverflow.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]            \n",
    "            idx += 1\n",
    "        elif source_type == 'git' and ('github.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'misc' and 'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        if not examples_in_source:\n",
    "            continue\n",
    "        logger.info('')\n",
    "        logger.info(Fore.RED + f\"{task_title}\" + Style.RESET_ALL)    \n",
    "        logger.info(s)\n",
    "        logger.info('')\n",
    "\n",
    "        for _, _, pweights, y_predict, y_probs, text in examples_in_source:\n",
    "            logger.info(_template.format(pweights, y_predict, y_probs, text))\n",
    "            logger.info('')\n",
    "        logger.info('-' * 20)\n",
    "      \n",
    "        if n_samples and idx >= n_samples:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Fjg9kKaDM0fo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAPI\u001b[0m\n",
      "\n",
      "\u001b[31mHow to Integrate reCAPTCHA 2.0 in Android\u001b[0m\n",
      "https://developer.android.com/training/safetynet/recaptcha\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7355]\u001b[0m In the Adding reCAPTCHA to your app section on the page that appears next, your public and private keys appear under Site key and Secret key, respectively.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7347]\u001b[0m reCAPTCHA is a free service that uses an advanced risk analysis engine to protect your app from spam and other abusive actions.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7316]\u001b[0m The SafetyNet service includes a reCAPTCHA API that you can use to protect your app from malicious traffic.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7314]\u001b[0m When the reCAPTCHA API executes the onSuccess ( ) method, the user has successfully completed the CAPTCHA challenge.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7314]\u001b[0m Add the calling app's package name to the site key on the reCAPTCHA Admin Console, or disable package name validation for your site key.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7307]\u001b[0m By accessing or using the reCAPTCHA API, you agree to the Google APIs Terms of Service, and to these Additional Terms.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7304]\u001b[0m Check the Accept the reCAPTCHA Terms of Service checkbox, then click Register.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7304]\u001b[0m To invoke the SafetyNet reCAPTCHA API, you call the verifyWithRecaptcha ( ) method.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7302]\u001b[0m Before using the reCAPTCHA API, you need to add the SafetyNet API to your project.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7298]\u001b[0m This section describes how to call the reCAPTCHA API to send a CAPTCHA verification request and receive the user response token.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mPermission Denial when trying to access contacts in Android\u001b[0m\n",
      "https://developer.android.com/training/permissions/requesting\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7176]\u001b[0m If the ContextCompat.checkSelfPermission ( ) method returns PERMISSION_DENIED, call shouldShowRequestPermissionRationale ( ).\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7127]\u001b[0m In particular, your app should make users aware of the features that don't work because of the missing permission.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7121]\u001b[0m This action has the same effect as if the user viewed a permission in system settings and changed your app's access level to Deny.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7116]\u001b[0m If the user revokes the one-time permission, such as in system settings, your app can not access the data, regardless of whether you launched a foreground service.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7114]\u001b[0m If the user denies a permission request, your app should help users understand the implications of denying the permission.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7112]\u001b[0m The following code snippet demonstrates how to request a permission using a request code:\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7095]\u001b[0m In certain situations, the permission might be denied automatically, without the user taking any action.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7077]\u001b[0m Also, the text in the system permission dialog references the permission group associated with the permission that you requested.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7073]\u001b[0m At the same time, your app should respect the user's decision to deny a permission.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7071]\u001b[0m In the following example, the system is modified such that it resets an app's permissions only one second after you stop interacting with an app:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mHow can I make this rxjava zip to run in parallel?\u001b[0m\n",
      "https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7085]\u001b[0m If you've used something like RxJava before, Flow provides similar functionality.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7055]\u001b[0m If you've used RxJava, you can use mapLatest exactly like you'd use switchMap.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7047]\u001b[0m Now that the sorting logic is in place, replace the code for plants and getPlantsWithGrowZone with the LiveData builder below:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6999]\u001b[0m If you've used libraries like RxJava extensively, this is one of the main differences provided by Flow.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6988]\u001b[0m How do I set up a device for development ?\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6966]\u001b[0m It's an easy way to communicate an event into a coroutine like we're doing here.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6960]\u001b[0m This is exactly the same as when we started this codelab with passing the LiveData through to the ViewModel.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6864]\u001b[0m The LiveData will be updated using the LiveData builder and coroutines with additional sorting logic:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6834]\u001b[0m So here we're emitting an empty list, delaying calling getOrAwait by 1500ms, then continuing the original flow.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6801]\u001b[0m So, why did Kotlin introduce a new Flow type, and how is it different than a regular sequence ?\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mkeyUp called when key is still pressed\u001b[0m\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7037]\u001b[0m To respond to modifier key events such as when a key is combined with Shift or Control, you can query the KeyEvent that's passed to the callback method.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7016]\u001b[0m However, the simplest solution is to check whether the exact modifier key you care about is being pressed with methods such as isShiftPressed ( ) and isCtrlPressed ( ).\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.6889]\u001b[0m To handle an individual key press, implement onKeyDown ( ) or onKeyUp ( ) as appropriate.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6821]\u001b[0m For example, this implementation responds to some keyboard keys to control a game:\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.6775]\u001b[0m If the user presses and holds the button, then onKeyDown ( ) is called multiple times.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6675]\u001b[0m For example, here's the onKeyUp ( ) implementation again, with some extra handling for when the Shift key is held down with one of the keys:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6397]\u001b[0m You should never rely on receiving key events for any key on a soft input method ( an on-screen keyboard ).\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6191]\u001b[0m If, however, you'd like to intercept or directly handle the keyboard input yourself, you can do so by implementing callback methods from the KeyEvent.Callback interface, such as onKeyDown ( ) and onKeyMultiple ( ).\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.6124]\u001b[0m Usually, you should use onKeyUp ( ) if you want to be sure that you receive only one event.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5696]\u001b[0m Both the Activity and View class implement the KeyEvent.Callback interface, so you should generally override the callback methods in your extension of these classes as appropriate.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for API sources\n",
    "\n",
    "logger.info(Fore.RED + \"API\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='api', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FDBgOWQXNW1i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mGIT\u001b[0m\n",
      "\n",
      "\u001b[31mPermission Denial when trying to access contacts in Android\u001b[0m\n",
      "https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7097]\u001b[0m Check permissions before calling Contacts.getAll ( )\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7090]\u001b[0m If permissions are not granted, the callback should be called, with the error field being non-null/undefined.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6979]\u001b[0m You must use read profile permission in android platform.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6974]\u001b[0m My PermissionsAndroid is granted and i can not catch the error, still have the crash with API 22 when i make a getAll call.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6937]\u001b[0m Contacts.getAll ( ) crashes Android app when permissions are not granted\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6931]\u001b[0m In iOS, permissions aren't granted, it will be handled in the error block:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6911]\u001b[0m Contacts.getAll ( ) crashes Android app when permissions are not granted · Issue # 516 · morenoh149/react-native-contacts · GitHub\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6880]\u001b[0m The weirdest part was how getAll did not throw an error, it just hung indefintiely, while addContact would create the contact in the mobile app BUT THEN throw an error on READ permission not granted, which was very difficult to reason through.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6824]\u001b[0m In Android, if permissions are not granted, errors do not get caught by this block.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6565]\u001b[0m I ran into this too and it was super weird, I found you need both WRITE_CONTACTS and READ_CONTACTS regardless of API version.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for GIT sources\n",
    "\n",
    "logger.info(Fore.RED + \"GIT\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='git', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "G4Bqx8AbNoV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSO\u001b[0m\n",
      "\n",
      "\u001b[31mDon’t leak MockWebServer ports across tests\u001b[0m\n",
      "https://stackoverflow.com/questions/24952513\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7288]\u001b[0m The easiest way to simulate network issues with MockWebServer is by setting the SocketPolicy to SocketPolicy.DISCONNECT _ AT_START, SocketPolicy.NO _ RESPONSE or etc:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7264]\u001b[0m As stated in above answers, MockWebServer is a great library for mocking retrofit responses, but you don't need that library for mocking this exception.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7243]\u001b[0m MockRestAdapter offers these APIs:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7213]\u001b[0m For mocking all other exceptions I would recommend MockWebServer, I use it a lot in my project for testing responses.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7180]\u001b[0m ConnectException - mockwebserver can throw a timeout exception.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7111]\u001b[0m I don't know if it's useful, but you can simulate a timeout with MockWebServer:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7106]\u001b[0m Retrofit has a retrofit-mock module which offers a MockRestAdapter class whose purpose is to simulate network delay and errors.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6272]\u001b[0m Note: Please, set HttpClient of your code -LRB- e.g. AsyncHttpClient -RRB- with that number port for testing purpose.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6069]\u001b[0m This is a used in conjunction with the normal RestAdapter to create an instance of your service.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5905]\u001b[0m You can see how to do it here:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mPermission Denial when trying to access contacts in Android\u001b[0m\n",
      "https://stackoverflow.com/questions/5233543\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7104]\u001b[0m While developing for a target platform of 2.3.3 using Eclipse on Ubuntu, I had permission failures in the log file that indicated I needed this exact line while working on something similar.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7060]\u001b[0m Beginning in Android 6.0 -LRB- API level 23 -RRB-, users grant permissions to apps while the app is running, not when they install the app.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7055]\u001b[0m These permissions will show a dialog to the user, similar to the following one:\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7042]\u001b[0m with the api 23, permission <uses-permission android:name=\"android.pemission.READ_CONTACTS\"/> dont work, change the api level in the emulator for api 22 -LRB- lollipop -RRB- or lower\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6979]\u001b[0m Hello Steven the debug log trace tells you that you need ... requires android.permission.READ _ CONTACTS\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6921]\u001b[0m The user can grant or deny each permission, and the app can continue to run with limited capabilities even if the user denies a permission request.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6915]\u001b[0m If the device is running Android 6.0 or higher, and your app's target SDK is 23 or higher: The app has to list the permissions in the manifest, and it must request each dangerous permission it needs while the app is running.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6907]\u001b[0m so just try something by editing the Manifest.xml like adding another permission, let see if its not correctly readed.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6885]\u001b[0m Requesting Permissions at Run Time\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.6816]\u001b[0m If the permission you need to add isn't listed under the normal permissions, you'll need to deal with `` Runtime Permissions''.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mHow can I make this rxjava zip to run in parallel?\u001b[0m\n",
      "https://stackoverflow.com/questions/35357919\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7205]\u001b[0m However, in both of these cases, the zip function can only accept a single Object -LSB- -RSB- parameter since the types of the observables in the list are not known in advance as well as their number.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7163]\u001b[0m I was trying to use @MyDogTom solution, unfortunately there is no Observable.from in RxJava.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7159]\u001b[0m The item 3would never be zipped since the other observables have completed.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7115]\u001b[0m This means that that the zip function would have to check the number of parameters and cast them accordingly.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7099]\u001b[0m You probably looked at the zip operator that works with 2 Observables.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7056]\u001b[0m I'm writing some computation heave code in Kotlin with JavaRx Observables and RxKotlin.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7049]\u001b[0m Then 1, Blah, True and 2, Hello, True would be the only items passed into the zip function -LRB- s -RRB-.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7046]\u001b[0m Note that in the zip function, the parameters have concrete types that correspond to the types of the observables being zipped.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7022]\u001b[0m There is also the static method Observable.zip.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6954]\u001b[0m which sounds like what you're after if you don't want parallel execution.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mHow to Integrate reCAPTCHA 2.0 in Android\u001b[0m\n",
      "https://stackoverflow.com/questions/27297067\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7338]\u001b[0m That means, that the widget will take care of asking questions, validating responses all the way till it determines that a user is actually a human, only then you get a g-recaptcha-response value.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7332]\u001b[0m A method I use in my login servlet to verify reCaptcha responses.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7321]\u001b[0m And replace the response_string with the value that you earlier got by the g-recaptcha-response field.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7309]\u001b[0m Anyone with HTTP POST knowledge could put random data inside of the g-recaptcha-response form field, and foll your site to make it think that this field was provided by the google widget.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7294]\u001b[0m The cool thing about the new Google Recaptcha is that the validation is now completely encapsulated in the widget.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7255]\u001b[0m Hi curious you can validate your google recaptcha at client side also 100 % work for me to verify your google recaptcha just see below code This code at the html body:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6463]\u001b[0m Returns the API response in a JsonObject.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6262]\u001b[0m Here is complete demo code to understand client side and server side process.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.5473]\u001b[0m You will get a JSON Response with a success field.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5444]\u001b[0m you can copy paste it and just replace google site key and google secret key.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for SO sources\n",
    "\n",
    "logger.info(Fore.RED + \"SO\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='so', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2_mgLqe0N-hs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mMISC\u001b[0m\n",
      "\n",
      "\u001b[31mPermission Denial when trying to access contacts in Android\u001b[0m\n",
      "https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7060]\u001b[0m They're the most dangerous, because any app with root privileges can do whatever it wants -- regardless which permissions you've already blocked or enabled.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7058]\u001b[0m See all apps that are using a specific permission This is similar to the method above, but it works from the opposite direction.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7039]\u001b[0m Choose any app, and tap Permissions.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7031]\u001b[0m Now Android allows you to decide which permissions to accept on a case-by-case basis -- after the app is installed.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7018]\u001b[0m The good: Fitness apps need this permission to monitor your heart rate while you exercise, provide health tips, etc..\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7016]\u001b[0m If you've installed a camera app, for example, it will need your permission to access the camera before it can actually take photos.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7013]\u001b[0m Android app permissions can give apps control of your phone and access to your private conversations, photos, and more.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6969]\u001b[0m Anyone who's ever installed an app from Google Play has likely seen an app permission request.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6952]\u001b[0m Choose any permission to see which apps are using it.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6937]\u001b[0m Just remember ... App permissions exist to protect you.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mPermission Denial when trying to access contacts in Android\u001b[0m\n",
      "https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7055]\u001b[0m These permissions will show a dialog to the user, similar to the following one:\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7052]\u001b[0m These permission can then be allowed or denied by the user.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7011]\u001b[0m These are permissions that are requested while the app is running ( instead of before the app is installed ).\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6975]\u001b[0m Your app will continue to use the old permissions model.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6974]\u001b[0m To request one of the many permissions, simply specify it in the AndroidManifest.xml: For example, an application that needs to read the user's contacts would add the following to it's AndroidManifest.xml:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6964]\u001b[0m All permissions listed in the AndroidManifest will be asked for at install time.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6961]\u001b[0m When the app needs to use any of the protected features of the device ( sending network requests, accessing the camera, sending an SMS, etc ) it must obtain the appropriate permission from the user to do so.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6960]\u001b[0m The user had no way of changing permissions, even after installing the app.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6952]\u001b[0m Users will be able to revoke permissions after the app is installed.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6942]\u001b[0m Overview By default, an Android app starts with zero permissions granted to it.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mHow can I make this rxjava zip to run in parallel?\u001b[0m\n",
      "https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7200]\u001b[0m DZone > Java Zone > RxJava: Idiomatic Concurrency -- flatMap ( ) vs. parallel ( )\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7177]\u001b[0m RxJava: Idiomatic Concurrency -- flatMap ( ) vs. parallel ( )\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7126]\u001b[0m java, rxjava, concurrency, parallel, flatmap, tutorial\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7107]\u001b[0m Introduced in RxJava 2.0.5, there is a new operator called ... parallel ( ) !\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7097]\u001b[0m By default, RxJava will take first 128 upstream events ( UUIDs ), turn them into sub-streams, and subscribe to all of them.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7097]\u001b[0m It's up to you, but parallel ( ) seems to be much easier to read and grasp.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7060]\u001b[0m And because all sub-streams are blocking, when RxJava tries to subscribe to all of them, it effectively subscribes sequentially to one after another.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7053]\u001b[0m RxJava doesn't introduce any thread pool unless explicitly asked for.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7051]\u001b[0m When it comes to concurrent programming using the RxJava library, here's a breakdown of flatMap ( ) and parallel ( ) and some guidance as to which is the most helpful.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7009]\u001b[0m It's quite surprising because an operator with the same name was removed before RxJava became 1.0 due to many misconceptions surrounding it, leading to it being misused.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mDon’t leak MockWebServer ports across tests\u001b[0m\n",
      "https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7278]\u001b[0m MockWebServer is a library from Square -- the people who made Retrofit and OkHttp.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7259]\u001b[0m Configure MockWebServer to return a 500 status code and write a UI test to verify that the app displays the text.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7250]\u001b[0m From now on, Gradle will use MockTestRunner whenever you run any UI tests.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7242]\u001b[0m In this tutorial, you've set up MockWebServer, configured it to mock API calls from a remote server and written UI tests to verify how an app functions.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7232]\u001b[0m Place the cursor on the word MockWebServer and press Alt-Enter, then choose Import to automatically add the missing import line and fix the build.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7231]\u001b[0m Create a file named MockTestRunner.kt in the androidTest folder and add the following code to it:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7229]\u001b[0m Configuring MockWebServer In this section, you'll configure a MockWebServer instance and make it return the response you saved in the JSON file.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7211]\u001b[0m Creating a File Reader to Read the Response MockWebServer can't read the response from the JSON file directly.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7211]\u001b[0m Testing a Successful Case For your first test case, you'll make MockWebServer return the response from the JSON file.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7210]\u001b[0m You can test MockWebServer even without Espresso but this tutorial uses it to demonstrate a complete testing scenario.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mDon’t leak MockWebServer ports across tests\u001b[0m\n",
      "https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7278]\u001b[0m and yes for all of this to work make changes to your build.gradle fileNow that all the setup is done let us dive into MockWebServerCase Study - A basic application that sends an API request as soon as you open the application.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7276]\u001b[0m Rather than making an actual network call MockWebServer allows you to mock the response of the network request.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7236]\u001b[0m Handling UI changes along with tons of network calls becomes a nightmare with Espresso.Thanks to the guys at Square we have MockWebServer that allows you to mock web request and helps a ton with instrumentation test.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7229]\u001b[0m Instrumentation testing with MockWebServer and Dagger2Mohak PuriFollowJun 30, 2018 · 5 min readCredit: GoogleTesting on android is tough specially when it comes to instrumentation testing.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7221]\u001b[0m Sign inAndroidLearn Advanced Android By DoingRoadmapLearn Advanced AndroidInstrumentation testing with MockWebServer and Dagger2Mohak PuriFollowJun 30, 2018 · 5 min readCredit: GoogleTesting on android is tough specially when it comes to instrumentation testing.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7182]\u001b[0m Let's codeAdding MockWebServer as a dependencyLet us quickly go through some dagger stuff.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7182]\u001b[0m So in a nutshell, when you run your test MockWebServer intercepts your network call providing you with the data you mock data.Why?So it comes down to this.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7179]\u001b[0m Also the focus is on MockWebServer and I wont be explaining Dagger.Enough talking !\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7176]\u001b[0m Instrumentation testing with MockWebServer and Dagger2Mohak PuriFollowJun 30, 2018 · 5 min read\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7136]\u001b[0m Let us create our custom runner class that extends the AndroidJUnitRunner.MockRunner.javaLet me bring you focus to this lineWhen we use this MockRunner for testing our application, rather than using MyTestingApp for creating our application component the test will use UiTestApp.So how does that help ?\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for MISC sources\n",
    "\n",
    "logger.info(Fore.RED + \"MISC\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='misc', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m301 entries VENN SET\u001b[0m\n",
      "To set this up, you'll need a mechanism to tell the app to use the real URL normally, but the mock URL when you run tests.\n",
      "Next, modify teardown ( ) to stop the server:\n",
      "Make sure you add it outside of the application tag.\n",
      "You can then use one of the following classes:\n",
      "Define a concrete implementation of the ContentProvider class and its required methods.\n",
      "Of the suggestions proposed, LINK actually combines observable results with each other, which may or may not be what is wanted, but was not asked in the question.\n",
      "Now that we've defined the basic adapter and ViewHolder, we need to begin filling in our adapter.\n",
      "Returns the value mapped by name if it exists and is an int or can be coerced to an int, or throws otherwise.\n",
      "I had the same error and traced it to a bug with DrawableCompat.wrap -LRB- -RRB- in 23.4.0 that doesn't exist in earlier & later versions of the support library.\n",
      "Important: Normal Permissions must be added to the AndroidManifest:\n",
      "The system passes in the user response to the permission dialog, as well as the request code that you defined, as shown in the following code snippet:\n",
      "Every android app has its own internal storage only that app can access, you can read from there or write to it.\n",
      "A mock web server is a program that mocks the behavior of an actual remote server but doesn't make calls over the internet.\n",
      "In this case, you want to add a `` placeholder'' container ( usually a FrameLayout ) to your activity where the fragment is inserted at runtime:\n",
      "This means that that the zip function would have to check the number of parameters and cast them accordingly.\n",
      "Each group contains multiple permissions, and approving a single permission from any group automatically approves all other permissions within that same group.\n",
      "Returns the value mapped by name if it exists, coercing it if necessary, or fallback if no such mapping exists.\n",
      "Although content providers are meant to make data available to other applications, you may of course have activities in your application that allow the user to query and modify the data managed by your provider.\n",
      "In your app's manifest file, declare the permissions that your app might need to request.\n",
      "Follow these steps to add a method to the MainActivity class that's called when the Send button is tapped:\n",
      "Runtime Permissions If the permission you need to add isn't listed under the normal permissions, you'll need to deal with `` Runtime Permissions''.\n",
      "The cool thing about the new Google Recaptcha is that the validation is now completely encapsulated in the widget.\n",
      "The following code shows how to do this in the context of an Activity, but this is also possible from within a Fragment.\n",
      "The following code snippet demonstrates how to request a permission using a request code:\n",
      "The above classes should be: The @JsonTypeInfo includes a few configuration fields to indicate how Jackson should find the classes to deserialize the JSON to.\n",
      "Returns the value mapped by name if it exists, coercing it if necessary, or the empty string if no such mapping exists.\n",
      "I'd still recommend to use use = JsonTypeInfo.Id.NAME, as the new way LINK in complex cases when it has no way to determine which subtype to use.\n",
      "Checking for permissions before performing privileged actions seems fine to me.\n",
      "Before using the reCAPTCHA API, you need to add the SafetyNet API to your project.\n",
      "You use the site key when you send the verify request, and you use the secret key when you validate the user response token.\n",
      "We didn't say that there should many sub-streams running concurrently.\n",
      "Let's create a Java class that will act as the Business model in our application:\n",
      "A Rectangle object's width and height are public fields.\n",
      "and successfully create a Business with Business.fromJson ( json ).\n",
      "These are permissions that are requested while the app is running ( instead of before the app is installed ).\n",
      "To allow the system to manage the request code that's associated with a permissions request, add dependencies on the following libraries in your module's build.gradle file:\n",
      "to this approach instead leveraging add, show, and hide in the FragmentTransaction:\n",
      "You can remove the if conditions because you only want to draw one icon right ?\n",
      "Keep in mind that your targetSdkVersion must be > = 23 and your emulator / device must be running Marshmallow to see the new permissions model.\n",
      "Statically To add the fragment statically, simply embed the fragment in the activity's xml layout file:\n",
      "If document page size is greater than the printed media size the content should be anchored to the upper left corner of the page for left-to-right locales and top right corner for right-to-left locales.\n",
      "To do this, we might modify this code:\n",
      "So really you want to replace:\n",
      "As you can see, there is nothing special for Cat and Dog, the only one that know about them is the abstract class Animal, so when deserializing, you'll target to Animal and the ObjectMapper will return the actual instance as you can see in the following test:\n",
      "When I updated your sample with these annotations, Jackson correctly deserialized each object to the expected subclass.\n",
      "In most of your interaction with the permission API's you'll be working with the individual permissions and not the permission groups, but pay close attention to what the API expects as both permissions and permission groups are Strings.\n",
      "Returns the value mapped by name if it exists and is a JSONArray, or null otherwise.\n",
      "1 -RRB- Add save Button in each row of RecyclerView on this Button click -LRB- onClick -RRB-\n",
      "An example of polymorphic deserialization is if you want your JSON object to deserialize into a java subclass.\n",
      "Design your app's UX so that specific actions in your app are associated with specific runtime permissions.\n",
      "Normal Permissions When you need to add a new permission, first check this page to see if the permission is considered a PROTECTION_NORMAL permission.\n",
      "Each time your app needs to access functionality that requires a permission, you should check that your app is still granted that permission.\n",
      "If the user denied the permission instead, gracefully degrade your app experience so that it provides functionality to the user, even without the information that's protected by that permission.\n",
      "When the app needs to use any of the protected features of the device ( sending network requests, accessing the camera, sending an SMS, etc ) it must obtain the appropriate permission from the user to do so.\n",
      "Communicating with Fragments Fragments should generally only communicate with their direct parent activity.\n",
      "If your app needs to use resources or information outside of its own sandbox, you can declare a permission and set up a permission request that provides this access.\n",
      "However, in both of these cases, the zip function can only accept a single Object -LSB- -RSB- parameter since the types of the observables in the list are not known in advance as well as their number.\n",
      "Returns the value mapped by name if it exists and is a JSONObject, or throws otherwise.\n",
      "We have a protocol where all JSON objects contain a _ type field that indicates what the JSON represents.\n",
      "Merely wrapping blocking code in a Flowable doesn't magically add concurrency.\n",
      "get a seekable file descriptor from your pdf document:\n",
      "Normal permissions are automatically granted at install time and never prompt the user asking for permission.\n",
      "Usually, you should use onKeyUp ( ) if you want to be sure that you receive only one event.\n",
      "Check the user's response, whether they chose to grant or deny the runtime permission.\n",
      "To do so, include the request code in a call to requestPermissions ( ).\n",
      "The Intent constructor takes two parameters, a Context and a Class.\n",
      "Usage Defining a Fragment A fragment, like an activity, has an XML layout file and a Java class that represents the Fragment controller.\n",
      "Returns the value mapped by name if it exists and is a long or can be coerced to a long, or throws otherwise.\n",
      "Next, you'll create an instance of MockWebServer.\n",
      "When the reCAPTCHA API executes the onSuccess ( ) method, the user has successfully completed the CAPTCHA challenge.\n",
      "Once the test is done we shutdown the server.\n",
      "Contacts Allows apps to read, create, or edit your contact list, as well as access the list of all accounts ( e.g., Facebook, Instagram, Twitter, etc. ) used on your device.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns the value mapped by name, or throws if no such mapping exists.\n",
      "In MainActivity, add the EXTRA_MESSAGE constant and the sendMessage ( ) code, as shown:\n",
      "However, in the API response, we actually get a collection of business JSON in an array.\n",
      "Consider the following below: If you have a JSON object for `` Vehicle'', it could be a `` Car'' or `` Plane'', each with its own fields, some unique to the other.\n",
      "If you don't declare any dangerous permissions, or if your app is installed on a device that runs Android 5.1 ( API level 22 ) or lower, the permissions are automatically granted, and you don't need to complete any of the remaining steps on this page.\n",
      "Next, we need to add method that would manage the deserialization of a JSON dictionary into a populated Business object:\n",
      "Therefore, Android will always ask you to approve dangerous permissions.\n",
      "Note that in the zip function, the parameters have concrete types that correspond to the types of the observables being zipped.\n",
      "And this code snippet demonstrates the recommended process of checking for a permission, and requesting a permission from the user when necessary:\n",
      "In your activity or fragment's initialization logic, pass in an implementation of ActivityResultCallback into a call to registerForActivityResult ( ).\n",
      "One of your classes implements a subclass ContentProvider, which is the interface between your provider and other applications.\n",
      "Since you want to offset the icon to the top right, you will need to offset the ( x, y ) position slightly, but make sure you use dp because if you simply offset the ( x, y ) by some amount it willnot translate to different devices.\n",
      "Override the onSuccess ( ) and onFailure ( ) methods to handle both possible outcomes of the verification request task.\n",
      "Keep a reference to the return value of registerForActivityResult ( ), which is of type ActivityResultLauncher.\n",
      "To register a key pair for use with the SafetyNet reCAPTCHA API, navigate to the reCAPTCHA Android signup site, then complete the following sequence of steps:\n",
      "There is a simple method call in android to go from pixels to dp.\n",
      "Fragments should be modular, standalone and reusable components.\n",
      "You will get a JSON Response with a success field.\n",
      "Create a file named MockTestRunner.kt in the androidTest folder and add the following code to it:\n",
      "You must check whether you have that permission every time you perform an operation that requires that permission.\n",
      "Check permissions before calling Contacts.getAll ( )\n",
      "Potentially dangerous permissions to look out for Anyone concerned about their privacy and security should keep an eye out for apps that request access to following nine permission groups.\n",
      "If you declare any dangerous permissions, and if your app is installed on a device that runs Android 6.0 ( API level 23 ) or higher, you must request the dangerous permissions at runtime by following the steps in this guide.\n",
      "Set the view Marker in the chart\n",
      "While developing for a target platform of 2.3.3 using Eclipse on Ubuntu, I had permission failures in the log file that indicated I needed this exact line while working on something similar.\n",
      "Returns the value mapped by name if it exists and is a long or can be coerced to a long, or 0 otherwise.\n",
      "The SafetyNet service includes a reCAPTCHA API that you can use to protect your app from malicious traffic.\n",
      "At that time, your app can request the runtime permission that's required for accessing that data.\n",
      "Just make a GET Request to\n",
      "Now Android allows you to decide which permissions to accept on a case-by-case basis -- after the app is installed.\n",
      "Android-Lollipop -LRB- api 21 -RRB- introduce a new API: LINK\n",
      "The constructors that create a Rectangle, and the methods that can modify one, do not prevent setting a negative value for width or height.\n",
      "If you are using Android Studio, or if you are using Gradle from the command line, you can add your own stuff to BuildConfig or otherwise tweak the debug and release build types to help distinguish these situations at runtime.\n",
      "Now add the following code in your PdfRenderActivity -- 7.\n",
      "With this method in place, we could take a single business JSON dictionary such as:\n",
      "The user can grant or deny each permission, and the app can continue to run with limited capabilities even if the user denies a permission request.\n",
      "with some custome code which simply draws a drawable icon.\n",
      "When scaling a document for printing the aspect ratio should be preserved.\n",
      "With that in place, we can now pass an JSONArray of business json data and process that easily into a nice ArrayList object for easy use in our application with Business.fromJson ( myJsonArray ).\n",
      "An Intent is an object that provides runtime binding between separate components, such as two activities.\n",
      "As promised, I'm putting an example for how to use annotations to serialize/deserialize polymorphic objects, I based this example in the Animal class from the tutorial you were reading.\n",
      "A Fragment is a combination of an XML layout file and a java class much like an Activity.\n",
      "So ideally we also would have an easy way of processing an array of businesses into an ArrayList of Business objects.\n",
      "RecyclerView is designed to be very efficient, even with large lists, by reusing, or recycling, the views that have scrolled off the screen.\n",
      "So in a nutshell, when you run your test MockWebServer intercepts your network call providing you with the data you mock data.Why?So it comes down to this.\n",
      "To request one of the many permissions, simply specify it in the AndroidManifest.xml: For example, an application that needs to read the user's contacts would add the following to it's AndroidManifest.xml:\n",
      "In you case, you first want to check if you such file exist before creating one.\n",
      "You have to explicitly use ... subscribeOn ( ):\n",
      "Request the runtime permission that your app requires in order to access the private user data.\n",
      "Returns the value mapped by name if it exists and is a boolean or can be coerced to a boolean, or fallback otherwise.\n",
      "However, this method only indicates that the user has solved the CAPTCHA correctly.\n",
      "The fragments allow their parent activity to respond to intents and callbacks in most cases.\n",
      "If your app can not communicate with the reCAPTCHA service successfully, it may be because the API is encountering an error.\n",
      "create the PdfRenderer\n",
      "You should add logic in your app to gracefully handle such an error.\n",
      "So you have to validate this token.\n",
      "We can create the basic empty adapter and holder together in ContactsAdapter.java as follows:\n",
      "Normal permission groups are allowed by default, because they don't pose a risk to your privacy.\n",
      "Every time the flow builder calls emit, it suspends until the element is completely processed.\n",
      "Runtime permissions are permissions that are requested as they are needed while the app is running.\n",
      "If you are using this class to rasterize a PDF for printing or show a print preview, it is recommended that you respect the following contract in order to provide a consistent user experience when seeing a preview and printing, i.e. the user sees a preview that is the same as the printout.\n",
      "That means, that the widget will take care of asking questions, validating responses all the way till it determines that a user is actually a human, only then you get a g-recaptcha-response value.\n",
      "These permissions will show a dialog to the user, similar to the following one:\n",
      "Unless you are importing the wrong BuildConfig class.\n",
      "If this isn't the case, see the backwards compatibility section to understand how permissions will behave on your configuration.\n",
      "It proved too difficult to implement the equivalents ( as const values, at least ) for kDebugMode and kProfileMode in all contexts, so I didn't do that.\n",
      "Check whether the user has already granted the runtime permission that your app requires.\n",
      "It appears that Jackson attempts to substitute the null with an instance of the default class.\n",
      "However, with a RecyclerView the adapter requires the existence of a `` ViewHolder'' object which describes and provides access to all the views within each item row.\n",
      "If we define a defaultImpl class as a catch-all for unknown types, deserialization fails for any protocol objects that contain other protocol objects if the reference to those objects is null.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That line draws a single event.\n",
      "In earlier versions of Android, accepting potentially dangerous permission groups was an all-or-nothing affair.\n",
      "Setting up our Model The primary resource in the Yelp API is the Business.\n",
      "Make sure you are referencing your project's BuildConfig class, not from any of your dependency libraries.\n",
      "When you create a test with a mock server, the app shouldn't use the real URL.\n",
      "Every Android app runs in a limited-access sandbox.\n",
      "In the Adding reCAPTCHA to your app section on the page that appears next, your public and private keys appear under Site key and Secret key, respectively.\n",
      "The following code snippet shows how to invoke this method:\n",
      "To display the system permissions dialog when necessary, call the launch ( ) method on the instance of ActivityResultLauncher that you saved in the previous step.\n",
      "You can also control concurrency, which means coordinating the execution of several coroutines declaratively with Flow.\n",
      "To learn how to validate the user's response token, see Verifying the user's response.\n",
      "Permission Groups Permission Groups avoids spamming the user with a lot of permission requests while allowing the app developer to only request the minimal amount of permissions needed at any point in time.\n",
      "Understanding the FragmentManager The FragmentManager is responsible for all runtime management of fragments including adding, removing, hiding, showing, or otherwise navigating between fragments.\n",
      "Now Run your app & you will see your PDF Document will render in android app itself.Wowww ... ... ... That's it ... Thanks ....\n",
      "When an app requests a permission that belongs to a particular permission group ( i.e. READ_CONTACTS ), Android asks the user about the higher level group instead ( CONTACTS ).\n",
      "Well, subscribeOn ( ) on the outer stream level basically said that all events should be processed sequentially, within this stream, on a different thread.\n",
      "Add the following line before setup ( ) in the MainActivityTest file:\n",
      "prepare the Bitmap\n",
      "Don't mess with the visibility flags of the container - FragmentTransaction.hide / show does that internally for you.\n",
      "subscribe ( ) is single-threaded by design and there is no way around it.\n",
      "Hi you do it by using this approach, all fragments will remain in the container once added initially and then we are simply revealing the desired fragment and hiding the others within the container.\n",
      "Basically you need to load a bitmap and pass to each event you want to draw.\n",
      "This made it easy for developers to deal with permissions, but wasn't the best user experience.\n",
      "Returns the value mapped by name if it exists and is an int or can be coerced to an int, or 0 otherwise.\n",
      "The simplest, and best long-term solution, is to use BuildConfig.DEBUG.\n",
      "In the form that appears, provide the following information:\n",
      "Respect the property whether the document would like to be scaled for printing as per shouldScaleForPrinting ( ).\n",
      "onStart ( ) is called once the fragment is ready to be displayed on screen.\n",
      "We can do that using the @JsonTypeInfo and @JsonSubTypes annotations.\n",
      "You still need to validate the user's response token from your backend server.\n",
      "There are a few different ways of using it, so let's look at an example.\n",
      "First of all your Animal class with the Json Annotations for the subclasses.\n",
      "The easiest way to simulate network issues with MockWebServer is by setting the SocketPolicy to SocketPolicy.DISCONNECT _ AT_START, SocketPolicy.NO _ RESPONSE or etc:\n",
      "Then your subclasses, Dog and Cat.\n",
      "MockWebServer makes it possible to easily test how your apps behave when making HTTP/HTTPS calls.\n",
      "The newApplication method provides the application instance you'll use in the test.\n",
      "Fragment Hiding vs Replace In many of the examples above, we call transaction.replace ( ... ) to load a dynamic fragment which first removes the existing fragment from the activity invoking onStop and onDestroy for that fragment before adding the new fragment to the container.\n",
      "For example, don't assume that permissions appear in the same permission group.\n",
      "Design the raw storage for your data.\n",
      "Define the provider's authority string, its content URIs, and column names.\n",
      "Output after running the Test class:\n",
      "Fragments encapsulate views and logic so that it is easier to reuse within activities.\n",
      "Fragment Listener If a fragment needs to communicate events to the activity, the fragment should define an interface as an inner type and require that the activity must implement this interface:\n",
      "Fragments communicate through their parent activity allowing the activity to manage the inputs and outputs of data from that fragment coordinating with other fragments or activities.\n",
      "To check if the user has already granted your app a particular permission, pass that permission into the ContextCompat.checkSelfPermission ( ) method.\n",
      "In addittion, you can do in a Fragment -LRB- for example when getting server data failed -RRB-:\n",
      "A test runner makes this possible.\n",
      "Dangerous permission groups, however, can give apps access to things like your calling history, private messages, location, camera, microphone, and more.\n",
      "This method returns either PERMISSION_GRANTED or PERMISSION_DENIED, depending on whether your app has the permission.\n",
      "The app will not crash, since all the\n",
      "In Marshmallow, Google has designated certain permissions to be `` safe'' and called these `` Normal Permissions''.\n",
      "You might have heard about this subscribeOn ( ) operator and how it enables concurrency.\n",
      "with the api 23, permission <uses-permission android:name=\"android.pemission.READ_CONTACTS\"/> dont work, change the api level in the emulator for api 22 -LRB- lollipop -RRB- or lower\n",
      "The following code snippet shows how to handle the permissions response:\n",
      "If the user denies or revokes a permission that a feature needs, gracefully degrade your app so that the user can continue using your app, possibly by disabling the feature that requires the permission.\n",
      "Returns the value mapped by name if it exists and is an int or can be coerced to an int, or fallback otherwise.\n",
      "But what if we want to render a PDF Document in our app itself.\n",
      "If the user granted the permission to your app, you can access the private user data.\n",
      "It introduced the concept of runtime permissions.\n",
      "When using the verifyWithRecaptcha ( ) method in your app, you must do the following:\n",
      "After Marshmallow, permissions must now be requested at runtime before being used.\n",
      "Returns the value mapped by name if it exists and is a double or can be coerced to a double, or fallback otherwise.\n",
      "Wait for the user to invoke the task or action in your app that requires access to specific private user data.\n",
      "Binding the Adapter to the RecyclerView In our activity, we will populate a set of sample users which should be displayed in the RecyclerView.\n",
      "Returns the value mapped by name if it exists, coercing it if necessary, or throws if no such mapping exists.\n",
      "If you create enough items and scroll through the list, the views will be recycled and far smoother by default than the ListView widget:\n",
      "Note: Please, set HttpClient of your code -LRB- e.g. AsyncHttpClient -RRB- with that number port for testing purpose.\n",
      "The startActivity ( ) method starts an instance of the DisplayMessageActivity that's specified by the Intent.\n",
      "This bug incorrectly sets the drawable bounds to 0 -LRB- or negative in the case of an inset drawable -RRB-.\n",
      "The important thing to keep in mind is that fragments should not directly communicate with each other and should generally only communicate with their parent activity.\n",
      "Returns the value mapped by name if it exists and is a boolean or can be coerced to a boolean, or throws otherwise.\n",
      "When a list item is scrolled off the screen, RecyclerView reuses that view for the next list item about to be displayed.\n",
      "Returns the value mapped by name if it exists and is a JSONObject, or null otherwise.\n",
      "Pass in your API site key as a parameter.\n",
      "In the meantime I think that you will need to annotate your child classes with @JsonTypeInfo and @JsonSubTypes to override the inherited annotations.\n",
      "PdfRenderer -- This class enables rendering a PDF document.\n",
      "The adapter's role is to convert an object at a position into a list row item to be inserted.\n",
      "Nothing much happening here before starting the test we create the server and start it at port 8080.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In particular, your app should make users aware of the features that don't work because of the missing permission.\n",
      "Here, http://127.0.0.1 is the local URL of your computer and 8080 is the port MockWebServer will use.\n",
      "Check out this stackoverflow for a discussion on deciding when to replace vs hide and show.\n",
      "These permission can then be allowed or denied by the user.\n",
      "The system displays a runtime permission prompt, such as the one shown on the permissions overview page.\n",
      "Overview A fragment is a reusable class implementing a portion of an activity.\n",
      "If the user presses and holds the button, then onKeyDown ( ) is called multiple times.\n",
      "The first step when adding a `` Runtime Permission'' is to add it to the AndroidManifest:\n",
      "render the page on the prepared bitmap\n",
      "A content provider manages access to a central repository of data.\n",
      "A Rectangle whose width or height is exactly zero has location along those axes with zero dimension, but is otherwise considered empty.\n",
      "Beginning in Android 6.0 -LRB- API level 23 -RRB-, users grant permissions to apps while the app is running, not when they install the app.\n",
      "Returns the value mapped by name if it exists and is a double or can be coerced to a double, or NaN otherwise.\n",
      "In certain situations, the permission might be denied automatically, without the user taking any action.\n",
      "Add other optional pieces, such as sample data or an implementation of AbstractThreadedSyncAdapter that can synchronize data between the provider and cloud-based data.\n",
      "During deserialization, you would want Jackson to deserialize the `` Vehicle'' JSON object to the appropriate `` Car'' or `` Plane'' class.\n",
      "Using this approach, all three fragments will remain in the container once added initially and then we are simply revealing the desired fragment and hiding the others within the container.\n",
      "Your example code prints the correct type value strings, but the deserialized object types are all instances of the Default class.\n",
      "Before Marshmallow, permissions were handled at install-time and specified in the AndroidManifest.xml within the project.\n",
      "This class is not thread safe.If you want to render a PDF, you create a renderer and for every page you want to render, you open the page, render it, and close the page.\n",
      "Ask for permissions in context, when the user starts to interact with the feature that requires it.\n",
      "Clicks can be handled using onClick property as usual or more typically in this case, using the onOptionsItemSelected method in the fragment:\n",
      "If so, your app can access the private user data.\n",
      "Note that you must always use getChildFragmentManager when interacting with nested fragments instead of using getSupportFragmentManager.\n",
      "Values may be any mix of JSONObjects, JSONArrays, Strings, Booleans, Integers, Longs, Doubles or NULL.\n",
      "It wasn't until I moved the * uses-permission ... READ_CONTACTS * line to outside the application tag that things worked.\n",
      "Zipping a list of observables is also possible, either directly:\n",
      "Returns the value mapped by name if it exists and is a boolean or can be coerced to a boolean, or false otherwise.\n",
      "If the fragment should always be within the activity, use XML to statically add the fragment but in more complex cases be sure to use the Java-based approach.\n",
      "The FragmentManager class and the FragmentTransaction class allow you to add, remove and replace fragments in the layout of your activity at runtime.\n",
      "Returns the value mapped by name if it exists and is a double or can be coerced to a double, or throws otherwise.\n",
      "They could easily be implemented as getters or functions, but they wouldn't be usable in const contexts.\n",
      "This way when the app later needs the WRITE_CONTACTS permission, Android can automatically grant this itself without prompting the user.\n",
      "To handle an individual key press, implement onKeyDown ( ) or onKeyUp ( ) as appropriate.\n",
      "Is it possible to render a PDF Document in android app ?\n",
      "The ActivityResultCallback defines how your app handles the user's response to the permission request.\n",
      "This means there are a couple more things to consider when working with permissions for a Marshmallow app.\n",
      "Check the Accept the reCAPTCHA Terms of Service checkbox, then click Register.\n",
      "onCreate of the Activity, you can use do the following\n",
      "Returns the value mapped by name if it exists and is a long or can be coerced to a long, or fallback otherwise.\n",
      "onCreate ( ) is called to do initial creation of the fragment.\n",
      "This is a boolean value that will be true for a debug build, false otherwise:\n",
      "Returns the value mapped by name if it exists and is a JSONArray, or throws otherwise.\n",
      "If the device is running Android 6.0 or higher, and your app's target SDK is 23 or higher: The app has to list the permissions in the manifest, and it must request each dangerous permission it needs while the app is running.\n",
      "After the user responds to the system permissions dialog, the system then invokes your app's implementation of onRequestPermissionsResult ( ).\n",
      "Next, you'll need to initiate the permission request and handle the result.\n",
      "and then you can use the FragmentManager to create a FragmentTransaction which allows us to add fragments to the FrameLayout at runtime:\n",
      "One thing that I ran across when I applied this approach to my production code is that you still need to keep the @JsonSubtypes annotation as part of the Base class.\n",
      "A typical use of the APIs to render a PDF looks like this:\n",
      "To invoke the SafetyNet reCAPTCHA API, you call the verifyWithRecaptcha ( ) method.\n",
      "I don't know if it's useful, but you can simulate a timeout with MockWebServer:\n",
      "reCAPTCHA is a free service that uses an advanced risk analysis engine to protect your app from spam and other abusive actions.\n",
      "Returns the value mapped by name, or null if no such mapping exists.\n",
      "Add following code in your layout file.\n",
      "Now you can simply write\n",
      "And replace the response_string with the value that you earlier got by the g-recaptcha-response field.\n",
      "You can see that it returns an application instance using PotterTestApp instead of PotterApp.\n",
      "This line means: add a meta-property on serialization or read a meta-property on deserialization -LRB- include = JsonTypeInfo.As.PROPERTY -RRB- called'' @class'' -LRB- property ='' @class'' -RRB- that holds the fully-qualified Java class name -LRB- use = JsonTypeInfo.Id.CLASS -RRB-.\n",
      "So the correct way to do this is:\n",
      "Each UUID is loaded sequentially.\n",
      "2 - Create MarkerView\n",
      "However, in many cases, we may want to keep both fragments around in the container and simply toggle their visibility.\n",
      "Creating a Test Runner Now, you need to provide a test runner that uses PotterTestApp instead of PotterApp when running a test.\n",
      "If you want to render a PDF, you create a renderer and for every page you want to render, you open the page, render it, and close the page.\n",
      "... or by wrapping the list into an Observable < Observable < ?\n",
      "I uploaded some sample code in a branch here:\n",
      "This class enables rendering a PDF document.\n",
      "You either allowed all permissions an app needed to function -- before installation -- or you declined them all, which meant you couldn't install the app.\n",
      "Every adapter has three primary methods: onCreateViewHolder to inflate the item layout and create the holder, onBindViewHolder to set the view attributes based on the data and getItemCount to determine the number of items.\n",
      "EDIT: When using Zip, make sure that the Observables being zipped all emit the same number of items.\n",
      "You can do this by modifying setup ( ) as follows:\n",
      "The Java controller for a fragment looks like:\n",
      "subscribeOn ( ) ( and observeOn ( ) for that matter ) barely switch execution to a different worker ( thread ) without introducing any concurrency.\n",
      "I didn't see a specific issue opened for this, but looking at the code for DrawableWrapperDonut/DrawableWrapperGingerbread, I can see that the problem was introduced around 23.4.0 and later fixed, so if you were using the buggy version, switching to a good version should fix this crash.\n",
      "Users should know which actions might require them to grant permission for your app to access private user data.\n",
      "You don't need to use so many lists, just create a class that will contain all the data of single item, there is no need for buttons, use just text change listener instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do not inset the content with any margins from the PrintAttributes as the application is responsible to render it such that the margins are respected.\n",
      "If the permission you need to add isn't listed under the normal permissions, you'll need to deal with `` Runtime Permissions''.\n",
      "The user had no way of changing permissions, even after installing the app.\n",
      "Anyone with HTTP POST knowledge could put random data inside of the g-recaptcha-response form field, and foll your site to make it think that this field was provided by the google widget.\n",
      "Instead, it should use the mock server's URL.\n"
     ]
    }
   ],
   "source": [
    "logger.info(Fore.RED + f\"{len(fold_results['venn_diagram_set'])} entries VENN SET\" + Style.RESET_ALL)\n",
    "for _t in fold_results['venn_diagram_set']:\n",
    "    logger.info(_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM51gMzrDUJf4OiiaquqBe4",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hugging-face-keras-bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7 Arthur hugging",
   "language": "python",
   "name": "msarthur-hface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03ddd131c9f0446eb83bb6dabee9a832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3518f71b0e4540be8b17a3fe72182cb4",
       "IPY_MODEL_a5ccb838d3704546937e925e456830be",
       "IPY_MODEL_8181fd24b3624c1b9c6a9d0302f43a56"
      ],
      "layout": "IPY_MODEL_f02cf8090f8d463eb7eeb59743a87276"
     }
    },
    "0466163ff4a945798423387d1ac900c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0efe94b613f44c029f2e9bd05696ad32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3e13535de4b44bb9139c3911684cee8",
      "placeholder": "​",
      "style": "IPY_MODEL_6ccdfb754c12418c9438ac218a172e63",
      "value": "Downloading: 100%"
     }
    },
    "153c3ed5c6314a49a5a37ad976417142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_262cc50dd08f49f78b781c2ce96a4ad7",
      "placeholder": "​",
      "style": "IPY_MODEL_f305b344487a4b598a7d41b007e49abd",
      "value": " 232k/232k [00:00&lt;00:00, 286kB/s]"
     }
    },
    "16b6cfa829ad43778c079452df231a3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17cfaa41c53842618c728987a81a44da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fc2d9969ea34bb3bb6e9f0260c2a75c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23531989ef014d7db16b220bb807c8fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "262cc50dd08f49f78b781c2ce96a4ad7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3518f71b0e4540be8b17a3fe72182cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9ef3ce0ace649c5a53e2244ba0dbb32",
      "placeholder": "​",
      "style": "IPY_MODEL_702a74b6e6e44d6b8ad68347f1a4b5fb",
      "value": "Downloading: 100%"
     }
    },
    "35a9eeb0acdb44738a6ad7fbf6d99b2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3950e2a7832c4dce8fd8209d6322a1f7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d32667132d604faeb419bbf9851c1bd8",
      "value": 231508
     }
    },
    "394b7988d36849b7b2c82872ae8d489d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3950e2a7832c4dce8fd8209d6322a1f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ccd384305c44ee3a86f47a2b994fbf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d84c022c44141268ef2c8d5e0190404": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40c212c9b352401697860624a6c54b1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4bd0f4c575714ad7848e818a576ee00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a38bc7017d545e2b44ad6ab0b2d937b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_929799bd24fb411bb4686988f2ae8996",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bd0f4c575714ad7848e818a576ee00a",
      "value": 570
     }
    },
    "5c6bfb038756422bb00be1349db7750b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c586016d3b594c6299cab2384f4c10aa",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d03c894896ad4ed6b48f19a70fbdf2af",
      "value": 466062
     }
    },
    "67f208ba489343dfa195c1dd915f3efe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16b6cfa829ad43778c079452df231a3d",
      "placeholder": "​",
      "style": "IPY_MODEL_a2a36eb594654c65acd584d9d4ebea20",
      "value": "Downloading: 100%"
     }
    },
    "6ccdfb754c12418c9438ac218a172e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cf29b5d508a4e2082751ccc7fa2f625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ccd384305c44ee3a86f47a2b994fbf9",
      "placeholder": "​",
      "style": "IPY_MODEL_23531989ef014d7db16b220bb807c8fd",
      "value": " 466k/466k [00:00&lt;00:00, 637kB/s]"
     }
    },
    "702a74b6e6e44d6b8ad68347f1a4b5fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71a15c5a038f451f8ee64ce046488f71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8181fd24b3624c1b9c6a9d0302f43a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "placeholder": "​",
      "style": "IPY_MODEL_911177bb86c749a0bd774cd3b7f9d302",
      "value": " 536M/536M [00:12&lt;00:00, 40.9MB/s]"
     }
    },
    "82b7fc20b50c44b2bd84b3bf882cdd43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c2b37becdef45bba205dfb20f8e37b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4276b6a5eac4023955218db6f78c84a",
      "placeholder": "​",
      "style": "IPY_MODEL_c4b0a1b67d304afda6ee4e52095584cc",
      "value": " 28.0/28.0 [00:00&lt;00:00, 631B/s]"
     }
    },
    "8c7cf993674145ffb7bb876e5591f6ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67f208ba489343dfa195c1dd915f3efe",
       "IPY_MODEL_35a9eeb0acdb44738a6ad7fbf6d99b2b",
       "IPY_MODEL_153c3ed5c6314a49a5a37ad976417142"
      ],
      "layout": "IPY_MODEL_82b7fc20b50c44b2bd84b3bf882cdd43"
     }
    },
    "901557318fb947dfa082f0cbf2d7365b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0efe94b613f44c029f2e9bd05696ad32",
       "IPY_MODEL_5a38bc7017d545e2b44ad6ab0b2d937b",
       "IPY_MODEL_b3db733aacf94a3c94519d70a7a56d7a"
      ],
      "layout": "IPY_MODEL_394b7988d36849b7b2c82872ae8d489d"
     }
    },
    "911177bb86c749a0bd774cd3b7f9d302": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "929799bd24fb411bb4686988f2ae8996": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "997b8c940317448c9409a2dee15fc519": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e99fb1211ba43459ee78dd64ab8c30e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2a36eb594654c65acd584d9d4ebea20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5ccb838d3704546937e925e456830be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d84c022c44141268ef2c8d5e0190404",
      "max": 536063208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40c212c9b352401697860624a6c54b1c",
      "value": 536063208
     }
    },
    "a66943be0fc0423880cb2bd63a1ea2d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6d9e21208294428a3f5572bbbd8b0b9",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d15e557fc621427a8295eecdc1e781a8",
      "value": 28
     }
    },
    "a8fd8b38a6b84be7b83b2f4df590fada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e99fb1211ba43459ee78dd64ab8c30e",
      "placeholder": "​",
      "style": "IPY_MODEL_71a15c5a038f451f8ee64ce046488f71",
      "value": "Downloading: 100%"
     }
    },
    "b12b35cc52454a249c97f695409d24ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3db733aacf94a3c94519d70a7a56d7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0466163ff4a945798423387d1ac900c8",
      "placeholder": "​",
      "style": "IPY_MODEL_17cfaa41c53842618c728987a81a44da",
      "value": " 570/570 [00:00&lt;00:00, 17.0kB/s]"
     }
    },
    "b4276b6a5eac4023955218db6f78c84a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d9e21208294428a3f5572bbbd8b0b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baffabe6cabf48f5b0b6523ea92aee78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18a3a9fc6d54b9f848e4454e1e36c21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8fd8b38a6b84be7b83b2f4df590fada",
       "IPY_MODEL_5c6bfb038756422bb00be1349db7750b",
       "IPY_MODEL_6cf29b5d508a4e2082751ccc7fa2f625"
      ],
      "layout": "IPY_MODEL_c4c410ab0c994a229a49b8baee221de4"
     }
    },
    "c4b0a1b67d304afda6ee4e52095584cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4c410ab0c994a229a49b8baee221de4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c586016d3b594c6299cab2384f4c10aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5b9bf1f3ae343ce97982c7802cfdc94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_997b8c940317448c9409a2dee15fc519",
      "placeholder": "​",
      "style": "IPY_MODEL_b12b35cc52454a249c97f695409d24ce",
      "value": "Downloading: 100%"
     }
    },
    "c9ef3ce0ace649c5a53e2244ba0dbb32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d03c894896ad4ed6b48f19a70fbdf2af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d15e557fc621427a8295eecdc1e781a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d32667132d604faeb419bbf9851c1bd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3e13535de4b44bb9139c3911684cee8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0e88103f9684ffdb957357222bbaaf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5b9bf1f3ae343ce97982c7802cfdc94",
       "IPY_MODEL_a66943be0fc0423880cb2bd63a1ea2d2",
       "IPY_MODEL_8c2b37becdef45bba205dfb20f8e37b2"
      ],
      "layout": "IPY_MODEL_baffabe6cabf48f5b0b6523ea92aee78"
     }
    },
    "f02cf8090f8d463eb7eeb59743a87276": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f305b344487a4b598a7d41b007e49abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
