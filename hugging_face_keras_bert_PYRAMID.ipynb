{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marquesarthur/vanilla-bert-vs-huggingface/blob/main/hugging_face_keras_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfNydjdoLcvK"
   },
   "source": [
    "Based on \n",
    "\n",
    "\n",
    "\n",
    "1.   https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379\n",
    "2.   https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/\n",
    "3.   https://huggingface.co/transformers/training.html#fine-tuning-with-keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**problem statement:**\n",
    "\n",
    "\n",
    "*   a developer has to inspect an **artifact X**\n",
    "*   Within the artifact, only a portion of the text is relevant to **input task Y**\n",
    "*   We ought to build a model that establishes relationships between **Y** and **sentences x âˆˆ X** \n",
    "*  The model must determine: **is x relevant to task Y**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Example of a task and an annotated artifact:*\n",
    "\n",
    "<br>\n",
    "\n",
    "[<img src=\"https://i.imgur.com/Zj1317H.jpg\">](https://i.imgur.com/Zj1317H.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* The coloured sentences are sentences annotated as relevant to the input task. \n",
    "* The warmer the color, the more annotators selected that portion of the text. \n",
    "* For simplicity, we process the data and used sentences \n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Ultimately, our data is a tuple representing:*\n",
    "\n",
    "\n",
    "*   **text** = artifact sentence\n",
    "\n",
    "*   **question** = task description\n",
    "\n",
    "*   **source** = URL of the artifact\n",
    "\n",
    "*   **category_index** = whether sentence is relevant [or not] for the input task\n",
    "\n",
    "*   **weights** = number of participants who annotated sentence as relevant\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtFJT5AK6RRc",
    "outputId": "f3eaf1c3-63c2-455e-eaa5-5eb9955afe4b"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "\n",
    "# !pip install transformers\n",
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y80jdm9S6wQA",
    "outputId": "de6caa10-19da-42af-958f-bf19fe70903d"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn tqdm pandas python-Levenshtein path colorama matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q38yIvW87NrN",
    "outputId": "425ff20e-e16f-475a-93fe-221008e32fdc"
   },
   "outputs": [],
   "source": [
    "# @title Download git repo\n",
    "# !git clone https://github.com/marquesarthur/vanilla-bert-vs-huggingface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyrLR-tf8P4Q",
    "outputId": "a2cc52fc-f3e9-4cf0-ce6d-c11cee304c39"
   },
   "outputs": [],
   "source": [
    "# %cd vanilla-bert-vs-huggingface\n",
    "# !git pull\n",
    "# !ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kudd2ZR8tKZ",
    "outputId": "2a38495e-b8e4-43b1-c126-ec92e98b07d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m39 \u001b[33m129 \u001b[0m https://developer.android.com/training/permissions/requesting\n",
      "\u001b[31m14 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/5233543\n",
      "\u001b[31m4 \u001b[33m34 \u001b[0m https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "\u001b[31m27 \u001b[33m63 \u001b[0m https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "\u001b[31m9 \u001b[33m161 \u001b[0m https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "\u001b[31m9 \u001b[33m15 \u001b[0m https://developer.android.com/training/volley/request\n",
      "\u001b[31m14 \u001b[33m65 \u001b[0m https://stackoverflow.com/questions/28504524\n",
      "\u001b[31m20 \u001b[33m59 \u001b[0m https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "\u001b[31m5 \u001b[33m97 \u001b[0m https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "\u001b[31m4 \u001b[33m12 \u001b[0m https://stackoverflow.com/questions/33241952\n",
      "\u001b[31m6 \u001b[33m33 \u001b[0m https://github.com/realm/realm-java/issues/776\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/8712652\n",
      "\u001b[31m8 \u001b[33m59 \u001b[0m https://dzone.com/articles/android-rotate-and-scale\n",
      "\u001b[31m5 \u001b[33m470 \u001b[0m https://developer.android.com/reference/android/widget/TextView\n",
      "\u001b[31m7 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/19025301\n",
      "\u001b[31m8 \u001b[33m95 \u001b[0m https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "\u001b[31m20 \u001b[33m145 \u001b[0m https://developer.android.com/training/dependency-injection/hilt-android\n",
      "\u001b[31m4 \u001b[33m8 \u001b[0m https://stackoverflow.com/questions/30648172\n",
      "\u001b[31m4 \u001b[33m81 \u001b[0m https://github.com/google/dagger/issues/1991\n",
      "\u001b[31m9 \u001b[33m48 \u001b[0m https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "\u001b[31m5 \u001b[33m47 \u001b[0m https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "\u001b[31m9 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/6442054\n",
      "\u001b[31m3 \u001b[33m22 \u001b[0m https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "\u001b[31m22 \u001b[33m211 \u001b[0m https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "\u001b[31m21 \u001b[33m59 \u001b[0m https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "\u001b[31m17 \u001b[33m33 \u001b[0m https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "\u001b[31m6 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/10108774\n",
      "\u001b[31m19 \u001b[33m250 \u001b[0m https://developer.android.com/guide/topics/media/camera\n",
      "\u001b[31m9 \u001b[33m32 \u001b[0m https://github.com/google/ExoPlayer/issues/8387\n",
      "\u001b[31m7 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/8184492\n",
      "\u001b[31m7 \u001b[33m58 \u001b[0m https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "\u001b[31m3 \u001b[33m50 \u001b[0m https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "\u001b[31m3 \u001b[33m56 \u001b[0m https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "\u001b[31m3 \u001b[33m5 \u001b[0m https://stackoverflow.com/questions/38980595\n",
      "\u001b[31m4 \u001b[33m38 \u001b[0m https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "\u001b[31m3 \u001b[33m36 \u001b[0m https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "\u001b[31m4 \u001b[33m131 \u001b[0m https://stackoverflow.com/questions/122105\n",
      "\u001b[31m3 \u001b[33m48 \u001b[0m https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "\u001b[31m8 \u001b[33m49 \u001b[0m https://developer.android.com/guide/topics/media/mediarecorder\n",
      "\u001b[31m4 \u001b[33m9 \u001b[0m https://stackoverflow.com/questions/6688444\n",
      "\u001b[31m4 \u001b[33m27 \u001b[0m https://stackoverflow.com/questions/24952513\n",
      "\u001b[31m18 \u001b[33m219 \u001b[0m https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "\u001b[31m3 \u001b[33m72 \u001b[0m https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "\u001b[31m5 \u001b[33m373 \u001b[0m https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "\u001b[31m12 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/35357919\n",
      "\u001b[31m11 \u001b[33m117 \u001b[0m https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "\u001b[31m8 \u001b[33m147 \u001b[0m https://developer.android.com/training/notify-user/build-notification\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/3059155\n",
      "\u001b[31m10 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/26838730\n",
      "\u001b[31m7 \u001b[33m283 \u001b[0m https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "\u001b[31m5 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/37096547\n",
      "\u001b[31m7 \u001b[33m179 \u001b[0m https://guides.codepath.com/android/using-the-recyclerview\n",
      "\u001b[31m3 \u001b[33m31 \u001b[0m https://stackoverflow.com/questions/47760861\n",
      "\u001b[31m13 \u001b[33m69 \u001b[0m https://developer.android.com/training/data-storage/sqlite\n",
      "\u001b[31m15 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/4015026\n",
      "\u001b[31m15 \u001b[33m81 \u001b[0m https://developer.android.com/guide/background/threading\n",
      "\u001b[31m6 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/2993085\n",
      "\u001b[31m11 \u001b[33m50 \u001b[0m https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "\u001b[31m5 \u001b[33m28 \u001b[0m https://stackoverflow.com/questions/23844667\n",
      "\u001b[31m5 \u001b[33m45 \u001b[0m https://github.com/flutter/flutter/issues/11392\n",
      "\u001b[31m4 \u001b[33m23 \u001b[0m https://stackoverflow.com/questions/29738510\n",
      "\u001b[31m5 \u001b[33m54 \u001b[0m https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "\u001b[31m7 \u001b[33m70 \u001b[0m https://guides.codepath.com/android/using-the-app-toolbar\n",
      "\u001b[31m4 \u001b[33m100 \u001b[0m https://stackoverflow.com/questions/2661536\n",
      "\u001b[31m9 \u001b[33m65 \u001b[0m https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "\u001b[31m5 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/24652078\n",
      "\u001b[31m8 \u001b[33m44 \u001b[0m https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/2883355\n",
      "\u001b[31m4 \u001b[33m37 \u001b[0m https://medium.com/android-dev-hacks/rendering-pdf-documents-in-android-using-pdfrenderer-f6d4f730b18\n",
      "\u001b[31m9 \u001b[33m51 \u001b[0m https://stackoverflow.com/questions/11064244\n",
      "\u001b[31m7 \u001b[33m138 \u001b[0m https://github.com/quarkusio/quarkus/issues/3954\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m16 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/29923376\n",
      "\u001b[31m4 \u001b[33m13 \u001b[0m https://github.com/google/dagger/issues/671\n",
      "\u001b[31m3 \u001b[33m19 \u001b[0m https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/36275986\n",
      "\u001b[31m42 \u001b[33m177 \u001b[0m https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "\u001b[31m9 \u001b[33m36 \u001b[0m https://developer.android.com/training/location/retrieve-current\n",
      "\u001b[31m5 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/46481789\n",
      "\u001b[31m22 \u001b[33m119 \u001b[0m https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "\u001b[31m15 \u001b[33m99 \u001b[0m https://javapapers.com/android/android-location-fused-provider\n",
      "\u001b[31m3 \u001b[33m14 \u001b[0m https://developer.android.com/training/keyboard-input/commands\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m3 \u001b[33m4 \u001b[0m https://stackoverflow.com/questions/40168601\n",
      "\u001b[31m20 \u001b[33m54 \u001b[0m https://developer.android.com/training/safetynet/recaptcha\n",
      "\u001b[31m11 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/27297067\n",
      "\u001b[31m8 \u001b[33m42 \u001b[0m https://stackoverflow.com/questions/30362446\n",
      "\u001b[31m10 \u001b[33m36 \u001b[0m https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "\u001b[31m5 \u001b[33m16 \u001b[0m https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "\u001b[31m5 \u001b[33m57 \u001b[0m https://github.com/signalapp/Signal-Android/issues/3376\n",
      "\u001b[31m5 \u001b[33m34 \u001b[0m https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "\u001b[31m22 \u001b[33m104 \u001b[0m https://developer.android.com/reference/org/json/JSONObject\n",
      "\u001b[31m8 \u001b[33m31 \u001b[0m https://guides.codepath.com/android/converting-json-to-models\n",
      "\u001b[31m7 \u001b[33m146 \u001b[0m https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "\u001b[31m5 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/24313539\n",
      "\u001b[31m12 \u001b[33m77 \u001b[0m https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "\u001b[31m6 \u001b[33m72 \u001b[0m https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "\u001b[31m5 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/14347588\n",
      "\u001b[31m31 \u001b[33m163 \u001b[0m https://guides.codepath.com/android/creating-and-using-fragments\n",
      "\u001b[31m4 \u001b[33m40 \u001b[0m https://developer.android.com/training/gestures/scale\n",
      "\u001b[31m6 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/10630373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m4 \u001b[33m54 \u001b[0m https://developer.android.com/training/gestures/scroll\n",
      "\u001b[31m4 \u001b[33m16 \u001b[0m https://stackoverflow.com/questions/39588322\n",
      "\u001b[31m20 \u001b[33m196 \u001b[0m https://developer.android.com/training/dependency-injection/dagger-android\n",
      "\u001b[31m6 \u001b[33m44 \u001b[0m https://stackoverflow.com/questions/57235136\n",
      "\u001b[31m24 \u001b[33m121 \u001b[0m https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "Sample entry from data:\n",
      "{\n",
      "    \"category_index\": 1,\n",
      "    \"question\": \"Permission Denial when trying to access contacts in Android\",\n",
      "    \"source\": \"https://developer.android.com/training/permissions/requesting\",\n",
      "    \"text\": \"Every Android app runs in a limited-access sandbox.\",\n",
      "    \"weights\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# @title Import data as JSON\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from Levenshtein import ratio\n",
    "from colorama import Fore, Style\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.level = logging.DEBUG\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "from ds_android import get_input_for_BERT\n",
    "\n",
    "raw_data = get_input_for_BERT()\n",
    "\n",
    "print('Sample entry from data:')\n",
    "print(json.dumps(raw_data[0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b_GXczz9CGs",
    "outputId": "2f6b91cb-8396-41af-e299-61360817d8b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution\n",
      "\n",
      "not-relevant -- 88%\n",
      "RELEVANT ------ 12%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "cnt = Counter([d['category_index'] for d in raw_data])\n",
    "\n",
    "total = sum(cnt.values())\n",
    "\n",
    "labels_cnt = [cnt[0] / float(total), cnt[1] / float(total)]\n",
    "print('label distribution')\n",
    "print('')\n",
    "print('not-relevant -- {:.0f}%'.format(labels_cnt[0] * 100))\n",
    "print('RELEVANT ------ {:.0f}%'.format(labels_cnt[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seframes = {}\n",
    "with open('seframes.json') as input_file:\n",
    "    seframes = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_meaningful_frame(text):    \n",
    "    meaning_frames = [\n",
    "        'Temporal_collocation', 'Execution', 'Using', 'Intentionally_act',\n",
    "        'Being_obligated', 'Likelihood', 'Causation', 'Required_event',\n",
    "        'Desiring', 'Awareness', 'Grasp', 'Attempt'\n",
    "    ]\n",
    "    \n",
    "    if text in seframes:\n",
    "        text_labels = seframes[text]\n",
    "        if any([elem in meaning_frames for elem in text_labels]):\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLoading data from cache\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fold_results = dict()\n",
    "if os.path.isfile('bert_ds_android_pyramid.json'):\n",
    "    logger.info(Fore.YELLOW + \"Loading data from cache\" + Style.RESET_ALL)\n",
    "    with open('bert_ds_android_pyramid.json') as input_file:\n",
    "        fold_results = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1l5DIHP_FUb",
    "outputId": "7f1648d0-2582-43a8-c1fc-50095d78892b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n"
     ]
    }
   ],
   "source": [
    "# @title Set environment variables\n",
    "\n",
    "model_id = 'bert-base-uncased'\n",
    "# model_id = 'distilbert-base-uncased'\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "USE_TPU = False\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "# @title Initialize TPU Strategy\n",
    "if USE_TPU:\n",
    "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
    "    tf.contrib.distribute.initialize_tpu_system(resolver)\n",
    "    strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
    "\n",
    "# sklearn libs\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "# Hugging face imports\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification, TFBertForSequenceClassification\n",
    "from transformers import TFDistilBertModel, DistilBertConfig\n",
    "from transformers import DistilBertTokenizerFast, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Model parameters\n",
    "\n",
    "# Bert Model Constants\n",
    "SEQ_LEN = 64 # 128\n",
    "BATCH_SIZE = 64 # 64 32 larger batch size causes OOM errors\n",
    "EPOCHS = 10 # 3 4\n",
    "LR = 1e-5 # 2e-5\n",
    "\n",
    "# 3e-4, 1e-4, 5e-5, 3e-5\n",
    "# My own constants\n",
    "# USE_FRAME_FILTERING = False\n",
    "# UNDERSAMPLING = True\n",
    "# N_UNDERSAMPLING = 2 # ratio of how many samples from 0-class, to 1-class, e.g.: 2:1\n",
    "# USE_DS_SYNTHETIC = False\n",
    "\n",
    "USE_FRAME_FILTERING = False\n",
    "UNDERSAMPLING = True\n",
    "N_UNDERSAMPLING = 2 # ratio of how many samples from 0-class, to 1-class, e.g.: 2:1\n",
    "USE_DS_SYNTHETIC = False\n",
    "MIN_W = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1T9xPdXp_kt9"
   },
   "outputs": [],
   "source": [
    "# @title JSON to dataframe helper functions\n",
    "def undersample_df(df, n_times=3):\n",
    "    class_0,class_1 = df.category_index.value_counts()\n",
    "    c0 = df[df['category_index'] == 0]\n",
    "    c1 = df[df['category_index'] == 1]\n",
    "    df_0 = c0.sample(int(n_times * class_1))\n",
    "    \n",
    "    undersampled_df = pd.concat([df_0, c1],axis=0)\n",
    "    return undersampled_df\n",
    "\n",
    "def get_ds_synthetic_data(min_w=MIN_W):\n",
    "    short_task = {\n",
    "      \"bugzilla\": \"\"\"How to query bugs using the custom fields with the Bugzilla REST API?\"\"\",\n",
    "      \"databases\": \"\"\"Which technology should be adopted for the database layer abstraction: Object/Relational Mapping (ORM) or a Java Database Connectivity API (JDBC)?\"\"\",\n",
    "      \"gpmdpu\": \"\"\"Can I bind the cmd key to the GPMDPU shortcuts?\"\"\",\n",
    "      \"lucene\": \"\"\"How does Lucene compute similarity scores for the BM25 similarity?\"\"\",\n",
    "      \"networking\": \"\"\"Which technology should be adopted for the notification system, Server-Sent Events (SSE) or WebSockets?\"\"\",\n",
    "    }\n",
    "\n",
    "    with open('relevance_corpus.json') as ipf:\n",
    "        aux = json.load(ipf)\n",
    "        raw_data = defaultdict(list)\n",
    "        for d in aux:\n",
    "            if d['task'] == 'yargs':\n",
    "                continue\n",
    "\n",
    "            raw_data['text'].append(d['text'])\n",
    "            raw_data['question'].append(short_task[d['task']])\n",
    "            raw_data['source'].append(d['source'])\n",
    "            raw_data['category_index'].append(1 if d['weight'] > min_w else 0)\n",
    "            raw_data['weights'].append(d['weight'] if d['weight'] > min_w else 0)\n",
    " \n",
    "        data = pd.DataFrame.from_dict(raw_data)\n",
    "        data = undersample_df(data, n_times=1)\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "      \n",
    "    return data\n",
    "\n",
    "def get_class_weights(y, smooth_factor=0, upper_bound=5.0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    clazz = {cls: float(majority / count) for cls, count in counter.items()}\n",
    "    result = {}\n",
    "    for key, value in clazz.items():\n",
    "        if value > upper_bound:\n",
    "            value = upper_bound\n",
    "        \n",
    "        result[key] = value\n",
    "    return result\n",
    "\n",
    "def add_raw_data(result, data):\n",
    "    s = data['source']\n",
    "    if 'docs.oracle' in s or 'developer.android' in s:\n",
    "        source_type = 'api'\n",
    "    elif 'stackoverflow.com' in s:\n",
    "        source_type = 'so'\n",
    "    elif 'github.com' in s:\n",
    "        source_type = 'git'\n",
    "    else:\n",
    "        source_type = 'misc'\n",
    "    pyramid = 1 if data['weights'] > 1 else 0\n",
    "    \n",
    "    result['text'].append(data['text'])\n",
    "    result['question'].append(data['question'])\n",
    "    result['source'].append(data['source'])\n",
    "    result['category_index'].append(pyramid)\n",
    "    result['weights'].append(data['weights'])\n",
    "    result['source_type'].append(source_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837,
     "referenced_widgets": [
      "8c7cf993674145ffb7bb876e5591f6ca",
      "67f208ba489343dfa195c1dd915f3efe",
      "35a9eeb0acdb44738a6ad7fbf6d99b2b",
      "153c3ed5c6314a49a5a37ad976417142",
      "82b7fc20b50c44b2bd84b3bf882cdd43",
      "16b6cfa829ad43778c079452df231a3d",
      "a2a36eb594654c65acd584d9d4ebea20",
      "3950e2a7832c4dce8fd8209d6322a1f7",
      "d32667132d604faeb419bbf9851c1bd8",
      "262cc50dd08f49f78b781c2ce96a4ad7",
      "f305b344487a4b598a7d41b007e49abd",
      "c18a3a9fc6d54b9f848e4454e1e36c21",
      "a8fd8b38a6b84be7b83b2f4df590fada",
      "5c6bfb038756422bb00be1349db7750b",
      "6cf29b5d508a4e2082751ccc7fa2f625",
      "c4c410ab0c994a229a49b8baee221de4",
      "9e99fb1211ba43459ee78dd64ab8c30e",
      "71a15c5a038f451f8ee64ce046488f71",
      "c586016d3b594c6299cab2384f4c10aa",
      "d03c894896ad4ed6b48f19a70fbdf2af",
      "3ccd384305c44ee3a86f47a2b994fbf9",
      "23531989ef014d7db16b220bb807c8fd",
      "e0e88103f9684ffdb957357222bbaaf7",
      "c5b9bf1f3ae343ce97982c7802cfdc94",
      "a66943be0fc0423880cb2bd63a1ea2d2",
      "8c2b37becdef45bba205dfb20f8e37b2",
      "baffabe6cabf48f5b0b6523ea92aee78",
      "997b8c940317448c9409a2dee15fc519",
      "b12b35cc52454a249c97f695409d24ce",
      "b6d9e21208294428a3f5572bbbd8b0b9",
      "d15e557fc621427a8295eecdc1e781a8",
      "b4276b6a5eac4023955218db6f78c84a",
      "c4b0a1b67d304afda6ee4e52095584cc",
      "901557318fb947dfa082f0cbf2d7365b",
      "0efe94b613f44c029f2e9bd05696ad32",
      "5a38bc7017d545e2b44ad6ab0b2d937b",
      "b3db733aacf94a3c94519d70a7a56d7a",
      "394b7988d36849b7b2c82872ae8d489d",
      "d3e13535de4b44bb9139c3911684cee8",
      "6ccdfb754c12418c9438ac218a172e63",
      "929799bd24fb411bb4686988f2ae8996",
      "4bd0f4c575714ad7848e818a576ee00a",
      "0466163ff4a945798423387d1ac900c8",
      "17cfaa41c53842618c728987a81a44da"
     ]
    },
    "id": "r_y7xwmxAT39",
    "outputId": "ba094ca3-4ef3-41c0-da55-0e07626c7fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# @title Tokenizer\n",
    "\n",
    "print(model_id)\n",
    "if model_id == 'distilbert-base-uncased':\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)\n",
    "else:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HdAYw7lBAmlO"
   },
   "outputs": [],
   "source": [
    "# @title data encoder\n",
    "\n",
    "def _encode(tokenizer, dataframe, max_length=SEQ_LEN):\n",
    "    \n",
    "    seq_a = dataframe['text'].tolist()\n",
    "    seq_b = dataframe['question'].tolist()\n",
    "    \n",
    "    return tokenizer(seq_a, seq_b, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "def to_one_hot_encoding(data, nb_classes = 2):\n",
    "    targets = np.array([data]).reshape(-1)\n",
    "    one_hot_targets = np.eye(nb_classes)[targets]\n",
    "    return one_hot_targets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "y-5ROuqDBU9X"
   },
   "outputs": [],
   "source": [
    "# @title Metrics & Logging functions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "recommendation_metrics = defaultdict(list)\n",
    "prediction_metrics = defaultdict(list)\n",
    "api_metrics = defaultdict(list)\n",
    "so_metrics = defaultdict(list)\n",
    "git_metrics = defaultdict(list)\n",
    "misc_metrics = defaultdict(list)\n",
    "\n",
    "classification_report_lst = []\n",
    "log_examples_lst = []\n",
    "source_lst = []\n",
    "venn_diagram_set = []\n",
    "\n",
    "def aggregate_macro_metrics(store_at, precision, recall, fscore):   \n",
    "    store_at['precision'].append(precision)\n",
    "    store_at['recall'].append(recall)\n",
    "    store_at['fscore'].append(fscore)\n",
    "    \n",
    "    \n",
    "def aggregate_macro_source_metrics(precision, recall, fscore, source):\n",
    "    s = source\n",
    "    if 'docs.oracle' in s or 'developer.android' in s:\n",
    "        aggregate_macro_metrics(api_metrics, precision, recall, fscore)\n",
    "    elif 'stackoverflow.com' in s:\n",
    "        aggregate_macro_metrics(so_metrics, precision, recall, fscore)\n",
    "    elif 'github.com' in s:\n",
    "        aggregate_macro_metrics(git_metrics, precision, recall, fscore)        \n",
    "    elif  'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
    "        aggregate_macro_metrics(misc_metrics, precision, recall, fscore)\n",
    "    \n",
    "\n",
    "def aggregate_recommendation_metrics(store_at, k, precision_at_k, pyramid_precision_at_k):\n",
    "    store_at['k'].append(k)\n",
    "    store_at['precision'].append(precision_at_k)\n",
    "    store_at['âˆ† precision'].append(pyramid_precision_at_k)\n",
    "    \n",
    "def aggregate_report_metrics(clz_report):\n",
    "    relevant_label = str(1)\n",
    "    if relevant_label in clz_report:\n",
    "        for _key in ['precision', 'recall']:\n",
    "            if _key in clz_report[relevant_label]:\n",
    "                clz_report_lst[_key].append(clz_report[relevant_label][_key])    \n",
    "                \n",
    "def log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10):\n",
    "    # get the predicted prob at every index\n",
    "    idx_probs = [(idx, y_predict[idx], y_probs[idx]) for idx, _ in enumerate(y_predict)]\n",
    "    \n",
    "    # filter probs for all indexes predicted as relevant  \n",
    "    idx_probs = list(filter(lambda k: k[1] == 1, idx_probs))\n",
    "    \n",
    "    most_probable = sorted(idx_probs, key=lambda i: i[2], reverse=True)\n",
    "    \n",
    "    result = [idx for idx, _, _ in most_probable][:k]\n",
    "    \n",
    "    for idx in result:\n",
    "        log_examples_lst.append((\n",
    "            source, \n",
    "            task_title,\n",
    "            pweights[idx],\n",
    "            y_predict[idx],\n",
    "            y_probs[idx],\n",
    "            text[idx]\n",
    "        ))\n",
    "        \n",
    "def log_venn_diagram(y_true, y_predicted, text):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        for _true, _predict, _t in zip(y_true, y_predicted, text):\n",
    "            if _true == 1 and _predict == 1:\n",
    "                cnt += 1\n",
    "                venn_diagram_set.append(_t)\n",
    "    except Exception as ex:\n",
    "        logger.info(str(ex))\n",
    "    logger.info(Fore.RED + str(cnt) + Style.RESET_ALL + \" entries logged\")\n",
    "\n",
    "    \n",
    "def avg_macro_metric_for(data):\n",
    "    __precision = data['precision']\n",
    "    __recall = data['recall']\n",
    "    __fscore = data['fscore']\n",
    "\n",
    "    return np.mean(__precision), np.mean(__recall), np.mean(__fscore)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4E1IN6UoPq96"
   },
   "outputs": [],
   "source": [
    "#@title Training procedures\n",
    "\n",
    "def get_train_val_test(task_uid, size=0.9, undersample=False, aug=True, undersample_n=3):\n",
    "    if not isinstance(task_uid, list):\n",
    "        task_uid = [task_uid]\n",
    "        \n",
    "    train_data_raw = defaultdict(list)\n",
    "    test_data_raw = defaultdict(list)\n",
    "    \n",
    "    for _data in tqdm(CORPUS):\n",
    "        if _data['question'] in task_uid:\n",
    "            add_raw_data(test_data_raw, _data)\n",
    "        else:\n",
    "            add_raw_data(train_data_raw, _data)\n",
    "    \n",
    "    train_val = pd.DataFrame.from_dict(train_data_raw)\n",
    "    test = pd.DataFrame.from_dict(test_data_raw)\n",
    "    \n",
    "    # https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "    #  randomize rows....    \n",
    "    train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "    test = test.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    if undersample:\n",
    "        train_val = undersample_df(train_val, n_times=undersample_n)\n",
    "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    if aug:\n",
    "        train_val = pd.concat([train_val, get_ds_synthetic_data()],axis=0)\n",
    "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    weights = get_class_weights(train_val['category_index'].tolist())\n",
    "    \n",
    "    train, val = train_test_split(\n",
    "        train_val, \n",
    "        stratify=train_val['category_index'].tolist(), \n",
    "        train_size=size\n",
    "    )\n",
    "    \n",
    "    return train, val, test, weights        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_predictions(task_title, text, y_predict, y_probs, relevant_class=1):\n",
    "    result = []\n",
    "    \n",
    "    for _t, _y, _prob in zip(text, y_predict, y_probs):\n",
    "        if _y == relevant_class:\n",
    "            if has_meaningful_frame(_t):\n",
    "                result.append(_y)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        else:\n",
    "            result.append(_y)\n",
    "    \n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vFePvH5vBVA7"
   },
   "outputs": [],
   "source": [
    "# @title Testing procedures\n",
    "\n",
    "# https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7\n",
    "def eval_model(model, test_data):\n",
    "    preds = model.predict(test_data.batch(1)).logits  \n",
    "    \n",
    "    #transform to array with probabilities\n",
    "    res = tf.nn.softmax(preds, axis=1).numpy()      \n",
    "\n",
    "    return res.argmax(axis=-1), res[:, 1]\n",
    "\n",
    "def test_model(source, df_test, model, tokenizer, pos_filter=False):\n",
    "    \n",
    "    df_source = df_test[df_test[\"source\"] == source]   \n",
    "    task_title = df_source['question'].tolist()[0]\n",
    "    text = df_source['text'].tolist()\n",
    "    pweights = df_source['weights'].tolist()\n",
    "    \n",
    "    # Encode X_test\n",
    "    test_encodings = _encode(tokenizer, df_source)\n",
    "    test_labels = df_source['category_index'].tolist()\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        dict(test_encodings),\n",
    "        test_labels\n",
    "    ))\n",
    "    \n",
    "    y_true = [y.numpy() for x, y in test_dataset]\n",
    "    \n",
    "    # <= 0  means that an artifact has no relevant information highlighted \n",
    "    # by two or more annotators. these artifacts are ignored\n",
    "    if len(list(filter(lambda k: k == 1, y_true))) > 0:\n",
    "        y_predict, y_probs = eval_model(model, test_dataset)\n",
    "\n",
    "        if pos_filter:\n",
    "            y_predict = update_predictions(task_title, text, y_predict, y_probs)\n",
    "\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_predict)\n",
    "        macro_f1 = f1_score(y_true, y_predict, average='macro')\n",
    "\n",
    "        classification_report_lst.append(classification_report(y_true, y_predict))\n",
    "        aggregate_report_metrics(classification_report(y_true, y_predict, output_dict=True))\n",
    "\n",
    "\n",
    "        logger.info(\"-\" * 20)    \n",
    "\n",
    "        logger.info(\"Y\")\n",
    "        logger.info(\"[0s] {} [1s] {}\".format(\n",
    "            len(list(filter(lambda k: k== 0, y_true))),\n",
    "            len(list(filter(lambda k: k== 1, y_true)))\n",
    "        ))\n",
    "\n",
    "\n",
    "        logger.info(\"predicted\")\n",
    "        logger.info(\"[0s] {} [1s] {}\".format(\n",
    "            len(list(filter(lambda k: k== 0, y_predict))),\n",
    "            len(list(filter(lambda k: k== 1, y_predict)))\n",
    "        ))\n",
    "\n",
    "        logger.info(\"-\" * 20)\n",
    "\n",
    "        logger.info(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "        logger.info(\"macro_f1: {:.4f}\".format(macro_f1))\n",
    "\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(y_true, y_predict, average='macro')\n",
    "\n",
    "        aggregate_macro_metrics(prediction_metrics, precision, recall, fscore)\n",
    "        aggregate_macro_source_metrics(precision, recall, fscore, source)\n",
    "\n",
    "        logger.info(\"Precision: {:.4f}\".format(precision))\n",
    "        logger.info(\"Recall: {:.4f}\".format(recall))\n",
    "        logger.info(\"F1: {:.4f}\".format(fscore))\n",
    "\n",
    "        log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10)\n",
    "        log_venn_diagram(y_true, y_predict, text)\n",
    "        source_lst.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_idx_fold_results(idx_split, store_at):\n",
    "    if idx_split not in store_at:\n",
    "        store_at[idx_split] = dict()\n",
    "        store_at[idx_split]['run_cnt'] = 0\n",
    "        store_at[idx_split]['overall'] = defaultdict(list)\n",
    "        store_at[idx_split]['api'] = defaultdict(list)\n",
    "        store_at[idx_split]['so'] = defaultdict(list)\n",
    "        store_at[idx_split]['git'] = defaultdict(list)\n",
    "        store_at[idx_split]['misc'] = defaultdict(list)\n",
    "    \n",
    "    store_at[idx_split]['run_cnt'] += 1\n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "    store_at[idx_split]['overall']['precision'].append(_precision)\n",
    "    store_at[idx_split]['overall']['recall'].append(_recall)\n",
    "    store_at[idx_split]['overall']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(api_metrics)\n",
    "    store_at[idx_split]['api']['precision'].append(_precision)\n",
    "    store_at[idx_split]['api']['recall'].append(_recall)\n",
    "    store_at[idx_split]['api']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(so_metrics)\n",
    "    store_at[idx_split]['so']['precision'].append(_precision)\n",
    "    store_at[idx_split]['so']['recall'].append(_recall)\n",
    "    store_at[idx_split]['so']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(git_metrics)\n",
    "    store_at[idx_split]['git']['precision'].append(_precision)\n",
    "    store_at[idx_split]['git']['recall'].append(_recall)\n",
    "    store_at[idx_split]['git']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(misc_metrics)\n",
    "    store_at[idx_split]['misc']['precision'].append(_precision)\n",
    "    store_at[idx_split]['misc']['recall'].append(_recall)\n",
    "    store_at[idx_split]['misc']['fscore'].append(_f1score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TFBertForSequenceClassification.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "03ddd131c9f0446eb83bb6dabee9a832",
      "3518f71b0e4540be8b17a3fe72182cb4",
      "a5ccb838d3704546937e925e456830be",
      "8181fd24b3624c1b9c6a9d0302f43a56",
      "f02cf8090f8d463eb7eeb59743a87276",
      "c9ef3ce0ace649c5a53e2244ba0dbb32",
      "702a74b6e6e44d6b8ad68347f1a4b5fb",
      "3d84c022c44141268ef2c8d5e0190404",
      "40c212c9b352401697860624a6c54b1c",
      "1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "911177bb86c749a0bd774cd3b7f9d302"
     ]
    },
    "id": "1oZGDUKnB1gw",
    "outputId": "21690a29-4add-4780-f87f-fa497b87d5e1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n",
      "Hide MarkerView when nothing selected\n",
      "How to check programmatically whether app is running in debug mode or not?\n",
      "JSONObject parse dictionary objects\n",
      "Want to add drawable icons insteadof colorful dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7930/7930 [00:00<00:00, 801504.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    504\n",
      "1    252\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    708\n",
      "1     27\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2ae4bdabd3d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2ae4bdabd3d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8806 - sparse_categorical_accuracy: 0.6336The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64768, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 9s 740ms/step - loss: 0.8806 - sparse_categorical_accuracy: 0.6336 - val_loss: 0.6477 - val_sparse_categorical_accuracy: 0.6071\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8139 - sparse_categorical_accuracy: 0.7090\n",
      "Epoch 00002: val_loss improved from 0.64768 to 0.61392, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 478ms/step - loss: 0.8139 - sparse_categorical_accuracy: 0.7090 - val_loss: 0.6139 - val_sparse_categorical_accuracy: 0.6429\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7457 - sparse_categorical_accuracy: 0.7579\n",
      "Epoch 00003: val_loss improved from 0.61392 to 0.61293, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 458ms/step - loss: 0.7457 - sparse_categorical_accuracy: 0.7579 - val_loss: 0.6129 - val_sparse_categorical_accuracy: 0.6905\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6655 - sparse_categorical_accuracy: 0.7738\n",
      "Epoch 00004: val_loss improved from 0.61293 to 0.60087, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 473ms/step - loss: 0.6655 - sparse_categorical_accuracy: 0.7738 - val_loss: 0.6009 - val_sparse_categorical_accuracy: 0.6905\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5836 - sparse_categorical_accuracy: 0.8148\n",
      "Epoch 00005: val_loss did not improve from 0.60087\n",
      "12/12 [==============================] - 3s 241ms/step - loss: 0.5836 - sparse_categorical_accuracy: 0.8148 - val_loss: 0.6509 - val_sparse_categorical_accuracy: 0.6548\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5115 - sparse_categorical_accuracy: 0.8466\n",
      "Epoch 00006: val_loss did not improve from 0.60087\n",
      "12/12 [==============================] - 3s 242ms/step - loss: 0.5115 - sparse_categorical_accuracy: 0.8466 - val_loss: 0.6621 - val_sparse_categorical_accuracy: 0.7024\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4462 - sparse_categorical_accuracy: 0.8624\n",
      "Epoch 00007: val_loss did not improve from 0.60087\n",
      "12/12 [==============================] - 3s 242ms/step - loss: 0.4462 - sparse_categorical_accuracy: 0.8624 - val_loss: 0.6742 - val_sparse_categorical_accuracy: 0.6905\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3902 - sparse_categorical_accuracy: 0.8849Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.60087\n",
      "12/12 [==============================] - 3s 261ms/step - loss: 0.3902 - sparse_categorical_accuracy: 0.8849 - val_loss: 0.6636 - val_sparse_categorical_accuracy: 0.7143\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 87 [1s] 17\n",
      "predicted\n",
      "[0s] 32 [1s] 72\n",
      "--------------------\n",
      "Accuracy: 0.4712\n",
      "macro_f1: 0.4599\n",
      "Precision: 0.6181\n",
      "Recall: 0.6839\n",
      "F1: 0.4599\n",
      "\u001b[31m17\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 2\n",
      "predicted\n",
      "[0s] 18 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.5806\n",
      "macro_f1: 0.4284\n",
      "Precision: 0.5107\n",
      "Recall: 0.5431\n",
      "F1: 0.4284\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/23844667\n",
      "--------------------\n",
      "Y\n",
      "[0s] 24 [1s] 4\n",
      "predicted\n",
      "[0s] 11 [1s] 17\n",
      "--------------------\n",
      "Accuracy: 0.4643\n",
      "macro_f1: 0.4286\n",
      "Precision: 0.5428\n",
      "Recall: 0.5833\n",
      "F1: 0.4286\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/37096547\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 16 [1s] 1\n",
      "predicted\n",
      "[0s] 12 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.7647\n",
      "macro_f1: 0.5952\n",
      "Precision: 0.6000\n",
      "Recall: 0.8750\n",
      "F1: 0.5952\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "--------------------\n",
      "Y\n",
      "[0s] 33 [1s] 3\n",
      "predicted\n",
      "[0s] 19 [1s] 17\n",
      "--------------------\n",
      "Accuracy: 0.5556\n",
      "macro_f1: 0.4462\n",
      "Precision: 0.5325\n",
      "Recall: 0.6061\n",
      "F1: 0.4462\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/33241952\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.561\u001b[0m\n",
      "recall:    \u001b[31m0.658\u001b[0m\n",
      "f1-score:  \u001b[31m0.472\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.618\u001b[0m\n",
      "recall:    \u001b[31m0.684\u001b[0m\n",
      "f1-score:  \u001b[31m0.460\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.571\u001b[0m\n",
      "recall:    \u001b[31m0.729\u001b[0m\n",
      "f1-score:  \u001b[31m0.512\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.533\u001b[0m\n",
      "recall:    \u001b[31m0.606\u001b[0m\n",
      "f1-score:  \u001b[31m0.446\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.511\u001b[0m\n",
      "recall:    \u001b[31m0.543\u001b[0m\n",
      "f1-score:  \u001b[31m0.428\u001b[0m\n",
      "next 1\n",
      "\n",
      "\u001b[31mFold 1\u001b[0m\n",
      " height must be > 0\n",
      "Write and Read a json data to internal storage android\n",
      "Android PDF Rendering\n",
      "How can I hide a fragment on start of my MainActivity( or the application)?\n",
      "polymorphic deserialization of JSON with jackson, property type becomes &quot;null&quot;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7930/7930 [00:00<00:00, 731521.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    486\n",
      "1    243\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    736\n",
      "1     37\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9056 - sparse_categorical_accuracy: 0.5281The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59046, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 8s 689ms/step - loss: 0.9056 - sparse_categorical_accuracy: 0.5281 - val_loss: 0.5905 - val_sparse_categorical_accuracy: 0.7037\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8248 - sparse_categorical_accuracy: 0.6872\n",
      "Epoch 00002: val_loss improved from 0.59046 to 0.56942, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 461ms/step - loss: 0.8248 - sparse_categorical_accuracy: 0.6872 - val_loss: 0.5694 - val_sparse_categorical_accuracy: 0.7037\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7426 - sparse_categorical_accuracy: 0.7215\n",
      "Epoch 00003: val_loss improved from 0.56942 to 0.55178, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 446ms/step - loss: 0.7426 - sparse_categorical_accuracy: 0.7215 - val_loss: 0.5518 - val_sparse_categorical_accuracy: 0.6914\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6723 - sparse_categorical_accuracy: 0.7490\n",
      "Epoch 00004: val_loss improved from 0.55178 to 0.51312, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 450ms/step - loss: 0.6723 - sparse_categorical_accuracy: 0.7490 - val_loss: 0.5131 - val_sparse_categorical_accuracy: 0.7160\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6070 - sparse_categorical_accuracy: 0.8011\n",
      "Epoch 00005: val_loss improved from 0.51312 to 0.49273, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 449ms/step - loss: 0.6070 - sparse_categorical_accuracy: 0.8011 - val_loss: 0.4927 - val_sparse_categorical_accuracy: 0.7407\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5277 - sparse_categorical_accuracy: 0.8066\n",
      "Epoch 00006: val_loss improved from 0.49273 to 0.45326, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 460ms/step - loss: 0.5277 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.4533 - val_sparse_categorical_accuracy: 0.7778\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4484 - sparse_categorical_accuracy: 0.8765\n",
      "Epoch 00007: val_loss did not improve from 0.45326\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 0.4484 - sparse_categorical_accuracy: 0.8765 - val_loss: 0.4691 - val_sparse_categorical_accuracy: 0.7531\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3996 - sparse_categorical_accuracy: 0.8656\n",
      "Epoch 00008: val_loss did not improve from 0.45326\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 0.3996 - sparse_categorical_accuracy: 0.8656 - val_loss: 0.4913 - val_sparse_categorical_accuracy: 0.7901\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3280 - sparse_categorical_accuracy: 0.9122\n",
      "Epoch 00009: val_loss improved from 0.45326 to 0.40078, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 466ms/step - loss: 0.3280 - sparse_categorical_accuracy: 0.9122 - val_loss: 0.4008 - val_sparse_categorical_accuracy: 0.8765\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2796 - sparse_categorical_accuracy: 0.9300\n",
      "Epoch 00010: val_loss did not improve from 0.40078\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 0.2796 - sparse_categorical_accuracy: 0.9300 - val_loss: 0.4816 - val_sparse_categorical_accuracy: 0.8272\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "https://stackoverflow.com/questions/30362446\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 39 [1s] 3\n",
      "predicted\n",
      "[0s] 26 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.6429\n",
      "macro_f1: 0.4899\n",
      "Precision: 0.5433\n",
      "Recall: 0.6538\n",
      "F1: 0.4899\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/creating-and-using-fragments\n",
      "--------------------\n",
      "Y\n",
      "[0s] 153 [1s] 10\n",
      "predicted\n",
      "[0s] 97 [1s] 66\n",
      "--------------------\n",
      "Accuracy: 0.6319\n",
      "macro_f1: 0.4853\n",
      "Precision: 0.5503\n",
      "Recall: 0.7105\n",
      "F1: 0.4853\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://medium.com/android-dev-hacks/rendering-pdf-documents-in-android-using-pdfrenderer-f6d4f730b18\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 1\n",
      "predicted\n",
      "[0s] 13 [1s] 24\n",
      "--------------------\n",
      "Accuracy: 0.3784\n",
      "macro_f1: 0.3053\n",
      "Precision: 0.5208\n",
      "Recall: 0.6806\n",
      "F1: 0.3053\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "https://stackoverflow.com/questions/40168601\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 2 [1s] 2\n",
      "predicted\n",
      "[0s] 3 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.7500\n",
      "macro_f1: 0.7333\n",
      "Precision: 0.8333\n",
      "Recall: 0.7500\n",
      "F1: 0.7333\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 2\n",
      "predicted\n",
      "[0s] 27 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.6944\n",
      "macro_f1: 0.4098\n",
      "Precision: 0.4630\n",
      "Recall: 0.3676\n",
      "F1: 0.4098\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2883355\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 22 [1s] 2\n",
      "predicted\n",
      "[0s] 15 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.6250\n",
      "macro_f1: 0.4693\n",
      "Precision: 0.5222\n",
      "Recall: 0.5682\n",
      "F1: 0.4693\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 8\n",
      "predicted\n",
      "[0s] 23 [1s] 21\n",
      "--------------------\n",
      "Accuracy: 0.6591\n",
      "macro_f1: 0.6143\n",
      "Precision: 0.6449\n",
      "Recall: 0.7431\n",
      "F1: 0.6143\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "https://stackoverflow.com/questions/38980595\n",
      "--------------------\n",
      "Y\n",
      "[0s] 3 [1s] 2\n",
      "predicted\n",
      "[0s] 4 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.8000\n",
      "macro_f1: 0.7619\n",
      "Precision: 0.8750\n",
      "Recall: 0.7500\n",
      "F1: 0.7619\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 3\n",
      "predicted\n",
      "[0s] 3 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.3750\n",
      "macro_f1: 0.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6154\n",
      "Recall: 0.6154\n",
      "F1: 0.3750\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/14347588\n",
      "--------------------\n",
      "Y\n",
      "[0s] 21 [1s] 4\n",
      "predicted\n",
      "[0s] 14 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.6400\n",
      "macro_f1: 0.5714\n",
      "Precision: 0.6006\n",
      "Recall: 0.6845\n",
      "F1: 0.5714\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.617\u001b[0m\n",
      "recall:    \u001b[31m0.652\u001b[0m\n",
      "f1-score:  \u001b[31m0.522\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.645\u001b[0m\n",
      "recall:    \u001b[31m0.743\u001b[0m\n",
      "f1-score:  \u001b[31m0.614\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.675\u001b[0m\n",
      "recall:    \u001b[31m0.681\u001b[0m\n",
      "f1-score:  \u001b[31m0.605\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.463\u001b[0m\n",
      "recall:    \u001b[31m0.368\u001b[0m\n",
      "f1-score:  \u001b[31m0.410\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.562\u001b[0m\n",
      "recall:    \u001b[31m0.669\u001b[0m\n",
      "f1-score:  \u001b[31m0.389\u001b[0m\n",
      "next 2\n",
      "\n",
      "\u001b[31mFold 2\u001b[0m\n",
      "How to Integrate reCAPTCHA 2.0 in Android\n",
      "How can I make this rxjava zip to run in parallel?\n",
      "Permission Denial when trying to access contacts in Android\n",
      "keyUp called when key is still pressed\n",
      "Donâ€™t leak MockWebServer ports across tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7930/7930 [00:00<00:00, 748426.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    455\n",
      "1    228\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1304\n",
      "1      54\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9327 - sparse_categorical_accuracy: 0.6296The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66495, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 8s 758ms/step - loss: 0.9327 - sparse_categorical_accuracy: 0.6296 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.6579\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8995 - sparse_categorical_accuracy: 0.6032\n",
      "Epoch 00002: val_loss did not improve from 0.66495\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 0.8995 - sparse_categorical_accuracy: 0.6032 - val_loss: 0.6714 - val_sparse_categorical_accuracy: 0.5263\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8624 - sparse_categorical_accuracy: 0.6120\n",
      "Epoch 00003: val_loss improved from 0.66495 to 0.64588, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 5s 479ms/step - loss: 0.8624 - sparse_categorical_accuracy: 0.6120 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.6184\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8061 - sparse_categorical_accuracy: 0.7233\n",
      "Epoch 00004: val_loss did not improve from 0.64588\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 0.8061 - sparse_categorical_accuracy: 0.7233 - val_loss: 0.6538 - val_sparse_categorical_accuracy: 0.6053\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7773 - sparse_categorical_accuracy: 0.6823\n",
      "Epoch 00005: val_loss improved from 0.64588 to 0.61788, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 5s 475ms/step - loss: 0.7773 - sparse_categorical_accuracy: 0.6823 - val_loss: 0.6179 - val_sparse_categorical_accuracy: 0.6842\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7000 - sparse_categorical_accuracy: 0.7247\n",
      "Epoch 00006: val_loss improved from 0.61788 to 0.60069, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 5s 483ms/step - loss: 0.7000 - sparse_categorical_accuracy: 0.7247 - val_loss: 0.6007 - val_sparse_categorical_accuracy: 0.7237\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6444 - sparse_categorical_accuracy: 0.7833\n",
      "Epoch 00007: val_loss did not improve from 0.60069\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 0.6444 - sparse_categorical_accuracy: 0.7833 - val_loss: 0.6100 - val_sparse_categorical_accuracy: 0.6842\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5742 - sparse_categorical_accuracy: 0.8097\n",
      "Epoch 00008: val_loss improved from 0.60069 to 0.56314, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 5s 495ms/step - loss: 0.5742 - sparse_categorical_accuracy: 0.8097 - val_loss: 0.5631 - val_sparse_categorical_accuracy: 0.6974\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5043 - sparse_categorical_accuracy: 0.8389\n",
      "Epoch 00009: val_loss did not improve from 0.56314\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 0.5043 - sparse_categorical_accuracy: 0.8389 - val_loss: 0.5875 - val_sparse_categorical_accuracy: 0.6711\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4651 - sparse_categorical_accuracy: 0.8551\n",
      "Epoch 00010: val_loss did not improve from 0.56314\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.4651 - sparse_categorical_accuracy: 0.8551 - val_loss: 0.6236 - val_sparse_categorical_accuracy: 0.6447\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 158 [1s] 3\n",
      "predicted\n",
      "[0s] 100 [1s] 61\n",
      "--------------------\n",
      "Accuracy: 0.6398\n",
      "macro_f1: 0.4345\n",
      "Precision: 0.5246\n",
      "Recall: 0.8165\n",
      "F1: 0.4345\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://developer.android.com/training/permissions/requesting\n",
      "--------------------\n",
      "Y\n",
      "[0s] 114 [1s] 15\n",
      "predicted\n",
      "[0s] 55 [1s] 74\n",
      "--------------------\n",
      "Accuracy: 0.4806\n",
      "macro_f1: 0.4254\n",
      "Precision: 0.5380\n",
      "Recall: 0.5904\n",
      "F1: 0.4254\n",
      "\u001b[31m11\u001b[0m entries logged\n",
      "https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "--------------------\n",
      "Y\n",
      "[0s] 70 [1s] 2\n",
      "predicted\n",
      "[0s] 60 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.8333\n",
      "macro_f1: 0.5253\n",
      "Precision: 0.5333\n",
      "Recall: 0.6714\n",
      "F1: 0.5253\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 116 [1s] 1\n",
      "predicted\n",
      "[0s] 110 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.9316\n",
      "macro_f1: 0.4823\n",
      "Precision: 0.4955\n",
      "Recall: 0.4698\n",
      "F1: 0.4823\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24952513\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 3\n",
      "predicted\n",
      "[0s] 5 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.5714\n",
      "macro_f1: 0.5625\n",
      "Precision: 0.6667\n",
      "Recall: 0.7273\n",
      "F1: 0.5625\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "--------------------\n",
      "Y\n",
      "[0s] 59 [1s] 4\n",
      "predicted\n",
      "[0s] 26 [1s] 37\n",
      "--------------------\n",
      "Accuracy: 0.4444\n",
      "macro_f1: 0.3673\n",
      "Precision: 0.5213\n",
      "Recall: 0.5869\n",
      "F1: 0.3673\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "https://stackoverflow.com/questions/27297067\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 8\n",
      "predicted\n",
      "[0s] 15 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.7143\n",
      "macro_f1: 0.6786\n",
      "Precision: 0.7000\n",
      "Recall: 0.6731\n",
      "F1: 0.6786\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://developer.android.com/training/safetynet/recaptcha\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 6\n",
      "predicted\n",
      "[0s] 36 [1s] 18\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.5179\n",
      "Precision: 0.5417\n",
      "Recall: 0.5938\n",
      "F1: 0.5179\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/5233543\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 8\n",
      "predicted\n",
      "[0s] 8 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.6667\n",
      "Precision: 0.7067\n",
      "Recall: 0.7067\n",
      "F1: 0.6667\n",
      "\u001b[31m7\u001b[0m entries logged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stackoverflow.com/questions/35357919\n",
      "--------------------\n",
      "Y\n",
      "[0s] 49 [1s] 4\n",
      "predicted\n",
      "[0s] 50 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.8679\n",
      "macro_f1: 0.4646\n",
      "Precision: 0.4600\n",
      "Recall: 0.4694\n",
      "F1: 0.4646\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.569\u001b[0m\n",
      "recall:    \u001b[31m0.631\u001b[0m\n",
      "f1-score:  \u001b[31m0.512\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.582\u001b[0m\n",
      "recall:    \u001b[31m0.637\u001b[0m\n",
      "f1-score:  \u001b[31m0.502\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.622\u001b[0m\n",
      "recall:    \u001b[31m0.616\u001b[0m\n",
      "f1-score:  \u001b[31m0.603\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.519\u001b[0m\n",
      "recall:    \u001b[31m0.636\u001b[0m\n",
      "f1-score:  \u001b[31m0.452\u001b[0m\n",
      "next 3\n",
      "\n",
      "\u001b[31mFold 3\u001b[0m\n",
      "Is there an accepted best-practice on making asynchronous HTTP requests in Android?\n",
      "How to set a minimum crop window ?\n",
      "Camera API: Cross device issues\n",
      "Quick Actions don't get displayed on Android 7.0\n",
      "Application icon doesn&#39;t show up in Android action bar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7930/7930 [00:00<00:00, 652659.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    493\n",
      "1    246\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    737\n",
      "1     33\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9279 - sparse_categorical_accuracy: 0.6022The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64438, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 8s 697ms/step - loss: 0.9279 - sparse_categorical_accuracy: 0.6022 - val_loss: 0.6444 - val_sparse_categorical_accuracy: 0.6747\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8874 - sparse_categorical_accuracy: 0.6292\n",
      "Epoch 00002: val_loss improved from 0.64438 to 0.63700, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 457ms/step - loss: 0.8874 - sparse_categorical_accuracy: 0.6292 - val_loss: 0.6370 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8512 - sparse_categorical_accuracy: 0.6414\n",
      "Epoch 00003: val_loss improved from 0.63700 to 0.56559, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 453ms/step - loss: 0.8512 - sparse_categorical_accuracy: 0.6414 - val_loss: 0.5656 - val_sparse_categorical_accuracy: 0.7711\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7624 - sparse_categorical_accuracy: 0.7334\n",
      "Epoch 00004: val_loss improved from 0.56559 to 0.55809, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 445ms/step - loss: 0.7624 - sparse_categorical_accuracy: 0.7334 - val_loss: 0.5581 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6680 - sparse_categorical_accuracy: 0.7673\n",
      "Epoch 00005: val_loss improved from 0.55809 to 0.52261, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 459ms/step - loss: 0.6680 - sparse_categorical_accuracy: 0.7673 - val_loss: 0.5226 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5779 - sparse_categorical_accuracy: 0.8336\n",
      "Epoch 00006: val_loss did not improve from 0.52261\n",
      "12/12 [==============================] - 3s 237ms/step - loss: 0.5779 - sparse_categorical_accuracy: 0.8336 - val_loss: 0.5280 - val_sparse_categorical_accuracy: 0.7229\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5095 - sparse_categorical_accuracy: 0.8512\n",
      "Epoch 00007: val_loss did not improve from 0.52261\n",
      "12/12 [==============================] - 3s 237ms/step - loss: 0.5095 - sparse_categorical_accuracy: 0.8512 - val_loss: 0.5307 - val_sparse_categorical_accuracy: 0.7229\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4181 - sparse_categorical_accuracy: 0.8863\n",
      "Epoch 00008: val_loss improved from 0.52261 to 0.43903, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 465ms/step - loss: 0.4181 - sparse_categorical_accuracy: 0.8863 - val_loss: 0.4390 - val_sparse_categorical_accuracy: 0.8072\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3513 - sparse_categorical_accuracy: 0.9134\n",
      "Epoch 00009: val_loss did not improve from 0.43903\n",
      "12/12 [==============================] - 3s 238ms/step - loss: 0.3513 - sparse_categorical_accuracy: 0.9134 - val_loss: 0.4796 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3279 - sparse_categorical_accuracy: 0.9147\n",
      "Epoch 00010: val_loss did not improve from 0.43903\n",
      "12/12 [==============================] - 3s 237ms/step - loss: 0.3279 - sparse_categorical_accuracy: 0.9147 - val_loss: 0.4714 - val_sparse_categorical_accuracy: 0.8072\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/guide/topics/media/camera\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 239 [1s] 11\n",
      "predicted\n",
      "[0s] 95 [1s] 155\n",
      "--------------------\n",
      "Accuracy: 0.4000\n",
      "macro_f1: 0.3236\n",
      "Precision: 0.5100\n",
      "Recall: 0.5561\n",
      "F1: 0.3236\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/3059155\n",
      "https://developer.android.com/training/notify-user/build-notification\n",
      "--------------------\n",
      "Y\n",
      "[0s] 145 [1s] 2\n",
      "predicted\n",
      "[0s] 108 [1s] 39\n",
      "--------------------\n",
      "Accuracy: 0.7347\n",
      "macro_f1: 0.4473\n",
      "Precision: 0.5082\n",
      "Recall: 0.6190\n",
      "F1: 0.4473\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/28504524\n",
      "--------------------\n",
      "Y\n",
      "[0s] 61 [1s] 4\n",
      "predicted\n",
      "[0s] 46 [1s] 19\n",
      "--------------------\n",
      "Accuracy: 0.6462\n",
      "macro_f1: 0.3925\n",
      "Precision: 0.4565\n",
      "Recall: 0.3443\n",
      "F1: 0.3925\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "--------------------\n",
      "Y\n",
      "[0s] 52 [1s] 7\n",
      "predicted\n",
      "[0s] 22 [1s] 37\n",
      "--------------------\n",
      "Accuracy: 0.4237\n",
      "macro_f1: 0.3839\n",
      "Precision: 0.5221\n",
      "Recall: 0.5495\n",
      "F1: 0.3839\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/26838730\n",
      "--------------------\n",
      "Y\n",
      "[0s] 18 [1s] 7\n",
      "predicted\n",
      "[0s] 19 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.8000\n",
      "macro_f1: 0.7401\n",
      "Precision: 0.7544\n",
      "Recall: 0.7302\n",
      "F1: 0.7401\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://developer.android.com/training/volley/request\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 2\n",
      "predicted\n",
      "[0s] 6 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.4000\n",
      "macro_f1: 0.3541\n",
      "Precision: 0.4722\n",
      "Recall: 0.4423\n",
      "F1: 0.3541\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.537\u001b[0m\n",
      "recall:    \u001b[31m0.540\u001b[0m\n",
      "f1-score:  \u001b[31m0.440\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.497\u001b[0m\n",
      "recall:    \u001b[31m0.539\u001b[0m\n",
      "f1-score:  \u001b[31m0.375\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.605\u001b[0m\n",
      "recall:    \u001b[31m0.537\u001b[0m\n",
      "f1-score:  \u001b[31m0.566\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.522\u001b[0m\n",
      "recall:    \u001b[31m0.549\u001b[0m\n",
      "f1-score:  \u001b[31m0.384\u001b[0m\n",
      "next 4\n",
      "\n",
      "\u001b[31mFold 4\u001b[0m\n",
      "Android: rotate canvas around the center of the screen\n",
      "TS shows numbers instead of contact names in notifications\n",
      "No lock screen controls ever\n",
      "Enums support with Realm?\n",
      "Sound panning should work for stereo files (and if not, add it to the docs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7930/7930 [00:00<00:00, 769570.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    533\n",
      "1    266\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    265\n",
      "1     11\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9573 - sparse_categorical_accuracy: 0.5970The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68578, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 8s 648ms/step - loss: 0.9573 - sparse_categorical_accuracy: 0.5970 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.5618\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9056 - sparse_categorical_accuracy: 0.5294\n",
      "Epoch 00002: val_loss did not improve from 0.68578\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 0.9056 - sparse_categorical_accuracy: 0.5294 - val_loss: 0.6918 - val_sparse_categorical_accuracy: 0.5281\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8622 - sparse_categorical_accuracy: 0.5795\n",
      "Epoch 00003: val_loss improved from 0.68578 to 0.64535, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 465ms/step - loss: 0.8622 - sparse_categorical_accuracy: 0.5795 - val_loss: 0.6453 - val_sparse_categorical_accuracy: 0.6742\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8066 - sparse_categorical_accuracy: 0.7109\n",
      "Epoch 00004: val_loss improved from 0.64535 to 0.63077, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 433ms/step - loss: 0.8066 - sparse_categorical_accuracy: 0.7109 - val_loss: 0.6308 - val_sparse_categorical_accuracy: 0.6854\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.7581 - sparse_categorical_accuracy: 0.7685\n",
      "Epoch 00005: val_loss improved from 0.63077 to 0.61607, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 439ms/step - loss: 0.7581 - sparse_categorical_accuracy: 0.7685 - val_loss: 0.6161 - val_sparse_categorical_accuracy: 0.7528\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6976 - sparse_categorical_accuracy: 0.7785\n",
      "Epoch 00006: val_loss did not improve from 0.61607\n",
      "13/13 [==============================] - 3s 237ms/step - loss: 0.6976 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.6164 - val_sparse_categorical_accuracy: 0.7416\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6021 - sparse_categorical_accuracy: 0.8335\n",
      "Epoch 00007: val_loss improved from 0.61607 to 0.53646, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 438ms/step - loss: 0.6021 - sparse_categorical_accuracy: 0.8335 - val_loss: 0.5365 - val_sparse_categorical_accuracy: 0.7416\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5283 - sparse_categorical_accuracy: 0.8548\n",
      "Epoch 00008: val_loss did not improve from 0.53646\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 0.5283 - sparse_categorical_accuracy: 0.8548 - val_loss: 0.5555 - val_sparse_categorical_accuracy: 0.7528\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4320 - sparse_categorical_accuracy: 0.8874\n",
      "Epoch 00009: val_loss did not improve from 0.53646\n",
      "13/13 [==============================] - 3s 240ms/step - loss: 0.4320 - sparse_categorical_accuracy: 0.8874 - val_loss: 0.5661 - val_sparse_categorical_accuracy: 0.7640\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3501 - sparse_categorical_accuracy: 0.9312\n",
      "Epoch 00010: val_loss did not improve from 0.53646\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 0.3501 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.5409 - val_sparse_categorical_accuracy: 0.7640\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/8712652\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 15 [1s] 2\n",
      "predicted\n",
      "[0s] 13 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.8824\n",
      "macro_f1: 0.7976\n",
      "Precision: 0.7500\n",
      "Recall: 0.9333\n",
      "F1: 0.7976\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "https://github.com/signalapp/Signal-Android/issues/3376\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 54 [1s] 3\n",
      "predicted\n",
      "[0s] 56 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.9298\n",
      "macro_f1: 0.4818\n",
      "Precision: 0.4732\n",
      "Recall: 0.4907\n",
      "F1: 0.4818\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://dzone.com/articles/android-rotate-and-scale\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 58 [1s] 1\n",
      "predicted\n",
      "[0s] 45 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.7797\n",
      "macro_f1: 0.5036\n",
      "Precision: 0.5357\n",
      "Recall: 0.8879\n",
      "F1: 0.5036\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "https://stackoverflow.com/questions/24652078\n",
      "--------------------\n",
      "Y\n",
      "[0s] 8 [1s] 3\n",
      "predicted\n",
      "[0s] 11 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.7273\n",
      "macro_f1: 0.4211\n",
      "Precision: 0.3636\n",
      "Recall: 0.5000\n",
      "F1: 0.4211\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://github.com/realm/realm-java/issues/776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 31 [1s] 2\n",
      "predicted\n",
      "[0s] 30 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.8485\n",
      "macro_f1: 0.4590\n",
      "Precision: 0.4667\n",
      "Recall: 0.4516\n",
      "F1: 0.4590\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.518\u001b[0m\n",
      "recall:    \u001b[31m0.653\u001b[0m\n",
      "f1-score:  \u001b[31m0.533\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.557\u001b[0m\n",
      "recall:    \u001b[31m0.717\u001b[0m\n",
      "f1-score:  \u001b[31m0.609\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.470\u001b[0m\n",
      "recall:    \u001b[31m0.471\u001b[0m\n",
      "f1-score:  \u001b[31m0.470\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.536\u001b[0m\n",
      "recall:    \u001b[31m0.888\u001b[0m\n",
      "f1-score:  \u001b[31m0.504\u001b[0m\n",
      "next 5\n",
      "\n",
      "\u001b[31mFold 5\u001b[0m\n",
      "Different actions from contact info depending on whether hitting back key or back arrow in top left\n",
      "Unlimited/Dynamic ViewPager in both directions\n",
      "Java: Efficient ArrayList filtering?\n",
      "shouldn't snackbar DSL helpers take CharSequence?\n",
      "Not receiving notifications when phone is locked and connected through WIFI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7930/7930 [00:00<00:00, 770908.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    493\n",
      "1    246\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    770\n",
      "1     33\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9387 - sparse_categorical_accuracy: 0.6360The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66546, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 8s 691ms/step - loss: 0.9387 - sparse_categorical_accuracy: 0.6360 - val_loss: 0.6655 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9026 - sparse_categorical_accuracy: 0.6333\n",
      "Epoch 00002: val_loss improved from 0.66546 to 0.63969, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 458ms/step - loss: 0.9026 - sparse_categorical_accuracy: 0.6333 - val_loss: 0.6397 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8323 - sparse_categorical_accuracy: 0.7118\n",
      "Epoch 00003: val_loss improved from 0.63969 to 0.61540, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 451ms/step - loss: 0.8323 - sparse_categorical_accuracy: 0.7118 - val_loss: 0.6154 - val_sparse_categorical_accuracy: 0.6747\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7442 - sparse_categorical_accuracy: 0.7618\n",
      "Epoch 00004: val_loss improved from 0.61540 to 0.56200, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 452ms/step - loss: 0.7442 - sparse_categorical_accuracy: 0.7618 - val_loss: 0.5620 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6536 - sparse_categorical_accuracy: 0.7930\n",
      "Epoch 00005: val_loss improved from 0.56200 to 0.54107, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 451ms/step - loss: 0.6536 - sparse_categorical_accuracy: 0.7930 - val_loss: 0.5411 - val_sparse_categorical_accuracy: 0.7590\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5493 - sparse_categorical_accuracy: 0.8539\n",
      "Epoch 00006: val_loss improved from 0.54107 to 0.50732, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 460ms/step - loss: 0.5493 - sparse_categorical_accuracy: 0.8539 - val_loss: 0.5073 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4474 - sparse_categorical_accuracy: 0.8823\n",
      "Epoch 00007: val_loss did not improve from 0.50732\n",
      "12/12 [==============================] - 3s 239ms/step - loss: 0.4474 - sparse_categorical_accuracy: 0.8823 - val_loss: 0.5310 - val_sparse_categorical_accuracy: 0.7229\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3660 - sparse_categorical_accuracy: 0.9134\n",
      "Epoch 00008: val_loss did not improve from 0.50732\n",
      "12/12 [==============================] - 3s 237ms/step - loss: 0.3660 - sparse_categorical_accuracy: 0.9134 - val_loss: 0.5678 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2963 - sparse_categorical_accuracy: 0.9405\n",
      "Epoch 00009: val_loss did not improve from 0.50732\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 0.2963 - sparse_categorical_accuracy: 0.9405 - val_loss: 0.5370 - val_sparse_categorical_accuracy: 0.7590\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2462 - sparse_categorical_accuracy: 0.9513Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.50732\n",
      "12/12 [==============================] - 3s 252ms/step - loss: 0.2462 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.5873 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/10108774\n",
      "https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 25 [1s] 8\n",
      "predicted\n",
      "[0s] 32 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.7273\n",
      "macro_f1: 0.4211\n",
      "Precision: 0.3750\n",
      "Recall: 0.4800\n",
      "F1: 0.4211\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 165 [1s] 12\n",
      "predicted\n",
      "[0s] 135 [1s] 42\n",
      "--------------------\n",
      "Accuracy: 0.7401\n",
      "macro_f1: 0.4974\n",
      "Precision: 0.5180\n",
      "Recall: 0.5515\n",
      "F1: 0.4974\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "https://stackoverflow.com/questions/24313539\n",
      "--------------------\n",
      "Y\n",
      "[0s] 51 [1s] 4\n",
      "predicted\n",
      "[0s] 45 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7455\n",
      "macro_f1: 0.4271\n",
      "Precision: 0.4556\n",
      "Recall: 0.4020\n",
      "F1: 0.4271\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/122105\n",
      "--------------------\n",
      "Y\n",
      "[0s] 130 [1s] 1\n",
      "predicted\n",
      "[0s] 46 [1s] 85\n",
      "--------------------\n",
      "Accuracy: 0.3588\n",
      "macro_f1: 0.2730\n",
      "Precision: 0.5059\n",
      "Recall: 0.6769\n",
      "F1: 0.2730\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 2\n",
      "predicted\n",
      "[0s] 20 [1s] 18\n",
      "--------------------\n",
      "Accuracy: 0.5789\n",
      "macro_f1: 0.4571\n",
      "Precision: 0.5556\n",
      "Recall: 0.7778\n",
      "F1: 0.4571\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "--------------------\n",
      "Y\n",
      "[0s] 144 [1s] 2\n",
      "predicted\n",
      "[0s] 47 [1s] 99\n",
      "--------------------\n",
      "Accuracy: 0.3356\n",
      "macro_f1: 0.2659\n",
      "Precision: 0.5101\n",
      "Recall: 0.6632\n",
      "F1: 0.2659\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 75 [1s] 2\n",
      "predicted\n",
      "[0s] 52 [1s] 25\n",
      "--------------------\n",
      "Accuracy: 0.6753\n",
      "macro_f1: 0.4386\n",
      "Precision: 0.5104\n",
      "Recall: 0.5900\n",
      "F1: 0.4386\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "https://stackoverflow.com/questions/36275986\n",
      "--------------------\n",
      "Y\n",
      "[0s] 22 [1s] 2\n",
      "predicted\n",
      "[0s] 17 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.7917\n",
      "macro_f1: 0.6581\n",
      "Precision: 0.6429\n",
      "Recall: 0.8864\n",
      "F1: 0.6581\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.509\u001b[0m\n",
      "recall:    \u001b[31m0.628\u001b[0m\n",
      "f1-score:  \u001b[31m0.430\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.480\u001b[0m\n",
      "recall:    \u001b[31m0.640\u001b[0m\n",
      "f1-score:  \u001b[31m0.381\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.535\u001b[0m\n",
      "recall:    \u001b[31m0.655\u001b[0m\n",
      "f1-score:  \u001b[31m0.453\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.514\u001b[0m\n",
      "recall:    \u001b[31m0.571\u001b[0m\n",
      "f1-score:  \u001b[31m0.468\u001b[0m\n",
      "next 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31mFold 6\u001b[0m\n",
      "Generating an error when using Provider for scoped instances\n",
      "Why settings.xml layout is overlapping the ActionBar/Toolbar?\n",
      "Explanation of the getView() method of an ArrayAdapter\n",
      "Dagger 2 doesn't implement some of the component methods in Android project with custom annotation processor\n",
      "Android - Jackson JSON parser returns null value in &#39;release&#39; builds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7930/7930 [00:00<00:00, 817139.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    464\n",
      "1    232\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1302\n",
      "1      49\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8989 - sparse_categorical_accuracy: 0.5417The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66391, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 8s 731ms/step - loss: 0.8989 - sparse_categorical_accuracy: 0.5417 - val_loss: 0.6639 - val_sparse_categorical_accuracy: 0.6282\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8480 - sparse_categorical_accuracy: 0.6552\n",
      "Epoch 00002: val_loss improved from 0.66391 to 0.66209, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 5s 498ms/step - loss: 0.8480 - sparse_categorical_accuracy: 0.6552 - val_loss: 0.6621 - val_sparse_categorical_accuracy: 0.5769\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7905 - sparse_categorical_accuracy: 0.6897\n",
      "Epoch 00003: val_loss improved from 0.66209 to 0.65695, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 5s 487ms/step - loss: 0.7905 - sparse_categorical_accuracy: 0.6897 - val_loss: 0.6570 - val_sparse_categorical_accuracy: 0.6026\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7279 - sparse_categorical_accuracy: 0.7213\n",
      "Epoch 00004: val_loss improved from 0.65695 to 0.61995, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 5s 476ms/step - loss: 0.7279 - sparse_categorical_accuracy: 0.7213 - val_loss: 0.6199 - val_sparse_categorical_accuracy: 0.6410\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6401 - sparse_categorical_accuracy: 0.8003\n",
      "Epoch 00005: val_loss improved from 0.61995 to 0.55697, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 5s 490ms/step - loss: 0.6401 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.5570 - val_sparse_categorical_accuracy: 0.7436\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5435 - sparse_categorical_accuracy: 0.8218\n",
      "Epoch 00006: val_loss improved from 0.55697 to 0.51616, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 5s 479ms/step - loss: 0.5435 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.5162 - val_sparse_categorical_accuracy: 0.7436\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4750 - sparse_categorical_accuracy: 0.8678\n",
      "Epoch 00007: val_loss improved from 0.51616 to 0.51141, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 5s 478ms/step - loss: 0.4750 - sparse_categorical_accuracy: 0.8678 - val_loss: 0.5114 - val_sparse_categorical_accuracy: 0.7436\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4137 - sparse_categorical_accuracy: 0.8664\n",
      "Epoch 00008: val_loss did not improve from 0.51141\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.4137 - sparse_categorical_accuracy: 0.8664 - val_loss: 0.5145 - val_sparse_categorical_accuracy: 0.7436\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3461 - sparse_categorical_accuracy: 0.9009\n",
      "Epoch 00009: val_loss did not improve from 0.51141\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.3461 - sparse_categorical_accuracy: 0.9009 - val_loss: 0.5261 - val_sparse_categorical_accuracy: 0.7692\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2937 - sparse_categorical_accuracy: 0.9253\n",
      "Epoch 00010: val_loss improved from 0.51141 to 0.50301, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 5s 500ms/step - loss: 0.2937 - sparse_categorical_accuracy: 0.9253 - val_loss: 0.5030 - val_sparse_categorical_accuracy: 0.7821\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://github.com/quarkusio/quarkus/issues/3954\n",
      "https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 203 [1s] 8\n",
      "predicted\n",
      "[0s] 164 [1s] 47\n",
      "--------------------\n",
      "Accuracy: 0.7773\n",
      "macro_f1: 0.5087\n",
      "Precision: 0.5304\n",
      "Recall: 0.6441\n",
      "F1: 0.5087\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://developer.android.com/training/dependency-injection/dagger-android\n",
      "--------------------\n",
      "Y\n",
      "[0s] 195 [1s] 1\n",
      "predicted\n",
      "[0s] 119 [1s] 77\n",
      "--------------------\n",
      "Accuracy: 0.6122\n",
      "macro_f1: 0.3918\n",
      "Precision: 0.5065\n",
      "Recall: 0.8051\n",
      "F1: 0.3918\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "--------------------\n",
      "Y\n",
      "[0s] 47 [1s] 12\n",
      "predicted\n",
      "[0s] 25 [1s] 34\n",
      "--------------------\n",
      "Accuracy: 0.5254\n",
      "macro_f1: 0.5012\n",
      "Precision: 0.5724\n",
      "Recall: 0.6090\n",
      "F1: 0.5012\n",
      "\u001b[31m9\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/using-the-app-toolbar\n",
      "--------------------\n",
      "Y\n",
      "[0s] 65 [1s] 5\n",
      "predicted\n",
      "[0s] 35 [1s] 35\n",
      "--------------------\n",
      "Accuracy: 0.5143\n",
      "macro_f1: 0.4050\n",
      "Precision: 0.5143\n",
      "Recall: 0.5538\n",
      "F1: 0.4050\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/11064244\n",
      "--------------------\n",
      "Y\n",
      "[0s] 47 [1s] 4\n",
      "predicted\n",
      "[0s] 35 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.7647\n",
      "macro_f1: 0.6268\n",
      "Precision: 0.6250\n",
      "Recall: 0.8723\n",
      "F1: 0.6268\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "--------------------\n",
      "Y\n",
      "[0s] 44 [1s] 3\n",
      "predicted\n",
      "[0s] 25 [1s] 22\n",
      "--------------------\n",
      "Accuracy: 0.5532\n",
      "macro_f1: 0.4278\n",
      "Precision: 0.5255\n",
      "Recall: 0.6061\n",
      "F1: 0.4278\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "https://github.com/google/dagger/issues/671\n",
      "https://stackoverflow.com/questions/29738510\n",
      "--------------------\n",
      "Y\n",
      "[0s] 21 [1s] 2\n",
      "predicted\n",
      "[0s] 21 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.8261\n",
      "macro_f1: 0.4524\n",
      "Precision: 0.4524\n",
      "Recall: 0.4524\n",
      "F1: 0.4524\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/29923376\n",
      "--------------------\n",
      "Y\n",
      "[0s] 28 [1s] 4\n",
      "predicted\n",
      "[0s] 15 [1s] 17\n",
      "--------------------\n",
      "Accuracy: 0.5938\n",
      "macro_f1: 0.5393\n",
      "Precision: 0.6176\n",
      "Recall: 0.7679\n",
      "F1: 0.5393\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "https://stackoverflow.com/questions/6442054\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 14 [1s] 7\n",
      "predicted\n",
      "[0s] 10 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.3333\n",
      "macro_f1: 0.3194\n",
      "Precision: 0.3409\n",
      "Recall: 0.3214\n",
      "F1: 0.3194\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/57235136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 3\n",
      "predicted\n",
      "[0s] 34 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7955\n",
      "macro_f1: 0.5938\n",
      "Precision: 0.5853\n",
      "Recall: 0.7358\n",
      "F1: 0.5938\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.527\u001b[0m\n",
      "recall:    \u001b[31m0.637\u001b[0m\n",
      "f1-score:  \u001b[31m0.477\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.516\u001b[0m\n",
      "recall:    \u001b[31m0.706\u001b[0m\n",
      "f1-score:  \u001b[31m0.410\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.524\u001b[0m\n",
      "recall:    \u001b[31m0.630\u001b[0m\n",
      "f1-score:  \u001b[31m0.506\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.539\u001b[0m\n",
      "recall:    \u001b[31m0.602\u001b[0m\n",
      "f1-score:  \u001b[31m0.472\u001b[0m\n",
      "next 7\n",
      "\n",
      "\u001b[31mFold 7\u001b[0m\n",
      "Doesn't scroll properly inside ViewPager\n",
      "The gravity is not working on the TextView in some situation.\n",
      "Support for GoogleApiClient and new FusedLocationProviderApi\n",
      "How to record phone calls in Android\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7930/7930 [00:00<00:00, 803770.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    504\n",
      "1    252\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    871\n",
      "1     27\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9051 - sparse_categorical_accuracy: 0.5212The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69480, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 8s 652ms/step - loss: 0.9051 - sparse_categorical_accuracy: 0.5212 - val_loss: 0.6948 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8178 - sparse_categorical_accuracy: 0.6825\n",
      "Epoch 00002: val_loss did not improve from 0.69480\n",
      "12/12 [==============================] - 3s 242ms/step - loss: 0.8178 - sparse_categorical_accuracy: 0.6825 - val_loss: 0.7077 - val_sparse_categorical_accuracy: 0.5238\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7320 - sparse_categorical_accuracy: 0.7302\n",
      "Epoch 00003: val_loss improved from 0.69480 to 0.63667, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 452ms/step - loss: 0.7320 - sparse_categorical_accuracy: 0.7302 - val_loss: 0.6367 - val_sparse_categorical_accuracy: 0.5952\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6695 - sparse_categorical_accuracy: 0.7738\n",
      "Epoch 00004: val_loss improved from 0.63667 to 0.60964, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 459ms/step - loss: 0.6695 - sparse_categorical_accuracy: 0.7738 - val_loss: 0.6096 - val_sparse_categorical_accuracy: 0.6310\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5836 - sparse_categorical_accuracy: 0.8280\n",
      "Epoch 00005: val_loss did not improve from 0.60964\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 0.5836 - sparse_categorical_accuracy: 0.8280 - val_loss: 0.6278 - val_sparse_categorical_accuracy: 0.6429\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5201 - sparse_categorical_accuracy: 0.8466\n",
      "Epoch 00006: val_loss improved from 0.60964 to 0.58435, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 457ms/step - loss: 0.5201 - sparse_categorical_accuracy: 0.8466 - val_loss: 0.5844 - val_sparse_categorical_accuracy: 0.6786\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4656 - sparse_categorical_accuracy: 0.8558\n",
      "Epoch 00007: val_loss improved from 0.58435 to 0.53067, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 505ms/step - loss: 0.4656 - sparse_categorical_accuracy: 0.8558 - val_loss: 0.5307 - val_sparse_categorical_accuracy: 0.7262\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4214 - sparse_categorical_accuracy: 0.8929\n",
      "Epoch 00008: val_loss did not improve from 0.53067\n",
      "12/12 [==============================] - 3s 242ms/step - loss: 0.4214 - sparse_categorical_accuracy: 0.8929 - val_loss: 0.5356 - val_sparse_categorical_accuracy: 0.7500\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3574 - sparse_categorical_accuracy: 0.9233\n",
      "Epoch 00009: val_loss did not improve from 0.53067\n",
      "12/12 [==============================] - 3s 242ms/step - loss: 0.3574 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.5945 - val_sparse_categorical_accuracy: 0.7381\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3195 - sparse_categorical_accuracy: 0.9206\n",
      "Epoch 00010: val_loss did not improve from 0.53067\n",
      "12/12 [==============================] - 3s 241ms/step - loss: 0.3195 - sparse_categorical_accuracy: 0.9206 - val_loss: 0.5673 - val_sparse_categorical_accuracy: 0.7143\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/reference/android/widget/TextView\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 468 [1s] 2\n",
      "predicted\n",
      "[0s] 422 [1s] 48\n",
      "--------------------\n",
      "Accuracy: 0.8936\n",
      "macro_f1: 0.4719\n",
      "Precision: 0.4976\n",
      "Recall: 0.4487\n",
      "F1: 0.4719\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "--------------------\n",
      "Y\n",
      "[0s] 113 [1s] 6\n",
      "predicted\n",
      "[0s] 108 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.8739\n",
      "macro_f1: 0.5249\n",
      "Precision: 0.5223\n",
      "Recall: 0.5391\n",
      "F1: 0.5249\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/46481789\n",
      "https://developer.android.com/training/gestures/scroll\n",
      "https://javapapers.com/android/android-location-fused-provider\n",
      "--------------------\n",
      "Y\n",
      "[0s] 97 [1s] 2\n",
      "predicted\n",
      "[0s] 77 [1s] 22\n",
      "--------------------\n",
      "Accuracy: 0.7980\n",
      "macro_f1: 0.5259\n",
      "Precision: 0.5455\n",
      "Recall: 0.8969\n",
      "F1: 0.5259\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/training/location/retrieve-current\n",
      "https://developer.android.com/guide/topics/media/mediarecorder\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 45 [1s] 4\n",
      "predicted\n",
      "[0s] 37 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.7551\n",
      "macro_f1: 0.5518\n",
      "Precision: 0.5563\n",
      "Recall: 0.6389\n",
      "F1: 0.5518\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/39588322\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 3\n",
      "predicted\n",
      "[0s] 10 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.8125\n",
      "macro_f1: 0.7681\n",
      "Precision: 0.7500\n",
      "Recall: 0.8846\n",
      "F1: 0.7681\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/19025301\n",
      "--------------------\n",
      "Y\n",
      "[0s] 5 [1s] 6\n",
      "predicted\n",
      "[0s] 2 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.7273\n",
      "macro_f1: 0.6857\n",
      "Precision: 0.8333\n",
      "Recall: 0.7000\n",
      "F1: 0.6857\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/6688444\n",
      "--------------------\n",
      "Y\n",
      "[0s] 5 [1s] 4\n",
      "predicted\n",
      "[0s] 2 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.6494\n",
      "Precision: 0.7857\n",
      "Recall: 0.7000\n",
      "F1: 0.6494\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.642\u001b[0m\n",
      "recall:    \u001b[31m0.687\u001b[0m\n",
      "f1-score:  \u001b[31m0.597\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.527\u001b[0m\n",
      "recall:    \u001b[31m0.544\u001b[0m\n",
      "f1-score:  \u001b[31m0.512\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.790\u001b[0m\n",
      "recall:    \u001b[31m0.762\u001b[0m\n",
      "f1-score:  \u001b[31m0.701\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.534\u001b[0m\n",
      "recall:    \u001b[31m0.718\u001b[0m\n",
      "f1-score:  \u001b[31m0.525\u001b[0m\n",
      "next 8\n",
      "\n",
      "\u001b[31mFold 8\u001b[0m\n",
      "SeekTo Position of cutted song not working\n",
      "Android Gallery with pinch zoom\n",
      "Wait for 2 async REST calls to result in success or error\n",
      "how  to set Screenshot frame size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7930/7930 [00:00<00:00, 802413.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    533\n",
      "1    266\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    377\n",
      "1     11\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9388 - sparse_categorical_accuracy: 0.4431The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68804, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 8s 614ms/step - loss: 0.9388 - sparse_categorical_accuracy: 0.4431 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.4831\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8953 - sparse_categorical_accuracy: 0.6270\n",
      "Epoch 00002: val_loss improved from 0.68804 to 0.64617, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 433ms/step - loss: 0.8953 - sparse_categorical_accuracy: 0.6270 - val_loss: 0.6462 - val_sparse_categorical_accuracy: 0.6404\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8402 - sparse_categorical_accuracy: 0.7121\n",
      "Epoch 00003: val_loss improved from 0.64617 to 0.62249, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 431ms/step - loss: 0.8402 - sparse_categorical_accuracy: 0.7121 - val_loss: 0.6225 - val_sparse_categorical_accuracy: 0.6404\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.7530 - sparse_categorical_accuracy: 0.7572\n",
      "Epoch 00004: val_loss improved from 0.62249 to 0.59399, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 430ms/step - loss: 0.7530 - sparse_categorical_accuracy: 0.7572 - val_loss: 0.5940 - val_sparse_categorical_accuracy: 0.6404\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6618 - sparse_categorical_accuracy: 0.8073\n",
      "Epoch 00005: val_loss did not improve from 0.59399\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 0.6618 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.5942 - val_sparse_categorical_accuracy: 0.6854\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5685 - sparse_categorical_accuracy: 0.8436\n",
      "Epoch 00006: val_loss did not improve from 0.59399\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 0.5685 - sparse_categorical_accuracy: 0.8436 - val_loss: 0.6281 - val_sparse_categorical_accuracy: 0.6067\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4715 - sparse_categorical_accuracy: 0.8773\n",
      "Epoch 00007: val_loss did not improve from 0.59399\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 0.4715 - sparse_categorical_accuracy: 0.8773 - val_loss: 0.5950 - val_sparse_categorical_accuracy: 0.7079\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3831 - sparse_categorical_accuracy: 0.9049Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.59399\n",
      "13/13 [==============================] - 3s 252ms/step - loss: 0.3831 - sparse_categorical_accuracy: 0.9049 - val_loss: 0.6643 - val_sparse_categorical_accuracy: 0.7191\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/2661536\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 99 [1s] 1\n",
      "predicted\n",
      "[0s] 46 [1s] 54\n",
      "--------------------\n",
      "Accuracy: 0.4700\n",
      "macro_f1: 0.3354\n",
      "Precision: 0.5093\n",
      "Recall: 0.7323\n",
      "F1: 0.3354\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/guide/background/threading\n",
      "https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 2\n",
      "predicted\n",
      "[0s] 41 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.7800\n",
      "macro_f1: 0.4382\n",
      "Precision: 0.4756\n",
      "Recall: 0.4062\n",
      "F1: 0.4382\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2993085\n",
      "https://developer.android.com/training/gestures/scale\n",
      "https://stackoverflow.com/questions/10630373\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 3\n",
      "predicted\n",
      "[0s] 12 [1s] 20\n",
      "--------------------\n",
      "Accuracy: 0.4688\n",
      "macro_f1: 0.4231\n",
      "Precision: 0.5750\n",
      "Recall: 0.7069\n",
      "F1: 0.4231\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://github.com/google/ExoPlayer/issues/8387\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 27 [1s] 5\n",
      "predicted\n",
      "[0s] 18 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.5938\n",
      "macro_f1: 0.5135\n",
      "Precision: 0.5516\n",
      "Recall: 0.5963\n",
      "F1: 0.5135\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.528\u001b[0m\n",
      "recall:    \u001b[31m0.610\u001b[0m\n",
      "f1-score:  \u001b[31m0.428\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.542\u001b[0m\n",
      "recall:    \u001b[31m0.720\u001b[0m\n",
      "f1-score:  \u001b[31m0.379\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.552\u001b[0m\n",
      "recall:    \u001b[31m0.596\u001b[0m\n",
      "f1-score:  \u001b[31m0.513\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.476\u001b[0m\n",
      "recall:    \u001b[31m0.406\u001b[0m\n",
      "f1-score:  \u001b[31m0.438\u001b[0m\n",
      "next 9\n",
      "\n",
      "\u001b[31mFold 9\u001b[0m\n",
      "Android SQLite performance in complex queries\n",
      "Custom Annotations in Retrofit 2.0\n",
      "Android App Retrieve Data from Server but in a Secure way\n",
      "Hilt: How to prevent Hilt from picking dependency from a library?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7930/7930 [00:00<00:00, 810903.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    507\n",
      "1    254\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    553\n",
      "1     25\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9426 - sparse_categorical_accuracy: 0.6334The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65691, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 8s 683ms/step - loss: 0.9426 - sparse_categorical_accuracy: 0.6334 - val_loss: 0.6569 - val_sparse_categorical_accuracy: 0.6588\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8800 - sparse_categorical_accuracy: 0.6728\n",
      "Epoch 00002: val_loss improved from 0.65691 to 0.62993, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 463ms/step - loss: 0.8800 - sparse_categorical_accuracy: 0.6728 - val_loss: 0.6299 - val_sparse_categorical_accuracy: 0.7059\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8061 - sparse_categorical_accuracy: 0.7109\n",
      "Epoch 00003: val_loss improved from 0.62993 to 0.58493, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 5s 452ms/step - loss: 0.8061 - sparse_categorical_accuracy: 0.7109 - val_loss: 0.5849 - val_sparse_categorical_accuracy: 0.7059\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7031 - sparse_categorical_accuracy: 0.7543\n",
      "Epoch 00004: val_loss improved from 0.58493 to 0.48459, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 463ms/step - loss: 0.7031 - sparse_categorical_accuracy: 0.7543 - val_loss: 0.4846 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6032 - sparse_categorical_accuracy: 0.7989\n",
      "Epoch 00005: val_loss did not improve from 0.48459\n",
      "12/12 [==============================] - 3s 245ms/step - loss: 0.6032 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.5102 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5380 - sparse_categorical_accuracy: 0.8252\n",
      "Epoch 00006: val_loss improved from 0.48459 to 0.47774, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 459ms/step - loss: 0.5380 - sparse_categorical_accuracy: 0.8252 - val_loss: 0.4777 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4595 - sparse_categorical_accuracy: 0.8607\n",
      "Epoch 00007: val_loss improved from 0.47774 to 0.44491, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 466ms/step - loss: 0.4595 - sparse_categorical_accuracy: 0.8607 - val_loss: 0.4449 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3984 - sparse_categorical_accuracy: 0.8909\n",
      "Epoch 00008: val_loss did not improve from 0.44491\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 0.3984 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.4771 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3110 - sparse_categorical_accuracy: 0.9225\n",
      "Epoch 00009: val_loss did not improve from 0.44491\n",
      "12/12 [==============================] - 3s 243ms/step - loss: 0.3110 - sparse_categorical_accuracy: 0.9225 - val_loss: 0.5005 - val_sparse_categorical_accuracy: 0.8118\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2442 - sparse_categorical_accuracy: 0.9474\n",
      "Epoch 00010: val_loss did not improve from 0.44491\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 0.2442 - sparse_categorical_accuracy: 0.9474 - val_loss: 0.5428 - val_sparse_categorical_accuracy: 0.7765\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 45 [1s] 3\n",
      "predicted\n",
      "[0s] 31 [1s] 17\n",
      "--------------------\n",
      "Accuracy: 0.6250\n",
      "macro_f1: 0.4316\n",
      "Precision: 0.4972\n",
      "Recall: 0.4889\n",
      "F1: 0.4316\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/training/dependency-injection/hilt-android\n",
      "--------------------\n",
      "Y\n",
      "[0s] 141 [1s] 4\n",
      "predicted\n",
      "[0s] 54 [1s] 91\n",
      "--------------------\n",
      "Accuracy: 0.3448\n",
      "macro_f1: 0.2564\n",
      "Precision: 0.4630\n",
      "Recall: 0.1773\n",
      "F1: 0.2564\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/training/data-storage/sqlite\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 67 [1s] 2\n",
      "predicted\n",
      "[0s] 28 [1s] 41\n",
      "--------------------\n",
      "Accuracy: 0.4348\n",
      "macro_f1: 0.3412\n",
      "Precision: 0.5244\n",
      "Recall: 0.7090\n",
      "F1: 0.3412\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "https://github.com/google/dagger/issues/1991\n",
      "https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 2\n",
      "predicted\n",
      "[0s] 38 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.7200\n",
      "macro_f1: 0.4186\n",
      "Precision: 0.4737\n",
      "Recall: 0.3750\n",
      "F1: 0.4186\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/47760861\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 2\n",
      "predicted\n",
      "[0s] 17 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.6129\n",
      "macro_f1: 0.4946\n",
      "Precision: 0.5714\n",
      "Recall: 0.7931\n",
      "F1: 0.4946\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/4015026\n",
      "--------------------\n",
      "Y\n",
      "[0s] 26 [1s] 9\n",
      "predicted\n",
      "[0s] 9 [1s] 26\n",
      "--------------------\n",
      "Accuracy: 0.4571\n",
      "macro_f1: 0.4571\n",
      "Precision: 0.5983\n",
      "Recall: 0.5983\n",
      "F1: 0.4571\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/8184492\n",
      "--------------------\n",
      "Y\n",
      "[0s] 50 [1s] 3\n",
      "predicted\n",
      "[0s] 37 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.6792\n",
      "macro_f1: 0.4549\n",
      "Precision: 0.5042\n",
      "Recall: 0.5167\n",
      "F1: 0.4549\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30648172\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.519\u001b[0m\n",
      "recall:    \u001b[31m0.523\u001b[0m\n",
      "f1-score:  \u001b[31m0.408\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.494\u001b[0m\n",
      "recall:    \u001b[31m0.443\u001b[0m\n",
      "f1-score:  \u001b[31m0.299\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.558\u001b[0m\n",
      "recall:    \u001b[31m0.636\u001b[0m\n",
      "f1-score:  \u001b[31m0.469\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.485\u001b[0m\n",
      "recall:    \u001b[31m0.432\u001b[0m\n",
      "f1-score:  \u001b[31m0.425\u001b[0m\n",
      "next 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# @title 10-fold cross validation WIP\n",
    "CORPUS = raw_data\n",
    "\n",
    "all_tasks = sorted(list(set([d['question'] for d in raw_data])))\n",
    "rseed = 20210343\n",
    "random.seed(rseed)\n",
    "random.shuffle(all_tasks)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "file_handler = logging.FileHandler('/home/msarthur/scratch/LOG-bert_ds_android_pyramid.ans')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, random_state=rseed)\n",
    "np_tasks_arr = np.array(all_tasks)\n",
    "\n",
    "\n",
    "\n",
    "idx_split = 0\n",
    "for train_index, test_index in kf.split(np_tasks_arr):\n",
    "\n",
    "    idx_split = str(idx_split)\n",
    "    eval_fold = True\n",
    "    # 10 runs per fold to avoid reporting peek results in a given fold\n",
    "    if idx_split in fold_results and fold_results[idx_split]['run_cnt'] >= 10:\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split} FULLY TESTED\" + Style.RESET_ALL)\n",
    "        eval_fold = False\n",
    "\n",
    "\n",
    "    if eval_fold:\n",
    "        # <------------------------------------------------------------------------- EVAL VARIABLES\n",
    "        recommendation_metrics = defaultdict(list)\n",
    "        prediction_metrics = defaultdict(list)\n",
    "        api_metrics = defaultdict(list)\n",
    "        so_metrics = defaultdict(list)\n",
    "        git_metrics = defaultdict(list)\n",
    "        misc_metrics = defaultdict(list)\n",
    "        random_prediction_metrics = defaultdict(list)\n",
    "        clz_report_lst = defaultdict(list)\n",
    "\n",
    "        classification_report_lst = []\n",
    "        log_examples_lst = []\n",
    "        source_lst = []\n",
    "        venn_diagram_set = []\n",
    "        # <------------------------------------------------------------------------- EVAL VARIABLES\n",
    "\n",
    "\n",
    "        test_tasks_lst = np_tasks_arr[test_index].tolist()\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split}\" + Style.RESET_ALL)\n",
    "        logger.info('\\n'.join(test_tasks_lst))\n",
    "\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "        df_train, df_val, df_test, weights = get_train_val_test(\n",
    "            test_tasks_lst,\n",
    "            aug=USE_DS_SYNTHETIC,\n",
    "            undersample=UNDERSAMPLING, \n",
    "            undersample_n=N_UNDERSAMPLING\n",
    "        )\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "\n",
    "        logger.info('-' * 10)\n",
    "        logger.info(Fore.RED + 'train'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_train.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'test'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_test.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'weights'+ Style.RESET_ALL)\n",
    "        logger.info(str(weights))\n",
    "        logger.info('-' * 10)\n",
    "\n",
    "\n",
    "        # Encode X_train\n",
    "        train_encodings = _encode(tokenizer, df_train)\n",
    "        train_labels = df_train['category_index'].tolist()\n",
    "\n",
    "        # Encode X_valid\n",
    "        val_encodings = _encode(tokenizer, df_val)\n",
    "        val_labels = df_val['category_index'].tolist()\n",
    "\n",
    "\n",
    "        # https://huggingface.co/transformers/custom_datasets.html\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(train_encodings),\n",
    "            train_labels\n",
    "        ))\n",
    "\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(val_encodings),\n",
    "            val_labels\n",
    "        ))\n",
    "\n",
    "\n",
    "        if model_id == 'distilbert-base-uncased':\n",
    "            model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "                model_id, cache_dir='/home/msarthur/scratch'\n",
    "            )\n",
    "        else:\n",
    "            model = TFBertForSequenceClassification.from_pretrained(\n",
    "                model_id, cache_dir='/home/msarthur/scratch', local_files_only=True\n",
    "            )\n",
    "\n",
    "        # freeze all the parameters\n",
    "        # for param in model.parameters():\n",
    "        #   param.requires_grad = False\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "        METRICS = [\n",
    "            tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        ]\n",
    "\n",
    "        early_stopper = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', mode='min', patience=4, \n",
    "            verbose=1, restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
    "        checkpoint_filepath = '/home/msarthur/scratch/best_pyramid_model'\n",
    "\n",
    "        mc = tf.keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath, \n",
    "            monitor='val_loss', mode='min', verbose=1, \n",
    "            save_best_only=True,\n",
    "            save_weights_only=True\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_fn,\n",
    "            metrics=METRICS\n",
    "        )\n",
    "\n",
    "        # https://discuss.huggingface.co/t/how-to-dealing-with-data-imbalance/393/3\n",
    "        # https://wandb.ai/ayush-thakur/huggingface/reports/Early-Stopping-in-HuggingFace-Examples--Vmlldzo0MzE2MTM\n",
    "        model.fit(\n",
    "            train_dataset.shuffle(1000).batch(BATCH_SIZE), \n",
    "            epochs=EPOCHS, \n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_weight=weights,\n",
    "            validation_data=val_dataset.shuffle(1000).batch(BATCH_SIZE),\n",
    "            callbacks=[early_stopper, mc]\n",
    "        )\n",
    "\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Testing model\" + Style.RESET_ALL)\n",
    "        for source in df_test[\"source\"].unique():\n",
    "            df_source = df_test[df_test[\"source\"] == source]   \n",
    "            logger.info(source)\n",
    "            test_model(source, df_source, model, tokenizer, pos_filter=USE_FRAME_FILTERING)\n",
    "\n",
    "        add_idx_fold_results(idx_split, fold_results)\n",
    "        if 'venn_diagram_set' not in fold_results:\n",
    "            fold_results['venn_diagram_set'] = []\n",
    "\n",
    "        fold_results['venn_diagram_set'] += venn_diagram_set\n",
    "        fold_results['venn_diagram_set'] = list(set(fold_results['venn_diagram_set']))\n",
    "\n",
    "\n",
    "        _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "        logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "        logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "        logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        log_sources_data = [api_metrics, so_metrics, git_metrics, misc_metrics]\n",
    "        log_sources_ids = ['api_metrics', 'so_metrics', 'git_metrics', 'misc_metrics']\n",
    "\n",
    "        for _id, __data in zip(log_sources_ids, log_sources_data):\n",
    "            _precision, _recall, _f1score = avg_macro_metric_for(__data)\n",
    "\n",
    "            logger.info(\"\")\n",
    "            logger.info(Fore.YELLOW + f\"{_id}\" + Style.RESET_ALL)\n",
    "            logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "            logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "            logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "    idx_split = int(idx_split)\n",
    "    idx_split += 1\n",
    "    logger.info(f\"next {idx_split}\")\n",
    "#     break\n",
    "#         if idx_split >= 7:\n",
    "#             logger.info(f\"breaking at {idx_split}\")\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m0\u001b[0m\n",
      "precision: \u001b[31m0.524\u001b[0m [0.48, 0.54, 0.56]\n",
      "recall:    \u001b[31m0.601\u001b[0m [0.56, 0.58, 0.66]\n",
      "f1-score:  \u001b[31m0.493\u001b[0m [0.5, 0.51, 0.47]\n",
      "\u001b[33m1\u001b[0m\n",
      "precision: \u001b[31m0.600\u001b[0m [0.65, 0.54, 0.62]\n",
      "recall:    \u001b[31m0.651\u001b[0m [0.71, 0.6, 0.65]\n",
      "f1-score:  \u001b[31m0.506\u001b[0m [0.53, 0.46, 0.52]\n",
      "\u001b[33m2\u001b[0m\n",
      "precision: \u001b[31m0.561\u001b[0m [0.55, 0.57, 0.57]\n",
      "recall:    \u001b[31m0.626\u001b[0m [0.58, 0.67, 0.63]\n",
      "f1-score:  \u001b[31m0.466\u001b[0m [0.48, 0.4, 0.51]\n",
      "\u001b[33m3\u001b[0m\n",
      "precision: \u001b[31m0.511\u001b[0m [0.5, 0.5, 0.54]\n",
      "recall:    \u001b[31m0.537\u001b[0m [0.52, 0.55, 0.54]\n",
      "f1-score:  \u001b[31m0.451\u001b[0m [0.48, 0.43, 0.44]\n",
      "\u001b[33m4\u001b[0m\n",
      "precision: \u001b[31m0.567\u001b[0m [0.62, 0.56, 0.52]\n",
      "recall:    \u001b[31m0.660\u001b[0m [0.69, 0.64, 0.65]\n",
      "f1-score:  \u001b[31m0.520\u001b[0m [0.56, 0.47, 0.53]\n",
      "\u001b[33m5\u001b[0m\n",
      "precision: \u001b[31m0.507\u001b[0m [0.51, 0.5, 0.51]\n",
      "recall:    \u001b[31m0.622\u001b[0m [0.63, 0.61, 0.63]\n",
      "f1-score:  \u001b[31m0.431\u001b[0m [0.43, 0.43, 0.43]\n",
      "\u001b[33m6\u001b[0m\n",
      "precision: \u001b[31m0.520\u001b[0m [0.55, 0.48, 0.53]\n",
      "recall:    \u001b[31m0.592\u001b[0m [0.63, 0.5, 0.64]\n",
      "f1-score:  \u001b[31m0.448\u001b[0m [0.38, 0.49, 0.48]\n",
      "\u001b[33m7\u001b[0m\n",
      "precision: \u001b[31m0.604\u001b[0m [0.59, 0.58, 0.64]\n",
      "recall:    \u001b[31m0.668\u001b[0m [0.64, 0.68, 0.69]\n",
      "f1-score:  \u001b[31m0.539\u001b[0m [0.5, 0.52, 0.6]\n",
      "\u001b[33m8\u001b[0m\n",
      "precision: \u001b[31m0.551\u001b[0m [0.59, 0.53, 0.53]\n",
      "recall:    \u001b[31m0.702\u001b[0m [0.79, 0.7, 0.61]\n",
      "f1-score:  \u001b[31m0.487\u001b[0m [0.58, 0.45, 0.43]\n",
      "\u001b[33m9\u001b[0m\n",
      "precision: \u001b[31m0.524\u001b[0m [0.53, 0.52, 0.52]\n",
      "recall:    \u001b[31m0.530\u001b[0m [0.56, 0.51, 0.52]\n",
      "f1-score:  \u001b[31m0.411\u001b[0m [0.44, 0.38, 0.41]\n"
     ]
    }
   ],
   "source": [
    "for key_i, value in fold_results.items():\n",
    "    if isinstance(value, dict):\n",
    "        for key_j, __data in value.items():\n",
    "            if key_j == 'overall':\n",
    "                logger.info(Fore.YELLOW + f\"{key_i}\" + Style.RESET_ALL)\n",
    "                logger.info(\"precision: \" + Fore.RED +\n",
    "                            \"{:.3f}\".format(np.mean(__data['precision'])) + Style.RESET_ALL +\n",
    "                           f\" {str([round(x, 2) for x in __data['precision']])}\")\n",
    "                logger.info(\"recall:    \" + Fore.RED +\n",
    "                            \"{:.3f}\".format(np.mean(__data['recall'])) + Style.RESET_ALL+\n",
    "                           f\" {str([round(x, 2) for x in __data['recall']])}\")\n",
    "                logger.info(\"f1-score:  \" + \n",
    "                            Fore.RED + \"{:.3f}\".format(np.mean(__data['fscore'])) + Style.RESET_ALL+\n",
    "                           f\" {str([round(x, 2) for x in __data['fscore']])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCaching results\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(Fore.YELLOW + \"Caching results\" + Style.RESET_ALL)\n",
    "with open('bert_ds_android_pyramid.json', 'w') as fo:\n",
    "    json.dump(fold_results, fo, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', 'venn_diagram_set', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for source in df_test[\"source\"].unique():\n",
    "#     df_source = df_test[df_test[\"source\"] == source]   \n",
    "#     logger.info(source)\n",
    "#     test_model(source, df_source, model, tokenizer, pos_filter=True)\n",
    "#     cnt += 1\n",
    "#     if cnt >= 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cYVkKLe-B1j0"
   },
   "outputs": [],
   "source": [
    "#@title Metrics report\n",
    "# logger.info(json.dumps(fold_results, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(api_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"API metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(so_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"SO metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(git_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"GIT metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(misc_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"MISC metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "zUOGnWgIMYLN"
   },
   "outputs": [],
   "source": [
    "def examples_per_source_type(source_type='misc', n_samples=None):\n",
    "    _sources = list(set([x[0] for x in log_examples_lst]))\n",
    "\n",
    "    _template = \"[w={}]\" + Fore.RED + \"[y={}]\" + Fore.YELLOW + \"[p={:.4f}]\" + Style.RESET_ALL + \" {}\"\n",
    "\n",
    "    idx = 0\n",
    "    for s in _sources:\n",
    "        examples_in_source = []\n",
    "        if source_type == 'api' and ('docs.oracle' in s or 'developer.android' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'so' and ('stackoverflow.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]            \n",
    "            idx += 1\n",
    "        elif source_type == 'git' and ('github.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'misc' and 'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        if not examples_in_source:\n",
    "            continue\n",
    "        logger.info('')\n",
    "        logger.info(Fore.RED + f\"{task_title}\" + Style.RESET_ALL)    \n",
    "        logger.info(s)\n",
    "        logger.info('')\n",
    "\n",
    "        for _, _, pweights, y_predict, y_probs, text in examples_in_source:\n",
    "            logger.info(_template.format(pweights, y_predict, y_probs, text))\n",
    "            logger.info('')\n",
    "        logger.info('-' * 20)\n",
    "      \n",
    "        if n_samples and idx >= n_samples:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Fjg9kKaDM0fo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAPI\u001b[0m\n",
      "\n",
      "\u001b[31mHilt: How to prevent Hilt from picking dependency from a library?\u001b[0m\n",
      "https://developer.android.com/training/dependency-injection/hilt-android\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8685]\u001b[0m To migrate a project that uses Dagger to Hilt, see the migration guide and the Migrating your Dagger app to Hilt codelab.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8637]\u001b[0m To learn more about Hilt component scopes, see Scoping in Android and Hilt.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8604]\u001b[0m The following example demonstrates how to scope a binding to a component in a Hilt module.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8563]\u001b[0m The Hilt module AnalyticsModule is annotated with @InstallIn ( ActivityComponent:: class ) because you want Hilt to inject that dependency into ExampleActivity.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8557]\u001b[0m If you want a content provider to use Hilt to get some dependencies, you need to define an interface that is annotated with @EntryPoint for each binding type that you want and include qualifiers.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8525]\u001b[0m @AndroidEntryPoint generates an individual Hilt component for each Android class in your project.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8503]\u001b[0m For each Android class in which you can perform field injection, there's an associated Hilt component that you can refer to in the @InstallIn annotation.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8487]\u001b[0m Hilt is a dependency injection library for Android that reduces the boilerplate of doing manual dependency injection in your project.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8482]\u001b[0m First, add the hilt-android-gradle-plugin plugin to your project's root build.gradle file:\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8447]\u001b[0m If you don't directly own the AnalyticsService class, you can tell Hilt how to provide instances of this type by creating a function inside a Hilt module and annotating that function with @Provides.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mAndroid SQLite performance in complex queries\u001b[0m\n",
      "https://developer.android.com/training/data-storage/sqlite\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8882]\u001b[0m This page assumes that you are familiar with SQL databases in general and helps you get started with SQLite databases on Android.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8808]\u001b[0m As your data graph changes, you need to update the affected SQL queries manually.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8800]\u001b[0m To use SQLiteOpenHelper, create a subclass that overrides the onCreate ( ) and onUpgrade ( ) callback methods.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8765]\u001b[0m The APIs you'll need to use a database on Android are available in the android.database.sqlite package.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8752]\u001b[0m You need to use lots of boilerplate code to convert between SQL queries and data objects.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8704]\u001b[0m For example, here's an implementation of SQLiteOpenHelper that uses some of the commands shown above:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8639]\u001b[0m It's not required, but this can help your database work harmoniously with the Android framework.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8618]\u001b[0m For these reasons, we highly recommended using the Room Persistence Library as an abstraction layer for accessing information in your app's SQLite databases.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8606]\u001b[0m Since getWritableDatabase ( ) and getReadableDatabase ( ) are expensive to call when the database is closed, you should leave your database connection open for as long as you possibly need to access it.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8555]\u001b[0m To access your database, instantiate your subclass of SQLiteOpenHelper:\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for API sources\n",
    "\n",
    "logger.info(Fore.RED + \"API\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='api', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FDBgOWQXNW1i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mGIT\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for GIT sources\n",
    "\n",
    "logger.info(Fore.RED + \"GIT\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='git', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "G4Bqx8AbNoV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSO\u001b[0m\n",
      "\n",
      "\u001b[31mAndroid SQLite performance in complex queries\u001b[0m\n",
      "https://stackoverflow.com/questions/4015026\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8946]\u001b[0m I dropped this into my ContentProvider.query -LRB- -RRB- and now I can see exactly how all the queries are getting performed.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8892]\u001b[0m Use EXPLAIN QUERY PLAN on your queries to see which index would be used or if the query requires a full table scan.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8866]\u001b[0m Here's a bit of code to get EXPLAIN QUERY PLAN results into Android logcat from a running Android app.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8780]\u001b[0m Pin down exactly which queries you need to optimize.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8738]\u001b[0m If you have more complex queries that can't make use of any indexes that you might create, you can de-normalize your schema, structuring your data in such a way that the queries are simpler and can be answered using indexes.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8725]\u001b[0m For SELECTs and UPDATEs, indexes can things up, but only if the indexes you create can actually be used by the queries that you need speeding up.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8701]\u001b[0m SQLite LINK using savepoints, but I'm not sure that you'll gain anything there performance-wise.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8684]\u001b[0m I'm starting with an SQLiteOpenHelper dbHelper and an SQLiteQueryBuilder qb.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8640]\u001b[0m Using both WHERE predicates and ORDER BY both require an index and SQLite can only use one, so that can be a point where performance suffers.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8524]\u001b[0m There is a LINK for optimizing SQLite in general in the SQLite documentation.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mCustom Annotations in Retrofit 2.0\u001b[0m\n",
      "https://stackoverflow.com/questions/47760861\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.9013]\u001b[0m Since the version of Retrofit 2.6.0, you can get the annotations in OkHttp Interceptor using the tag field like this:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8957]\u001b[0m While if you do not insist on custom annotations, the easiest way for now in my opinion is to add custom header to the api interface, then read and remove it in the interceptor.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8903]\u001b[0m We read the annotation in the CallAdapter.Factory and when the request gets created in the CallAdapter, we will store some information for this kind of request within some map, to identify it later in some interceptor.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8843]\u001b[0m We'll use the gson converter -LRB- GsonConverterFactory -RRB- provided by Retrofit and modify it slightly to include a listener in GsonResponseBodyConverter.class which handles the http response parsing.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8725]\u001b[0m What you need to do is have two OkHttp clients, with their respective instances of Retrofit.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8368]\u001b[0m It uses a custom CallAdapter to get annotation @Authenticated, and put data into a map, which later parsed in the Interceptor.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8209]\u001b[0m Then inside of the interceptor, you can verify if the request is annotated or no.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8071]\u001b[0m I have similar requirement, what I found is Annotation can be read in LINK, LINK and LINK.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7907]\u001b[0m New: @Tag parameter annotation for setting tags on the underlying OkHttp Request object.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7895]\u001b[0m getAnnotation -LRB- annotationClass -RRB-\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mAndroid App Retrieve Data from Server but in a Secure way\u001b[0m\n",
      "https://stackoverflow.com/questions/8184492\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7847]\u001b[0m As for storing data in the app what you can encrypt the data before storing or you can use another format other than SQLite for better security as you can view sqlite databases using the browser pretty easily.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7779]\u001b[0m If you want to pretty much ensure the user can not see the data other than by looking at your app then encryption is really the only way.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7672]\u001b[0m This link from Android developers site advice you some of the good tips for security - LINK\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7563]\u001b[0m Use SSL on HTTPS to transfer data instead of HTTP you need to setup the certificates on the webserver not very sure how it works.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7466]\u001b[0m If you are really concerned about the data then further encrypt it with a unique algorithm before sending and decrypt it when it reaches the app.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7308]\u001b[0m LINK http://developer.android.com/reference/javax/net/ssl/package-summary.html LINK\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6904]\u001b[0m Every application on Android runs in a secure sandbox environment, so other processes on the system can not access your code or private data without proper handshake.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6799]\u001b[0m It's not 100 % secure -LRB- a hacker could de-compile your app and figure out how to decrypt the data -RRB-, but it's a major pain to crack and will stop most hackers.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6577]\u001b[0m The only real way of securing your data is by asking your user for a password, besides doing all the work I wrote about above.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6328]\u001b[0m To conclude, if your information is not super-duper sensitive -LRB- e.g. credit card information -RRB-, I'd suggest just sticking with the default security provided by Android -LRB- i.e. save everything in plain text, knowing other apps can't access it -RRB-.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for SO sources\n",
    "\n",
    "logger.info(Fore.RED + \"SO\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='so', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2_mgLqe0N-hs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mMISC\u001b[0m\n",
      "\n",
      "\u001b[31mHilt: How to prevent Hilt from picking dependency from a library?\u001b[0m\n",
      "https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8682]\u001b[0m Setting up Hilt To set up Hilt in your application, first follow the directions from the guide: Installing Gradle Build ...\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8544]\u001b[0m An easy way to use dependency injection in Android apps Hilt Is a new library for dependency injection built on top of Dagger ... It allows you to use Dagger's capabilities in Android apps in a simplified way.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.8510]\u001b[0m How to make a dependency injectable To make an object embeddable in Hilt, you need to tell Hilt how to instantiate that object.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8418]\u001b[0m After installing all the required elements and plugins to use Hilt, annotate your Application class @HiltAndroidApp.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8400]\u001b[0m These classes are entry points into the Hilt dependency graph, and Hilt needs to know that they have dependencies to inject.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8387]\u001b[0m Hilt module Think of it as a set of `` recipes'' that tell Hilt how to instantiate something that doesn't have a constructor, such as an interface or a system service.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8358]\u001b[0m This tutorial describes the basic functionality of the library and provides some code snippets to help you get started using Hilt in your projects.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8311]\u001b[0m A good example of this is activities that are normally generated by the Android platform, not by the Hilt library.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8263]\u001b[0m A practical guide to using Hilt with Kotlin\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8230]\u001b[0m â®• Using the module Two other ways to convert objects to embedded in Hilt are through the use of modules.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mAndroid App Retrieve Data from Server but in a Secure way\u001b[0m\n",
      "https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8398]\u001b[0m So what do we do?Step two: Use Native CodeIn android you can write some or all of your code in c/c + + languages using NDK.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8371]\u001b[0m So this way the hacker who is sniffing our requests wouldn't know what we are doing and what information are we sending so they can't go ahead and make fake requests.But the new problem here is that decompiling an Android application isn't that hard, actually it's pretty easy.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8263]\u001b[0m Yet, I don't think reading this article would be of no value.Imagine that you have a server for your Android application.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8233]\u001b[0m How to Send a Semi Secure Request to a Server in AndroidReza BigdeliJan 14, 2016 Â· 5 min read\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8013]\u001b[0m How to Send a Semi Secure Request to a Server in AndroidReza BigdeliJan 14, 2016 Â· 5 min readDisclaimer: This article is written a couple of years ago.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7668]\u001b[0m 224 224 3 Android App DevelopmentNative AppEncryptionMore from Reza BigdeliFollowAndroid developer https://www.linkedin.com/in/rezabigdeli/More From MediumText Recognition in Android Using Firebase VisionPayam Asefi in The Startup5 Reasons to go Serverless With Azure.Ajiri Gunn in The StartupDesigning the Android Application Architecture: Ravi SahaniSliding Up And Down: View AnimationMudit SenManaging Application Sizearun kumarCompose O'ClockMarton Braun in Google Developers ExpertsBitrise -- Run Android instrumented tests on different modules within the same projectAlessandro Mautone in The StartupAndroid: Partition tablesDmFrPro\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7430]\u001b[0m Get startedOpen in appReza Bigdeli263 FollowersAboutFollowSign inGet startedFollow263 FollowersAboutGet startedOpen in appHow to Send a Semi Secure Request to a Server in AndroidReza BigdeliJan 14, 2016 Â· 5 min readDisclaimer: This article is written a couple of years ago.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6267]\u001b[0m Well I believe I have a solution.The solution has some steps to follow and in each step a problem will arise and we will try to solve them along the way to get to what we want which is a secure valid request to the server.Step One: Just Respond to Application RequestsIf we make the server to only respond to the requests sent from the application we can be a little bit more sure that requests are sent from a real person who is using our application, not a bot or a program of a hacker.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6056]\u001b[0m The solution has some steps to follow and in each step a problem will arise and we will try to solve them along the way to get to what we want which is a secure valid request to the server.Step One: Just Respond to Application RequestsIf we make the server to only respond to the requests sent from the application we can be a little bit more sure that requests are sent from a real person who is using our application, not a bot or a program of a hacker.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5512]\u001b[0m What if a hacker sniff your requests from the application and just creates the same structured requests and sends them to your server to fill its database with fake users.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for MISC sources\n",
    "\n",
    "logger.info(Fore.RED + \"MISC\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='misc', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m247 entries VENN SET\u001b[0m\n",
      "To do this, we need to create our own custom ArrayAdapter class.\n",
      "To be able to record, your app must tell the user that it will access the device's audio input.\n",
      "Use ANALYZE to allow SQLite's query planner to work more efficiently.\n",
      "Returns the value mapped by name if it exists and is an int or can be coerced to an int, or throws otherwise.\n",
      "But that does not keep your site safe from HTTP client request forgery.\n",
      "It triggers when you scroll the view -LRB- list for example -RRB-.\n",
      "basically I used a private string property taken as a string to construct a computed property with that enum correspondance.\n",
      "dataSpec.length is the length of data that the caller wants to read, or C.LENGTH _ UNSET to read to the end of the media.\n",
      "I haven't tried recording phone call's but there is a option in LINK for:\n",
      "inject.Scope annotation - Dependencies declared with that scope with have caching Provider with double-check lock generated and only single instance will be created for it within component declared with the same scope and its creation will be thread safe.\n",
      "Due to the specifics of Android threading, we can not run network tasks on the same thread as the UI thread.\n",
      "When scaling a document for printing the aspect ratio should be preserved.\n",
      "The following code snippet demonstrates how to request a permission using a request code:\n",
      "Try adding this piece of code before loading your viewPager\n",
      "A typical use of the APIs to render a PDF looks like this:\n",
      "These are permissions that are requested while the app is running ( instead of before the app is installed ).\n",
      "Before using the reCAPTCHA API, you need to add the SafetyNet API to your project.\n",
      "And this code snippet demonstrates the recommended process of checking for a permission, and requesting a permission from the user when necessary:\n",
      "Make sure you have the icon set in the manifest.xml file, in the application tag as:\n",
      "The CompletionStage API lets programmers define pipelines of asynchronous operations for data, and handles the asynchronous behaviour for you.\n",
      "Respect the property whether the document would like to be scaled for printing as per shouldScaleForPrinting ( ).\n",
      "We check if a View is recycled with if ( convertView == null ).\n",
      "To read from a database, use the query ( ) method, passing it your selection criteria and desired columns.\n",
      "As getView is call many times inflating a new view every time is expensive so list view provides you one of the previously created view to re-use.\n",
      "Usually, you should use onKeyUp ( ) if you want to be sure that you receive only one event.\n",
      "Normally, the Android OS prohibits apps from accessing each other's files -LRB- i.e. databases, preference files, regular files stored in the app's private directory -RRB- through proven Linux file permissions.\n",
      "A Fragment is a combination of an XML layout file and a java class much like an Activity.\n",
      "To fix this issue, open MainActivity.kt and add the following line inside onCreate ( ) below the line where you connect the PageAdapter to the ViewPager:\n",
      "We use a ScaleGestureDetector on the activity to listen to touch events.\n",
      "We can create a custom ListView of User objects by subclassing ArrayAdapter to describe how to translate the object into a view within that class and then using it like any other adapter.\n",
      "Now add the following code in your PdfRenderActivity -- 7.\n",
      "Returns the value mapped by name if it exists and is a JSONObject, or throws otherwise.\n",
      "get a seekable file descriptor from your pdf document:\n",
      "That is because, when your app starts, the ViewPager displays the movie at index 0.\n",
      "It works kind of like this: The ListView asks the adapter what it should display, and the adapter jumps into action:\n",
      "You use them following the same basic pattern you use for other types of requests.\n",
      "Starting with Android 8.0, users can choose to disable or enable lock screen notifications for each notification channel.\n",
      "The results of the query are returned to you in a Cursor object.\n",
      "with the api 23, permission <uses-permissionÂ android:name=\"android.pemission.READ_CONTACTS\"/> dont work, change the api level in the emulator for api 22 -LRB- lollipop -RRB- or lower\n",
      "Since you want to offset the icon to the top right, you will need to offset the ( x, y ) position slightly, but make sure you use dp because if you simply offset the ( x, y ) by some amount it willnot translate to different devices.\n",
      "Once the test is done we shutdown the server.\n",
      "The following example code demonstrates how to create a basic camera preview class that can be included in a View layout.\n",
      "If you want to set a specific size for your camera preview, set this in the surfaceChanged ( ) method as noted in the comments above.\n",
      "The following code snippet shows how to handle the permissions response:\n",
      "Use android: fillViewport = `` true'' in ScrollView\n",
      "Make a Snackbar to display a message\n",
      "If you don't declare any dangerous permissions, or if your app is installed on a device that runs Android 5.1 ( API level 22 ) or lower, the permissions are automatically granted, and you don't need to complete any of the remaining steps on this page.\n",
      "Unscoped dependency will have simple Provider generated without any caching and any instance of that dependency created in component will be new for every new injection -LRB- as in constructor, or in module provision method, or just as a field -RRB-.\n",
      "If the user granted the permission to your app, you can access the private user data.\n",
      "So normally the simplified algorithm is like that:\n",
      "This class enables rendering a PDF document.\n",
      "While developing for a target platform of 2.3.3 using Eclipse on Ubuntu, I had permission failures in the log file that indicated I needed this exact line while working on something similar.\n",
      "it is used for the Android Music Remote control even if the App is in Lock mode.\n",
      "We can do that using the @JsonTypeInfo and @JsonSubTypes annotations.\n",
      "Since the version of Retrofit 2.6.0, you can get the annotations in OkHttp Interceptor using the tag field like this:\n",
      "and in the LinearLayout, the default gravity -LRB- used here -RRB- is ` center'\n",
      "Finally, getView ( ) creates a view to be used as a row in the list.\n",
      "Create a Preview Class - Create a camera preview class that extends SurfaceView and implements the SurfaceHolder interface.\n",
      "If you are using Android Studio, or if you are using Gradle from the command line, you can add your own stuff to BuildConfig or otherwise tweak the debug and release build types to help distinguish these situations at runtime.\n",
      "Improving Performance with the ViewHolder Pattern To improve performance, we should modify the custom adapter by applying the ViewHolder pattern which speeds up the population of the ListView considerably by caching view lookups for smoother, faster item loading:\n",
      "layout_gravity is the way the TextView will align itself in its parent, in your case in the vertical LinearLayout\n",
      "The magic behind this is the setTag ( ) method which lets us attach an arbitrary object onto a View object, which is how we save the already inflated View for future reuse.\n",
      "In your app's manifest file, declare the permissions that your app might need to request.\n",
      "The error message you are getting appears to be due to dubiously-legal JSON, particularly on the receiving side:\n",
      "Every android app has its own internal storage only that app can access, you can read from there or write to it.\n",
      "Gets a View that displays in the drop down popup the data at the specified position in the data set.\n",
      "If the permission you need to add isn't listed under the normal permissions, you'll need to deal with `` Runtime Permissions''.\n",
      "Returns the value mapped by name if it exists and is a long or can be coerced to a long, or throws otherwise.\n",
      "Now you need to add a Toolbar to your Activity layout file.\n",
      "Listening for Location Updates After you invoke `` getLastLocation'', you might want to request periodic updates from the Fused Location Provider.\n",
      "And replace the response_string with the value that you earlier got by the g-recaptcha-response field.\n",
      "Returns the value mapped by name if it exists and is a double or can be coerced to a double, or NaN otherwise.\n",
      "Check out this stackoverflow for a discussion on deciding when to replace vs hide and show.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following code shows how to do this in the context of an Activity, but this is also possible from within a Fragment.\n",
      "There are a few different ways of using it, so let's look at an example.\n",
      "These repeated calls can seriously harm the ListView's performance, especially if your app is running on limited resources and/or you have a very large list.\n",
      "But these action buttons should not duplicate the action performed when the user taps the notification.\n",
      "So ideally we also would have an easy way of processing an array of businesses into an ArrayList of Business objects.\n",
      "This code sample demonstrates how to modify the contents of the text view defined in the previous XML layout:\n",
      "This class implements SurfaceHolder.Callback in order to capture the callback events for creating and destroying the view, which are needed for assigning the camera preview input.\n",
      "Beginning in Android 6.0 -LRB- API level 23 -RRB-, users grant permissions to apps while the app is running, not when they install the app.\n",
      "reCAPTCHA is a free service that uses an advanced risk analysis engine to protect your app from spam and other abusive actions.\n",
      "So really you want to replace:\n",
      "You can read more about this on the material design guidelines which state: `` The use of application icon plus title as a standard layout is discouraged on API 21 devices and newer.''\n",
      "Therefore, Android will always ask you to approve dangerous permissions.\n",
      "So the correct way to do this is:\n",
      "Returns the value mapped by name if it exists and is an int or can be coerced to an int, or 0 otherwise.\n",
      "Using a Custom ArrayAdapter When we want to display a series of items from a list using a custom representation of the items, we need to use our own custom XML layout for each item.\n",
      "Say we have a few simple observables of different types:\n",
      "The simplest way to wait for them all is something like this:\n",
      "You can develop these things yourself, but if you would like to use a pre-made custom view, copy LINK into your project and use it like a normal ImageView.\n",
      "Well, subscribeOn ( ) on the outer stream level basically said that all events should be processed sequentially, within this stream, on a different thread.\n",
      "Basically you need to load a bitmap and pass to each event you want to draw.\n",
      "As you can see, there is nothing special for Cat and Dog, the only one that know about them is the abstract class Animal, so when deserializing, you'll target to Animal and the ObjectMapper will return the actual instance as you can see in the following test:\n",
      "Ask for permissions in context, when the user starts to interact with the feature that requires it.\n",
      "If your app needs to use resources or information outside of its own sandbox, you can declare a permission and set up a permission request that provides this access.\n",
      "A camera preview class is a SurfaceView that can display the live image data coming from a camera, so users can frame and capture a picture or video.\n",
      "The first step when adding a `` Runtime Permission'' is to add it to the AndroidManifest:\n",
      "The naive approach to this ( without any view caching ) looks like the following:\n",
      "Returns the value mapped by name if it exists and is a boolean or can be coerced to a boolean, or throws otherwise.\n",
      "If you declare any dangerous permissions, and if your app is installed on a device that runs Android 6.0 ( API level 23 ) or higher, you must request the dangerous permissions at runtime by following the steps in this guide.\n",
      "Usually these are the following steps to create json object through the Http connection in android.\n",
      "Returns the value mapped by name if it exists and is a boolean or can be coerced to a boolean, or fallback otherwise.\n",
      "To overcome this, I have created a custom ViewPager -LRB- based on LINK -RRB- that calculates it's height in the required manner.\n",
      "For SELECTs and UPDATEs, indexes can things up, but only if the indexes you create can actually be used by the queries that you need speeding up.\n",
      "gravity is the way the text will align itself in the TextView.\n",
      "In addittion, you can do in a Fragment -LRB- for example when getting server data failed -RRB-:\n",
      "Something like this:\n",
      "Pin down exactly which queries you need to optimize.\n",
      "After that override getView -LRB- -RRB- method and make sure to return your custom View there.\n",
      "Set the audio source using setAudioSource ( ).\n",
      "If you would like an application icon -LRB- but I discourage it -RRB-, you can use the method setLogo -LRB- -RRB-.\n",
      "with some custome code which simply draws a drawable icon.\n",
      "The cool thing about the new Google Recaptcha is that the validation is now completely encapsulated in the widget.\n",
      "you should try this:\n",
      "It should hopefully be clear that if dataSpec.position is non-zero, readPosition = mediaPosition + dataSpec.position ( correct ) is going to end up reading from a different position than readPosition = mediaPosition ( incorrect ).\n",
      "However, in the API response, we actually get a collection of business JSON in an array.\n",
      "This is designed to prevent apps from eavesdropping on telephone conversations.\n",
      "If you want to render a PDF, you create a renderer and for every page you want to render, you open the page, render it, and close the page.\n",
      "Have you checked RemoteControlClient ?\n",
      "Using of rawQuery -LRB- -RRB- instead of building using ContentValues will fasten up in certain cases.\n",
      "The simplest adapter to use is called an ArrayAdapter because the adapter converts an ArrayList of objects into View items loaded into the ListView container.\n",
      "Get the data item associated with the specified position in the data set.\n",
      "Use android: fitsSystemWindows = `` true'' in the root view of your layout -LRB- LinearLayout in your case -RRB-.\n",
      "You don't need to use so many lists, just create a class that will contain all the data of single item, there is no need for buttons, use just text change listener instead.\n",
      "Try to check below FragmentPagerAdapter to get endless viewpager adapter:\n",
      "Javac annotation processor uses rounds instead of defining processors order.\n",
      "It wasn't until I moved the * uses-permission ... READ_CONTACTS * line to outside the application tag that things worked.\n",
      "Here's a bit of code to get EXPLAIN QUERY PLAN results into Android logcat from a running Android app.\n",
      "Returns the value mapped by name if it exists and is a long or can be coerced to a long, or fallback otherwise.\n",
      "Instead, as the user scrolls through the list, items that leave the screen are kept in memory for later use and then every new row that enters the screen reuses an older row kept around in memory.\n",
      "Check whether the user has already granted the runtime permission that your app requires.\n",
      "I would suggest that you write your downloaded JSON out to a file and compare it with your original to see if there is a problem with the download logic.\n",
      "I created a ViewPager that supports infinite looping effect, smart auto-scroll, compatible with any indicators and easy to use.\n",
      "Since getCount ( ) now returns a number larger than the size of the list, the ViewPager will try to access the movie at an index greater than the array size when the user swipes past the last movie.\n",
      "If you are using this class to rasterize a PDF for printing or show a print preview, it is recommended that you respect the following contract in order to provide a consistent user experience when seeing a preview and printing, i.e. the user sees a preview that is the same as the printout.\n",
      "If it is not null then we have a recycled View and can just change its values, otherwise we need to create a new row View.\n",
      "If the user presses and holds the button, then onKeyDown ( ) is called multiple times.\n",
      "Next, we will create a BufferedReader that will allow us to iterate through the response.\n",
      "Make a Snackbar to display a message.\n",
      "Using this approach, all three fragments will remain in the container once added initially and then we are simply revealing the desired fragment and hiding the others within the container.\n",
      "We instantiate a new LocationRequest object.\n",
      "Call this method, passing in the outer most ViewGroup that you want a screen shot of:\n",
      "You must check whether you have that permission every time you perform an operation that requires that permission.\n",
      "This document shows you how to use MediaRecorder to write an application that captures audio from a device microphone, save the audio, and play it back ( with MediaPlayer ).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dangerous permission groups, however, can give apps access to things like your calling history, private messages, location, camera, microphone, and more.\n",
      "Users can use the system settings to choose the level of detail visible in lock screen notifications, including the option to disable all lock screen notifications.\n",
      "To register a key pair for use with the SafetyNet reCAPTCHA API, navigate to the reCAPTCHA Android signup site, then complete the following sequence of steps:\n",
      "Usage Defining a Fragment A fragment, like an activity, has an XML layout file and a Java class that represents the Fragment controller.\n",
      "It returns View that will be displayed as your list/grid/gallary / any view that use adapter item.\n",
      "Below we place the toolbar at the top of a LinearLayout like the standard ActionBar:\n",
      "A Toolbar is a generalization of action bars for use within application layouts.\n",
      "I am using mic to record phone audio and also use the Telephony manager to find the calling state.\n",
      "You may extend it from BaseAdapter.\n",
      "It is worth noting that apparently Dagger2 creates a single instance per scoped provider in a module per component.\n",
      "The dataSpec argument is not defining the entire media.\n",
      "Java 8 -LRB- LINK -RRB- solves this problem using streams and lambdas in one line of code:\n",
      "It is possible that the JSONObject parser has been made more lenient in newer Android releases.\n",
      "If you have a lot of string / text type data, consider creating Virtual tables using full text search -LRB- FTS3 -RRB-, which can run faster query.\n",
      "If document page size is greater than the printed media size the content should be anchored to the upper left corner of the page for left-to-right locales and top right corner for right-to-left locales.\n",
      "Do not inset the content with any margins from the PrintAttributes as the application is responsible to render it such that the margins are respected.\n",
      "You set this text view a width of `` wrap_content'' it means, what ever the text is, the view take the size of the text.\n",
      "For example, this snippet fetches a JSON feed and displays it as text in the UI:\n",
      "The more indexes you have, the slower your INSERTs will be, so you will have to work out the best trade-off for your situation.\n",
      "The following code sample shows a typical use, with an XML layout and code to modify the contents of the text view:\n",
      "dataSpec.position is the position within the media that the caller wants to start reading from.\n",
      "SolutionThe solution to open PDF is solved by the introduction of the class PdfRenderer in Android-Lollipop ( API 21 ).\n",
      "This bug incorrectly sets the drawable bounds to 0 -LRB- or negative in the case of an inset drawable -RRB-.\n",
      "This tells the ViewPager to display the movie found in the middle of the array.\n",
      "Nothing much happening here before starting the test we create the server and start it at port 8080.\n",
      "You can also do it by rotating the canvas before drawing:\n",
      "You can avoid this problem by using the View Holder Pattern.\n",
      "The important thing to keep in mind is that fragments should not directly communicate with each other and should generally only communicate with their parent activity.\n",
      "Here you define what information shows and where it sits within the ListView.\n",
      "Now Android allows you to decide which permissions to accept on a case-by-case basis -- after the app is installed.\n",
      "Get a View that displays the data at the specified position in the data set.\n",
      "Here we caught our IOException, printed the stack trace in order to see more details if/when we have do debug, and set our result to null.\n",
      "In Android development, any time we want to show a vertical list of scrollable items we will use a ListView which has data populated using an Adapter.\n",
      "Then inside of the interceptor, you can verify if the request is annotated or no.\n",
      "Returns the value mapped by name if it exists and is a JSONArray, or null otherwise.\n",
      "First, we will create an InputStreamReader that reads our request input.\n",
      "Use EXPLAIN QUERY PLAN on your queries to see which index would be used or if the query requires a full table scan.\n",
      "Here is a LINK on how to record audio using the LINK.\n",
      "How to make a dependency injectable To make an object embeddable in Hilt, you need to tell Hilt how to instantiate that object.\n",
      "I am using mic to record calls for better support and compatibility.\n",
      "You can either rotate your bitmap when you draw it by using a matrix:\n",
      "So in order to get a scoped provider in a module, you need to specify the scope for your module's provider method.\n",
      "Returns the value mapped by name if it exists and is an int or can be coerced to an int, or fallback otherwise.\n",
      "Continuous Location Access Activity Following is the complete class which accesses the Fused Location Provider to get the location continuously in the Android example application.\n",
      "Returns the value mapped by name if it exists and is a JSONObject, or null otherwise.\n",
      "The Dagger basics page explained how Dagger can help you automate dependency injection in your app.\n",
      "This is a boolean value that will be true for a debug build, false otherwise:\n",
      "In the meantime I think that you will need to annotate your child classes with @JsonTypeInfo and @JsonSubTypes to override the inherited annotations.\n",
      "Consider the following below: If you have a JSON object for `` Vehicle'', it could be a `` Car'' or `` Plane'', each with its own fields, some unique to the other.\n",
      "Don't mess with the visibility flags of the container - FragmentTransaction.hide / show does that internally for you.\n",
      "Next, you'll need to initiate the permission request and handle the result.\n",
      "This becomes a problem specifically when seeking, because dataSpec.position will not be 0 in this case, yet your implementation will nevertheless read from the start of the media.\n",
      "The FragmentPagerAdapter stores the fragments in memory as long as the user can navigate between them.\n",
      "During deserialization, you would want Jackson to deserialize the `` Vehicle'' JSON object to the appropriate `` Car'' or `` Plane'' class.\n",
      "Returns the value mapped by name if it exists and is a boolean or can be coerced to a boolean, or false otherwise.\n",
      "In you case, you first want to check if you such file exist before creating one.\n",
      "Fragment Hiding vs Replace In many of the examples above, we call transaction.replace ( ... ) to load a dynamic fragment which first removes the existing fragment from the activity invoking onStop and onDestroy for that fragment before adding the new fragment to the container.\n",
      "When a scale -LRB- ie, pinch -RRB- gesture is detected, then the scale factor is used to resize the ImageView.\n",
      "Anyone with HTTP POST knowledge could put random data inside of the g-recaptcha-response form field, and foll your site to make it think that this field was provided by the google widget.\n",
      "GoogleApiClient FusedLocationProviderApi requires the GoogleApiClient instance to get the Location and it can be obtained as below.\n",
      "to this approach instead leveraging add, show, and hide in the FragmentTransaction:\n",
      "Returns the value mapped by name if it exists and is a long or can be coerced to a long, or 0 otherwise.\n",
      "Overview A fragment is a reusable class implementing a portion of an activity.\n",
      "This may boost your phone speed, but it will lead to delayed or no notifications from your apps.\n",
      "Although the icon can be added back with:\n",
      "Those recording sources may only be used by system apps.\n",
      "Note that in the zip function, the parameters have concrete types that correspond to the types of the observables being zipped.\n",
      "Wait for the user to invoke the task or action in your app that requires access to specific private user data.\n",
      "The following code snippet shows how to invoke this method:\n",
      "Note that this means if you are in a RelativeLayout, you need to ensure that all other views are positioned below the toolbar explicitly.\n",
      "PdfRenderer -- This class enables rendering a PDF document.\n",
      "Returns the value mapped by name if it exists and is a JSONArray, or throws otherwise.\n",
      "However, in many cases, we may want to keep both fragments around in the container and simply toggle their visibility.\n",
      "The TextView being in wrap_content this does nothing, as the TextView is exactly the size of the text.\n",
      "Skip all the expensive inflation steps and just get the holder you already made.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You also inflate a custom view from the XML layout defined in res/layout/list_item_recipe.xml -- more on this in the next section.\n",
      "One thing that I ran across when I applied this approach to my production code is that you still need to keep the @JsonSubtypes annotation as part of the Base class.\n",
      "Although what you are doing is really not appropriate.\n",
      "After that, extend the class AsyncTask.\n",
      "This line means: add a meta-property on serialization or read a meta-property on deserialization -LRB- include = JsonTypeInfo.As.PROPERTY -RRB- called'' @class'' -LRB- property ='' @class'' -RRB- that holds the fully-qualified Java class name -LRB- use = JsonTypeInfo.Id.CLASS -RRB-.\n",
      "that is done because rotation is around the top left point ( the origin ) of the view.\n",
      "If you have more complex queries that can't make use of any indexes that you might create, you can de-normalize your schema, structuring your data in such a way that the queries are simpler and can be answered using indexes.\n",
      "Pass in your API site key as a parameter.\n",
      "To handle an individual key press, implement onKeyDown ( ) or onKeyUp ( ) as appropriate.\n",
      "Values may be any mix of JSONObjects, JSONArrays, Strings, Booleans, Integers, Longs, Doubles or NULL.\n",
      "But the easiest option is to generate java code directly and your generated java classes will be picked up by javac automatically, launching second round of annotation processing, where dagger will process them.\n",
      "That means, that the widget will take care of asking questions, validating responses all the way till it determines that a user is actually a human, only then you get a g-recaptcha-response value.\n",
      "Starting in Android 2.2 ( API Level 8 ), you can use the setDisplayOrientation ( ) method to set the rotation of the preview image.\n",
      "Check the user's response, whether they chose to grant or deny the runtime permission.\n",
      "A reference to the parent view that this view will be a child of.\n",
      "In order to change preview orientation as the user re-orients the phone, within the surfaceChanged ( ) method of your preview class, first stop the preview with Camera.stopPreview ( ) change the orientation and then start the preview again with Camera.startPreview ( ).\n",
      "First of all your Animal class with the Json Annotations for the subclasses.\n",
      "At that time, your app can request the runtime permission that's required for accessing that data.\n",
      "The use of application icon plus title as a standard layout is discouraged on API 21 devices and newer.\n",
      "I'm still convinced that there are some security settings in the OS that deny the access to the contacts.\n",
      "When setting preview size, you must use values from getSupportedPreviewSizes ( ).\n",
      "Set the audio encoder using setAudioEncoder ( ).\n",
      "The simplest, and best long-term solution, is to use BuildConfig.DEBUG.\n",
      "Returns the value mapped by name if it exists and is a double or can be coerced to a double, or throws otherwise.\n",
      "Returns the value mapped by name if it exists and is a double or can be coerced to a double, or fallback otherwise.\n",
      "If so, your app can access the private user data.\n",
      "For simplicity in rendering a camera preview, you should change your application's preview activity orientation to landscape by adding the following to your manifest.\n"
     ]
    }
   ],
   "source": [
    "logger.info(Fore.RED + f\"{len(fold_results['venn_diagram_set'])} entries VENN SET\" + Style.RESET_ALL)\n",
    "for _t in fold_results['venn_diagram_set']:\n",
    "    logger.info(_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM51gMzrDUJf4OiiaquqBe4",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hugging-face-keras-bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7 Arthur hugging",
   "language": "python",
   "name": "msarthur-hface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03ddd131c9f0446eb83bb6dabee9a832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3518f71b0e4540be8b17a3fe72182cb4",
       "IPY_MODEL_a5ccb838d3704546937e925e456830be",
       "IPY_MODEL_8181fd24b3624c1b9c6a9d0302f43a56"
      ],
      "layout": "IPY_MODEL_f02cf8090f8d463eb7eeb59743a87276"
     }
    },
    "0466163ff4a945798423387d1ac900c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0efe94b613f44c029f2e9bd05696ad32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3e13535de4b44bb9139c3911684cee8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6ccdfb754c12418c9438ac218a172e63",
      "value": "Downloading: 100%"
     }
    },
    "153c3ed5c6314a49a5a37ad976417142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_262cc50dd08f49f78b781c2ce96a4ad7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f305b344487a4b598a7d41b007e49abd",
      "value": " 232k/232k [00:00&lt;00:00, 286kB/s]"
     }
    },
    "16b6cfa829ad43778c079452df231a3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17cfaa41c53842618c728987a81a44da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fc2d9969ea34bb3bb6e9f0260c2a75c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23531989ef014d7db16b220bb807c8fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "262cc50dd08f49f78b781c2ce96a4ad7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3518f71b0e4540be8b17a3fe72182cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9ef3ce0ace649c5a53e2244ba0dbb32",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_702a74b6e6e44d6b8ad68347f1a4b5fb",
      "value": "Downloading: 100%"
     }
    },
    "35a9eeb0acdb44738a6ad7fbf6d99b2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3950e2a7832c4dce8fd8209d6322a1f7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d32667132d604faeb419bbf9851c1bd8",
      "value": 231508
     }
    },
    "394b7988d36849b7b2c82872ae8d489d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3950e2a7832c4dce8fd8209d6322a1f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ccd384305c44ee3a86f47a2b994fbf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d84c022c44141268ef2c8d5e0190404": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40c212c9b352401697860624a6c54b1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4bd0f4c575714ad7848e818a576ee00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a38bc7017d545e2b44ad6ab0b2d937b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_929799bd24fb411bb4686988f2ae8996",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bd0f4c575714ad7848e818a576ee00a",
      "value": 570
     }
    },
    "5c6bfb038756422bb00be1349db7750b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c586016d3b594c6299cab2384f4c10aa",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d03c894896ad4ed6b48f19a70fbdf2af",
      "value": 466062
     }
    },
    "67f208ba489343dfa195c1dd915f3efe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16b6cfa829ad43778c079452df231a3d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a2a36eb594654c65acd584d9d4ebea20",
      "value": "Downloading: 100%"
     }
    },
    "6ccdfb754c12418c9438ac218a172e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cf29b5d508a4e2082751ccc7fa2f625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ccd384305c44ee3a86f47a2b994fbf9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_23531989ef014d7db16b220bb807c8fd",
      "value": " 466k/466k [00:00&lt;00:00, 637kB/s]"
     }
    },
    "702a74b6e6e44d6b8ad68347f1a4b5fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71a15c5a038f451f8ee64ce046488f71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8181fd24b3624c1b9c6a9d0302f43a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_911177bb86c749a0bd774cd3b7f9d302",
      "value": " 536M/536M [00:12&lt;00:00, 40.9MB/s]"
     }
    },
    "82b7fc20b50c44b2bd84b3bf882cdd43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c2b37becdef45bba205dfb20f8e37b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4276b6a5eac4023955218db6f78c84a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c4b0a1b67d304afda6ee4e52095584cc",
      "value": " 28.0/28.0 [00:00&lt;00:00, 631B/s]"
     }
    },
    "8c7cf993674145ffb7bb876e5591f6ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67f208ba489343dfa195c1dd915f3efe",
       "IPY_MODEL_35a9eeb0acdb44738a6ad7fbf6d99b2b",
       "IPY_MODEL_153c3ed5c6314a49a5a37ad976417142"
      ],
      "layout": "IPY_MODEL_82b7fc20b50c44b2bd84b3bf882cdd43"
     }
    },
    "901557318fb947dfa082f0cbf2d7365b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0efe94b613f44c029f2e9bd05696ad32",
       "IPY_MODEL_5a38bc7017d545e2b44ad6ab0b2d937b",
       "IPY_MODEL_b3db733aacf94a3c94519d70a7a56d7a"
      ],
      "layout": "IPY_MODEL_394b7988d36849b7b2c82872ae8d489d"
     }
    },
    "911177bb86c749a0bd774cd3b7f9d302": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "929799bd24fb411bb4686988f2ae8996": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "997b8c940317448c9409a2dee15fc519": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e99fb1211ba43459ee78dd64ab8c30e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2a36eb594654c65acd584d9d4ebea20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5ccb838d3704546937e925e456830be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d84c022c44141268ef2c8d5e0190404",
      "max": 536063208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40c212c9b352401697860624a6c54b1c",
      "value": 536063208
     }
    },
    "a66943be0fc0423880cb2bd63a1ea2d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6d9e21208294428a3f5572bbbd8b0b9",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d15e557fc621427a8295eecdc1e781a8",
      "value": 28
     }
    },
    "a8fd8b38a6b84be7b83b2f4df590fada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e99fb1211ba43459ee78dd64ab8c30e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_71a15c5a038f451f8ee64ce046488f71",
      "value": "Downloading: 100%"
     }
    },
    "b12b35cc52454a249c97f695409d24ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3db733aacf94a3c94519d70a7a56d7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0466163ff4a945798423387d1ac900c8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_17cfaa41c53842618c728987a81a44da",
      "value": " 570/570 [00:00&lt;00:00, 17.0kB/s]"
     }
    },
    "b4276b6a5eac4023955218db6f78c84a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d9e21208294428a3f5572bbbd8b0b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baffabe6cabf48f5b0b6523ea92aee78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18a3a9fc6d54b9f848e4454e1e36c21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8fd8b38a6b84be7b83b2f4df590fada",
       "IPY_MODEL_5c6bfb038756422bb00be1349db7750b",
       "IPY_MODEL_6cf29b5d508a4e2082751ccc7fa2f625"
      ],
      "layout": "IPY_MODEL_c4c410ab0c994a229a49b8baee221de4"
     }
    },
    "c4b0a1b67d304afda6ee4e52095584cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4c410ab0c994a229a49b8baee221de4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c586016d3b594c6299cab2384f4c10aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5b9bf1f3ae343ce97982c7802cfdc94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_997b8c940317448c9409a2dee15fc519",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b12b35cc52454a249c97f695409d24ce",
      "value": "Downloading: 100%"
     }
    },
    "c9ef3ce0ace649c5a53e2244ba0dbb32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d03c894896ad4ed6b48f19a70fbdf2af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d15e557fc621427a8295eecdc1e781a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d32667132d604faeb419bbf9851c1bd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3e13535de4b44bb9139c3911684cee8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0e88103f9684ffdb957357222bbaaf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5b9bf1f3ae343ce97982c7802cfdc94",
       "IPY_MODEL_a66943be0fc0423880cb2bd63a1ea2d2",
       "IPY_MODEL_8c2b37becdef45bba205dfb20f8e37b2"
      ],
      "layout": "IPY_MODEL_baffabe6cabf48f5b0b6523ea92aee78"
     }
    },
    "f02cf8090f8d463eb7eeb59743a87276": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f305b344487a4b598a7d41b007e49abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
