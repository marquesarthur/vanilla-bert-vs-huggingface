{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marquesarthur/vanilla-bert-vs-huggingface/blob/main/hugging_face_keras_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfNydjdoLcvK"
   },
   "source": [
    "Based on \n",
    "\n",
    "\n",
    "\n",
    "1.   https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379\n",
    "2.   https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/\n",
    "3.   https://huggingface.co/transformers/training.html#fine-tuning-with-keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**problem statement:**\n",
    "\n",
    "\n",
    "*   a developer has to inspect an **artifact X**\n",
    "*   Within the artifact, only a portion of the text is relevant to **input task Y**\n",
    "*   We ought to build a model that establishes relationships between **Y** and **sentences x âˆˆ X** \n",
    "*  The model must determine: **is x relevant to task Y**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Example of a task and an annotated artifact:*\n",
    "\n",
    "<br>\n",
    "\n",
    "[<img src=\"https://i.imgur.com/Zj1317H.jpg\">](https://i.imgur.com/Zj1317H.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* The coloured sentences are sentences annotated as relevant to the input task. \n",
    "* The warmer the color, the more annotators selected that portion of the text. \n",
    "* For simplicity, we process the data and used sentences \n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Ultimately, our data is a tuple representing:*\n",
    "\n",
    "\n",
    "*   **text** = artifact sentence\n",
    "\n",
    "*   **question** = task description\n",
    "\n",
    "*   **source** = URL of the artifact\n",
    "\n",
    "*   **category_index** = whether sentence is relevant [or not] for the input task\n",
    "\n",
    "*   **weights** = number of participants who annotated sentence as relevant\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtFJT5AK6RRc",
    "outputId": "f3eaf1c3-63c2-455e-eaa5-5eb9955afe4b"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "\n",
    "# !pip install transformers\n",
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y80jdm9S6wQA",
    "outputId": "de6caa10-19da-42af-958f-bf19fe70903d"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn tqdm pandas python-Levenshtein path colorama matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q38yIvW87NrN",
    "outputId": "425ff20e-e16f-475a-93fe-221008e32fdc"
   },
   "outputs": [],
   "source": [
    "# @title Download git repo\n",
    "# !git clone https://github.com/marquesarthur/vanilla-bert-vs-huggingface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyrLR-tf8P4Q",
    "outputId": "a2cc52fc-f3e9-4cf0-ce6d-c11cee304c39"
   },
   "outputs": [],
   "source": [
    "# %cd vanilla-bert-vs-huggingface\n",
    "# !git pull\n",
    "# !ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kudd2ZR8tKZ",
    "outputId": "2a38495e-b8e4-43b1-c126-ec92e98b07d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m39 \u001b[33m129 \u001b[0m https://developer.android.com/training/permissions/requesting\n",
      "\u001b[31m14 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/5233543\n",
      "\u001b[31m4 \u001b[33m34 \u001b[0m https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "\u001b[31m27 \u001b[33m63 \u001b[0m https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "\u001b[31m9 \u001b[33m161 \u001b[0m https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "\u001b[31m9 \u001b[33m15 \u001b[0m https://developer.android.com/training/volley/request\n",
      "\u001b[31m14 \u001b[33m65 \u001b[0m https://stackoverflow.com/questions/28504524\n",
      "\u001b[31m20 \u001b[33m59 \u001b[0m https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "\u001b[31m5 \u001b[33m97 \u001b[0m https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "\u001b[31m4 \u001b[33m12 \u001b[0m https://stackoverflow.com/questions/33241952\n",
      "\u001b[31m6 \u001b[33m33 \u001b[0m https://github.com/realm/realm-java/issues/776\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/8712652\n",
      "\u001b[31m8 \u001b[33m59 \u001b[0m https://dzone.com/articles/android-rotate-and-scale\n",
      "\u001b[31m5 \u001b[33m470 \u001b[0m https://developer.android.com/reference/android/widget/TextView\n",
      "\u001b[31m7 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/19025301\n",
      "\u001b[31m8 \u001b[33m95 \u001b[0m https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "\u001b[31m20 \u001b[33m145 \u001b[0m https://developer.android.com/training/dependency-injection/hilt-android\n",
      "\u001b[31m4 \u001b[33m8 \u001b[0m https://stackoverflow.com/questions/30648172\n",
      "\u001b[31m4 \u001b[33m81 \u001b[0m https://github.com/google/dagger/issues/1991\n",
      "\u001b[31m9 \u001b[33m48 \u001b[0m https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "\u001b[31m5 \u001b[33m47 \u001b[0m https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "\u001b[31m9 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/6442054\n",
      "\u001b[31m3 \u001b[33m22 \u001b[0m https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "\u001b[31m22 \u001b[33m211 \u001b[0m https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "\u001b[31m21 \u001b[33m59 \u001b[0m https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "\u001b[31m17 \u001b[33m33 \u001b[0m https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "\u001b[31m6 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/10108774\n",
      "\u001b[31m19 \u001b[33m250 \u001b[0m https://developer.android.com/guide/topics/media/camera\n",
      "\u001b[31m9 \u001b[33m32 \u001b[0m https://github.com/google/ExoPlayer/issues/8387\n",
      "\u001b[31m7 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/8184492\n",
      "\u001b[31m7 \u001b[33m58 \u001b[0m https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "\u001b[31m3 \u001b[33m50 \u001b[0m https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "\u001b[31m3 \u001b[33m56 \u001b[0m https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "\u001b[31m3 \u001b[33m5 \u001b[0m https://stackoverflow.com/questions/38980595\n",
      "\u001b[31m4 \u001b[33m38 \u001b[0m https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "\u001b[31m8 \u001b[33m36 \u001b[0m https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "\u001b[31m4 \u001b[33m131 \u001b[0m https://stackoverflow.com/questions/122105\n",
      "\u001b[31m3 \u001b[33m48 \u001b[0m https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "\u001b[31m8 \u001b[33m49 \u001b[0m https://developer.android.com/guide/topics/media/mediarecorder\n",
      "\u001b[31m4 \u001b[33m9 \u001b[0m https://stackoverflow.com/questions/6688444\n",
      "\u001b[31m3 \u001b[33m23 \u001b[0m https://github.com/google/oboe/issues/447\n",
      "\u001b[31m4 \u001b[33m27 \u001b[0m https://stackoverflow.com/questions/24952513\n",
      "\u001b[31m18 \u001b[33m219 \u001b[0m https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "\u001b[31m3 \u001b[33m72 \u001b[0m https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "\u001b[31m5 \u001b[33m373 \u001b[0m https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "\u001b[31m12 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/35357919\n",
      "\u001b[31m11 \u001b[33m117 \u001b[0m https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "\u001b[31m8 \u001b[33m147 \u001b[0m https://developer.android.com/training/notify-user/build-notification\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/3059155\n",
      "\u001b[31m10 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/26838730\n",
      "\u001b[31m7 \u001b[33m48 \u001b[0m https://guides.codepath.com/android/Defining-The-ActionBar\n",
      "\u001b[31m7 \u001b[33m283 \u001b[0m https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "\u001b[31m5 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/37096547\n",
      "\u001b[31m7 \u001b[33m179 \u001b[0m https://guides.codepath.com/android/using-the-recyclerview\n",
      "\u001b[31m3 \u001b[33m31 \u001b[0m https://stackoverflow.com/questions/47760861\n",
      "\u001b[31m13 \u001b[33m69 \u001b[0m https://developer.android.com/training/data-storage/sqlite\n",
      "\u001b[31m15 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/4015026\n",
      "\u001b[31m15 \u001b[33m81 \u001b[0m https://developer.android.com/guide/background/threading\n",
      "\u001b[31m6 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/2993085\n",
      "\u001b[31m11 \u001b[33m50 \u001b[0m https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "\u001b[31m5 \u001b[33m28 \u001b[0m https://stackoverflow.com/questions/23844667\n",
      "\u001b[31m5 \u001b[33m45 \u001b[0m https://github.com/flutter/flutter/issues/11392\n",
      "\u001b[31m4 \u001b[33m23 \u001b[0m https://stackoverflow.com/questions/29738510\n",
      "\u001b[31m5 \u001b[33m54 \u001b[0m https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "\u001b[31m4 \u001b[33m100 \u001b[0m https://stackoverflow.com/questions/2661536\n",
      "\u001b[31m9 \u001b[33m65 \u001b[0m https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "\u001b[31m5 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/24652078\n",
      "\u001b[31m8 \u001b[33m44 \u001b[0m https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/2883355\n",
      "\u001b[31m7 \u001b[33m24 \u001b[0m https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "\u001b[31m9 \u001b[33m51 \u001b[0m https://stackoverflow.com/questions/11064244\n",
      "\u001b[31m7 \u001b[33m138 \u001b[0m https://github.com/quarkusio/quarkus/issues/3954\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m16 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/29923376\n",
      "\u001b[31m4 \u001b[33m13 \u001b[0m https://github.com/google/dagger/issues/671\n",
      "\u001b[31m3 \u001b[33m19 \u001b[0m https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/36275986\n",
      "\u001b[31m42 \u001b[33m177 \u001b[0m https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "\u001b[31m9 \u001b[33m36 \u001b[0m https://developer.android.com/training/location/retrieve-current\n",
      "\u001b[31m5 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/46481789\n",
      "\u001b[31m22 \u001b[33m119 \u001b[0m https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "\u001b[31m15 \u001b[33m99 \u001b[0m https://javapapers.com/android/android-location-fused-provider\n",
      "\u001b[31m3 \u001b[33m14 \u001b[0m https://developer.android.com/training/keyboard-input/commands\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m3 \u001b[33m4 \u001b[0m https://stackoverflow.com/questions/40168601\n",
      "\u001b[31m20 \u001b[33m54 \u001b[0m https://developer.android.com/training/safetynet/recaptcha\n",
      "\u001b[31m11 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/27297067\n",
      "\u001b[31m8 \u001b[33m42 \u001b[0m https://stackoverflow.com/questions/30362446\n",
      "\u001b[31m10 \u001b[33m36 \u001b[0m https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "\u001b[31m5 \u001b[33m16 \u001b[0m https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "\u001b[31m5 \u001b[33m57 \u001b[0m https://github.com/signalapp/Signal-Android/issues/3376\n",
      "\u001b[31m5 \u001b[33m34 \u001b[0m https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "\u001b[31m22 \u001b[33m104 \u001b[0m https://developer.android.com/reference/org/json/JSONObject\n",
      "\u001b[31m8 \u001b[33m31 \u001b[0m https://guides.codepath.com/android/converting-json-to-models\n",
      "\u001b[31m7 \u001b[33m146 \u001b[0m https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "\u001b[31m5 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/24313539\n",
      "\u001b[31m12 \u001b[33m77 \u001b[0m https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "\u001b[31m6 \u001b[33m72 \u001b[0m https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "\u001b[31m5 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/14347588\n",
      "\u001b[31m31 \u001b[33m163 \u001b[0m https://guides.codepath.com/android/creating-and-using-fragments\n",
      "\u001b[31m4 \u001b[33m40 \u001b[0m https://developer.android.com/training/gestures/scale\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m6 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/10630373\n",
      "\u001b[31m4 \u001b[33m54 \u001b[0m https://developer.android.com/training/gestures/scroll\n",
      "\u001b[31m4 \u001b[33m16 \u001b[0m https://stackoverflow.com/questions/39588322\n",
      "\u001b[31m20 \u001b[33m196 \u001b[0m https://developer.android.com/training/dependency-injection/dagger-android\n",
      "\u001b[31m6 \u001b[33m44 \u001b[0m https://stackoverflow.com/questions/57235136\n",
      "\u001b[31m24 \u001b[33m121 \u001b[0m https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "Sample entry from data:\n",
      "{\n",
      "    \"category_index\": 1,\n",
      "    \"question\": \"Permission Denial when trying to access contacts in Android\",\n",
      "    \"source\": \"https://developer.android.com/training/permissions/requesting\",\n",
      "    \"text\": \"Every Android app runs in a limited-access sandbox.\",\n",
      "    \"weights\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# @title Import data as JSON\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from Levenshtein import ratio\n",
    "from colorama import Fore, Style\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.level = logging.DEBUG\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "from ds_android import get_input_for_BERT\n",
    "\n",
    "raw_data = get_input_for_BERT()\n",
    "\n",
    "print('Sample entry from data:')\n",
    "print(json.dumps(raw_data[0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b_GXczz9CGs",
    "outputId": "2f6b91cb-8396-41af-e299-61360817d8b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution\n",
      "\n",
      "not-relevant -- 87%\n",
      "RELEVANT ------ 13%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "cnt = Counter([d['category_index'] for d in raw_data])\n",
    "\n",
    "total = sum(cnt.values())\n",
    "\n",
    "labels_cnt = [cnt[0] / float(total), cnt[1] / float(total)]\n",
    "print('label distribution')\n",
    "print('')\n",
    "print('not-relevant -- {:.0f}%'.format(labels_cnt[0] * 100))\n",
    "print('RELEVANT ------ {:.0f}%'.format(labels_cnt[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seframes = {}\n",
    "with open('seframes.json') as input_file:\n",
    "    seframes = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_meaningful_frame(text):    \n",
    "    meaning_frames = [\n",
    "        'Temporal_collocation', 'Execution', 'Using', 'Intentionally_act',\n",
    "        'Being_obligated', 'Likelihood', 'Causation', 'Required_event',\n",
    "        'Desiring', 'Awareness', 'Grasp', 'Attempt'\n",
    "    ]\n",
    "    \n",
    "    if text in seframes:\n",
    "        text_labels = seframes[text]\n",
    "        if any([elem in meaning_frames for elem in text_labels]):\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLoading data from cache\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fold_results = dict()\n",
    "if os.path.isfile('bert_ds_android_pyramid.json'):\n",
    "    logger.info(Fore.YELLOW + \"Loading data from cache\" + Style.RESET_ALL)\n",
    "    with open('bert_ds_android_pyramid.json') as input_file:\n",
    "        fold_results = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1l5DIHP_FUb",
    "outputId": "7f1648d0-2582-43a8-c1fc-50095d78892b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n"
     ]
    }
   ],
   "source": [
    "# @title Set environment variables\n",
    "\n",
    "model_id = 'bert-base-uncased'\n",
    "# model_id = 'distilbert-base-uncased'\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "USE_TPU = False\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "# @title Initialize TPU Strategy\n",
    "if USE_TPU:\n",
    "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
    "    tf.contrib.distribute.initialize_tpu_system(resolver)\n",
    "    strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
    "\n",
    "# sklearn libs\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "# Hugging face imports\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification, TFBertForSequenceClassification\n",
    "from transformers import TFDistilBertModel, DistilBertConfig\n",
    "from transformers import DistilBertTokenizerFast, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Model parameters\n",
    "\n",
    "# Bert Model Constants\n",
    "SEQ_LEN = 64 # 128\n",
    "BATCH_SIZE = 64 # 64 32 larger batch size causes OOM errors\n",
    "EPOCHS = 10 # 3 4\n",
    "LR = 1e-5 # 2e-5\n",
    "\n",
    "# 3e-4, 1e-4, 5e-5, 3e-5\n",
    "# My own constants\n",
    "# USE_FRAME_FILTERING = False\n",
    "# UNDERSAMPLING = True\n",
    "# N_UNDERSAMPLING = 2 # ratio of how many samples from 0-class, to 1-class, e.g.: 2:1\n",
    "# USE_DS_SYNTHETIC = False\n",
    "\n",
    "USE_FRAME_FILTERING = False\n",
    "UNDERSAMPLING = True\n",
    "N_UNDERSAMPLING = 2 # ratio of how many samples from 0-class, to 1-class, e.g.: 2:1\n",
    "USE_DS_SYNTHETIC = False\n",
    "MIN_W = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1T9xPdXp_kt9"
   },
   "outputs": [],
   "source": [
    "# @title JSON to dataframe helper functions\n",
    "def undersample_df(df, n_times=3):\n",
    "    class_0,class_1 = df.category_index.value_counts()\n",
    "    c0 = df[df['category_index'] == 0]\n",
    "    c1 = df[df['category_index'] == 1]\n",
    "    df_0 = c0.sample(int(n_times * class_1))\n",
    "    \n",
    "    undersampled_df = pd.concat([df_0, c1],axis=0)\n",
    "    return undersampled_df\n",
    "\n",
    "def get_ds_synthetic_data(min_w=MIN_W):\n",
    "    short_task = {\n",
    "      \"bugzilla\": \"\"\"How to query bugs using the custom fields with the Bugzilla REST API?\"\"\",\n",
    "      \"databases\": \"\"\"Which technology should be adopted for the database layer abstraction: Object/Relational Mapping (ORM) or a Java Database Connectivity API (JDBC)?\"\"\",\n",
    "      \"gpmdpu\": \"\"\"Can I bind the cmd key to the GPMDPU shortcuts?\"\"\",\n",
    "      \"lucene\": \"\"\"How does Lucene compute similarity scores for the BM25 similarity?\"\"\",\n",
    "      \"networking\": \"\"\"Which technology should be adopted for the notification system, Server-Sent Events (SSE) or WebSockets?\"\"\",\n",
    "    }\n",
    "\n",
    "    with open('relevance_corpus.json') as ipf:\n",
    "        aux = json.load(ipf)\n",
    "        raw_data = defaultdict(list)\n",
    "        for d in aux:\n",
    "            if d['task'] == 'yargs':\n",
    "                continue\n",
    "\n",
    "            raw_data['text'].append(d['text'])\n",
    "            raw_data['question'].append(short_task[d['task']])\n",
    "            raw_data['source'].append(d['source'])\n",
    "            raw_data['category_index'].append(1 if d['weight'] > min_w else 0)\n",
    "            raw_data['weights'].append(d['weight'] if d['weight'] > min_w else 0)\n",
    " \n",
    "        data = pd.DataFrame.from_dict(raw_data)\n",
    "        data = undersample_df(data, n_times=1)\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "      \n",
    "    return data\n",
    "\n",
    "def get_class_weights(y, smooth_factor=0, upper_bound=5.0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    clazz = {cls: float(majority / count) for cls, count in counter.items()}\n",
    "    result = {}\n",
    "    for key, value in clazz.items():\n",
    "        if value > upper_bound:\n",
    "            value = upper_bound\n",
    "        \n",
    "        result[key] = value\n",
    "    return result\n",
    "\n",
    "def add_raw_data(result, data):\n",
    "    s = data['source']\n",
    "    if 'docs.oracle' in s or 'developer.android' in s:\n",
    "        source_type = 'api'\n",
    "    elif 'stackoverflow.com' in s:\n",
    "        source_type = 'so'\n",
    "    elif 'github.com' in s:\n",
    "        source_type = 'git'\n",
    "    else:\n",
    "        source_type = 'misc'\n",
    "    pyramid = 1 if data['weights'] > 1 else 0\n",
    "    \n",
    "    result['text'].append(data['text'])\n",
    "    result['question'].append(data['question'])\n",
    "    result['source'].append(data['source'])\n",
    "    result['category_index'].append(pyramid)\n",
    "    result['weights'].append(data['weights'])\n",
    "    result['source_type'].append(source_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837,
     "referenced_widgets": [
      "8c7cf993674145ffb7bb876e5591f6ca",
      "67f208ba489343dfa195c1dd915f3efe",
      "35a9eeb0acdb44738a6ad7fbf6d99b2b",
      "153c3ed5c6314a49a5a37ad976417142",
      "82b7fc20b50c44b2bd84b3bf882cdd43",
      "16b6cfa829ad43778c079452df231a3d",
      "a2a36eb594654c65acd584d9d4ebea20",
      "3950e2a7832c4dce8fd8209d6322a1f7",
      "d32667132d604faeb419bbf9851c1bd8",
      "262cc50dd08f49f78b781c2ce96a4ad7",
      "f305b344487a4b598a7d41b007e49abd",
      "c18a3a9fc6d54b9f848e4454e1e36c21",
      "a8fd8b38a6b84be7b83b2f4df590fada",
      "5c6bfb038756422bb00be1349db7750b",
      "6cf29b5d508a4e2082751ccc7fa2f625",
      "c4c410ab0c994a229a49b8baee221de4",
      "9e99fb1211ba43459ee78dd64ab8c30e",
      "71a15c5a038f451f8ee64ce046488f71",
      "c586016d3b594c6299cab2384f4c10aa",
      "d03c894896ad4ed6b48f19a70fbdf2af",
      "3ccd384305c44ee3a86f47a2b994fbf9",
      "23531989ef014d7db16b220bb807c8fd",
      "e0e88103f9684ffdb957357222bbaaf7",
      "c5b9bf1f3ae343ce97982c7802cfdc94",
      "a66943be0fc0423880cb2bd63a1ea2d2",
      "8c2b37becdef45bba205dfb20f8e37b2",
      "baffabe6cabf48f5b0b6523ea92aee78",
      "997b8c940317448c9409a2dee15fc519",
      "b12b35cc52454a249c97f695409d24ce",
      "b6d9e21208294428a3f5572bbbd8b0b9",
      "d15e557fc621427a8295eecdc1e781a8",
      "b4276b6a5eac4023955218db6f78c84a",
      "c4b0a1b67d304afda6ee4e52095584cc",
      "901557318fb947dfa082f0cbf2d7365b",
      "0efe94b613f44c029f2e9bd05696ad32",
      "5a38bc7017d545e2b44ad6ab0b2d937b",
      "b3db733aacf94a3c94519d70a7a56d7a",
      "394b7988d36849b7b2c82872ae8d489d",
      "d3e13535de4b44bb9139c3911684cee8",
      "6ccdfb754c12418c9438ac218a172e63",
      "929799bd24fb411bb4686988f2ae8996",
      "4bd0f4c575714ad7848e818a576ee00a",
      "0466163ff4a945798423387d1ac900c8",
      "17cfaa41c53842618c728987a81a44da"
     ]
    },
    "id": "r_y7xwmxAT39",
    "outputId": "ba094ca3-4ef3-41c0-da55-0e07626c7fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# @title Tokenizer\n",
    "\n",
    "print(model_id)\n",
    "if model_id == 'distilbert-base-uncased':\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)\n",
    "else:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HdAYw7lBAmlO"
   },
   "outputs": [],
   "source": [
    "# @title data encoder\n",
    "\n",
    "def _encode(tokenizer, dataframe, max_length=SEQ_LEN):\n",
    "    \n",
    "    seq_a = dataframe['text'].tolist()\n",
    "    seq_b = dataframe['question'].tolist()\n",
    "    \n",
    "    return tokenizer(seq_a, seq_b, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "def to_one_hot_encoding(data, nb_classes = 2):\n",
    "    targets = np.array([data]).reshape(-1)\n",
    "    one_hot_targets = np.eye(nb_classes)[targets]\n",
    "    return one_hot_targets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "y-5ROuqDBU9X"
   },
   "outputs": [],
   "source": [
    "# @title Metrics & Logging functions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "recommendation_metrics = defaultdict(list)\n",
    "prediction_metrics = defaultdict(list)\n",
    "api_metrics = defaultdict(list)\n",
    "so_metrics = defaultdict(list)\n",
    "git_metrics = defaultdict(list)\n",
    "misc_metrics = defaultdict(list)\n",
    "\n",
    "classification_report_lst = []\n",
    "log_examples_lst = []\n",
    "source_lst = []\n",
    "venn_diagram_set = []\n",
    "\n",
    "def aggregate_macro_metrics(store_at, precision, recall, fscore):   \n",
    "    store_at['precision'].append(precision)\n",
    "    store_at['recall'].append(recall)\n",
    "    store_at['fscore'].append(fscore)\n",
    "    \n",
    "    \n",
    "def aggregate_macro_source_metrics(precision, recall, fscore, source):\n",
    "    s = source\n",
    "    if 'docs.oracle' in s or 'developer.android' in s:\n",
    "        aggregate_macro_metrics(api_metrics, precision, recall, fscore)\n",
    "    elif 'stackoverflow.com' in s:\n",
    "        aggregate_macro_metrics(so_metrics, precision, recall, fscore)\n",
    "    elif 'github.com' in s:\n",
    "        aggregate_macro_metrics(git_metrics, precision, recall, fscore)        \n",
    "    elif  'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
    "        aggregate_macro_metrics(misc_metrics, precision, recall, fscore)\n",
    "    \n",
    "\n",
    "def aggregate_recommendation_metrics(store_at, k, precision_at_k, pyramid_precision_at_k):\n",
    "    store_at['k'].append(k)\n",
    "    store_at['precision'].append(precision_at_k)\n",
    "    store_at['âˆ† precision'].append(pyramid_precision_at_k)\n",
    "    \n",
    "def aggregate_report_metrics(clz_report):\n",
    "    relevant_label = str(1)\n",
    "    if relevant_label in clz_report:\n",
    "        for _key in ['precision', 'recall']:\n",
    "            if _key in clz_report[relevant_label]:\n",
    "                clz_report_lst[_key].append(clz_report[relevant_label][_key])    \n",
    "                \n",
    "def log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10):\n",
    "    # get the predicted prob at every index\n",
    "    idx_probs = [(idx, y_predict[idx], y_probs[idx]) for idx, _ in enumerate(y_predict)]\n",
    "    \n",
    "    # filter probs for all indexes predicted as relevant  \n",
    "    idx_probs = list(filter(lambda k: k[1] == 1, idx_probs))\n",
    "    \n",
    "    most_probable = sorted(idx_probs, key=lambda i: i[2], reverse=True)\n",
    "    \n",
    "    result = [idx for idx, _, _ in most_probable][:k]\n",
    "    \n",
    "    for idx in result:\n",
    "        log_examples_lst.append((\n",
    "            source, \n",
    "            task_title,\n",
    "            pweights[idx],\n",
    "            y_predict[idx],\n",
    "            y_probs[idx],\n",
    "            text[idx]\n",
    "        ))\n",
    "        \n",
    "def log_venn_diagram(y_true, y_predicted, text):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        for _true, _predict, _t in zip(y_true, y_predicted, text):\n",
    "            if _true == 1 and _predict == 1:\n",
    "                cnt += 1\n",
    "                venn_diagram_set.append(_t)\n",
    "    except Exception as ex:\n",
    "        logger.info(str(ex))\n",
    "    logger.info(Fore.RED + str(cnt) + Style.RESET_ALL + \" entries logged\")\n",
    "\n",
    "    \n",
    "def avg_macro_metric_for(data):\n",
    "    __precision = data['precision']\n",
    "    __recall = data['recall']\n",
    "    __fscore = data['fscore']\n",
    "\n",
    "    return np.mean(__precision), np.mean(__recall), np.mean(__fscore)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4E1IN6UoPq96"
   },
   "outputs": [],
   "source": [
    "#@title Training procedures\n",
    "\n",
    "def get_train_val_test(task_uid, size=0.9, undersample=False, aug=True, undersample_n=3):\n",
    "    if not isinstance(task_uid, list):\n",
    "        task_uid = [task_uid]\n",
    "        \n",
    "    train_data_raw = defaultdict(list)\n",
    "    test_data_raw = defaultdict(list)\n",
    "    \n",
    "    for _data in tqdm(CORPUS):\n",
    "        if _data['question'] in task_uid:\n",
    "            add_raw_data(test_data_raw, _data)\n",
    "        else:\n",
    "            add_raw_data(train_data_raw, _data)\n",
    "    \n",
    "    train_val = pd.DataFrame.from_dict(train_data_raw)\n",
    "    test = pd.DataFrame.from_dict(test_data_raw)\n",
    "    \n",
    "    # https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "    #  randomize rows....    \n",
    "    train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "    test = test.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    if undersample:\n",
    "        train_val = undersample_df(train_val, n_times=undersample_n)\n",
    "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    if aug:\n",
    "        train_val = pd.concat([train_val, get_ds_synthetic_data()],axis=0)\n",
    "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    weights = get_class_weights(train_val['category_index'].tolist())\n",
    "    \n",
    "    train, val = train_test_split(\n",
    "        train_val, \n",
    "        stratify=train_val['category_index'].tolist(), \n",
    "        train_size=size\n",
    "    )\n",
    "    \n",
    "    return train, val, test, weights        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_predictions(task_title, text, y_predict, y_probs, relevant_class=1):\n",
    "    result = []\n",
    "    \n",
    "    for _t, _y, _prob in zip(text, y_predict, y_probs):\n",
    "        if _y == relevant_class:\n",
    "            if has_meaningful_frame(_t):\n",
    "                result.append(_y)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        else:\n",
    "            result.append(_y)\n",
    "    \n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vFePvH5vBVA7"
   },
   "outputs": [],
   "source": [
    "# @title Testing procedures\n",
    "\n",
    "# https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7\n",
    "def eval_model(model, test_data):\n",
    "    preds = model.predict(test_data.batch(1)).logits  \n",
    "    \n",
    "    #transform to array with probabilities\n",
    "    res = tf.nn.softmax(preds, axis=1).numpy()      \n",
    "\n",
    "    return res.argmax(axis=-1), res[:, 1]\n",
    "\n",
    "def test_model(source, df_test, model, tokenizer, pos_filter=False):\n",
    "    \n",
    "    df_source = df_test[df_test[\"source\"] == source]   \n",
    "    task_title = df_source['question'].tolist()[0]\n",
    "    text = df_source['text'].tolist()\n",
    "    pweights = df_source['weights'].tolist()\n",
    "    \n",
    "    # Encode X_test\n",
    "    test_encodings = _encode(tokenizer, df_source)\n",
    "    test_labels = df_source['category_index'].tolist()\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        dict(test_encodings),\n",
    "        test_labels\n",
    "    ))\n",
    "    \n",
    "    y_true = [y.numpy() for x, y in test_dataset]\n",
    "    \n",
    "    # <= 0  means that an artifact has no relevant information highlighted \n",
    "    # by two or more annotators. these artifacts are ignored\n",
    "    if len(list(filter(lambda k: k == 1, y_true))) > 0:\n",
    "        y_predict, y_probs = eval_model(model, test_dataset)\n",
    "\n",
    "        if pos_filter:\n",
    "            y_predict = update_predictions(task_title, text, y_predict, y_probs)\n",
    "\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_predict)\n",
    "        macro_f1 = f1_score(y_true, y_predict, average='macro')\n",
    "\n",
    "        classification_report_lst.append(classification_report(y_true, y_predict))\n",
    "        aggregate_report_metrics(classification_report(y_true, y_predict, output_dict=True))\n",
    "\n",
    "\n",
    "        logger.info(\"-\" * 20)    \n",
    "\n",
    "        logger.info(\"Y\")\n",
    "        logger.info(\"[0s] {} [1s] {}\".format(\n",
    "            len(list(filter(lambda k: k== 0, y_true))),\n",
    "            len(list(filter(lambda k: k== 1, y_true)))\n",
    "        ))\n",
    "\n",
    "\n",
    "        logger.info(\"predicted\")\n",
    "        logger.info(\"[0s] {} [1s] {}\".format(\n",
    "            len(list(filter(lambda k: k== 0, y_predict))),\n",
    "            len(list(filter(lambda k: k== 1, y_predict)))\n",
    "        ))\n",
    "\n",
    "        logger.info(\"-\" * 20)\n",
    "\n",
    "        logger.info(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "        logger.info(\"macro_f1: {:.4f}\".format(macro_f1))\n",
    "\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(y_true, y_predict, average='macro')\n",
    "\n",
    "        aggregate_macro_metrics(prediction_metrics, precision, recall, fscore)\n",
    "        aggregate_macro_source_metrics(precision, recall, fscore, source)\n",
    "\n",
    "        logger.info(\"Precision: {:.4f}\".format(precision))\n",
    "        logger.info(\"Recall: {:.4f}\".format(recall))\n",
    "        logger.info(\"F1: {:.4f}\".format(fscore))\n",
    "\n",
    "        log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10)\n",
    "        log_venn_diagram(y_true, y_predict, text)\n",
    "        source_lst.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_idx_fold_results(idx_split, store_at):\n",
    "    if idx_split not in store_at:\n",
    "        store_at[idx_split] = dict()\n",
    "        store_at[idx_split]['run_cnt'] = 0\n",
    "        store_at[idx_split]['overall'] = defaultdict(list)\n",
    "        store_at[idx_split]['api'] = defaultdict(list)\n",
    "        store_at[idx_split]['so'] = defaultdict(list)\n",
    "        store_at[idx_split]['git'] = defaultdict(list)\n",
    "        store_at[idx_split]['misc'] = defaultdict(list)\n",
    "    \n",
    "    store_at[idx_split]['run_cnt'] += 1\n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "    store_at[idx_split]['overall']['precision'].append(_precision)\n",
    "    store_at[idx_split]['overall']['recall'].append(_recall)\n",
    "    store_at[idx_split]['overall']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(api_metrics)\n",
    "    store_at[idx_split]['api']['precision'].append(_precision)\n",
    "    store_at[idx_split]['api']['recall'].append(_recall)\n",
    "    store_at[idx_split]['api']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(so_metrics)\n",
    "    store_at[idx_split]['so']['precision'].append(_precision)\n",
    "    store_at[idx_split]['so']['recall'].append(_recall)\n",
    "    store_at[idx_split]['so']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(git_metrics)\n",
    "    store_at[idx_split]['git']['precision'].append(_precision)\n",
    "    store_at[idx_split]['git']['recall'].append(_recall)\n",
    "    store_at[idx_split]['git']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(misc_metrics)\n",
    "    store_at[idx_split]['misc']['precision'].append(_precision)\n",
    "    store_at[idx_split]['misc']['recall'].append(_recall)\n",
    "    store_at[idx_split]['misc']['fscore'].append(_f1score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TFBertForSequenceClassification.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "03ddd131c9f0446eb83bb6dabee9a832",
      "3518f71b0e4540be8b17a3fe72182cb4",
      "a5ccb838d3704546937e925e456830be",
      "8181fd24b3624c1b9c6a9d0302f43a56",
      "f02cf8090f8d463eb7eeb59743a87276",
      "c9ef3ce0ace649c5a53e2244ba0dbb32",
      "702a74b6e6e44d6b8ad68347f1a4b5fb",
      "3d84c022c44141268ef2c8d5e0190404",
      "40c212c9b352401697860624a6c54b1c",
      "1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "911177bb86c749a0bd774cd3b7f9d302"
     ]
    },
    "id": "1oZGDUKnB1gw",
    "outputId": "21690a29-4add-4780-f87f-fa497b87d5e1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n",
      "Hide MarkerView when nothing selected\n",
      "How to check programmatically whether app is running in debug mode or not?\n",
      "JSONObject parse dictionary objects\n",
      "Want to add drawable icons insteadof colorful dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 759670.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    507\n",
      "1    254\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    706\n",
      "1     29\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2af9643253d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2af9643253d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9836 - sparse_categorical_accuracy: 0.6426The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66729, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 10s 801ms/step - loss: 0.9836 - sparse_categorical_accuracy: 0.6426 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.6471\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9189 - sparse_categorical_accuracy: 0.5348\n",
      "Epoch 00002: val_loss did not improve from 0.66729\n",
      "12/12 [==============================] - 3s 243ms/step - loss: 0.9189 - sparse_categorical_accuracy: 0.5348 - val_loss: 0.6785 - val_sparse_categorical_accuracy: 0.5765\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8857 - sparse_categorical_accuracy: 0.5650\n",
      "Epoch 00003: val_loss improved from 0.66729 to 0.62784, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 8s 689ms/step - loss: 0.8857 - sparse_categorical_accuracy: 0.5650 - val_loss: 0.6278 - val_sparse_categorical_accuracy: 0.7059\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8352 - sparse_categorical_accuracy: 0.6807\n",
      "Epoch 00004: val_loss did not improve from 0.62784\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 0.8352 - sparse_categorical_accuracy: 0.6807 - val_loss: 0.6306 - val_sparse_categorical_accuracy: 0.7176\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7815 - sparse_categorical_accuracy: 0.7083\n",
      "Epoch 00005: val_loss improved from 0.62784 to 0.56208, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 542ms/step - loss: 0.7815 - sparse_categorical_accuracy: 0.7083 - val_loss: 0.5621 - val_sparse_categorical_accuracy: 0.7529\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7355 - sparse_categorical_accuracy: 0.7608\n",
      "Epoch 00006: val_loss did not improve from 0.56208\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 0.7355 - sparse_categorical_accuracy: 0.7608 - val_loss: 0.5630 - val_sparse_categorical_accuracy: 0.7294\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6521 - sparse_categorical_accuracy: 0.7950\n",
      "Epoch 00007: val_loss improved from 0.56208 to 0.51157, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 552ms/step - loss: 0.6521 - sparse_categorical_accuracy: 0.7950 - val_loss: 0.5116 - val_sparse_categorical_accuracy: 0.7882\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6209 - sparse_categorical_accuracy: 0.8239\n",
      "Epoch 00008: val_loss did not improve from 0.51157\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 0.6209 - sparse_categorical_accuracy: 0.8239 - val_loss: 0.5785 - val_sparse_categorical_accuracy: 0.7294\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5439 - sparse_categorical_accuracy: 0.8515\n",
      "Epoch 00009: val_loss did not improve from 0.51157\n",
      "12/12 [==============================] - 3s 246ms/step - loss: 0.5439 - sparse_categorical_accuracy: 0.8515 - val_loss: 0.5228 - val_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4732 - sparse_categorical_accuracy: 0.8817\n",
      "Epoch 00010: val_loss did not improve from 0.51157\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 0.4732 - sparse_categorical_accuracy: 0.8817 - val_loss: 0.5205 - val_sparse_categorical_accuracy: 0.7765\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/23844667\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 24 [1s] 4\n",
      "predicted\n",
      "[0s] 26 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.7857\n",
      "macro_f1: 0.4400\n",
      "Precision: 0.4231\n",
      "Recall: 0.4583\n",
      "F1: 0.4400\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 87 [1s] 17\n",
      "predicted\n",
      "[0s] 100 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.7981\n",
      "macro_f1: 0.4439\n",
      "Precision: 0.4150\n",
      "Recall: 0.4770\n",
      "F1: 0.4439\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "--------------------\n",
      "Y\n",
      "[0s] 31 [1s] 5\n",
      "predicted\n",
      "[0s] 35 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.8333\n",
      "macro_f1: 0.4545\n",
      "Precision: 0.4286\n",
      "Recall: 0.4839\n",
      "F1: 0.4545\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 2\n",
      "predicted\n",
      "[0s] 24 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.8387\n",
      "macro_f1: 0.6751\n",
      "Precision: 0.6429\n",
      "Recall: 0.9138\n",
      "F1: 0.6751\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "https://stackoverflow.com/questions/33241952\n",
      "https://stackoverflow.com/questions/37096547\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 16 [1s] 1\n",
      "predicted\n",
      "[0s] 16 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.8824\n",
      "macro_f1: 0.4688\n",
      "Precision: 0.4688\n",
      "Recall: 0.4688\n",
      "F1: 0.4688\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.476\u001b[0m\n",
      "recall:    \u001b[31m0.560\u001b[0m\n",
      "f1-score:  \u001b[31m0.496\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: \u001b[31m0.415\u001b[0m\n",
      "recall:    \u001b[31m0.477\u001b[0m\n",
      "f1-score:  \u001b[31m0.444\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.446\u001b[0m\n",
      "recall:    \u001b[31m0.464\u001b[0m\n",
      "f1-score:  \u001b[31m0.454\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.429\u001b[0m\n",
      "recall:    \u001b[31m0.484\u001b[0m\n",
      "f1-score:  \u001b[31m0.455\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.643\u001b[0m\n",
      "recall:    \u001b[31m0.914\u001b[0m\n",
      "f1-score:  \u001b[31m0.675\u001b[0m\n",
      "next 1\n",
      "\n",
      "\u001b[31mFold 1\u001b[0m\n",
      " height must be > 0\n",
      "Write and Read a json data to internal storage android\n",
      "Android PDF Rendering\n",
      "How can I hide a fragment on start of my MainActivity( or the application)?\n",
      "polymorphic deserialization of JSON with jackson, property type becomes &quot;null&quot;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 834539.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    491\n",
      "1    246\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    722\n",
      "1     38\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9253 - sparse_categorical_accuracy: 0.4844The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68416, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 12s 997ms/step - loss: 0.9253 - sparse_categorical_accuracy: 0.4844 - val_loss: 0.6842 - val_sparse_categorical_accuracy: 0.5610\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8935 - sparse_categorical_accuracy: 0.6377\n",
      "Epoch 00002: val_loss improved from 0.68416 to 0.66902, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 530ms/step - loss: 0.8935 - sparse_categorical_accuracy: 0.6377 - val_loss: 0.6690 - val_sparse_categorical_accuracy: 0.5488\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8416 - sparse_categorical_accuracy: 0.6825\n",
      "Epoch 00003: val_loss improved from 0.66902 to 0.63517, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 542ms/step - loss: 0.8416 - sparse_categorical_accuracy: 0.6825 - val_loss: 0.6352 - val_sparse_categorical_accuracy: 0.5976\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7669 - sparse_categorical_accuracy: 0.7422\n",
      "Epoch 00004: val_loss improved from 0.63517 to 0.58523, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 544ms/step - loss: 0.7669 - sparse_categorical_accuracy: 0.7422 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.7073\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6801 - sparse_categorical_accuracy: 0.7829\n",
      "Epoch 00005: val_loss improved from 0.58523 to 0.58255, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 570ms/step - loss: 0.6801 - sparse_categorical_accuracy: 0.7829 - val_loss: 0.5826 - val_sparse_categorical_accuracy: 0.6829\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5949 - sparse_categorical_accuracy: 0.8046\n",
      "Epoch 00006: val_loss did not improve from 0.58255\n",
      "12/12 [==============================] - 3s 237ms/step - loss: 0.5949 - sparse_categorical_accuracy: 0.8046 - val_loss: 0.6088 - val_sparse_categorical_accuracy: 0.6707\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5006 - sparse_categorical_accuracy: 0.8562\n",
      "Epoch 00007: val_loss did not improve from 0.58255\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 0.5006 - sparse_categorical_accuracy: 0.8562 - val_loss: 0.6195 - val_sparse_categorical_accuracy: 0.6951\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4358 - sparse_categorical_accuracy: 0.8725\n",
      "Epoch 00008: val_loss did not improve from 0.58255\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 0.4358 - sparse_categorical_accuracy: 0.8725 - val_loss: 0.6042 - val_sparse_categorical_accuracy: 0.7317\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3793 - sparse_categorical_accuracy: 0.8942Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.58255\n",
      "12/12 [==============================] - 3s 253ms/step - loss: 0.3793 - sparse_categorical_accuracy: 0.8942 - val_loss: 0.6058 - val_sparse_categorical_accuracy: 0.7073\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "https://guides.codepath.com/android/creating-and-using-fragments\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 153 [1s] 10\n",
      "predicted\n",
      "[0s] 75 [1s] 88\n",
      "--------------------\n",
      "Accuracy: 0.4724\n",
      "macro_f1: 0.3726\n",
      "Precision: 0.5074\n",
      "Recall: 0.5320\n",
      "F1: 0.3726\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "https://stackoverflow.com/questions/2883355\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 22 [1s] 2\n",
      "predicted\n",
      "[0s] 12 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.5000\n",
      "macro_f1: 0.3950\n",
      "Precision: 0.5000\n",
      "Recall: 0.5000\n",
      "F1: 0.3950\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 8\n",
      "predicted\n",
      "[0s] 20 [1s] 24\n",
      "--------------------\n",
      "Accuracy: 0.6364\n",
      "macro_f1: 0.6071\n",
      "Precision: 0.6667\n",
      "Recall: 0.7778\n",
      "F1: 0.6071\n",
      "\u001b[31m8\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/14347588\n",
      "--------------------\n",
      "Y\n",
      "[0s] 21 [1s] 4\n",
      "predicted\n",
      "[0s] 14 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.6400\n",
      "macro_f1: 0.5714\n",
      "Precision: 0.6006\n",
      "Recall: 0.6845\n",
      "F1: 0.5714\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 3\n",
      "predicted\n",
      "[0s] 3 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.3750\n",
      "macro_f1: 0.3750\n",
      "Precision: 0.6154\n",
      "Recall: 0.6154\n",
      "F1: 0.3750\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30362446\n",
      "--------------------\n",
      "Y\n",
      "[0s] 39 [1s] 3\n",
      "predicted\n",
      "[0s] 23 [1s] 19\n",
      "--------------------\n",
      "Accuracy: 0.6190\n",
      "macro_f1: 0.5073\n",
      "Precision: 0.5789\n",
      "Recall: 0.7949\n",
      "F1: 0.5073\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 2\n",
      "predicted\n",
      "[0s] 23 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.6944\n",
      "macro_f1: 0.5368\n",
      "Precision: 0.5769\n",
      "Recall: 0.8382\n",
      "F1: 0.5368\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 22 [1s] 2\n",
      "predicted\n",
      "[0s] 3 [1s] 21\n",
      "--------------------\n",
      "Accuracy: 0.2083\n",
      "macro_f1: 0.2070\n",
      "Precision: 0.5476\n",
      "Recall: 0.5682\n",
      "F1: 0.2070\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/40168601\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 2 [1s] 2\n",
      "predicted\n",
      "[0s] 2 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 1.0000\n",
      "macro_f1: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1: 1.0000\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/38980595\n",
      "--------------------\n",
      "Y\n",
      "[0s] 3 [1s] 2\n",
      "predicted\n",
      "[0s] 4 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.8000\n",
      "macro_f1: 0.7619\n",
      "Precision: 0.8750\n",
      "Recall: 0.7500\n",
      "F1: 0.7619\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.647\u001b[0m\n",
      "recall:    \u001b[31m0.706\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score:  \u001b[31m0.533\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.667\u001b[0m\n",
      "recall:    \u001b[31m0.778\u001b[0m\n",
      "f1-score:  \u001b[31m0.607\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.711\u001b[0m\n",
      "recall:    \u001b[31m0.746\u001b[0m\n",
      "f1-score:  \u001b[31m0.647\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.577\u001b[0m\n",
      "recall:    \u001b[31m0.838\u001b[0m\n",
      "f1-score:  \u001b[31m0.537\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.557\u001b[0m\n",
      "recall:    \u001b[31m0.572\u001b[0m\n",
      "f1-score:  \u001b[31m0.318\u001b[0m\n",
      "next 2\n",
      "\n",
      "\u001b[31mFold 2\u001b[0m\n",
      "How to Integrate reCAPTCHA 2.0 in Android\n",
      "How can I make this rxjava zip to run in parallel?\n",
      "Permission Denial when trying to access contacts in Android\n",
      "keyUp called when key is still pressed\n",
      "Donâ€™t leak MockWebServer ports across tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 837823.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    462\n",
      "1    231\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1304\n",
      "1      54\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9010 - sparse_categorical_accuracy: 0.6147The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67115, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 9s 814ms/step - loss: 0.9010 - sparse_categorical_accuracy: 0.6147 - val_loss: 0.6712 - val_sparse_categorical_accuracy: 0.5641\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8751 - sparse_categorical_accuracy: 0.6378\n",
      "Epoch 00002: val_loss improved from 0.67115 to 0.64512, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 7s 649ms/step - loss: 0.8751 - sparse_categorical_accuracy: 0.6378 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.6282\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8281 - sparse_categorical_accuracy: 0.6912\n",
      "Epoch 00003: val_loss improved from 0.64512 to 0.60525, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 6s 569ms/step - loss: 0.8281 - sparse_categorical_accuracy: 0.6912 - val_loss: 0.6052 - val_sparse_categorical_accuracy: 0.6282\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7628 - sparse_categorical_accuracy: 0.7056\n",
      "Epoch 00004: val_loss improved from 0.60525 to 0.57401, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 6s 578ms/step - loss: 0.7628 - sparse_categorical_accuracy: 0.7056 - val_loss: 0.5740 - val_sparse_categorical_accuracy: 0.6795\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6924 - sparse_categorical_accuracy: 0.7605\n",
      "Epoch 00005: val_loss improved from 0.57401 to 0.55573, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 7s 606ms/step - loss: 0.6924 - sparse_categorical_accuracy: 0.7605 - val_loss: 0.5557 - val_sparse_categorical_accuracy: 0.7179\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6230 - sparse_categorical_accuracy: 0.7937\n",
      "Epoch 00006: val_loss improved from 0.55573 to 0.53635, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 6s 583ms/step - loss: 0.6230 - sparse_categorical_accuracy: 0.7937 - val_loss: 0.5363 - val_sparse_categorical_accuracy: 0.7564\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5475 - sparse_categorical_accuracy: 0.8225\n",
      "Epoch 00007: val_loss improved from 0.53635 to 0.50962, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 7s 655ms/step - loss: 0.5475 - sparse_categorical_accuracy: 0.8225 - val_loss: 0.5096 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5109 - sparse_categorical_accuracy: 0.8341\n",
      "Epoch 00008: val_loss improved from 0.50962 to 0.49289, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 6s 583ms/step - loss: 0.5109 - sparse_categorical_accuracy: 0.8341 - val_loss: 0.4929 - val_sparse_categorical_accuracy: 0.7949\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4216 - sparse_categorical_accuracy: 0.8658\n",
      "Epoch 00009: val_loss improved from 0.49289 to 0.48317, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "11/11 [==============================] - 10s 908ms/step - loss: 0.4216 - sparse_categorical_accuracy: 0.8658 - val_loss: 0.4832 - val_sparse_categorical_accuracy: 0.8333\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3688 - sparse_categorical_accuracy: 0.9105\n",
      "Epoch 00010: val_loss did not improve from 0.48317\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 0.3688 - sparse_categorical_accuracy: 0.9105 - val_loss: 0.5131 - val_sparse_categorical_accuracy: 0.8333\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "https://stackoverflow.com/questions/35357919\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 49 [1s] 4\n",
      "predicted\n",
      "[0s] 39 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.6604\n",
      "macro_f1: 0.3977\n",
      "Precision: 0.4487\n",
      "Recall: 0.3571\n",
      "F1: 0.3977\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/training/safetynet/recaptcha\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 6\n",
      "predicted\n",
      "[0s] 38 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.7037\n",
      "macro_f1: 0.5433\n",
      "Precision: 0.5543\n",
      "Recall: 0.6146\n",
      "F1: 0.5433\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 116 [1s] 1\n",
      "predicted\n",
      "[0s] 96 [1s] 21\n",
      "--------------------\n",
      "Accuracy: 0.8120\n",
      "macro_f1: 0.4481\n",
      "Precision: 0.4948\n",
      "Recall: 0.4095\n",
      "F1: 0.4481\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/training/permissions/requesting\n",
      "--------------------\n",
      "Y\n",
      "[0s] 114 [1s] 15\n",
      "predicted\n",
      "[0s] 48 [1s] 81\n",
      "--------------------\n",
      "Accuracy: 0.4884\n",
      "macro_f1: 0.4525\n",
      "Precision: 0.5926\n",
      "Recall: 0.7105\n",
      "F1: 0.4525\n",
      "\u001b[31m15\u001b[0m entries logged\n",
      "https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "--------------------\n",
      "Y\n",
      "[0s] 158 [1s] 3\n",
      "predicted\n",
      "[0s] 83 [1s] 78\n",
      "--------------------\n",
      "Accuracy: 0.5342\n",
      "macro_f1: 0.3814\n",
      "Precision: 0.5192\n",
      "Recall: 0.7627\n",
      "F1: 0.3814\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 3\n",
      "predicted\n",
      "[0s] 7 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.5714\n",
      "macro_f1: 0.5333\n",
      "Precision: 0.5714\n",
      "Recall: 0.6061\n",
      "F1: 0.5333\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "--------------------\n",
      "Y\n",
      "[0s] 59 [1s] 4\n",
      "predicted\n",
      "[0s] 25 [1s] 38\n",
      "--------------------\n",
      "Accuracy: 0.4286\n",
      "macro_f1: 0.3571\n",
      "Precision: 0.5195\n",
      "Recall: 0.5784\n",
      "F1: 0.3571\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "--------------------\n",
      "Y\n",
      "[0s] 70 [1s] 2\n",
      "predicted\n",
      "[0s] 63 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.8472\n",
      "macro_f1: 0.4586\n",
      "Precision: 0.4841\n",
      "Recall: 0.4357\n",
      "F1: 0.4586\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/27297067\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n",
      "[0s] 13 [1s] 8\n",
      "predicted\n",
      "[0s] 15 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.7143\n",
      "macro_f1: 0.6786\n",
      "Precision: 0.7000\n",
      "Recall: 0.6731\n",
      "F1: 0.6786\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/5233543\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 8\n",
      "predicted\n",
      "[0s] 8 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.5714\n",
      "macro_f1: 0.5714\n",
      "Precision: 0.6058\n",
      "Recall: 0.6058\n",
      "F1: 0.5714\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "https://stackoverflow.com/questions/24952513\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.549\u001b[0m\n",
      "recall:    \u001b[31m0.575\u001b[0m\n",
      "f1-score:  \u001b[31m0.482\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.573\u001b[0m\n",
      "recall:    \u001b[31m0.644\u001b[0m\n",
      "f1-score:  \u001b[31m0.510\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.585\u001b[0m\n",
      "recall:    \u001b[31m0.545\u001b[0m\n",
      "f1-score:  \u001b[31m0.549\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.504\u001b[0m\n",
      "recall:    \u001b[31m0.547\u001b[0m\n",
      "f1-score:  \u001b[31m0.411\u001b[0m\n",
      "next 3\n",
      "\n",
      "\u001b[31mFold 3\u001b[0m\n",
      "Is there an accepted best-practice on making asynchronous HTTP requests in Android?\n",
      "How to set a minimum crop window ?\n",
      "Camera API: Cross device issues\n",
      "Quick Actions don't get displayed on Android 7.0\n",
      "Application icon doesn&#39;t show up in Android action bar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 789054.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    493\n",
      "1    246\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    781\n",
      "1     37\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0610 - sparse_categorical_accuracy: 0.6089The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65575, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 9s 788ms/step - loss: 1.0610 - sparse_categorical_accuracy: 0.6089 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8770 - sparse_categorical_accuracy: 0.5805\n",
      "Epoch 00002: val_loss improved from 0.65575 to 0.62871, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 8s 657ms/step - loss: 0.8770 - sparse_categorical_accuracy: 0.5805 - val_loss: 0.6287 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8072 - sparse_categorical_accuracy: 0.7064\n",
      "Epoch 00003: val_loss improved from 0.62871 to 0.54657, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 548ms/step - loss: 0.8072 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.5466 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7380 - sparse_categorical_accuracy: 0.7686\n",
      "Epoch 00004: val_loss improved from 0.54657 to 0.50170, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 583ms/step - loss: 0.7380 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5017 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6792 - sparse_categorical_accuracy: 0.7984\n",
      "Epoch 00005: val_loss improved from 0.50170 to 0.49990, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 515ms/step - loss: 0.6792 - sparse_categorical_accuracy: 0.7984 - val_loss: 0.4999 - val_sparse_categorical_accuracy: 0.7590\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6112 - sparse_categorical_accuracy: 0.8444\n",
      "Epoch 00006: val_loss did not improve from 0.49990\n",
      "12/12 [==============================] - 3s 237ms/step - loss: 0.6112 - sparse_categorical_accuracy: 0.8444 - val_loss: 0.5051 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5325 - sparse_categorical_accuracy: 0.8403\n",
      "Epoch 00007: val_loss improved from 0.49990 to 0.47014, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 8s 642ms/step - loss: 0.5325 - sparse_categorical_accuracy: 0.8403 - val_loss: 0.4701 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4433 - sparse_categorical_accuracy: 0.9026\n",
      "Epoch 00008: val_loss did not improve from 0.47014\n",
      "12/12 [==============================] - 3s 238ms/step - loss: 0.4433 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.5237 - val_sparse_categorical_accuracy: 0.7470\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3762 - sparse_categorical_accuracy: 0.9175\n",
      "Epoch 00009: val_loss improved from 0.47014 to 0.45940, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 544ms/step - loss: 0.3762 - sparse_categorical_accuracy: 0.9175 - val_loss: 0.4594 - val_sparse_categorical_accuracy: 0.8193\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3009 - sparse_categorical_accuracy: 0.9432\n",
      "Epoch 00010: val_loss did not improve from 0.45940\n",
      "12/12 [==============================] - 3s 237ms/step - loss: 0.3009 - sparse_categorical_accuracy: 0.9432 - val_loss: 0.5088 - val_sparse_categorical_accuracy: 0.7831\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/guide/topics/media/camera\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 239 [1s] 11\n",
      "predicted\n",
      "[0s] 203 [1s] 47\n",
      "--------------------\n",
      "Accuracy: 0.8000\n",
      "macro_f1: 0.5124\n",
      "Precision: 0.5253\n",
      "Recall: 0.5919\n",
      "F1: 0.5124\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/28504524\n",
      "--------------------\n",
      "Y\n",
      "[0s] 61 [1s] 4\n",
      "predicted\n",
      "[0s] 64 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.9231\n",
      "macro_f1: 0.4800\n",
      "Precision: 0.4688\n",
      "Recall: 0.4918\n",
      "F1: 0.4800\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "--------------------\n",
      "Y\n",
      "[0s] 52 [1s] 7\n",
      "predicted\n",
      "[0s] 58 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.8644\n",
      "macro_f1: 0.4636\n",
      "Precision: 0.4397\n",
      "Recall: 0.4904\n",
      "F1: 0.4636\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/training/notify-user/build-notification\n",
      "--------------------\n",
      "Y\n",
      "[0s] 145 [1s] 2\n",
      "predicted\n",
      "[0s] 131 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.8776\n",
      "macro_f1: 0.4674\n",
      "Precision: 0.4924\n",
      "Recall: 0.4448\n",
      "F1: 0.4674\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "https://guides.codepath.com/android/Defining-The-ActionBar\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 44 [1s] 4\n",
      "predicted\n",
      "[0s] 17 [1s] 31\n",
      "--------------------\n",
      "Accuracy: 0.3542\n",
      "macro_f1: 0.3030\n",
      "Precision: 0.4734\n",
      "Recall: 0.4205\n",
      "F1: 0.3030\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/26838730\n",
      "--------------------\n",
      "Y\n",
      "[0s] 18 [1s] 7\n",
      "predicted\n",
      "[0s] 17 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.7200\n",
      "macro_f1: 0.6667\n",
      "Precision: 0.6618\n",
      "Recall: 0.6746\n",
      "F1: 0.6667\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/3059155\n",
      "https://developer.android.com/training/volley/request\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 2\n",
      "predicted\n",
      "[0s] 15 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.8667\n",
      "macro_f1: 0.4643\n",
      "Precision: 0.4333\n",
      "Recall: 0.5000\n",
      "F1: 0.4643\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.499\u001b[0m\n",
      "recall:    \u001b[31m0.516\u001b[0m\n",
      "f1-score:  \u001b[31m0.480\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.484\u001b[0m\n",
      "recall:    \u001b[31m0.512\u001b[0m\n",
      "f1-score:  \u001b[31m0.481\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.565\u001b[0m\n",
      "recall:    \u001b[31m0.583\u001b[0m\n",
      "f1-score:  \u001b[31m0.573\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.457\u001b[0m\n",
      "recall:    \u001b[31m0.455\u001b[0m\n",
      "f1-score:  \u001b[31m0.383\u001b[0m\n",
      "next 4\n",
      "\n",
      "\u001b[31mFold 4\u001b[0m\n",
      "Android: rotate canvas around the center of the screen\n",
      "TS shows numbers instead of contact names in notifications\n",
      "No lock screen controls ever\n",
      "Enums support with Realm?\n",
      "Sound panning should work for stereo files (and if not, add it to the docs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 815021.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    540\n",
      "1    270\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    265\n",
      "1     11\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9410 - sparse_categorical_accuracy: 0.6370The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67355, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 9s 672ms/step - loss: 0.9410 - sparse_categorical_accuracy: 0.6370 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.6444\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9026 - sparse_categorical_accuracy: 0.5506\n",
      "Epoch 00002: val_loss did not improve from 0.67355\n",
      "13/13 [==============================] - 3s 240ms/step - loss: 0.9026 - sparse_categorical_accuracy: 0.5506 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.4778\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8348 - sparse_categorical_accuracy: 0.6617\n",
      "Epoch 00003: val_loss improved from 0.67355 to 0.66907, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 7s 520ms/step - loss: 0.8348 - sparse_categorical_accuracy: 0.6617 - val_loss: 0.6691 - val_sparse_categorical_accuracy: 0.5333\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.7656 - sparse_categorical_accuracy: 0.7407\n",
      "Epoch 00004: val_loss improved from 0.66907 to 0.65811, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 7s 526ms/step - loss: 0.7656 - sparse_categorical_accuracy: 0.7407 - val_loss: 0.6581 - val_sparse_categorical_accuracy: 0.5889\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6762 - sparse_categorical_accuracy: 0.7864\n",
      "Epoch 00005: val_loss improved from 0.65811 to 0.65436, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 494ms/step - loss: 0.6762 - sparse_categorical_accuracy: 0.7864 - val_loss: 0.6544 - val_sparse_categorical_accuracy: 0.6111\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5846 - sparse_categorical_accuracy: 0.8272\n",
      "Epoch 00006: val_loss improved from 0.65436 to 0.63828, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 7s 571ms/step - loss: 0.5846 - sparse_categorical_accuracy: 0.8272 - val_loss: 0.6383 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5194 - sparse_categorical_accuracy: 0.8593\n",
      "Epoch 00007: val_loss did not improve from 0.63828\n",
      "13/13 [==============================] - 3s 241ms/step - loss: 0.5194 - sparse_categorical_accuracy: 0.8593 - val_loss: 0.7140 - val_sparse_categorical_accuracy: 0.6222\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4776 - sparse_categorical_accuracy: 0.8716\n",
      "Epoch 00008: val_loss did not improve from 0.63828\n",
      "13/13 [==============================] - 3s 241ms/step - loss: 0.4776 - sparse_categorical_accuracy: 0.8716 - val_loss: 0.6670 - val_sparse_categorical_accuracy: 0.6556\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3833 - sparse_categorical_accuracy: 0.9074\n",
      "Epoch 00009: val_loss did not improve from 0.63828\n",
      "13/13 [==============================] - 3s 241ms/step - loss: 0.3833 - sparse_categorical_accuracy: 0.9074 - val_loss: 0.7115 - val_sparse_categorical_accuracy: 0.6778\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3318 - sparse_categorical_accuracy: 0.9247Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.63828\n",
      "13/13 [==============================] - 3s 258ms/step - loss: 0.3318 - sparse_categorical_accuracy: 0.9247 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/24652078\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 8 [1s] 3\n",
      "predicted\n",
      "[0s] 10 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.8182\n",
      "macro_f1: 0.6944\n",
      "Precision: 0.9000\n",
      "Recall: 0.6667\n",
      "F1: 0.6944\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/realm/realm-java/issues/776\n",
      "--------------------\n",
      "Y\n",
      "[0s] 31 [1s] 2\n",
      "predicted\n",
      "[0s] 28 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.8485\n",
      "macro_f1: 0.6005\n",
      "Precision: 0.5821\n",
      "Recall: 0.6855\n",
      "F1: 0.6005\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "https://github.com/signalapp/Signal-Android/issues/3376\n",
      "--------------------\n",
      "Y\n",
      "[0s] 54 [1s] 3\n",
      "predicted\n",
      "[0s] 50 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.8246\n",
      "macro_f1: 0.4519\n",
      "Precision: 0.4700\n",
      "Recall: 0.4352\n",
      "F1: 0.4519\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://dzone.com/articles/android-rotate-and-scale\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 58 [1s] 1\n",
      "predicted\n",
      "[0s] 42 [1s] 17\n",
      "--------------------\n",
      "Accuracy: 0.7288\n",
      "macro_f1: 0.4756\n",
      "Precision: 0.5294\n",
      "Recall: 0.8621\n",
      "F1: 0.4756\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/8712652\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 15 [1s] 2\n",
      "predicted\n",
      "[0s] 9 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.6471\n",
      "macro_f1: 0.5750\n",
      "Precision: 0.6250\n",
      "Recall: 0.8000\n",
      "F1: 0.5750\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.621\u001b[0m\n",
      "recall:    \u001b[31m0.690\u001b[0m\n",
      "f1-score:  \u001b[31m0.559\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.762\u001b[0m\n",
      "recall:    \u001b[31m0.733\u001b[0m\n",
      "f1-score:  \u001b[31m0.635\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.526\u001b[0m\n",
      "recall:    \u001b[31m0.560\u001b[0m\n",
      "f1-score:  \u001b[31m0.526\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.529\u001b[0m\n",
      "recall:    \u001b[31m0.862\u001b[0m\n",
      "f1-score:  \u001b[31m0.476\u001b[0m\n",
      "next 5\n",
      "\n",
      "\u001b[31mFold 5\u001b[0m\n",
      "Different actions from contact info depending on whether hitting back key or back arrow in top left\n",
      "Unlimited/Dynamic ViewPager in both directions\n",
      "Java: Efficient ArrayList filtering?\n",
      "shouldn't snackbar DSL helpers take CharSequence?\n",
      "Not receiving notifications when phone is locked and connected through WIFI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 850330.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    500\n",
      "1    250\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    770\n",
      "1     33\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9385 - sparse_categorical_accuracy: 0.5640The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67017, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 10s 797ms/step - loss: 0.9385 - sparse_categorical_accuracy: 0.5640 - val_loss: 0.6702 - val_sparse_categorical_accuracy: 0.5952\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9004 - sparse_categorical_accuracy: 0.6427\n",
      "Epoch 00002: val_loss improved from 0.67017 to 0.65860, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 570ms/step - loss: 0.9004 - sparse_categorical_accuracy: 0.6427 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.5595\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8493 - sparse_categorical_accuracy: 0.6933\n",
      "Epoch 00003: val_loss improved from 0.65860 to 0.63576, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 555ms/step - loss: 0.8493 - sparse_categorical_accuracy: 0.6933 - val_loss: 0.6358 - val_sparse_categorical_accuracy: 0.6071\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7773 - sparse_categorical_accuracy: 0.7067\n",
      "Epoch 00004: val_loss improved from 0.63576 to 0.63337, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 598ms/step - loss: 0.7773 - sparse_categorical_accuracy: 0.7067 - val_loss: 0.6334 - val_sparse_categorical_accuracy: 0.5952\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6878 - sparse_categorical_accuracy: 0.7560\n",
      "Epoch 00005: val_loss improved from 0.63337 to 0.59793, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 560ms/step - loss: 0.6878 - sparse_categorical_accuracy: 0.7560 - val_loss: 0.5979 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5967 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 00006: val_loss improved from 0.59793 to 0.57533, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 537ms/step - loss: 0.5967 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.5753 - val_sparse_categorical_accuracy: 0.6905\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5278 - sparse_categorical_accuracy: 0.8320\n",
      "Epoch 00007: val_loss did not improve from 0.57533\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 0.5278 - sparse_categorical_accuracy: 0.8320 - val_loss: 0.5932 - val_sparse_categorical_accuracy: 0.7024\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4270 - sparse_categorical_accuracy: 0.8760\n",
      "Epoch 00008: val_loss did not improve from 0.57533\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 0.4270 - sparse_categorical_accuracy: 0.8760 - val_loss: 0.5962 - val_sparse_categorical_accuracy: 0.7143\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3598 - sparse_categorical_accuracy: 0.9053\n",
      "Epoch 00009: val_loss did not improve from 0.57533\n",
      "12/12 [==============================] - 3s 240ms/step - loss: 0.3598 - sparse_categorical_accuracy: 0.9053 - val_loss: 0.6234 - val_sparse_categorical_accuracy: 0.7381\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2805 - sparse_categorical_accuracy: 0.9347Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.57533\n",
      "12/12 [==============================] - 3s 256ms/step - loss: 0.2805 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.6719 - val_sparse_categorical_accuracy: 0.7262\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/122105\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 130 [1s] 1\n",
      "predicted\n",
      "[0s] 61 [1s] 70\n",
      "--------------------\n",
      "Accuracy: 0.4733\n",
      "macro_f1: 0.3335\n",
      "Precision: 0.5071\n",
      "Recall: 0.7346\n",
      "F1: 0.3335\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 165 [1s] 12\n",
      "predicted\n",
      "[0s] 133 [1s] 44\n",
      "--------------------\n",
      "Accuracy: 0.7175\n",
      "macro_f1: 0.4697\n",
      "Precision: 0.5003\n",
      "Recall: 0.5008\n",
      "F1: 0.4697\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "--------------------\n",
      "Y\n",
      "[0s] 144 [1s] 2\n",
      "predicted\n",
      "[0s] 51 [1s] 95\n",
      "--------------------\n",
      "Accuracy: 0.3630\n",
      "macro_f1: 0.2822\n",
      "Precision: 0.5105\n",
      "Recall: 0.6771\n",
      "F1: 0.2822\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/10108774\n",
      "https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 75 [1s] 2\n",
      "predicted\n",
      "[0s] 44 [1s] 33\n",
      "--------------------\n",
      "Accuracy: 0.5714\n",
      "macro_f1: 0.3899\n",
      "Precision: 0.5038\n",
      "Recall: 0.5367\n",
      "F1: 0.3899\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "--------------------\n",
      "Y\n",
      "[0s] 25 [1s] 8\n",
      "predicted\n",
      "[0s] 33 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.7576\n",
      "macro_f1: 0.4310\n",
      "Precision: 0.3788\n",
      "Recall: 0.5000\n",
      "F1: 0.4310\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24313539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 51 [1s] 4\n",
      "predicted\n",
      "[0s] 44 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.7273\n",
      "macro_f1: 0.4211\n",
      "Precision: 0.4545\n",
      "Recall: 0.3922\n",
      "F1: 0.4211\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 2\n",
      "predicted\n",
      "[0s] 22 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.6316\n",
      "macro_f1: 0.4904\n",
      "Precision: 0.5625\n",
      "Recall: 0.8056\n",
      "F1: 0.4904\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "https://stackoverflow.com/questions/36275986\n",
      "--------------------\n",
      "Y\n",
      "[0s] 22 [1s] 2\n",
      "predicted\n",
      "[0s] 17 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.7917\n",
      "macro_f1: 0.6581\n",
      "Precision: 0.6429\n",
      "Recall: 0.8864\n",
      "F1: 0.6581\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.508\u001b[0m\n",
      "recall:    \u001b[31m0.629\u001b[0m\n",
      "f1-score:  \u001b[31m0.434\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.484\u001b[0m\n",
      "recall:    \u001b[31m0.661\u001b[0m\n",
      "f1-score:  \u001b[31m0.401\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.535\u001b[0m\n",
      "recall:    \u001b[31m0.671\u001b[0m\n",
      "f1-score:  \u001b[31m0.471\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.502\u001b[0m\n",
      "recall:    \u001b[31m0.519\u001b[0m\n",
      "f1-score:  \u001b[31m0.430\u001b[0m\n",
      "next 6\n",
      "\n",
      "\u001b[31mFold 6\u001b[0m\n",
      "Generating an error when using Provider for scoped instances\n",
      "Why settings.xml layout is overlapping the ActionBar/Toolbar?\n",
      "Explanation of the getView() method of an ArrayAdapter\n",
      "Dagger 2 doesn't implement some of the component methods in Android project with custom annotation processor\n",
      "Android - Jackson JSON parser returns null value in &#39;release&#39; builds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 666115.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    480\n",
      "1    240\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1237\n",
      "1      44\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9287 - sparse_categorical_accuracy: 0.5778The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66103, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 9s 772ms/step - loss: 0.9287 - sparse_categorical_accuracy: 0.5778 - val_loss: 0.6610 - val_sparse_categorical_accuracy: 0.7901\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9049 - sparse_categorical_accuracy: 0.6458\n",
      "Epoch 00002: val_loss improved from 0.66103 to 0.61216, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 544ms/step - loss: 0.9049 - sparse_categorical_accuracy: 0.6458 - val_loss: 0.6122 - val_sparse_categorical_accuracy: 0.8148\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8524 - sparse_categorical_accuracy: 0.6208\n",
      "Epoch 00003: val_loss improved from 0.61216 to 0.57892, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 530ms/step - loss: 0.8524 - sparse_categorical_accuracy: 0.6208 - val_loss: 0.5789 - val_sparse_categorical_accuracy: 0.7531\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7943 - sparse_categorical_accuracy: 0.7236\n",
      "Epoch 00004: val_loss improved from 0.57892 to 0.55164, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 7s 545ms/step - loss: 0.7943 - sparse_categorical_accuracy: 0.7236 - val_loss: 0.5516 - val_sparse_categorical_accuracy: 0.7654\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7294 - sparse_categorical_accuracy: 0.7264\n",
      "Epoch 00005: val_loss improved from 0.55164 to 0.49653, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 530ms/step - loss: 0.7294 - sparse_categorical_accuracy: 0.7264 - val_loss: 0.4965 - val_sparse_categorical_accuracy: 0.7901\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6511 - sparse_categorical_accuracy: 0.7764\n",
      "Epoch 00006: val_loss improved from 0.49653 to 0.48523, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 513ms/step - loss: 0.6511 - sparse_categorical_accuracy: 0.7764 - val_loss: 0.4852 - val_sparse_categorical_accuracy: 0.8025\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5807 - sparse_categorical_accuracy: 0.8153\n",
      "Epoch 00007: val_loss improved from 0.48523 to 0.48256, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 473ms/step - loss: 0.5807 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.4826 - val_sparse_categorical_accuracy: 0.7778\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5065 - sparse_categorical_accuracy: 0.8375\n",
      "Epoch 00008: val_loss improved from 0.48256 to 0.47393, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 477ms/step - loss: 0.5065 - sparse_categorical_accuracy: 0.8375 - val_loss: 0.4739 - val_sparse_categorical_accuracy: 0.8272\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4464 - sparse_categorical_accuracy: 0.8639\n",
      "Epoch 00009: val_loss improved from 0.47393 to 0.45382, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 487ms/step - loss: 0.4464 - sparse_categorical_accuracy: 0.8639 - val_loss: 0.4538 - val_sparse_categorical_accuracy: 0.8395\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3842 - sparse_categorical_accuracy: 0.8792\n",
      "Epoch 00010: val_loss did not improve from 0.45382\n",
      "12/12 [==============================] - 3s 231ms/step - loss: 0.3842 - sparse_categorical_accuracy: 0.8792 - val_loss: 0.4690 - val_sparse_categorical_accuracy: 0.8395\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 44 [1s] 3\n",
      "predicted\n",
      "[0s] 11 [1s] 36\n",
      "--------------------\n",
      "Accuracy: 0.2979\n",
      "macro_f1: 0.2769\n",
      "Precision: 0.5417\n",
      "Recall: 0.6250\n",
      "F1: 0.2769\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "https://developer.android.com/training/dependency-injection/dagger-android\n",
      "--------------------\n",
      "Y\n",
      "[0s] 195 [1s] 1\n",
      "predicted\n",
      "[0s] 66 [1s] 130\n",
      "--------------------\n",
      "Accuracy: 0.3418\n",
      "macro_f1: 0.2605\n",
      "Precision: 0.5038\n",
      "Recall: 0.6692\n",
      "F1: 0.2605\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "https://stackoverflow.com/questions/29923376\n",
      "--------------------\n",
      "Y\n",
      "[0s] 28 [1s] 4\n",
      "predicted\n",
      "[0s] 5 [1s] 27\n",
      "--------------------\n",
      "Accuracy: 0.2812\n",
      "macro_f1: 0.2805\n",
      "Precision: 0.5741\n",
      "Recall: 0.5893\n",
      "F1: 0.2805\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 203 [1s] 8\n",
      "predicted\n",
      "[0s] 113 [1s] 98\n",
      "--------------------\n",
      "Accuracy: 0.5545\n",
      "macro_f1: 0.4079\n",
      "Precision: 0.5218\n",
      "Recall: 0.6484\n",
      "F1: 0.4079\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://github.com/quarkusio/quarkus/issues/3954\n",
      "https://stackoverflow.com/questions/11064244\n",
      "--------------------\n",
      "Y\n",
      "[0s] 47 [1s] 4\n",
      "predicted\n",
      "[0s] 16 [1s] 35\n",
      "--------------------\n",
      "Accuracy: 0.3922\n",
      "macro_f1: 0.3565\n",
      "Precision: 0.5571\n",
      "Recall: 0.6702\n",
      "F1: 0.3565\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/6442054\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 14 [1s] 7\n",
      "predicted\n",
      "[0s] 5 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.4762\n",
      "macro_f1: 0.4714\n",
      "Precision: 0.5875\n",
      "Recall: 0.5714\n",
      "F1: 0.4714\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://github.com/google/dagger/issues/671\n",
      "https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "--------------------\n",
      "Y\n",
      "[0s] 47 [1s] 12\n",
      "predicted\n",
      "[0s] 13 [1s] 46\n",
      "--------------------\n",
      "Accuracy: 0.3559\n",
      "macro_f1: 0.3557\n",
      "Precision: 0.5318\n",
      "Recall: 0.5337\n",
      "F1: 0.3557\n",
      "\u001b[31m10\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/29738510\n",
      "--------------------\n",
      "Y\n",
      "[0s] 21 [1s] 2\n",
      "predicted\n",
      "[0s] 17 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.7391\n",
      "macro_f1: 0.5461\n",
      "Precision: 0.5539\n",
      "Recall: 0.6310\n",
      "F1: 0.5461\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/57235136\n",
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 3\n",
      "predicted\n",
      "[0s] 22 [1s] 22\n",
      "--------------------\n",
      "Accuracy: 0.5682\n",
      "macro_f1: 0.4692\n",
      "Precision: 0.5682\n",
      "Recall: 0.7683\n",
      "F1: 0.4692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m3\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.549\u001b[0m\n",
      "recall:    \u001b[31m0.634\u001b[0m\n",
      "f1-score:  \u001b[31m0.381\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.523\u001b[0m\n",
      "recall:    \u001b[31m0.647\u001b[0m\n",
      "f1-score:  \u001b[31m0.269\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.568\u001b[0m\n",
      "recall:    \u001b[31m0.646\u001b[0m\n",
      "f1-score:  \u001b[31m0.425\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.527\u001b[0m\n",
      "recall:    \u001b[31m0.591\u001b[0m\n",
      "f1-score:  \u001b[31m0.382\u001b[0m\n",
      "next 7\n",
      "\n",
      "\u001b[31mFold 7\u001b[0m\n",
      "Doesn't scroll properly inside ViewPager\n",
      "The gravity is not working on the TextView in some situation.\n",
      "Support for GoogleApiClient and new FusedLocationProviderApi\n",
      "How to record phone calls in Android\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 841581.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    507\n",
      "1    254\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    892\n",
      "1     29\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9002 - sparse_categorical_accuracy: 0.5177The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64620, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 10s 853ms/step - loss: 0.9002 - sparse_categorical_accuracy: 0.5177 - val_loss: 0.6462 - val_sparse_categorical_accuracy: 0.6118\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8254 - sparse_categorical_accuracy: 0.6531\n",
      "Epoch 00002: val_loss improved from 0.64620 to 0.62649, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 535ms/step - loss: 0.8254 - sparse_categorical_accuracy: 0.6531 - val_loss: 0.6265 - val_sparse_categorical_accuracy: 0.5882\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.7471 - sparse_categorical_accuracy: 0.7109\n",
      "Epoch 00003: val_loss improved from 0.62649 to 0.61150, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 542ms/step - loss: 0.7471 - sparse_categorical_accuracy: 0.7109 - val_loss: 0.6115 - val_sparse_categorical_accuracy: 0.6471\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6681 - sparse_categorical_accuracy: 0.7516\n",
      "Epoch 00004: val_loss improved from 0.61150 to 0.60114, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 497ms/step - loss: 0.6681 - sparse_categorical_accuracy: 0.7516 - val_loss: 0.6011 - val_sparse_categorical_accuracy: 0.6471\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5607 - sparse_categorical_accuracy: 0.8029\n",
      "Epoch 00005: val_loss improved from 0.60114 to 0.59601, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 504ms/step - loss: 0.5607 - sparse_categorical_accuracy: 0.8029 - val_loss: 0.5960 - val_sparse_categorical_accuracy: 0.6824\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4554 - sparse_categorical_accuracy: 0.8633\n",
      "Epoch 00006: val_loss did not improve from 0.59601\n",
      "12/12 [==============================] - 3s 243ms/step - loss: 0.4554 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.6097 - val_sparse_categorical_accuracy: 0.6588\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3739 - sparse_categorical_accuracy: 0.8909\n",
      "Epoch 00007: val_loss improved from 0.59601 to 0.58579, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "12/12 [==============================] - 6s 528ms/step - loss: 0.3739 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.5858 - val_sparse_categorical_accuracy: 0.7412\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3226 - sparse_categorical_accuracy: 0.9041\n",
      "Epoch 00008: val_loss did not improve from 0.58579\n",
      "12/12 [==============================] - 3s 243ms/step - loss: 0.3226 - sparse_categorical_accuracy: 0.9041 - val_loss: 0.6823 - val_sparse_categorical_accuracy: 0.7176\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2700 - sparse_categorical_accuracy: 0.9264\n",
      "Epoch 00009: val_loss did not improve from 0.58579\n",
      "12/12 [==============================] - 3s 244ms/step - loss: 0.2700 - sparse_categorical_accuracy: 0.9264 - val_loss: 0.8655 - val_sparse_categorical_accuracy: 0.6353\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2384 - sparse_categorical_accuracy: 0.9369\n",
      "Epoch 00010: val_loss did not improve from 0.58579\n",
      "12/12 [==============================] - 3s 245ms/step - loss: 0.2384 - sparse_categorical_accuracy: 0.9369 - val_loss: 0.8806 - val_sparse_categorical_accuracy: 0.6588\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/reference/android/widget/TextView\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 468 [1s] 2\n",
      "predicted\n",
      "[0s] 364 [1s] 106\n",
      "--------------------\n",
      "Accuracy: 0.7702\n",
      "macro_f1: 0.4351\n",
      "Precision: 0.4973\n",
      "Recall: 0.3868\n",
      "F1: 0.4351\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/media/mediarecorder\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 45 [1s] 4\n",
      "predicted\n",
      "[0s] 25 [1s] 24\n",
      "--------------------\n",
      "Accuracy: 0.5918\n",
      "macro_f1: 0.5000\n",
      "Precision: 0.5833\n",
      "Recall: 0.7778\n",
      "F1: 0.5000\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/19025301\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 5 [1s] 6\n",
      "predicted\n",
      "[0s] 2 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.7273\n",
      "macro_f1: 0.6857\n",
      "Precision: 0.8333\n",
      "Recall: 0.7000\n",
      "F1: 0.6857\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://developer.android.com/training/gestures/scroll\n",
      "https://developer.android.com/training/location/retrieve-current\n",
      "https://javapapers.com/android/android-location-fused-provider\n",
      "--------------------\n",
      "Y\n",
      "[0s] 97 [1s] 2\n",
      "predicted\n",
      "[0s] 77 [1s] 22\n",
      "--------------------\n",
      "Accuracy: 0.7980\n",
      "macro_f1: 0.5259\n",
      "Precision: 0.5455\n",
      "Recall: 0.8969\n",
      "F1: 0.5259\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/6688444\n",
      "--------------------\n",
      "Y\n",
      "[0s] 5 [1s] 4\n",
      "predicted\n",
      "[0s] 1 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.5556\n",
      "macro_f1: 0.5000\n",
      "Precision: 0.7500\n",
      "Recall: 0.6000\n",
      "F1: 0.5000\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/39588322\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 3\n",
      "predicted\n",
      "[0s] 14 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.6875\n",
      "macro_f1: 0.4074\n",
      "Precision: 0.3929\n",
      "Recall: 0.4231\n",
      "F1: 0.4074\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "--------------------\n",
      "Y\n",
      "[0s] 113 [1s] 6\n",
      "predicted\n",
      "[0s] 105 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.8655\n",
      "macro_f1: 0.5633\n",
      "Precision: 0.5524\n",
      "Recall: 0.6136\n",
      "F1: 0.5633\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://github.com/google/oboe/issues/447\n",
      "--------------------\n",
      "Y\n",
      "[0s] 21 [1s] 2\n",
      "predicted\n",
      "[0s] 8 [1s] 15\n",
      "--------------------\n",
      "Accuracy: 0.4348\n",
      "macro_f1: 0.3935\n",
      "Precision: 0.5667\n",
      "Recall: 0.6905\n",
      "F1: 0.3935\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/46481789\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.590\u001b[0m\n",
      "recall:    \u001b[31m0.636\u001b[0m\n",
      "f1-score:  \u001b[31m0.501\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.540\u001b[0m\n",
      "recall:    \u001b[31m0.582\u001b[0m\n",
      "f1-score:  \u001b[31m0.468\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.659\u001b[0m\n",
      "recall:    \u001b[31m0.574\u001b[0m\n",
      "f1-score:  \u001b[31m0.531\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.567\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:    \u001b[31m0.690\u001b[0m\n",
      "f1-score:  \u001b[31m0.394\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.549\u001b[0m\n",
      "recall:    \u001b[31m0.755\u001b[0m\n",
      "f1-score:  \u001b[31m0.545\u001b[0m\n",
      "next 8\n",
      "\n",
      "\u001b[31mFold 8\u001b[0m\n",
      "SeekTo Position of cutted song not working\n",
      "Android Gallery with pinch zoom\n",
      "Wait for 2 async REST calls to result in success or error\n",
      "how  to set Screenshot frame size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 824900.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    540\n",
      "1    270\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    377\n",
      "1     11\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9939 - sparse_categorical_accuracy: 0.6556The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66504, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 9s 688ms/step - loss: 0.9939 - sparse_categorical_accuracy: 0.6556 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.6222\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8860 - sparse_categorical_accuracy: 0.5765\n",
      "Epoch 00002: val_loss improved from 0.66504 to 0.63390, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 7s 505ms/step - loss: 0.8860 - sparse_categorical_accuracy: 0.5765 - val_loss: 0.6339 - val_sparse_categorical_accuracy: 0.7556\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8122 - sparse_categorical_accuracy: 0.6938\n",
      "Epoch 00003: val_loss did not improve from 0.63390\n",
      "13/13 [==============================] - 3s 242ms/step - loss: 0.8122 - sparse_categorical_accuracy: 0.6938 - val_loss: 0.6589 - val_sparse_categorical_accuracy: 0.6778\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.7367 - sparse_categorical_accuracy: 0.7568\n",
      "Epoch 00004: val_loss improved from 0.63390 to 0.53380, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 479ms/step - loss: 0.7367 - sparse_categorical_accuracy: 0.7568 - val_loss: 0.5338 - val_sparse_categorical_accuracy: 0.7889\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6614 - sparse_categorical_accuracy: 0.7864\n",
      "Epoch 00005: val_loss improved from 0.53380 to 0.51765, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 477ms/step - loss: 0.6614 - sparse_categorical_accuracy: 0.7864 - val_loss: 0.5177 - val_sparse_categorical_accuracy: 0.7778\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5790 - sparse_categorical_accuracy: 0.8395\n",
      "Epoch 00006: val_loss improved from 0.51765 to 0.49695, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 472ms/step - loss: 0.5790 - sparse_categorical_accuracy: 0.8395 - val_loss: 0.4969 - val_sparse_categorical_accuracy: 0.7889\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4968 - sparse_categorical_accuracy: 0.8605\n",
      "Epoch 00007: val_loss did not improve from 0.49695\n",
      "13/13 [==============================] - 3s 241ms/step - loss: 0.4968 - sparse_categorical_accuracy: 0.8605 - val_loss: 0.5062 - val_sparse_categorical_accuracy: 0.7778\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4500 - sparse_categorical_accuracy: 0.8790\n",
      "Epoch 00008: val_loss did not improve from 0.49695\n",
      "13/13 [==============================] - 3s 241ms/step - loss: 0.4500 - sparse_categorical_accuracy: 0.8790 - val_loss: 0.5370 - val_sparse_categorical_accuracy: 0.7556\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3605 - sparse_categorical_accuracy: 0.9148\n",
      "Epoch 00009: val_loss did not improve from 0.49695\n",
      "13/13 [==============================] - 3s 240ms/step - loss: 0.3605 - sparse_categorical_accuracy: 0.9148 - val_loss: 0.5465 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3045 - sparse_categorical_accuracy: 0.9284Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.49695\n",
      "13/13 [==============================] - 3s 257ms/step - loss: 0.3045 - sparse_categorical_accuracy: 0.9284 - val_loss: 0.5888 - val_sparse_categorical_accuracy: 0.7333\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/2661536\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 99 [1s] 1\n",
      "predicted\n",
      "[0s] 79 [1s] 21\n",
      "--------------------\n",
      "Accuracy: 0.8000\n",
      "macro_f1: 0.4893\n",
      "Precision: 0.5238\n",
      "Recall: 0.8990\n",
      "F1: 0.4893\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2993085\n",
      "https://developer.android.com/training/gestures/scale\n",
      "https://github.com/google/ExoPlayer/issues/8387\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 27 [1s] 5\n",
      "predicted\n",
      "[0s] 18 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.6562\n",
      "macro_f1: 0.5883\n",
      "Precision: 0.6151\n",
      "Recall: 0.7148\n",
      "F1: 0.5883\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/10630373\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 3\n",
      "predicted\n",
      "[0s] 20 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.7188\n",
      "macro_f1: 0.6082\n",
      "Precision: 0.6250\n",
      "Recall: 0.8448\n",
      "F1: 0.6082\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 2\n",
      "predicted\n",
      "[0s] 46 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.9200\n",
      "macro_f1: 0.6454\n",
      "Precision: 0.6141\n",
      "Recall: 0.7188\n",
      "F1: 0.6454\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/guide/background/threading\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.595\u001b[0m\n",
      "recall:    \u001b[31m0.794\u001b[0m\n",
      "f1-score:  \u001b[31m0.583\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.574\u001b[0m\n",
      "recall:    \u001b[31m0.872\u001b[0m\n",
      "f1-score:  \u001b[31m0.549\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.615\u001b[0m\n",
      "recall:    \u001b[31m0.715\u001b[0m\n",
      "f1-score:  \u001b[31m0.588\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.614\u001b[0m\n",
      "recall:    \u001b[31m0.719\u001b[0m\n",
      "f1-score:  \u001b[31m0.645\u001b[0m\n",
      "next 9\n",
      "\n",
      "\u001b[31mFold 9\u001b[0m\n",
      "Android SQLite performance in complex queries\n",
      "Custom Annotations in Retrofit 2.0\n",
      "Android App Retrieve Data from Server but in a Secure way\n",
      "Hilt: How to prevent Hilt from picking dependency from a library?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 766083.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    515\n",
      "1    257\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    553\n",
      "1     25\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.8980 - sparse_categorical_accuracy: 0.5260The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62862, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 11s 871ms/step - loss: 0.8990 - sparse_categorical_accuracy: 0.5272 - val_loss: 0.6286 - val_sparse_categorical_accuracy: 0.6628\n",
      "Epoch 2/10\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.8347 - sparse_categorical_accuracy: 0.6667\n",
      "Epoch 00002: val_loss improved from 0.62862 to 0.61279, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 7s 533ms/step - loss: 0.8355 - sparse_categorical_accuracy: 0.6658 - val_loss: 0.6128 - val_sparse_categorical_accuracy: 0.6279\n",
      "Epoch 3/10\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.7759 - sparse_categorical_accuracy: 0.7096\n",
      "Epoch 00003: val_loss improved from 0.61279 to 0.58354, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 463ms/step - loss: 0.7756 - sparse_categorical_accuracy: 0.7073 - val_loss: 0.5835 - val_sparse_categorical_accuracy: 0.6628\n",
      "Epoch 4/10\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.7198 - sparse_categorical_accuracy: 0.7435\n",
      "Epoch 00004: val_loss improved from 0.58354 to 0.56460, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 466ms/step - loss: 0.7197 - sparse_categorical_accuracy: 0.7422 - val_loss: 0.5646 - val_sparse_categorical_accuracy: 0.6628\n",
      "Epoch 5/10\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.6684 - sparse_categorical_accuracy: 0.7943\n",
      "Epoch 00005: val_loss improved from 0.56460 to 0.50070, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 495ms/step - loss: 0.6675 - sparse_categorical_accuracy: 0.7940 - val_loss: 0.5007 - val_sparse_categorical_accuracy: 0.7442\n",
      "Epoch 6/10\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.5927 - sparse_categorical_accuracy: 0.8151\n",
      "Epoch 00006: val_loss improved from 0.50070 to 0.49499, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 483ms/step - loss: 0.5923 - sparse_categorical_accuracy: 0.8148 - val_loss: 0.4950 - val_sparse_categorical_accuracy: 0.7326\n",
      "Epoch 7/10\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.5113 - sparse_categorical_accuracy: 0.8659\n",
      "Epoch 00007: val_loss did not improve from 0.49499\n",
      "13/13 [==============================] - 3s 232ms/step - loss: 0.5105 - sparse_categorical_accuracy: 0.8653 - val_loss: 0.5037 - val_sparse_categorical_accuracy: 0.7326\n",
      "Epoch 8/10\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.4691 - sparse_categorical_accuracy: 0.8646\n",
      "Epoch 00008: val_loss improved from 0.49499 to 0.48078, saving model to /home/msarthur/scratch/best_pyramid_model\n",
      "13/13 [==============================] - 6s 476ms/step - loss: 0.4689 - sparse_categorical_accuracy: 0.8653 - val_loss: 0.4808 - val_sparse_categorical_accuracy: 0.7209\n",
      "Epoch 9/10\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.4170 - sparse_categorical_accuracy: 0.8906\n",
      "Epoch 00009: val_loss did not improve from 0.48078\n",
      "13/13 [==============================] - 3s 230ms/step - loss: 0.4160 - sparse_categorical_accuracy: 0.8912 - val_loss: 0.5098 - val_sparse_categorical_accuracy: 0.7093\n",
      "Epoch 10/10\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.3769 - sparse_categorical_accuracy: 0.8984\n",
      "Epoch 00010: val_loss did not improve from 0.48078\n",
      "13/13 [==============================] - 3s 229ms/step - loss: 0.3761 - sparse_categorical_accuracy: 0.8990 - val_loss: 0.4974 - val_sparse_categorical_accuracy: 0.7326\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/training/dependency-injection/hilt-android\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 141 [1s] 4\n",
      "predicted\n",
      "[0s] 57 [1s] 88\n",
      "--------------------\n",
      "Accuracy: 0.3655\n",
      "macro_f1: 0.2677\n",
      "Precision: 0.4649\n",
      "Recall: 0.1879\n",
      "F1: 0.2677\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "https://github.com/google/dagger/issues/1991\n",
      "https://stackoverflow.com/questions/8184492\n",
      "--------------------\n",
      "Y\n",
      "[0s] 50 [1s] 3\n",
      "predicted\n",
      "[0s] 48 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.8491\n",
      "macro_f1: 0.4592\n",
      "Precision: 0.4688\n",
      "Recall: 0.4500\n",
      "F1: 0.4592\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/47760861\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 2\n",
      "predicted\n",
      "[0s] 20 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.7097\n",
      "macro_f1: 0.5620\n",
      "Precision: 0.5909\n",
      "Recall: 0.8448\n",
      "F1: 0.5620\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 45 [1s] 3\n",
      "predicted\n",
      "[0s] 33 [1s] 15\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.4530\n",
      "Precision: 0.5030\n",
      "Recall: 0.5111\n",
      "F1: 0.4530\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/training/data-storage/sqlite\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 67 [1s] 2\n",
      "predicted\n",
      "[0s] 36 [1s] 33\n",
      "--------------------\n",
      "Accuracy: 0.5507\n",
      "macro_f1: 0.4067\n",
      "Precision: 0.5303\n",
      "Recall: 0.7687\n",
      "F1: 0.4067\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30648172\n",
      "https://stackoverflow.com/questions/4015026\n",
      "--------------------\n",
      "Y\n",
      "[0s] 26 [1s] 9\n",
      "predicted\n",
      "[0s] 8 [1s] 27\n",
      "--------------------\n",
      "Accuracy: 0.4857\n",
      "macro_f1: 0.4853\n",
      "Precision: 0.6667\n",
      "Recall: 0.6538\n",
      "F1: 0.4853\n",
      "\u001b[31m9\u001b[0m entries logged\n",
      "https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 2\n",
      "predicted\n",
      "[0s] 47 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.9000\n",
      "macro_f1: 0.4737\n",
      "Precision: 0.4787\n",
      "Recall: 0.4688\n",
      "F1: 0.4737\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.529\u001b[0m\n",
      "recall:    \u001b[31m0.555\u001b[0m\n",
      "f1-score:  \u001b[31m0.444\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.498\u001b[0m\n",
      "recall:    \u001b[31m0.478\u001b[0m\n",
      "f1-score:  \u001b[31m0.337\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.575\u001b[0m\n",
      "recall:    \u001b[31m0.650\u001b[0m\n",
      "f1-score:  \u001b[31m0.502\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.491\u001b[0m\n",
      "recall:    \u001b[31m0.490\u001b[0m\n",
      "f1-score:  \u001b[31m0.463\u001b[0m\n",
      "next 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# @title 10-fold cross validation WIP\n",
    "CORPUS = raw_data\n",
    "\n",
    "all_tasks = sorted(list(set([d['question'] for d in raw_data])))\n",
    "rseed = 20210343\n",
    "random.seed(rseed)\n",
    "random.shuffle(all_tasks)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "file_handler = logging.FileHandler('/home/msarthur/scratch/LOG-bert_ds_android_pyramid.ans')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, random_state=rseed)\n",
    "np_tasks_arr = np.array(all_tasks)\n",
    "\n",
    "\n",
    "\n",
    "idx_split = 0\n",
    "for train_index, test_index in kf.split(np_tasks_arr):\n",
    "\n",
    "    idx_split = str(idx_split)\n",
    "    eval_fold = True\n",
    "    # 10 runs per fold to avoid reporting peek results in a given fold\n",
    "    if idx_split in fold_results and fold_results[idx_split]['run_cnt'] >= 10:\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split} FULLY TESTED\" + Style.RESET_ALL)\n",
    "        eval_fold = False\n",
    "\n",
    "\n",
    "    if eval_fold:\n",
    "        # <------------------------------------------------------------------------- EVAL VARIABLES\n",
    "        recommendation_metrics = defaultdict(list)\n",
    "        prediction_metrics = defaultdict(list)\n",
    "        api_metrics = defaultdict(list)\n",
    "        so_metrics = defaultdict(list)\n",
    "        git_metrics = defaultdict(list)\n",
    "        misc_metrics = defaultdict(list)\n",
    "        random_prediction_metrics = defaultdict(list)\n",
    "        clz_report_lst = defaultdict(list)\n",
    "\n",
    "        classification_report_lst = []\n",
    "        log_examples_lst = []\n",
    "        source_lst = []\n",
    "        venn_diagram_set = []\n",
    "        # <------------------------------------------------------------------------- EVAL VARIABLES\n",
    "\n",
    "\n",
    "        test_tasks_lst = np_tasks_arr[test_index].tolist()\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split}\" + Style.RESET_ALL)\n",
    "        logger.info('\\n'.join(test_tasks_lst))\n",
    "\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "        df_train, df_val, df_test, weights = get_train_val_test(\n",
    "            test_tasks_lst,\n",
    "            aug=USE_DS_SYNTHETIC,\n",
    "            undersample=UNDERSAMPLING, \n",
    "            undersample_n=N_UNDERSAMPLING\n",
    "        )\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "\n",
    "        logger.info('-' * 10)\n",
    "        logger.info(Fore.RED + 'train'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_train.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'test'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_test.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'weights'+ Style.RESET_ALL)\n",
    "        logger.info(str(weights))\n",
    "        logger.info('-' * 10)\n",
    "\n",
    "\n",
    "        # Encode X_train\n",
    "        train_encodings = _encode(tokenizer, df_train)\n",
    "        train_labels = df_train['category_index'].tolist()\n",
    "\n",
    "        # Encode X_valid\n",
    "        val_encodings = _encode(tokenizer, df_val)\n",
    "        val_labels = df_val['category_index'].tolist()\n",
    "\n",
    "\n",
    "        # https://huggingface.co/transformers/custom_datasets.html\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(train_encodings),\n",
    "            train_labels\n",
    "        ))\n",
    "\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(val_encodings),\n",
    "            val_labels\n",
    "        ))\n",
    "\n",
    "\n",
    "        if model_id == 'distilbert-base-uncased':\n",
    "            model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "                model_id, cache_dir='/home/msarthur/scratch'\n",
    "            )\n",
    "        else:\n",
    "            model = TFBertForSequenceClassification.from_pretrained(\n",
    "                model_id, cache_dir='/home/msarthur/scratch', local_files_only=True\n",
    "            )\n",
    "\n",
    "        # freeze all the parameters\n",
    "        # for param in model.parameters():\n",
    "        #   param.requires_grad = False\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "        METRICS = [\n",
    "            tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        ]\n",
    "\n",
    "        early_stopper = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', mode='min', patience=4, \n",
    "            verbose=1, restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
    "        checkpoint_filepath = '/home/msarthur/scratch/best_pyramid_model'\n",
    "\n",
    "        mc = tf.keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath, \n",
    "            monitor='val_loss', mode='min', verbose=1, \n",
    "            save_best_only=True,\n",
    "            save_weights_only=True\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_fn,\n",
    "            metrics=METRICS\n",
    "        )\n",
    "\n",
    "        # https://discuss.huggingface.co/t/how-to-dealing-with-data-imbalance/393/3\n",
    "        # https://wandb.ai/ayush-thakur/huggingface/reports/Early-Stopping-in-HuggingFace-Examples--Vmlldzo0MzE2MTM\n",
    "        model.fit(\n",
    "            train_dataset.shuffle(1000).batch(BATCH_SIZE), \n",
    "            epochs=EPOCHS, \n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_weight=weights,\n",
    "            validation_data=val_dataset.shuffle(1000).batch(BATCH_SIZE),\n",
    "            callbacks=[early_stopper, mc]\n",
    "        )\n",
    "\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Testing model\" + Style.RESET_ALL)\n",
    "        for source in df_test[\"source\"].unique():\n",
    "            df_source = df_test[df_test[\"source\"] == source]   \n",
    "            logger.info(source)\n",
    "            test_model(source, df_source, model, tokenizer, pos_filter=USE_FRAME_FILTERING)\n",
    "\n",
    "        add_idx_fold_results(idx_split, fold_results)\n",
    "        if 'venn_diagram_set' not in fold_results:\n",
    "            fold_results['venn_diagram_set'] = []\n",
    "\n",
    "        fold_results['venn_diagram_set'] += venn_diagram_set\n",
    "        fold_results['venn_diagram_set'] = list(set(fold_results['venn_diagram_set']))\n",
    "\n",
    "\n",
    "        _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "        logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "        logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "        logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        log_sources_data = [api_metrics, so_metrics, git_metrics, misc_metrics]\n",
    "        log_sources_ids = ['api_metrics', 'so_metrics', 'git_metrics', 'misc_metrics']\n",
    "\n",
    "        for _id, __data in zip(log_sources_ids, log_sources_data):\n",
    "            _precision, _recall, _f1score = avg_macro_metric_for(__data)\n",
    "\n",
    "            logger.info(\"\")\n",
    "            logger.info(Fore.YELLOW + f\"{_id}\" + Style.RESET_ALL)\n",
    "            logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "            logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "            logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "    idx_split = int(idx_split)\n",
    "    idx_split += 1\n",
    "    logger.info(f\"next {idx_split}\")\n",
    "#     break\n",
    "#         if idx_split >= 7:\n",
    "#             logger.info(f\"breaking at {idx_split}\")\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m0\u001b[0m\n",
      "precision: \u001b[31m0.476\u001b[0m [0.48]\n",
      "recall:    \u001b[31m0.560\u001b[0m [0.56]\n",
      "f1-score:  \u001b[31m0.496\u001b[0m [0.5]\n",
      "\u001b[33m1\u001b[0m\n",
      "precision: \u001b[31m0.647\u001b[0m [0.65]\n",
      "recall:    \u001b[31m0.706\u001b[0m [0.71]\n",
      "f1-score:  \u001b[31m0.533\u001b[0m [0.53]\n",
      "\u001b[33m2\u001b[0m\n",
      "precision: \u001b[31m0.549\u001b[0m [0.55]\n",
      "recall:    \u001b[31m0.575\u001b[0m [0.58]\n",
      "f1-score:  \u001b[31m0.482\u001b[0m [0.48]\n",
      "\u001b[33m3\u001b[0m\n",
      "precision: \u001b[31m0.499\u001b[0m [0.5]\n",
      "recall:    \u001b[31m0.516\u001b[0m [0.52]\n",
      "f1-score:  \u001b[31m0.480\u001b[0m [0.48]\n",
      "\u001b[33m4\u001b[0m\n",
      "precision: \u001b[31m0.621\u001b[0m [0.62]\n",
      "recall:    \u001b[31m0.690\u001b[0m [0.69]\n",
      "f1-score:  \u001b[31m0.559\u001b[0m [0.56]\n",
      "\u001b[33m5\u001b[0m\n",
      "precision: \u001b[31m0.508\u001b[0m [0.51]\n",
      "recall:    \u001b[31m0.629\u001b[0m [0.63]\n",
      "f1-score:  \u001b[31m0.434\u001b[0m [0.43]\n",
      "\u001b[33m6\u001b[0m\n",
      "precision: \u001b[31m0.549\u001b[0m [0.55]\n",
      "recall:    \u001b[31m0.634\u001b[0m [0.63]\n",
      "f1-score:  \u001b[31m0.381\u001b[0m [0.38]\n",
      "\u001b[33m7\u001b[0m\n",
      "precision: \u001b[31m0.590\u001b[0m [0.59]\n",
      "recall:    \u001b[31m0.636\u001b[0m [0.64]\n",
      "f1-score:  \u001b[31m0.501\u001b[0m [0.5]\n",
      "\u001b[33m8\u001b[0m\n",
      "precision: \u001b[31m0.595\u001b[0m [0.59]\n",
      "recall:    \u001b[31m0.794\u001b[0m [0.79]\n",
      "f1-score:  \u001b[31m0.583\u001b[0m [0.58]\n",
      "\u001b[33m9\u001b[0m\n",
      "precision: \u001b[31m0.529\u001b[0m [0.53]\n",
      "recall:    \u001b[31m0.555\u001b[0m [0.56]\n",
      "f1-score:  \u001b[31m0.444\u001b[0m [0.44]\n"
     ]
    }
   ],
   "source": [
    "for key_i, value in fold_results.items():\n",
    "    if isinstance(value, dict):\n",
    "        for key_j, __data in value.items():\n",
    "            if key_j == 'overall':\n",
    "                logger.info(Fore.YELLOW + f\"{key_i}\" + Style.RESET_ALL)\n",
    "                logger.info(\"precision: \" + Fore.RED +\n",
    "                            \"{:.3f}\".format(np.mean(__data['precision'])) + Style.RESET_ALL +\n",
    "                           f\" {str([round(x, 2) for x in __data['precision']])}\")\n",
    "                logger.info(\"recall:    \" + Fore.RED +\n",
    "                            \"{:.3f}\".format(np.mean(__data['recall'])) + Style.RESET_ALL+\n",
    "                           f\" {str([round(x, 2) for x in __data['recall']])}\")\n",
    "                logger.info(\"f1-score:  \" + \n",
    "                            Fore.RED + \"{:.3f}\".format(np.mean(__data['fscore'])) + Style.RESET_ALL+\n",
    "                           f\" {str([round(x, 2) for x in __data['fscore']])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCaching results\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(Fore.YELLOW + \"Caching results\" + Style.RESET_ALL)\n",
    "with open('bert_ds_android_pyramid.json', 'w') as fo:\n",
    "    json.dump(fold_results, fo, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', 'venn_diagram_set', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for source in df_test[\"source\"].unique():\n",
    "#     df_source = df_test[df_test[\"source\"] == source]   \n",
    "#     logger.info(source)\n",
    "#     test_model(source, df_source, model, tokenizer, pos_filter=True)\n",
    "#     cnt += 1\n",
    "#     if cnt >= 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cYVkKLe-B1j0"
   },
   "outputs": [],
   "source": [
    "#@title Metrics report\n",
    "# logger.info(json.dumps(fold_results, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(api_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"API metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(so_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"SO metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(git_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"GIT metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(misc_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"MISC metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "zUOGnWgIMYLN"
   },
   "outputs": [],
   "source": [
    "def examples_per_source_type(source_type='misc', n_samples=None):\n",
    "    _sources = list(set([x[0] for x in log_examples_lst]))\n",
    "\n",
    "    _template = \"[w={}]\" + Fore.RED + \"[y={}]\" + Fore.YELLOW + \"[p={:.4f}]\" + Style.RESET_ALL + \" {}\"\n",
    "\n",
    "    idx = 0\n",
    "    for s in _sources:\n",
    "        examples_in_source = []\n",
    "        if source_type == 'api' and ('docs.oracle' in s or 'developer.android' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'so' and ('stackoverflow.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]            \n",
    "            idx += 1\n",
    "        elif source_type == 'git' and ('github.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'misc' and 'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        if not examples_in_source:\n",
    "            continue\n",
    "        logger.info('')\n",
    "        logger.info(Fore.RED + f\"{task_title}\" + Style.RESET_ALL)    \n",
    "        logger.info(s)\n",
    "        logger.info('')\n",
    "\n",
    "        for _, _, pweights, y_predict, y_probs, text in examples_in_source:\n",
    "            logger.info(_template.format(pweights, y_predict, y_probs, text))\n",
    "            logger.info('')\n",
    "        logger.info('-' * 20)\n",
    "      \n",
    "        if n_samples and idx >= n_samples:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Fjg9kKaDM0fo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAPI\u001b[0m\n",
      "\n",
      "\u001b[31mHilt: How to prevent Hilt from picking dependency from a library?\u001b[0m\n",
      "https://developer.android.com/training/dependency-injection/hilt-android\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7789]\u001b[0m Using Hilt in your Android app\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7788]\u001b[0m In that case, you need to tell Hilt how to provide two different implementations of OkHttpClient.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7783]\u001b[0m It also includes a demonstration of how to bootstrap an existing app to use Hilt.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7777]\u001b[0m The Hilt module AnalyticsModule is annotated with @InstallIn ( ActivityComponent:: class ) because you want Hilt to inject that dependency into ExampleActivity.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7768]\u001b[0m @HiltAndroidApp triggers Hilt's code generation, including a base class for your application that serves as the application-level dependency container.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7766]\u001b[0m Hilt reduces the boilerplate code that is involved in using Dagger in an Android application.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7749]\u001b[0m However, in most cases it is best to use Hilt to manage all of your usage of Dagger on Android.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7748]\u001b[0m Hilt is a dependency injection library for Android that reduces the boilerplate of doing manual dependency injection in your project.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7744]\u001b[0m To migrate a project that uses Dagger to Hilt, see the migration guide and the Migrating your Dagger app to Hilt codelab.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7741]\u001b[0m For each Android class in which you can perform field injection, there's an associated Hilt component that you can refer to in the @InstallIn annotation.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mAndroid SQLite performance in complex queries\u001b[0m\n",
      "https://developer.android.com/training/data-storage/sqlite\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7752]\u001b[0m The APIs you'll need to use a database on Android are available in the android.database.sqlite package.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7726]\u001b[0m This page assumes that you are familiar with SQL databases in general and helps you get started with SQLite databases on Android.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7723]\u001b[0m The Android SDK includes a sqlite3 shell tool that allows you to browse table contents, run SQL commands, and perform other useful functions on SQLite databases.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7692]\u001b[0m As your data graph changes, you need to update the affected SQL queries manually.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7690]\u001b[0m For example, here's an implementation of SQLiteOpenHelper that uses some of the commands shown above:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7663]\u001b[0m It's not required, but this can help your database work harmoniously with the Android framework.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7657]\u001b[0m To access your database, instantiate your subclass of SQLiteOpenHelper:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7645]\u001b[0m To use SQLiteOpenHelper, create a subclass that overrides the onCreate ( ) and onUpgrade ( ) callback methods.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7635]\u001b[0m You need to use lots of boilerplate code to convert between SQL queries and data objects.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7628]\u001b[0m There is no compile-time verification of raw SQL queries.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for API sources\n",
    "\n",
    "logger.info(Fore.RED + \"API\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='api', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FDBgOWQXNW1i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mGIT\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for GIT sources\n",
    "\n",
    "logger.info(Fore.RED + \"GIT\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='git', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "G4Bqx8AbNoV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSO\u001b[0m\n",
      "\n",
      "\u001b[31mAndroid SQLite performance in complex queries\u001b[0m\n",
      "https://stackoverflow.com/questions/4015026\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7741]\u001b[0m If you have more complex queries that can't make use of any indexes that you might create, you can de-normalize your schema, structuring your data in such a way that the queries are simpler and can be answered using indexes.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7725]\u001b[0m Using both WHERE predicates and ORDER BY both require an index and SQLite can only use one, so that can be a point where performance suffers.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7700]\u001b[0m Use EXPLAIN QUERY PLAN on your queries to see which index would be used or if the query requires a full table scan.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7697]\u001b[0m Pin down exactly which queries you need to optimize.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7692]\u001b[0m SQLite LINK using savepoints, but I'm not sure that you'll gain anything there performance-wise.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7691]\u001b[0m Use ANALYZE to allow SQLite's query planner to work more efficiently.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7687]\u001b[0m There is a LINK for optimizing SQLite in general in the SQLite documentation.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7659]\u001b[0m Grab a copy of a typical database and use the REPL to time queries.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7602]\u001b[0m Only one index will be used on any given query.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7597]\u001b[0m You can have indexes that contain multiple columns -LRB- to assist queries with multiple predicates -RRB-.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mCustom Annotations in Retrofit 2.0\u001b[0m\n",
      "https://stackoverflow.com/questions/47760861\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7750]\u001b[0m While if you do not insist on custom annotations, the easiest way for now in my opinion is to add custom header to the api interface, then read and remove it in the interceptor.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7737]\u001b[0m Since the version of Retrofit 2.6.0, you can get the annotations in OkHttp Interceptor using the tag field like this:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7721]\u001b[0m What you need to do is have two OkHttp clients, with their respective instances of Retrofit.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7715]\u001b[0m We'll use the gson converter -LRB- GsonConverterFactory -RRB- provided by Retrofit and modify it slightly to include a listener in GsonResponseBodyConverter.class which handles the http response parsing.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7692]\u001b[0m Retrofit Changelog:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7680]\u001b[0m Interceptors are concepts that exist in OkHttp, Retrofit knows nothing about them.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7661]\u001b[0m We read the annotation in the CallAdapter.Factory and when the request gets created in the CallAdapter, we will store some information for this kind of request within some map, to identify it later in some interceptor.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7561]\u001b[0m Then inside of the interceptor, you can verify if the request is annotated or no.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7553]\u001b[0m It uses a custom CallAdapter to get annotation @Authenticated, and put data into a map, which later parsed in the Interceptor.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7393]\u001b[0m I have similar requirement, what I found is Annotation can be read in LINK, LINK and LINK.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mAndroid App Retrieve Data from Server but in a Secure way\u001b[0m\n",
      "https://stackoverflow.com/questions/8184492\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7345]\u001b[0m This link from Android developers site advice you some of the good tips for security - LINK\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7259]\u001b[0m But still there are many vulnerabilities are possible by poor design of the apps.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6311]\u001b[0m Use SSL on HTTPS to transfer data instead of HTTP you need to setup the certificates on the webserver not very sure how it works.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.5869]\u001b[0m First of all, always use HTTPS.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5518]\u001b[0m As for storing data in the app what you can encrypt the data before storing or you can use another format other than SQLite for better security as you can view sqlite databases using the browser pretty easily.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for SO sources\n",
    "\n",
    "logger.info(Fore.RED + \"SO\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='so', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2_mgLqe0N-hs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mMISC\u001b[0m\n",
      "\n",
      "\u001b[31mHilt: How to prevent Hilt from picking dependency from a library?\u001b[0m\n",
      "https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.7813]\u001b[0m How to make a dependency injectable To make an object embeddable in Hilt, you need to tell Hilt how to instantiate that object.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7790]\u001b[0m You don't need to do anything else, and you don't need to call Hilt directly.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7787]\u001b[0m These classes are entry points into the Hilt dependency graph, and Hilt needs to know that they have dependencies to inject.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7785]\u001b[0m Setting up Hilt To set up Hilt in your application, first follow the directions from the guide: Installing Gradle Build ...\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7768]\u001b[0m Hilt module Think of it as a set of `` recipes'' that tell Hilt how to instantiate something that doesn't have a constructor, such as an interface or a system service.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7759]\u001b[0m This tutorial describes the basic functionality of the library and provides some code snippets to help you get started using Hilt in your projects.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7758]\u001b[0m There are three ways to define anchor in Hilt.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7733]\u001b[0m An easy way to use dependency injection in Android apps Hilt Is a new library for dependency injection built on top of Dagger ... It allows you to use Dagger's capabilities in Android apps in a simplified way.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7720]\u001b[0m A good example of this is activities that are normally generated by the Android platform, not by the Hilt library.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7703]\u001b[0m â®• As constructor parameters If you mark the constructor with annotation @Inject, Hilt will implement all the parameters according to the bindings you define for these types.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mAndroid App Retrieve Data from Server but in a Secure way\u001b[0m\n",
      "https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7110]\u001b[0m So this way the hacker who is sniffing our requests wouldn't know what we are doing and what information are we sending so they can't go ahead and make fake requests.But the new problem here is that decompiling an Android application isn't that hard, actually it's pretty easy.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6886]\u001b[0m How to Send a Semi Secure Request to a Server in AndroidReza BigdeliJan 14, 2016 Â· 5 min read\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6562]\u001b[0m How to Send a Semi Secure Request to a Server in AndroidReza BigdeliJan 14, 2016 Â· 5 min readDisclaimer: This article is written a couple of years ago.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for MISC sources\n",
    "\n",
    "logger.info(Fore.RED + \"MISC\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='misc', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m174 entries VENN SET\u001b[0m\n",
      "Respect the property whether the document would like to be scaled for printing as per shouldScaleForPrinting ( ).\n",
      "You can read more about this on the material design guidelines which state: `` The use of application icon plus title as a standard layout is discouraged on API 21 devices and newer.''\n",
      "One thing that I ran across when I applied this approach to my production code is that you still need to keep the @JsonSubtypes annotation as part of the Base class.\n",
      "In order to change preview orientation as the user re-orients the phone, within the surfaceChanged ( ) method of your preview class, first stop the preview with Camera.stopPreview ( ) change the orientation and then start the preview again with Camera.startPreview ( ).\n",
      "In addittion, you can do in a Fragment -LRB- for example when getting server data failed -RRB-:\n",
      "Next, you'll need to initiate the permission request and handle the result.\n",
      "If you would like an application icon -LRB- but I discourage it -RRB-, you can use the method setLogo -LRB- -RRB-.\n",
      "To read from a database, use the query ( ) method, passing it your selection criteria and desired columns.\n",
      "Here is a LINK on how to record audio using the LINK.\n",
      "When setting preview size, you must use values from getSupportedPreviewSizes ( ).\n",
      "The cool thing about the new Google Recaptcha is that the validation is now completely encapsulated in the widget.\n",
      "The simplest adapter to use is called an ArrayAdapter because the adapter converts an ArrayList of objects into View items loaded into the ListView container.\n",
      "Set the audio encoder using setAudioEncoder ( ).\n",
      "Now Android allows you to decide which permissions to accept on a case-by-case basis -- after the app is installed.\n",
      "If you declare any dangerous permissions, and if your app is installed on a device that runs Android 6.0 ( API level 23 ) or higher, you must request the dangerous permissions at runtime by following the steps in this guide.\n",
      "I am using mic to record calls for better support and compatibility.\n",
      "If you don't declare any dangerous permissions, or if your app is installed on a device that runs Android 5.1 ( API level 22 ) or lower, the permissions are automatically granted, and you don't need to complete any of the remaining steps on this page.\n",
      "Unscoped dependency will have simple Provider generated without any caching and any instance of that dependency created in component will be new for every new injection -LRB- as in constructor, or in module provision method, or just as a field -RRB-.\n",
      "You can develop these things yourself, but if you would like to use a pre-made custom view, copy LINK into your project and use it like a normal ImageView.\n",
      "That is because, when your app starts, the ViewPager displays the movie at index 0.\n",
      "Wait for the user to invoke the task or action in your app that requires access to specific private user data.\n",
      "The naive approach to this ( without any view caching ) looks like the following:\n",
      "You can either rotate your bitmap when you draw it by using a matrix:\n",
      "get a seekable file descriptor from your pdf document:\n",
      "If you have more complex queries that can't make use of any indexes that you might create, you can de-normalize your schema, structuring your data in such a way that the queries are simpler and can be answered using indexes.\n",
      "Make a Snackbar to display a message.\n",
      "Beginning in Android 6.0 -LRB- API level 23 -RRB-, users grant permissions to apps while the app is running, not when they install the app.\n",
      "The important thing to keep in mind is that fragments should not directly communicate with each other and should generally only communicate with their parent activity.\n",
      "In Android development, any time we want to show a vertical list of scrollable items we will use a ListView which has data populated using an Adapter.\n",
      "If so, your app can access the private user data.\n",
      "At that time, your app can request the runtime permission that's required for accessing that data.\n",
      "dataSpec.length is the length of data that the caller wants to read, or C.LENGTH _ UNSET to read to the end of the media.\n",
      "Get the data item associated with the specified position in the data set.\n",
      "The first step when adding a `` Runtime Permission'' is to add it to the AndroidManifest:\n",
      "Set the audio source using setAudioSource ( ).\n",
      "This becomes a problem specifically when seeking, because dataSpec.position will not be 0 in this case, yet your implementation will nevertheless read from the start of the media.\n",
      "How to make a dependency injectable To make an object embeddable in Hilt, you need to tell Hilt how to instantiate that object.\n",
      "If you are using this class to rasterize a PDF for printing or show a print preview, it is recommended that you respect the following contract in order to provide a consistent user experience when seeing a preview and printing, i.e. the user sees a preview that is the same as the printout.\n",
      "Do not inset the content with any margins from the PrintAttributes as the application is responsible to render it such that the margins are respected.\n",
      "Before using the reCAPTCHA API, you need to add the SafetyNet API to your project.\n",
      "A Toolbar is a generalization of action bars for use within application layouts.\n",
      "Here you define what information shows and where it sits within the ListView.\n",
      "Pin down exactly which queries you need to optimize.\n",
      "Use android: fitsSystemWindows = `` true'' in the root view of your layout -LRB- LinearLayout in your case -RRB-.\n",
      "Something like this:\n",
      "In your app's manifest file, declare the permissions that your app might need to request.\n",
      "If the user granted the permission to your app, you can access the private user data.\n",
      "Call this method, passing in the outer most ViewGroup that you want a screen shot of:\n",
      "This line means: add a meta-property on serialization or read a meta-property on deserialization -LRB- include = JsonTypeInfo.As.PROPERTY -RRB- called'' @class'' -LRB- property ='' @class'' -RRB- that holds the fully-qualified Java class name -LRB- use = JsonTypeInfo.Id.CLASS -RRB-.\n",
      "The following code snippet demonstrates how to request a permission using a request code:\n",
      "We can do that using the @JsonTypeInfo and @JsonSubTypes annotations.\n",
      "basically I used a private string property taken as a string to construct a computed property with that enum correspondance.\n",
      "It wasn't until I moved the * uses-permission ... READ_CONTACTS * line to outside the application tag that things worked.\n",
      "Improving Performance with the ViewHolder Pattern To improve performance, we should modify the custom adapter by applying the ViewHolder pattern which speeds up the population of the ListView considerably by caching view lookups for smoother, faster item loading:\n",
      "If the user presses and holds the button, then onKeyDown ( ) is called multiple times.\n",
      "While developing for a target platform of 2.3.3 using Eclipse on Ubuntu, I had permission failures in the log file that indicated I needed this exact line while working on something similar.\n",
      "It should hopefully be clear that if dataSpec.position is non-zero, readPosition = mediaPosition + dataSpec.position ( correct ) is going to end up reading from a different position than readPosition = mediaPosition ( incorrect ).\n",
      "To be able to record, your app must tell the user that it will access the device's audio input.\n",
      "Check the user's response, whether they chose to grant or deny the runtime permission.\n",
      "Users can use the system settings to choose the level of detail visible in lock screen notifications, including the option to disable all lock screen notifications.\n",
      "The error message you are getting appears to be due to dubiously-legal JSON, particularly on the receiving side:\n",
      "A camera preview class is a SurfaceView that can display the live image data coming from a camera, so users can frame and capture a picture or video.\n",
      "I created a ViewPager that supports infinite looping effect, smart auto-scroll, compatible with any indicators and easy to use.\n",
      "As getView is call many times inflating a new view every time is expensive so list view provides you one of the previously created view to re-use.\n",
      "to this approach instead leveraging add, show, and hide in the FragmentTransaction:\n",
      "Finally, getView ( ) creates a view to be used as a row in the list.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layout_gravity is the way the TextView will align itself in its parent, in your case in the vertical LinearLayout\n",
      "If it is not null then we have a recycled View and can just change its values, otherwise we need to create a new row View.\n",
      "Then inside of the interceptor, you can verify if the request is annotated or no.\n",
      "First of all your Animal class with the Json Annotations for the subclasses.\n",
      "When a scale -LRB- ie, pinch -RRB- gesture is detected, then the scale factor is used to resize the ImageView.\n",
      "If you have a lot of string / text type data, consider creating Virtual tables using full text search -LRB- FTS3 -RRB-, which can run faster query.\n",
      "We use a ScaleGestureDetector on the activity to listen to touch events.\n",
      "Every android app has its own internal storage only that app can access, you can read from there or write to it.\n",
      "Therefore, Android will always ask you to approve dangerous permissions.\n",
      "Check out this stackoverflow for a discussion on deciding when to replace vs hide and show.\n",
      "Try to check below FragmentPagerAdapter to get endless viewpager adapter:\n",
      "This is designed to prevent apps from eavesdropping on telephone conversations.\n",
      "Java 8 -LRB- LINK -RRB- solves this problem using streams and lambdas in one line of code:\n",
      "But the easiest option is to generate java code directly and your generated java classes will be picked up by javac automatically, launching second round of annotation processing, where dagger will process them.\n",
      "Here's a bit of code to get EXPLAIN QUERY PLAN results into Android logcat from a running Android app.\n",
      "It is worth noting that apparently Dagger2 creates a single instance per scoped provider in a module per component.\n",
      "The CompletionStage API lets programmers define pipelines of asynchronous operations for data, and handles the asynchronous behaviour for you.\n",
      "I haven't tried recording phone call's but there is a option in LINK for:\n",
      "To handle an individual key press, implement onKeyDown ( ) or onKeyUp ( ) as appropriate.\n",
      "You may extend it from BaseAdapter.\n",
      "This bug incorrectly sets the drawable bounds to 0 -LRB- or negative in the case of an inset drawable -RRB-.\n",
      "If document page size is greater than the printed media size the content should be anchored to the upper left corner of the page for left-to-right locales and top right corner for right-to-left locales.\n",
      "And this code snippet demonstrates the recommended process of checking for a permission, and requesting a permission from the user when necessary:\n",
      "We instantiate a new LocationRequest object.\n",
      "Although the icon can be added back with:\n",
      "Using of rawQuery -LRB- -RRB- instead of building using ContentValues will fasten up in certain cases.\n",
      "Use EXPLAIN QUERY PLAN on your queries to see which index would be used or if the query requires a full table scan.\n",
      "These repeated calls can seriously harm the ListView's performance, especially if your app is running on limited resources and/or you have a very large list.\n",
      "The TextView being in wrap_content this does nothing, as the TextView is exactly the size of the text.\n",
      "reCAPTCHA is a free service that uses an advanced risk analysis engine to protect your app from spam and other abusive actions.\n",
      "Use ANALYZE to allow SQLite's query planner to work more efficiently.\n",
      "with the api 23, permission <uses-permissionÂ android:name=\"android.pemission.READ_CONTACTS\"/> dont work, change the api level in the emulator for api 22 -LRB- lollipop -RRB- or lower\n",
      "You can also do it by rotating the canvas before drawing:\n",
      "you should try this:\n",
      "So the correct way to do this is:\n",
      "GoogleApiClient FusedLocationProviderApi requires the GoogleApiClient instance to get the Location and it can be obtained as below.\n",
      "PdfRenderer -- This class enables rendering a PDF document.\n",
      "Javac annotation processor uses rounds instead of defining processors order.\n",
      "This document shows you how to use MediaRecorder to write an application that captures audio from a device microphone, save the audio, and play it back ( with MediaPlayer ).\n",
      "You can avoid this problem by using the View Holder Pattern.\n",
      "Don't mess with the visibility flags of the container - FragmentTransaction.hide / show does that internally for you.\n",
      "In the meantime I think that you will need to annotate your child classes with @JsonTypeInfo and @JsonSubTypes to override the inherited annotations.\n",
      "Listening for Location Updates After you invoke `` getLastLocation'', you might want to request periodic updates from the Fused Location Provider.\n",
      "Continuous Location Access Activity Following is the complete class which accesses the Fused Location Provider to get the location continuously in the Android example application.\n",
      "it is used for the Android Music Remote control even if the App is in Lock mode.\n",
      "I am using mic to record phone audio and also use the Telephony manager to find the calling state.\n",
      "These are permissions that are requested while the app is running ( instead of before the app is installed ).\n",
      "and in the LinearLayout, the default gravity -LRB- used here -RRB- is ` center'\n",
      "That means, that the widget will take care of asking questions, validating responses all the way till it determines that a user is actually a human, only then you get a g-recaptcha-response value.\n",
      "The results of the query are returned to you in a Cursor object.\n",
      "When scaling a document for printing the aspect ratio should be preserved.\n",
      "inject.Scope annotation - Dependencies declared with that scope with have caching Provider with double-check lock generated and only single instance will be created for it within component declared with the same scope and its creation will be thread safe.\n",
      "To register a key pair for use with the SafetyNet reCAPTCHA API, navigate to the reCAPTCHA Android signup site, then complete the following sequence of steps:\n",
      "I would suggest that you write your downloaded JSON out to a file and compare it with your original to see if there is a problem with the download logic.\n",
      "After that override getView -LRB- -RRB- method and make sure to return your custom View there.\n",
      "However, in many cases, we may want to keep both fragments around in the container and simply toggle their visibility.\n",
      "Consider the following below: If you have a JSON object for `` Vehicle'', it could be a `` Car'' or `` Plane'', each with its own fields, some unique to the other.\n",
      "Starting with Android 8.0, users can choose to disable or enable lock screen notifications for each notification channel.\n",
      "It returns View that will be displayed as your list/grid/gallary / any view that use adapter item.\n",
      "Now add the following code in your PdfRenderActivity -- 7.\n",
      "The following code snippet shows how to handle the permissions response:\n",
      "You set this text view a width of `` wrap_content'' it means, what ever the text is, the view take the size of the text.\n",
      "Check whether the user has already granted the runtime permission that your app requires.\n",
      "To fix this issue, open MainActivity.kt and add the following line inside onCreate ( ) below the line where you connect the PageAdapter to the ViewPager:\n",
      "Usually these are the following steps to create json object through the Http connection in android.\n",
      "This class enables rendering a PDF document.\n",
      "If you want to render a PDF, you create a renderer and for every page you want to render, you open the page, render it, and close the page.\n",
      "Gets a View that displays in the drop down popup the data at the specified position in the data set.\n",
      "It is possible that the JSONObject parser has been made more lenient in newer Android releases.\n",
      "The Dagger basics page explained how Dagger can help you automate dependency injection in your app.\n",
      "The dataSpec argument is not defining the entire media.\n",
      "This may boost your phone speed, but it will lead to delayed or no notifications from your apps.\n",
      "You also inflate a custom view from the XML layout defined in res/layout/list_item_recipe.xml -- more on this in the next section.\n",
      "This tells the ViewPager to display the movie found in the middle of the array.\n",
      "that is done because rotation is around the top left point ( the origin ) of the view.\n",
      "The magic behind this is the setTag ( ) method which lets us attach an arbitrary object onto a View object, which is how we save the already inflated View for future reuse.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gravity is the way the text will align itself in the TextView.\n",
      "A typical use of the APIs to render a PDF looks like this:\n",
      "Make sure you have the icon set in the manifest.xml file, in the application tag as:\n",
      "So normally the simplified algorithm is like that:\n",
      "To do this, we need to create our own custom ArrayAdapter class.\n",
      "If your app needs to use resources or information outside of its own sandbox, you can declare a permission and set up a permission request that provides this access.\n",
      "Make a Snackbar to display a message\n",
      "The more indexes you have, the slower your INSERTs will be, so you will have to work out the best trade-off for your situation.\n",
      "During deserialization, you would want Jackson to deserialize the `` Vehicle'' JSON object to the appropriate `` Car'' or `` Plane'' class.\n",
      "You must check whether you have that permission every time you perform an operation that requires that permission.\n",
      "Since the version of Retrofit 2.6.0, you can get the annotations in OkHttp Interceptor using the tag field like this:\n",
      "We can create a custom ListView of User objects by subclassing ArrayAdapter to describe how to translate the object into a view within that class and then using it like any other adapter.\n",
      "And replace the response_string with the value that you earlier got by the g-recaptcha-response field.\n",
      "So in order to get a scoped provider in a module, you need to specify the scope for your module's provider method.\n",
      "It triggers when you scroll the view -LRB- list for example -RRB-.\n",
      "We check if a View is recycled with if ( convertView == null ).\n",
      "For SELECTs and UPDATEs, indexes can things up, but only if the indexes you create can actually be used by the queries that you need speeding up.\n",
      "So ideally we also would have an easy way of processing an array of businesses into an ArrayList of Business objects.\n",
      "Those recording sources may only be used by system apps.\n",
      "Dangerous permission groups, however, can give apps access to things like your calling history, private messages, location, camera, microphone, and more.\n",
      "Anyone with HTTP POST knowledge could put random data inside of the g-recaptcha-response form field, and foll your site to make it think that this field was provided by the google widget.\n",
      "However, in the API response, we actually get a collection of business JSON in an array.\n",
      "Fragment Hiding vs Replace In many of the examples above, we call transaction.replace ( ... ) to load a dynamic fragment which first removes the existing fragment from the activity invoking onStop and onDestroy for that fragment before adding the new fragment to the container.\n",
      "As you can see, there is nothing special for Cat and Dog, the only one that know about them is the abstract class Animal, so when deserializing, you'll target to Animal and the ObjectMapper will return the actual instance as you can see in the following test:\n",
      "Get a View that displays the data at the specified position in the data set.\n",
      "Using this approach, all three fragments will remain in the container once added initially and then we are simply revealing the desired fragment and hiding the others within the container.\n",
      "Ask for permissions in context, when the user starts to interact with the feature that requires it.\n",
      "It works kind of like this: The ListView asks the adapter what it should display, and the adapter jumps into action:\n",
      "Starting in Android 2.2 ( API Level 8 ), you can use the setDisplayOrientation ( ) method to set the rotation of the preview image.\n",
      "A reference to the parent view that this view will be a child of.\n",
      "In you case, you first want to check if you such file exist before creating one.\n",
      "Using a Custom ArrayAdapter When we want to display a series of items from a list using a custom representation of the items, we need to use our own custom XML layout for each item.\n"
     ]
    }
   ],
   "source": [
    "logger.info(Fore.RED + f\"{len(fold_results['venn_diagram_set'])} entries VENN SET\" + Style.RESET_ALL)\n",
    "for _t in fold_results['venn_diagram_set']:\n",
    "    logger.info(_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM51gMzrDUJf4OiiaquqBe4",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hugging-face-keras-bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7 Arthur hugging",
   "language": "python",
   "name": "msarthur-hface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03ddd131c9f0446eb83bb6dabee9a832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3518f71b0e4540be8b17a3fe72182cb4",
       "IPY_MODEL_a5ccb838d3704546937e925e456830be",
       "IPY_MODEL_8181fd24b3624c1b9c6a9d0302f43a56"
      ],
      "layout": "IPY_MODEL_f02cf8090f8d463eb7eeb59743a87276"
     }
    },
    "0466163ff4a945798423387d1ac900c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0efe94b613f44c029f2e9bd05696ad32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3e13535de4b44bb9139c3911684cee8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6ccdfb754c12418c9438ac218a172e63",
      "value": "Downloading: 100%"
     }
    },
    "153c3ed5c6314a49a5a37ad976417142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_262cc50dd08f49f78b781c2ce96a4ad7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f305b344487a4b598a7d41b007e49abd",
      "value": " 232k/232k [00:00&lt;00:00, 286kB/s]"
     }
    },
    "16b6cfa829ad43778c079452df231a3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17cfaa41c53842618c728987a81a44da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fc2d9969ea34bb3bb6e9f0260c2a75c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23531989ef014d7db16b220bb807c8fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "262cc50dd08f49f78b781c2ce96a4ad7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3518f71b0e4540be8b17a3fe72182cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9ef3ce0ace649c5a53e2244ba0dbb32",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_702a74b6e6e44d6b8ad68347f1a4b5fb",
      "value": "Downloading: 100%"
     }
    },
    "35a9eeb0acdb44738a6ad7fbf6d99b2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3950e2a7832c4dce8fd8209d6322a1f7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d32667132d604faeb419bbf9851c1bd8",
      "value": 231508
     }
    },
    "394b7988d36849b7b2c82872ae8d489d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3950e2a7832c4dce8fd8209d6322a1f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ccd384305c44ee3a86f47a2b994fbf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d84c022c44141268ef2c8d5e0190404": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40c212c9b352401697860624a6c54b1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4bd0f4c575714ad7848e818a576ee00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a38bc7017d545e2b44ad6ab0b2d937b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_929799bd24fb411bb4686988f2ae8996",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bd0f4c575714ad7848e818a576ee00a",
      "value": 570
     }
    },
    "5c6bfb038756422bb00be1349db7750b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c586016d3b594c6299cab2384f4c10aa",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d03c894896ad4ed6b48f19a70fbdf2af",
      "value": 466062
     }
    },
    "67f208ba489343dfa195c1dd915f3efe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16b6cfa829ad43778c079452df231a3d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a2a36eb594654c65acd584d9d4ebea20",
      "value": "Downloading: 100%"
     }
    },
    "6ccdfb754c12418c9438ac218a172e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cf29b5d508a4e2082751ccc7fa2f625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ccd384305c44ee3a86f47a2b994fbf9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_23531989ef014d7db16b220bb807c8fd",
      "value": " 466k/466k [00:00&lt;00:00, 637kB/s]"
     }
    },
    "702a74b6e6e44d6b8ad68347f1a4b5fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71a15c5a038f451f8ee64ce046488f71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8181fd24b3624c1b9c6a9d0302f43a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_911177bb86c749a0bd774cd3b7f9d302",
      "value": " 536M/536M [00:12&lt;00:00, 40.9MB/s]"
     }
    },
    "82b7fc20b50c44b2bd84b3bf882cdd43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c2b37becdef45bba205dfb20f8e37b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4276b6a5eac4023955218db6f78c84a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c4b0a1b67d304afda6ee4e52095584cc",
      "value": " 28.0/28.0 [00:00&lt;00:00, 631B/s]"
     }
    },
    "8c7cf993674145ffb7bb876e5591f6ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67f208ba489343dfa195c1dd915f3efe",
       "IPY_MODEL_35a9eeb0acdb44738a6ad7fbf6d99b2b",
       "IPY_MODEL_153c3ed5c6314a49a5a37ad976417142"
      ],
      "layout": "IPY_MODEL_82b7fc20b50c44b2bd84b3bf882cdd43"
     }
    },
    "901557318fb947dfa082f0cbf2d7365b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0efe94b613f44c029f2e9bd05696ad32",
       "IPY_MODEL_5a38bc7017d545e2b44ad6ab0b2d937b",
       "IPY_MODEL_b3db733aacf94a3c94519d70a7a56d7a"
      ],
      "layout": "IPY_MODEL_394b7988d36849b7b2c82872ae8d489d"
     }
    },
    "911177bb86c749a0bd774cd3b7f9d302": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "929799bd24fb411bb4686988f2ae8996": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "997b8c940317448c9409a2dee15fc519": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e99fb1211ba43459ee78dd64ab8c30e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2a36eb594654c65acd584d9d4ebea20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5ccb838d3704546937e925e456830be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d84c022c44141268ef2c8d5e0190404",
      "max": 536063208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40c212c9b352401697860624a6c54b1c",
      "value": 536063208
     }
    },
    "a66943be0fc0423880cb2bd63a1ea2d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6d9e21208294428a3f5572bbbd8b0b9",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d15e557fc621427a8295eecdc1e781a8",
      "value": 28
     }
    },
    "a8fd8b38a6b84be7b83b2f4df590fada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e99fb1211ba43459ee78dd64ab8c30e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_71a15c5a038f451f8ee64ce046488f71",
      "value": "Downloading: 100%"
     }
    },
    "b12b35cc52454a249c97f695409d24ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3db733aacf94a3c94519d70a7a56d7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0466163ff4a945798423387d1ac900c8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_17cfaa41c53842618c728987a81a44da",
      "value": " 570/570 [00:00&lt;00:00, 17.0kB/s]"
     }
    },
    "b4276b6a5eac4023955218db6f78c84a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d9e21208294428a3f5572bbbd8b0b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baffabe6cabf48f5b0b6523ea92aee78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18a3a9fc6d54b9f848e4454e1e36c21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8fd8b38a6b84be7b83b2f4df590fada",
       "IPY_MODEL_5c6bfb038756422bb00be1349db7750b",
       "IPY_MODEL_6cf29b5d508a4e2082751ccc7fa2f625"
      ],
      "layout": "IPY_MODEL_c4c410ab0c994a229a49b8baee221de4"
     }
    },
    "c4b0a1b67d304afda6ee4e52095584cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4c410ab0c994a229a49b8baee221de4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c586016d3b594c6299cab2384f4c10aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5b9bf1f3ae343ce97982c7802cfdc94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_997b8c940317448c9409a2dee15fc519",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b12b35cc52454a249c97f695409d24ce",
      "value": "Downloading: 100%"
     }
    },
    "c9ef3ce0ace649c5a53e2244ba0dbb32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d03c894896ad4ed6b48f19a70fbdf2af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d15e557fc621427a8295eecdc1e781a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d32667132d604faeb419bbf9851c1bd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3e13535de4b44bb9139c3911684cee8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0e88103f9684ffdb957357222bbaaf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5b9bf1f3ae343ce97982c7802cfdc94",
       "IPY_MODEL_a66943be0fc0423880cb2bd63a1ea2d2",
       "IPY_MODEL_8c2b37becdef45bba205dfb20f8e37b2"
      ],
      "layout": "IPY_MODEL_baffabe6cabf48f5b0b6523ea92aee78"
     }
    },
    "f02cf8090f8d463eb7eeb59743a87276": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f305b344487a4b598a7d41b007e49abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
