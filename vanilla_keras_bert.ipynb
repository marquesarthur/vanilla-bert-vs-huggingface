{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marquesarthur/vanilla-bert-vs-huggingface/blob/main/vanilla_keras_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfNydjdoLcvK"
   },
   "source": [
    "Based on https://colab.research.google.com/drive/14b2rbIgwhQ1BI-zkyiMjQv-jV85xj9tf#scrollTo=5qSd2lLwJ7lH\n",
    "\n",
    "\n",
    "**problem statement:**\n",
    "\n",
    "\n",
    "*   a developer has to inspect an **artifact X**\n",
    "*   Within the artifact, only a portion of the text is relevant to **input task Y**\n",
    "*   We ought to build a model that establishes relationships between Y and sentences x ∈ X \n",
    "*  **The model must determine if x is relevant to task Y**\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Example of a task and an annotated artifact:*\n",
    "\n",
    "<br>\n",
    "\n",
    "[<img src=\"https://i.imgur.com/Zj1317H.jpg\">](https://i.imgur.com/Zj1317H.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* The coloured sentences are sentences annotated as relevant to the input task. \n",
    "* The warmer the color, the more annotators selected that portion of the text. \n",
    "* For simplicity, we process the data and used sentences \n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Ultimately, our data is a tuple representing:*\n",
    "\n",
    "\n",
    "*   **text** = artifact sentence\n",
    "\n",
    "*   **question** = task description\n",
    "\n",
    "*   **source** = URL of the artifact\n",
    "\n",
    "*   **category_index** = whether sentence is relevant [or not] for the input task\n",
    "\n",
    "*   **weights** = number of participants who annotated sentence as relevant\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## comments unless you run it on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtFJT5AK6RRc",
    "outputId": "0ac0f468-8360-4f02-9696-ee7d3abf8863"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "\n",
    "# !pip install -q keras-bert==0.85.0 keras-rectified-adam==0.15.0\n",
    "# !pip install -q keras-bert keras-rectified-adam\n",
    "# %tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y80jdm9S6wQA",
    "outputId": "b16bed5f-a8a0-45af-b08b-98950f4f8f5e"
   },
   "outputs": [],
   "source": [
    "# !pip install -q scikit-learn tqdm pandas python-Levenshtein path colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q38yIvW87NrN",
    "outputId": "9f3d748a-107f-4653-d145-f0a196173405"
   },
   "outputs": [],
   "source": [
    "# @title Download git repo\n",
    "# !git clone https://github.com/marquesarthur/vanilla-bert-vs-huggingface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyrLR-tf8P4Q",
    "outputId": "e42ead49-9f6b-4eb5-bad8-1ce2982e4b63"
   },
   "outputs": [],
   "source": [
    "# %cd vanilla-bert-vs-huggingface\n",
    "# !git pull\n",
    "# !ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNEueLra68M7",
    "outputId": "f28de7f7-b37c-4f7d-9131-e871975ed7fc"
   },
   "outputs": [],
   "source": [
    "# @title Download BERT model\n",
    "# !wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "# !unzip -o uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kudd2ZR8tKZ",
    "outputId": "532c2b90-b314-4247-dd80-45eddac2a4d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m5 \u001b[33m47 \u001b[0m https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "\u001b[31m9 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/6442054\n",
      "\u001b[31m3 \u001b[33m22 \u001b[0m https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "\u001b[31m22 \u001b[33m211 \u001b[0m https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "\u001b[31m21 \u001b[33m59 \u001b[0m https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "\u001b[31m6 \u001b[33m33 \u001b[0m https://github.com/realm/realm-java/issues/776\n",
      "\u001b[31m9 \u001b[33m15 \u001b[0m https://developer.android.com/training/volley/request\n",
      "\u001b[31m14 \u001b[33m65 \u001b[0m https://stackoverflow.com/questions/28504524\n",
      "\u001b[31m20 \u001b[33m59 \u001b[0m https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "\u001b[31m5 \u001b[33m97 \u001b[0m https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "\u001b[31m17 \u001b[33m33 \u001b[0m https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "\u001b[31m6 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/10108774\n",
      "\u001b[31m5 \u001b[33m470 \u001b[0m https://developer.android.com/reference/android/widget/TextView\n",
      "\u001b[31m7 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/19025301\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/8712652\n",
      "\u001b[31m8 \u001b[33m59 \u001b[0m https://dzone.com/articles/android-rotate-and-scale\n",
      "\u001b[31m39 \u001b[33m129 \u001b[0m https://developer.android.com/training/permissions/requesting\n",
      "\u001b[31m14 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/5233543\n",
      "\u001b[31m4 \u001b[33m34 \u001b[0m https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "\u001b[31m27 \u001b[33m63 \u001b[0m https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "\u001b[31m9 \u001b[33m161 \u001b[0m https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "\u001b[31m4 \u001b[33m12 \u001b[0m https://stackoverflow.com/questions/33241952\n",
      "\u001b[31m8 \u001b[33m95 \u001b[0m https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "\u001b[31m20 \u001b[33m145 \u001b[0m https://developer.android.com/training/dependency-injection/hilt-android\n",
      "\u001b[31m4 \u001b[33m8 \u001b[0m https://stackoverflow.com/questions/30648172\n",
      "\u001b[31m4 \u001b[33m81 \u001b[0m https://github.com/google/dagger/issues/1991\n",
      "\u001b[31m9 \u001b[33m48 \u001b[0m https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "\u001b[31m8 \u001b[33m49 \u001b[0m https://developer.android.com/guide/topics/media/mediarecorder\n",
      "\u001b[31m4 \u001b[33m9 \u001b[0m https://stackoverflow.com/questions/6688444\n",
      "\u001b[31m7 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/8184492\n",
      "\u001b[31m7 \u001b[33m58 \u001b[0m https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "\u001b[31m3 \u001b[33m50 \u001b[0m https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "\u001b[31m19 \u001b[33m250 \u001b[0m https://developer.android.com/guide/topics/media/camera\n",
      "\u001b[31m4 \u001b[33m38 \u001b[0m https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "\u001b[31m3 \u001b[33m56 \u001b[0m https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "\u001b[31m3 \u001b[33m5 \u001b[0m https://stackoverflow.com/questions/38980595\n",
      "\u001b[31m5 \u001b[33m373 \u001b[0m https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "\u001b[31m12 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/35357919\n",
      "\u001b[31m11 \u001b[33m117 \u001b[0m https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "\u001b[31m9 \u001b[33m32 \u001b[0m https://github.com/google/ExoPlayer/issues/8387\n",
      "\u001b[31m3 \u001b[33m36 \u001b[0m https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "\u001b[31m4 \u001b[33m27 \u001b[0m https://stackoverflow.com/questions/24952513\n",
      "\u001b[31m18 \u001b[33m219 \u001b[0m https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "\u001b[31m3 \u001b[33m72 \u001b[0m https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "\u001b[31m4 \u001b[33m131 \u001b[0m https://stackoverflow.com/questions/122105\n",
      "\u001b[31m3 \u001b[33m48 \u001b[0m https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "\u001b[31m5 \u001b[33m28 \u001b[0m https://stackoverflow.com/questions/23844667\n",
      "\u001b[31m5 \u001b[33m45 \u001b[0m https://github.com/flutter/flutter/issues/11392\n",
      "\u001b[31m4 \u001b[33m23 \u001b[0m https://stackoverflow.com/questions/29738510\n",
      "\u001b[31m5 \u001b[33m54 \u001b[0m https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "\u001b[31m7 \u001b[33m70 \u001b[0m https://guides.codepath.com/android/using-the-app-toolbar\n",
      "\u001b[31m8 \u001b[33m147 \u001b[0m https://developer.android.com/training/notify-user/build-notification\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/3059155\n",
      "\u001b[31m13 \u001b[33m69 \u001b[0m https://developer.android.com/training/data-storage/sqlite\n",
      "\u001b[31m15 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/4015026\n",
      "\u001b[31m15 \u001b[33m81 \u001b[0m https://developer.android.com/guide/background/threading\n",
      "\u001b[31m6 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/2993085\n",
      "\u001b[31m11 \u001b[33m50 \u001b[0m https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "\u001b[31m9 \u001b[33m65 \u001b[0m https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "\u001b[31m5 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/24652078\n",
      "\u001b[31m3 \u001b[33m31 \u001b[0m https://stackoverflow.com/questions/47760861\n",
      "\u001b[31m7 \u001b[33m283 \u001b[0m https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "\u001b[31m5 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/37096547\n",
      "\u001b[31m7 \u001b[33m179 \u001b[0m https://guides.codepath.com/android/using-the-recyclerview\n",
      "\u001b[31m10 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/26838730\n",
      "\u001b[31m4 \u001b[33m100 \u001b[0m https://stackoverflow.com/questions/2661536\n",
      "\u001b[31m20 \u001b[33m54 \u001b[0m https://developer.android.com/training/safetynet/recaptcha\n",
      "\u001b[31m11 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/27297067\n",
      "\u001b[31m9 \u001b[33m51 \u001b[0m https://stackoverflow.com/questions/11064244\n",
      "\u001b[31m7 \u001b[33m138 \u001b[0m https://github.com/quarkusio/quarkus/issues/3954\n",
      "\u001b[31m3 \u001b[33m14 \u001b[0m https://developer.android.com/training/keyboard-input/commands\n",
      "\u001b[31m9 \u001b[33m36 \u001b[0m https://developer.android.com/training/location/retrieve-current\n",
      "\u001b[31m5 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/46481789\n",
      "\u001b[31m22 \u001b[33m119 \u001b[0m https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "\u001b[31m15 \u001b[33m99 \u001b[0m https://javapapers.com/android/android-location-fused-provider\n",
      "\u001b[31m8 \u001b[33m44 \u001b[0m https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/2883355\n",
      "\u001b[31m7 \u001b[33m24 \u001b[0m https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "\u001b[31m3 \u001b[33m19 \u001b[0m https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/36275986\n",
      "\u001b[31m42 \u001b[33m177 \u001b[0m https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m16 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/29923376\n",
      "\u001b[31m4 \u001b[33m13 \u001b[0m https://github.com/google/dagger/issues/671\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m3 \u001b[33m4 \u001b[0m https://stackoverflow.com/questions/40168601\n",
      "\u001b[31m6 \u001b[33m72 \u001b[0m https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "\u001b[31m5 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/14347588\n",
      "\u001b[31m31 \u001b[33m163 \u001b[0m https://guides.codepath.com/android/creating-and-using-fragments\n",
      "\u001b[31m7 \u001b[33m146 \u001b[0m https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "\u001b[31m5 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/24313539\n",
      "\u001b[31m12 \u001b[33m77 \u001b[0m https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "\u001b[31m8 \u001b[33m42 \u001b[0m https://stackoverflow.com/questions/30362446\n",
      "\u001b[31m10 \u001b[33m36 \u001b[0m https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "\u001b[31m5 \u001b[33m16 \u001b[0m https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "\u001b[31m20 \u001b[33m196 \u001b[0m https://developer.android.com/training/dependency-injection/dagger-android\n",
      "\u001b[31m6 \u001b[33m44 \u001b[0m https://stackoverflow.com/questions/57235136\n",
      "\u001b[31m24 \u001b[33m121 \u001b[0m https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "\u001b[31m4 \u001b[33m54 \u001b[0m https://developer.android.com/training/gestures/scroll\n",
      "\u001b[31m4 \u001b[33m16 \u001b[0m https://stackoverflow.com/questions/39588322\n",
      "\u001b[31m5 \u001b[33m57 \u001b[0m https://github.com/signalapp/Signal-Android/issues/3376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m22 \u001b[33m104 \u001b[0m https://developer.android.com/reference/org/json/JSONObject\n",
      "\u001b[31m8 \u001b[33m31 \u001b[0m https://guides.codepath.com/android/converting-json-to-models\n",
      "\u001b[31m5 \u001b[33m34 \u001b[0m https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "\u001b[31m4 \u001b[33m40 \u001b[0m https://developer.android.com/training/gestures/scale\n",
      "\u001b[31m6 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/10630373\n",
      "Sample entry from data:\n",
      "{\n",
      "    \"category_index\": 0,\n",
      "    \"question\": \"Explanation of the getView() method of an ArrayAdapter\",\n",
      "    \"source\": \"https://developer.android.com/reference/android/widget/ArrayAdapter\",\n",
      "    \"text\": \"public class ArrayAdapter extends BaseAdapter implements Filterable, ThemedSpinnerAdapter\",\n",
      "    \"weights\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# @title Import data as JSON\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from Levenshtein import ratio\n",
    "from colorama import Fore, Style\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.level = logging.DEBUG\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "from ds_android import get_input_for_BERT\n",
    "\n",
    "raw_data = get_input_for_BERT()\n",
    "\n",
    "print('Sample entry from data:')\n",
    "print(json.dumps(raw_data[0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b_GXczz9CGs",
    "outputId": "15c55b16-5430-4539-dcb3-8d41b3e59e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution\n",
      "\n",
      "not-relevant -- 88%\n",
      "RELEVANT ------ 12%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "cnt = Counter([d['category_index'] for d in raw_data])\n",
    "\n",
    "total = sum(cnt.values())\n",
    "\n",
    "labels_cnt = [cnt[0] / float(total), cnt[1] / float(total)]\n",
    "print('label distribution')\n",
    "print('')\n",
    "print('not-relevant -- {:.0f}%'.format(labels_cnt[0] * 100))\n",
    "print('RELEVANT ------ {:.0f}%'.format(labels_cnt[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1l5DIHP_FUb",
    "outputId": "b580e907-d901-467f-b7d9-9beb42b6f992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating converter from 7 to 5\n",
      "Creating converter from 5 to 7\n",
      "Creating converter from 7 to 5\n",
      "Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "# @title Set environment variables\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "USE_TPU = False\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "# # @title Initialize TPU Strategy\n",
    "if USE_TPU:\n",
    "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
    "    tf.contrib.distribute.initialize_tpu_system(resolver)\n",
    "    strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
    "\n",
    "# sklearn libs\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Keras-bert imports\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import get_custom_objects\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "# Bert Model Constants\n",
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 32 # larger batch size causes OOM errors\n",
    "EPOCHS = 3\n",
    "LR = 2e-5\n",
    "\n",
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WjK4o7CY_X0a"
   },
   "outputs": [],
   "source": [
    "# @title Initialize Variables\n",
    "\n",
    "sess = K.get_session()\n",
    "uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
    "init_op = tf.variables_initializer(\n",
    "    [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
    ")\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1T9xPdXp_kt9"
   },
   "outputs": [],
   "source": [
    "# @title JSON to dataframe helper functions\n",
    "def undersample_df(df, n_times=3):\n",
    "    class_0,class_1 = df.category_index.value_counts()\n",
    "    c0 = df[df['category_index'] == 0]\n",
    "    c1 = df[df['category_index'] == 1]\n",
    "    df_0 = c0.sample(int(n_times * class_1))\n",
    "    \n",
    "    undersampled_df = pd.concat([df_0, c1],axis=0)\n",
    "    return undersampled_df\n",
    "\n",
    "def get_ds_synthetic_data(min_w=3):\n",
    "    short_task = {\n",
    "          \"bugzilla\": \"\"\"How to query bugs using the custom fields with the Bugzilla REST API?\"\"\",\n",
    "          \"databases\": \"\"\"Which technology should be adopted for the database layer abstraction: Object/Relational Mapping (ORM) or a Java Database Connectivity API (JDBC)?\"\"\",\n",
    "          \"gpmdpu\": \"\"\"Can I bind the cmd key to the GPMDPU shortcuts?\"\"\",\n",
    "          \"lucene\": \"\"\"How does Lucene compute similarity scores for the BM25 similarity?\"\"\",\n",
    "          \"networking\": \"\"\"Which technology should be adopted for the notification system, Server-Sent Events (SSE) or WebSockets?\"\"\",\n",
    "    }\n",
    "\n",
    "    with open('relevance_corpus.json') as ipf:\n",
    "        aux = json.load(ipf)\n",
    "        raw_data = defaultdict(list)\n",
    "        for d in aux:\n",
    "            if d['task'] == 'yargs':\n",
    "                continue\n",
    "\n",
    "            raw_data['text'].append(d['text'])\n",
    "            raw_data['question'].append(short_task[d['task']])\n",
    "            raw_data['source'].append(d['source'])\n",
    "            raw_data['category_index'].append(1 if d['weight'] > min_w else 0)\n",
    "            raw_data['weights'].append(d['weight'] if d['weight'] > min_w else 0)\n",
    "\n",
    "        data = pd.DataFrame.from_dict(raw_data)\n",
    "        data = undersample_df(data, n_times=1)\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_class_weights(y, smooth_factor=0, upper_bound=5.0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    clazz = {cls: float(majority / count) for cls, count in counter.items()}\n",
    "    result = {}\n",
    "    for key, value in clazz.items():\n",
    "        if value > upper_bound:\n",
    "            value = upper_bound\n",
    "        \n",
    "        result[key] = value\n",
    "    return result\n",
    "\n",
    "def add_raw_data(result, data):\n",
    "    result['text'].append(data['text'])\n",
    "    result['question'].append(data['question'])\n",
    "    result['source'].append(data['source'])\n",
    "    result['category_index'].append(data['category_index'])\n",
    "    result['weights'].append(data['weights'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "r_y7xwmxAT39"
   },
   "outputs": [],
   "source": [
    "# @title Tokenizer\n",
    "\n",
    "token_dict = {}\n",
    "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    "\n",
    "tokenizer = Tokenizer(token_dict)\n",
    "\n",
    "# FIXME: global variable that is referenced inside the train/test functions...\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HdAYw7lBAmlO"
   },
   "outputs": [],
   "source": [
    "# @title data encoder\n",
    "\n",
    "def encode_data(df, tokenizer, over_sampling=1, testing=False):\n",
    "    relevant = 1\n",
    "    indices, segments, labels, metadata = [], [], [], []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        _ids, _segments = tokenizer.encode(\n",
    "            first=row[\"text\"], \n",
    "            second=row[\"question\"], \n",
    "            max_len=SEQ_LEN\n",
    "        )\n",
    "        \n",
    "        label = row[\"category_index\"]\n",
    "        if label == relevant:\n",
    "            for _ in range(over_sampling):\n",
    "                indices.append(_ids)\n",
    "                segments.append(_segments)\n",
    "                labels.append(label)\n",
    "                metadata.append((row['weights'], row['text'], row[\"question\"]))\n",
    "        else:\n",
    "            indices.append(_ids)\n",
    "            segments.append(_segments)\n",
    "            labels.append(label)\n",
    "            metadata.append((row['weights'], row['text'], row[\"question\"]))\n",
    "        \n",
    "    # zip data into single list, shuffle everything and decompress\n",
    "    items = list(zip(indices, segments, labels, metadata))\n",
    "    np.random.shuffle(items)\n",
    "    indices, segments, labels, metadata = zip(*items)\n",
    "    indices = np.array(indices)\n",
    "    \n",
    "    # checks if array size is equals to batch size. If it's not, remove the last n entries to make it divisable\n",
    "    mod = indices.shape[0] % BATCH_SIZE\n",
    "    if mod > 0 and not testing:\n",
    "        indices, segments, labels, metadata = indices[:-mod], segments[:-mod], labels[:-mod], metadata[:-mod]\n",
    "    \n",
    "    X, y = [indices, np.array(segments)], np.array(labels)\n",
    "\n",
    "    return X, y, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "y-5ROuqDBU9X"
   },
   "outputs": [],
   "source": [
    "# @title Metrics & Logging functions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "recommendation_metrics = defaultdict(list)\n",
    "prediction_metrics = defaultdict(list)\n",
    "\n",
    "classification_report_lst = []\n",
    "log_examples_lst = []\n",
    "\n",
    "def aggregate_macro_metrics(store_at, precision, recall, fscore):   \n",
    "    store_at['precision'].append(precision)\n",
    "    store_at['recall'].append(recall)\n",
    "    store_at['fscore'].append(fscore)\n",
    "\n",
    "def aggregate_recommendation_metrics(store_at, k, precision_at_k, pyramid_precision_at_k):\n",
    "    store_at['k'].append(k)\n",
    "    store_at['precision'].append(precision_at_k)\n",
    "    store_at['∆ precision'].append(pyramid_precision_at_k)\n",
    "\n",
    "def log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10):\n",
    "    # get the predicted prob at every index\n",
    "    idx_probs = [(idx, y_predict[idx], y_probs[idx]) for idx, _ in enumerate(y_predict)]\n",
    "    \n",
    "    # filter probs for all indexes predicted as relevant  \n",
    "    idx_probs = list(filter(lambda k: k[1] == 1, idx_probs))\n",
    "    \n",
    "    most_probable = sorted(idx_probs, key=lambda i: i[2], reverse=True)\n",
    "    \n",
    "    result = [idx for idx, _, _ in most_probable][:k]\n",
    "    \n",
    "    for idx in result:\n",
    "        log_examples_lst.append((\n",
    "            source, \n",
    "            task_title,\n",
    "            pweights[idx],\n",
    "            y_predict[idx],\n",
    "            y_probs[idx],\n",
    "            text[idx]\n",
    "        ))\n",
    "\n",
    "def _precision_at_k(y_test, y_predict, y_prob, k=10):\n",
    "    # get the predicted prob at every index\n",
    "    idx_probs = [(idx, y_predict[idx], y_prob[idx]) for idx, _ in enumerate(y_test)]\n",
    "    \n",
    "    # filter probs for all indexes predicted as relevant  \n",
    "    idx_probs = list(filter(lambda k: k[1] == 1, idx_probs))\n",
    "    \n",
    "    most_probable = sorted(idx_probs, key=lambda i: i[2], reverse=True)\n",
    "    result = [y_test[idx] * y_predict[idx] for idx, _, _ in most_probable]   \n",
    "    y_predict = [y for _, y, _ in most_probable]\n",
    "    \n",
    "    result = result[:k]\n",
    "    y_predict = y_predict[:k]\n",
    "    ratio = sum(result) / float(len(y_predict) + 0.00001)\n",
    "    return ratio     \n",
    "\n",
    "\n",
    "def _pyramid_score(y_optimal, y_predicted, y_prob, k=10):\n",
    "\n",
    "    # create reference table for weights \n",
    "    # y_predicted = [i for i in y_optimal]\n",
    "    # get the predicted prob at every index\n",
    "    idx_probs = [(idx, y_optimal[idx], y_predicted[idx], y_prob[idx]) for idx, _ in enumerate(y_optimal)]\n",
    "    \n",
    "    # filter probs for all indexes predicted as relevant  \n",
    "    idx_probs = list(filter(lambda aux: aux[2] == 1, idx_probs))\n",
    "\n",
    "    # sort\n",
    "    most_probable = sorted(idx_probs, key=lambda i: i[3], reverse=True)\n",
    "\n",
    "    # compute predicted and optimal score up until K\n",
    "    predicted_score = [w for _, w, _, _ in most_probable][:k]\n",
    "    optimal_score = sorted(y_optimal, reverse=True)[:k]\n",
    "    \n",
    "    ratio = sum(predicted_score) / float(sum(optimal_score) + 0.00001)\n",
    "    return ratio           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4E1IN6UoPq96"
   },
   "outputs": [],
   "source": [
    "#@title Training procedures\n",
    "\n",
    "def get_train_val_test(task_uid, size=0.9, undersample=False, aug=True, undersample_n=3):\n",
    "    if not isinstance(task_uid, list):\n",
    "        task_uid = [task_uid]\n",
    "        \n",
    "    train_data_raw = defaultdict(list)\n",
    "    test_data_raw = defaultdict(list)\n",
    "    \n",
    "    for _data in tqdm(CORPUS):\n",
    "        if _data['question'] in task_uid:\n",
    "            add_raw_data(test_data_raw, _data)\n",
    "        else:\n",
    "            add_raw_data(train_data_raw, _data)\n",
    "    \n",
    "    train_val = pd.DataFrame.from_dict(train_data_raw)\n",
    "    test = pd.DataFrame.from_dict(test_data_raw)\n",
    "    \n",
    "    # https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "    #  randomize rows....    \n",
    "    train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "    test = test.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    if undersample:\n",
    "        train_val = undersample_df(train_val, n_times=undersample_n)\n",
    "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    if aug:\n",
    "        train_val = pd.concat([train_val, get_ds_synthetic_data()],axis=0)\n",
    "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    weights = get_class_weights(train_val['category_index'].tolist())\n",
    "    \n",
    "    train, val = train_test_split(\n",
    "        train_val, \n",
    "        stratify=train_val['category_index'].tolist(), \n",
    "        train_size=size\n",
    "    )\n",
    "    \n",
    "    return train, val, test, weights        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vFePvH5vBVA7"
   },
   "outputs": [],
   "source": [
    "# @title Testing procedures\n",
    "\n",
    "def test_model(source, df_test, model, tokenizer):\n",
    "    \n",
    "    test_x, test_y, metadata = encode_data(df_test, tokenizer, testing=True)\n",
    "    \n",
    "    logger.info(Fore.YELLOW + str(len(test_x)) + Style.RESET_ALL)\n",
    "    \n",
    "    text = [m[1] for m in metadata]\n",
    "    pweights = [m[0] for m in metadata]\n",
    "    task_title = metadata[0][2]\n",
    "\n",
    "    predicts = model.predict(test_x, verbose=True)\n",
    "    \n",
    "    y_probs = predicts[:, 1]\n",
    "    y_predict = predicts.argmax(axis=-1)\n",
    "\n",
    "    accuracy = accuracy_score(test_y, y_predict)\n",
    "    macro_f1 = f1_score(test_y, y_predict, average='macro')\n",
    "    \n",
    "    classification_report_lst.append(classification_report(test_y, y_predict))\n",
    "\n",
    "    logger.info(\"-\" * 20)    \n",
    "    \n",
    "    logger.info(\"Y\")\n",
    "    logger.info(\"[0s] {} [1s] {}\".format(\n",
    "        len(list(filter(lambda k: k== 0, test_y))),\n",
    "        len(list(filter(lambda k: k== 1, test_y)))\n",
    "    ))\n",
    "    \n",
    "        \n",
    "    logger.info(\"predicted\")\n",
    "    logger.info(\"[0s] {} [1s] {}\".format(\n",
    "        len(list(filter(lambda k: k== 0, y_predict))),\n",
    "        len(list(filter(lambda k: k== 1, y_predict)))\n",
    "    ))\n",
    "    \n",
    "    logger.info(\"-\" * 20)\n",
    "    \n",
    "    logger.info(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "    logger.info(\"macro_f1: {:.4f}\".format(macro_f1))\n",
    "\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(test_y, y_predict, average='macro')\n",
    "    \n",
    "    aggregate_macro_metrics(prediction_metrics, precision, recall, fscore)\n",
    "    \n",
    "    logger.info(\"Precision: {:.4f}\".format(precision))\n",
    "    logger.info(\"Recall: {:.4f}\".format(recall))\n",
    "    logger.info(\"F1: {:.4f}\".format(fscore))\n",
    "    \n",
    "    logger.info(\"-\" * 20)\n",
    "    \n",
    "    for k in [3, 5, 10]:\n",
    "        p_at_k = _precision_at_k(test_y, y_predict, y_probs, k=k)\n",
    "        score_at_k = _pyramid_score(pweights, y_predict, y_probs, k=k)\n",
    "                                     \n",
    "        aggregate_recommendation_metrics(recommendation_metrics, k, p_at_k, score_at_k)\n",
    "        \n",
    "        logger.info(\"\")\n",
    "        logger.info(\"Precision_at_{}: {:.4f}\".format(k, p_at_k))\n",
    "        logger.info(\"Pyramid_at_{}: {:.4f}\".format(k, score_at_k))\n",
    "    logger.info(\"-\" * 20)\n",
    "    \n",
    "    log_examples(task_title, source, text, pweights, y_predict, y_probs, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1oZGDUKnB1gw",
    "outputId": "d23c23cc-a3ba-442e-f2c3-a1c9b25f19d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n",
      "Hide MarkerView when nothing selected\n",
      "How to check programmatically whether app is running in debug mode or not?\n",
      "JSONObject parse dictionary objects\n",
      "Want to add drawable icons insteadof colorful dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/vanilla/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "100%|██████████| 7917/7917 [00:00<00:00, 449389.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    2645\n",
      "1     991\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mval\u001b[0m\n",
      "0    294\n",
      "1    110\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    669\n",
      "1     66\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.6693914623069936}\n",
      "----------\n",
      "From /home/msarthur/vanilla/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "From /home/msarthur/vanilla/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "\u001b[31mTraining model\u001b[0m\n",
      "From /home/msarthur/vanilla/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 3616 samples, validate on 384 samples\n",
      "Epoch 1/3\n",
      "3616/3616 [==============================] - 73s 20ms/sample - loss: 0.9221 - sparse_categorical_accuracy: 0.6173 - val_loss: 0.6116 - val_sparse_categorical_accuracy: 0.6536\n",
      "Epoch 2/3\n",
      "3616/3616 [==============================] - 63s 18ms/sample - loss: 0.7547 - sparse_categorical_accuracy: 0.7188 - val_loss: 0.6072 - val_sparse_categorical_accuracy: 0.6693\n",
      "Epoch 3/3\n",
      "3616/3616 [==============================] - 63s 17ms/sample - loss: 0.5971 - sparse_categorical_accuracy: 0.7898 - val_loss: 0.6110 - val_sparse_categorical_accuracy: 0.7135\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "\u001b[33m2\u001b[0m\n",
      "45/45 [==============================] - 2s 45ms/sample\n",
      "--------------------\n",
      "Y\n",
      "[0s] 40 [1s] 5\n",
      "predicted\n",
      "[0s] 40 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.7778\n",
      "macro_f1: 0.4375\n",
      "Precision: 0.4375\n",
      "Recall: 0.4375\n",
      "F1: 0.4375\n",
      "--------------------\n",
      "\n",
      "Precision_at_3: 0.0000\n",
      "Pyramid_at_3: 0.0000\n",
      "\n",
      "Precision_at_5: 0.0000\n",
      "Pyramid_at_5: 0.0000\n",
      "\n",
      "Precision_at_10: 0.0000\n",
      "Pyramid_at_10: 0.0000\n",
      "--------------------\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "\u001b[33m2\u001b[0m\n",
      "104/104 [==============================] - 1s 5ms/sample\n",
      "--------------------\n",
      "Y\n",
      "[0s] 82 [1s] 22\n",
      "predicted\n",
      "[0s] 35 [1s] 69\n",
      "--------------------\n",
      "Accuracy: 0.2788\n",
      "macro_f1: 0.2674\n",
      "Precision: 0.3580\n",
      "Recall: 0.3099\n",
      "F1: 0.2674\n",
      "--------------------\n",
      "\n",
      "Precision_at_3: 0.0000\n",
      "Pyramid_at_3: 0.0000\n",
      "\n",
      "Precision_at_5: 0.0000\n",
      "Pyramid_at_5: 0.0000\n",
      "\n",
      "Precision_at_10: 0.1000\n",
      "Pyramid_at_10: 0.1000\n",
      "--------------------\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "\u001b[33m2\u001b[0m\n",
      "283/283 [==============================] - 2s 5ms/sample\n",
      "--------------------\n",
      "Y\n",
      "[0s] 276 [1s] 7\n",
      "predicted\n",
      "[0s] 184 [1s] 99\n",
      "--------------------\n",
      "Accuracy: 0.6396\n",
      "macro_f1: 0.4080\n",
      "Precision: 0.4965\n",
      "Recall: 0.4671\n",
      "F1: 0.4080\n",
      "--------------------\n",
      "\n",
      "Precision_at_3: 0.0000\n",
      "Pyramid_at_3: 0.0000\n",
      "\n",
      "Precision_at_5: 0.0000\n",
      "Pyramid_at_5: 0.0000\n",
      "\n",
      "Precision_at_10: 0.0000\n",
      "Pyramid_at_10: 0.0000\n",
      "--------------------\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "\u001b[33m2\u001b[0m\n",
      "179/179 [==============================] - 1s 5ms/sample\n",
      "--------------------\n",
      "Y\n",
      "[0s] 172 [1s] 7\n",
      "predicted\n",
      "[0s] 120 [1s] 59\n",
      "--------------------\n",
      "Accuracy: 0.6648\n",
      "macro_f1: 0.4427\n",
      "Precision: 0.5088\n",
      "Recall: 0.5515\n",
      "F1: 0.4427\n",
      "--------------------\n",
      "\n",
      "Precision_at_3: 0.3333\n",
      "Pyramid_at_3: 0.3333\n",
      "\n",
      "Precision_at_5: 0.2000\n",
      "Pyramid_at_5: 0.2000\n",
      "\n",
      "Precision_at_10: 0.1000\n",
      "Pyramid_at_10: 0.1429\n",
      "--------------------\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "\u001b[33m2\u001b[0m\n",
      "36/36 [==============================] - 0s 6ms/sample\n",
      "--------------------\n",
      "Y\n",
      "[0s] 33 [1s] 3\n",
      "predicted\n",
      "[0s] 24 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.7500\n",
      "macro_f1: 0.6211\n",
      "Precision: 0.6250\n",
      "Recall: 0.8636\n",
      "F1: 0.6211\n",
      "--------------------\n",
      "\n",
      "Precision_at_3: 0.3333\n",
      "Pyramid_at_3: 0.3750\n",
      "\n",
      "Precision_at_5: 0.2000\n",
      "Pyramid_at_5: 0.3750\n",
      "\n",
      "Precision_at_10: 0.3000\n",
      "Pyramid_at_10: 1.0000\n",
      "--------------------\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "\u001b[33m2\u001b[0m\n",
      "31/31 [==============================] - 0s 5ms/sample\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 8\n",
      "predicted\n",
      "[0s] 16 [1s] 15\n",
      "--------------------\n",
      "Accuracy: 0.5161\n",
      "macro_f1: 0.4816\n",
      "Precision: 0.5083\n",
      "Recall: 0.5109\n",
      "F1: 0.4816\n",
      "--------------------\n",
      "\n",
      "Precision_at_3: 0.6667\n",
      "Pyramid_at_3: 0.4000\n",
      "\n",
      "Precision_at_5: 0.4000\n",
      "Pyramid_at_5: 0.2857\n",
      "\n",
      "Precision_at_10: 0.3000\n",
      "Pyramid_at_10: 0.4000\n",
      "--------------------\n",
      "https://stackoverflow.com/questions/23844667\n",
      "\u001b[33m2\u001b[0m\n",
      "28/28 [==============================] - 0s 5ms/sample\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 5\n",
      "predicted\n",
      "[0s] 17 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.5714\n",
      "macro_f1: 0.4750\n",
      "Precision: 0.5027\n",
      "Recall: 0.5043\n",
      "F1: 0.4750\n",
      "--------------------\n",
      "\n",
      "Precision_at_3: 0.0000\n",
      "Pyramid_at_3: 0.0000\n",
      "\n",
      "Precision_at_5: 0.2000\n",
      "Pyramid_at_5: 0.2308\n",
      "\n",
      "Precision_at_10: 0.2000\n",
      "Pyramid_at_10: 0.4615\n",
      "--------------------\n",
      "https://stackoverflow.com/questions/37096547\n",
      "\u001b[33m2\u001b[0m\n",
      "17/17 [==============================] - 0s 6ms/sample\n",
      "--------------------\n",
      "Y\n",
      "[0s] 12 [1s] 5\n",
      "predicted\n",
      "[0s] 14 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.6471\n",
      "macro_f1: 0.5096\n",
      "Precision: 0.5238\n",
      "Recall: 0.5167\n",
      "F1: 0.5096\n",
      "--------------------\n",
      "\n",
      "Precision_at_3: 0.3333\n",
      "Pyramid_at_3: 0.6000\n",
      "\n",
      "Precision_at_5: 0.3333\n",
      "Pyramid_at_5: 0.4286\n",
      "\n",
      "Precision_at_10: 0.3333\n",
      "Pyramid_at_10: 0.4286\n",
      "--------------------\n",
      "https://stackoverflow.com/questions/33241952\n",
      "\u001b[33m2\u001b[0m\n",
      "12/12 [==============================] - 0s 6ms/sample\n",
      "--------------------\n",
      "Y\n",
      "[0s] 8 [1s] 4\n",
      "predicted\n",
      "[0s] 8 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.6250\n",
      "Precision: 0.6250\n",
      "Recall: 0.6250\n",
      "F1: 0.6250\n",
      "--------------------\n",
      "\n",
      "Precision_at_3: 0.6667\n",
      "Pyramid_at_3: 0.6667\n",
      "\n",
      "Precision_at_5: 0.5000\n",
      "Pyramid_at_5: 0.5000\n",
      "\n",
      "Precision_at_10: 0.5000\n",
      "Pyramid_at_10: 0.5000\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# @title 10-fold cross validation WIP\n",
    "CORPUS = raw_data\n",
    "\n",
    "all_tasks = sorted(list(set([d['question'] for d in raw_data])))\n",
    "rseed = 20210343\n",
    "random.seed(rseed)\n",
    "random.shuffle(all_tasks)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, random_state=rseed)\n",
    "np_tasks_arr = np.array(all_tasks)\n",
    "\n",
    "idx_split = 0\n",
    "for train_index, test_index in kf.split(np_tasks_arr):    \n",
    "    test_tasks_lst = np_tasks_arr[test_index].tolist()\n",
    "    \n",
    "    logger.info(\"\")\n",
    "    logger.info(Fore.RED + f\"Fold {idx_split}\" + Style.RESET_ALL)\n",
    "    logger.info('\\n'.join(test_tasks_lst))\n",
    "    \n",
    "    df_train, df_val, df_test, weights = get_train_val_test(test_tasks_lst, undersample=True, undersample_n=3) \n",
    "    \n",
    "    logger.info('-' * 10)\n",
    "    logger.info(Fore.RED + 'train'+ Style.RESET_ALL)\n",
    "    logger.info(str(df_train.category_index.value_counts()))\n",
    "    logger.info(\"\")\n",
    "\n",
    "    logger.info(Fore.RED + 'val'+ Style.RESET_ALL)\n",
    "    logger.info(str(df_val.category_index.value_counts()))\n",
    "    logger.info(\"\")\n",
    "\n",
    "    logger.info(Fore.RED + 'test'+ Style.RESET_ALL)\n",
    "    logger.info(str(df_test.category_index.value_counts()))\n",
    "    logger.info(\"\")\n",
    "\n",
    "    logger.info(Fore.RED + 'weights'+ Style.RESET_ALL)\n",
    "    logger.info(str(weights))\n",
    "    logger.info('-' * 10)\n",
    "    \n",
    "    train_x, train_y, _ = encode_data(df_train, tokenizer, over_sampling=1)\n",
    "    val_x, val_y, _ = encode_data(df_val, tokenizer)\n",
    "    \n",
    "\n",
    "    model = load_trained_model_from_checkpoint(\n",
    "      config_path,\n",
    "      checkpoint_path,\n",
    "      training=True,\n",
    "      trainable=True,\n",
    "      seq_len=SEQ_LEN\n",
    "    )\n",
    "    \n",
    "    inputs = model.inputs[:2]\n",
    "    dense = model.get_layer('NSP-Dense').output\n",
    "    outputs = keras.layers.Dense(units=2, activation='softmax', name=\"probs\")(dense)\n",
    "    model = keras.models.Model(inputs, outputs)\n",
    "\n",
    "    optimizer = Adam(lr=LR)\n",
    "\n",
    "    \n",
    "    model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['sparse_categorical_accuracy'],\n",
    "    )\n",
    "    \n",
    "    \n",
    "    logger.info(\"\")\n",
    "    logger.info(Fore.RED + f\"Training model\" + Style.RESET_ALL)\n",
    "    history = model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_weight=weights,\n",
    "        validation_data=(val_x, val_y)\n",
    "    )\n",
    "    \n",
    "    logger.info(\"\")\n",
    "    logger.info(Fore.RED + f\"Testing model\" + Style.RESET_ALL)\n",
    "    for source in df_test[\"source\"].unique():\n",
    "        df_source = df_test[df_test[\"source\"] == source]   \n",
    "\n",
    "        logger.info(source)\n",
    "        test_model(source, df_source, model, tokenizer)\n",
    "            \n",
    "    idx_split += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "cYVkKLe-B1j0"
   },
   "outputs": [],
   "source": [
    "#@title Metrics report\n",
    "def avg_recommendation_metric_for(data, k=3, filter_outliers=True):\n",
    "    __precision = []\n",
    "    __pyramid = []\n",
    "    \n",
    "    total_len = len(data['k'])\n",
    "    \n",
    "    for idx in range(total_len):\n",
    "        \n",
    "        __value = data['k'][idx]\n",
    "        if __value  == k:\n",
    "            if filter_outliers:            \n",
    "                if data['precision'][idx] > 0.:\n",
    "                    __precision.append(data['precision'][idx])\n",
    "                if data['∆ precision'][idx] > 0.:\n",
    "                    __pyramid.append(data['∆ precision'][idx])\n",
    "            else:\n",
    "                __precision.append(data['precision'][idx])\n",
    "                __pyramid.append(data['∆ precision'][idx])\n",
    "                \n",
    "\n",
    "    return np.mean(__precision), np.mean(__pyramid)\n",
    "\n",
    "def avg_macro_metric_for(data):\n",
    "    __precision = data['precision']\n",
    "    __recall = data['recall']\n",
    "    __fscore = data['fscore']\n",
    "\n",
    "    return np.mean(__precision), np.mean(__recall), np.mean(__fscore)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXAU79kUB1m_",
    "outputId": "5cf6c8b4-cfac-4843-b305-42a6a2290c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mk=3\u001b[0m\n",
      "precision: \u001b[31m0.467\u001b[0m\n",
      "pyramid:   \u001b[31m0.475\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_precision, __pyramid_score = avg_recommendation_metric_for(\n",
    "    recommendation_metrics, \n",
    "    k=3\n",
    ")\n",
    "\n",
    "logger.info(Fore.YELLOW + \"k=3\" + Style.RESET_ALL)\n",
    "logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "logger.info(\"pyramid:   \" + Fore.RED + \"{:.3f}\".format(__pyramid_score) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0yBBd0lMHuI",
    "outputId": "94e1f3da-cd4c-46f1-d0ae-4b40f87b5c1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.510\u001b[0m\n",
      "recall:    \u001b[31m0.532\u001b[0m\n",
      "f1-score:  \u001b[31m0.474\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "_precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "logger.info(\"\")\n",
    "logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zUOGnWgIMYLN"
   },
   "outputs": [],
   "source": [
    "def examples_per_source_type(source_type='misc', n_samples=None):\n",
    "    _sources = list(set([x[0] for x in log_examples_lst]))\n",
    "    _template = \"[w={}]\" + Fore.RED + \"[y={}]\" + Fore.YELLOW + \"[p={:.4f}]\" + Style.RESET_ALL + \" {}\"\n",
    "\n",
    "    idx = 0\n",
    "    for s in _sources:\n",
    "        examples_in_source = []\n",
    "        if source_type == 'api' and ('docs.oracle' in s or 'developer.android' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'so' and ('stackoverflow.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]            \n",
    "            idx += 1\n",
    "        elif source_type == 'git' and ('github.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'misc' and 'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        if not examples_in_source:\n",
    "            continue\n",
    "        logger.info('')\n",
    "        logger.info(Fore.RED + f\"{task_title}\" + Style.RESET_ALL)    \n",
    "        logger.info(s)\n",
    "        logger.info('')\n",
    "\n",
    "        for _, _, pweights, y_predict, y_probs, text in examples_in_source:\n",
    "            logger.info(_template.format(pweights, y_predict, y_probs, text))\n",
    "            logger.info('')\n",
    "        logger.info('-' * 20)\n",
    "        \n",
    "        if n_samples and idx >= n_samples:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fjg9kKaDM0fo",
    "outputId": "775e2c15-1eeb-4233-b608-93ba0326c7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAPI\u001b[0m\n",
      "\n",
      "\u001b[31mhow can i get the value of text view in recyclerview item?\u001b[0m\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8901]\u001b[0m Create a variable called recyclerView and use findViewById ( ) to find a reference to the RecyclerView within the layout.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8862]\u001b[0m Since your layout only has a single child view, RecyclerView, you can switch to a simpler ViewGroup called FrameLayout that should be used for holding a single child view.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8749]\u001b[0m When you run the app, RecyclerView uses the adapter to figure out how to display your data on screen.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8701]\u001b[0m In this case, you need an adapter that takes an Affirmation instance from the list returned by loadAffirmations ( ), and turns it into a list item view, so that it can be displayed in the RecyclerView.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8629]\u001b[0m Replace getItemCount ( ) with this:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mJSONObject parse dictionary objects\u001b[0m\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.9038]\u001b[0m Use getType ( ) to retrieve a mandatory value.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8997]\u001b[0m Using accumulate will result in either a JSONArray or a mapping whose type is the type of value depending on the number of calls to it.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8951]\u001b[0m If the object is an array or Collection, returns an equivalent JSONArray.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8919]\u001b[0m This fails with a JSONException if the requested name has no value or if the value can not be coerced to the requested type.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8838]\u001b[0m If the object is a Map, returns an equivalent JSONObject.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for API sources\n",
    "\n",
    "logger.info(Fore.RED + \"API\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='api', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDBgOWQXNW1i",
    "outputId": "5d4f7df9-a1d8-48a0-9998-e4275d454466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mGIT\u001b[0m\n",
      "\n",
      "\u001b[31mHow to check programmatically whether app is running in debug mode or not?\u001b[0m\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8367]\u001b[0m Document how to check if profile/release/debug mode in dart\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7998]\u001b[0m Document how to check if profile/release/debug mode in dart · Issue # 11392 · flutter/flutter · GitHub\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7703]\u001b[0m The only way that works reliably has been posted above in # 11392 ( comment ).\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6336]\u001b[0m Check Flutter mode from Dart code\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5799]\u001b[0m Meanwhile, quickest way to get this into the repo might be by updating the docs: )\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mWant to add drawable icons insteadof colorful dots\u001b[0m\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.9016]\u001b[0m You can tweak the code on how you want to draw the icons:\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8781]\u001b[0m So really you want to replace:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8759]\u001b[0m Want to add drawable icons insteadof colorful dots\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8731]\u001b[0m You will need to load your icon probably in the init ( ) method of that class and draw using the that bitmap method.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8588]\u001b[0m Then change CompactCalendarController.java by removing those lines I mentioned and replacing with a call to draw your icon.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for GIT sources\n",
    "\n",
    "logger.info(Fore.RED + \"GIT\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='git', n_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4Bqx8AbNoV_",
    "outputId": "bf1737c0-a69b-43f4-d6d7-7e7d4a523ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSO\u001b[0m\n",
      "\n",
      "\u001b[31mHow to check programmatically whether app is running in debug mode or not?\u001b[0m\n",
      "https://stackoverflow.com/questions/23844667\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.9095]\u001b[0m Try the following:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8545]\u001b[0m then, in your code you detect the ENABLE_CRASHLYTICS flag as follows:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8243]\u001b[0m Alternatively, you could differentiate using BuildConfig.BUILD _ TYPE ;\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.8208]\u001b[0m If you are using Android Studio, or if you are using Gradle from the command line, you can add your own stuff to BuildConfig or otherwise tweak the debug and release build types to help distinguish these situations at runtime.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7598]\u001b[0m Due to the mixed comments about BuildConfig.DEBUG, I used the following to disable crashlytics -LRB- and analytics -RRB- in debug mode:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mhow can i get the value of text view in recyclerview item?\u001b[0m\n",
      "https://stackoverflow.com/questions/37096547\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6980]\u001b[0m To do this there are two ways: -\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.6558]\u001b[0m You don't need to use so many lists, just create a class that will contain all the data of single item, there is no need for buttons, use just text change listener instead.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6149]\u001b[0m I had a similar problem.My Recyclerview contained one Textview, two EditTexts and one remove Button to remove the item from the Recyclerview.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mHide MarkerView when nothing selected\u001b[0m\n",
      "https://stackoverflow.com/questions/33241952\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8318]\u001b[0m Set the view Marker in the chart\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8181]\u001b[0m set your marker to the chart\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7863]\u001b[0m 2 - Create MarkerView\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7291]\u001b[0m Use IMarker Interface -LRB- MarkerView has been deprecated since release 3.0.0 -RRB-\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for SO sources\n",
    "\n",
    "logger.info(Fore.RED + \"SO\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='so', n_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_mgLqe0N-hs",
    "outputId": "702b63f7-ff16-46df-9a3b-5acac955f23c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mMISC\u001b[0m\n",
      "\n",
      "\u001b[31mJSONObject parse dictionary objects\u001b[0m\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8979]\u001b[0m In this case, we want to execute a request to http://api.yelp.com/v2/search?term=food&location=San+Francisco and then this will return us a JSON dictionary that looks like:\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8885]\u001b[0m With this method in place, we could take a single business JSON dictionary such as:\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8839]\u001b[0m Next, we need to add method that would manage the deserialization of a JSON dictionary into a populated Business object:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8347]\u001b[0m We could now run the app and verify that the JSON array of business has the format we expect from the provided sample response in the documentation.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8255]\u001b[0m Jump to SectionTable of ContentsOverviewFetching JSON ResultsSetting up our ModelPutting It All TogetherBonus: Setting Up Your Adapter\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mhow can i get the value of text view in recyclerview item?\u001b[0m\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8834]\u001b[0m RecyclerView provides these built-in layout managers:\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.8773]\u001b[0m However, with a RecyclerView the adapter requires the existence of a `` ViewHolder'' object which describes and provides access to all the views within each item row.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8762]\u001b[0m SnappyRecyclerView For a more manual approach, we can create a custom extension to RecyclerView called SnappyRecyclerView which will snap items to center as the user scrolls:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8691]\u001b[0m If you want to use a RecyclerView, you will need to work with the following:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.8673]\u001b[0m Note that this can be used to recognize clicks on items, but not for recognizing clicks on individual buttons or other elements within your items ... Attaching Click Listeners with Decorators The easiest solution for handling a click on an item in a RecyclerView is to add a decorator class such as this clever ItemClickSupport decorator and then implement the following code in your Activity or Fragment code:\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for MISC sources\n",
    "\n",
    "logger.info(Fore.RED + \"MISC\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='misc', n_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0Aqy_IvONch"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOtaIhSr7Rl5GevhC5VQEpV",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "vanilla-keras-bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 Arthur vanilla",
   "language": "python",
   "name": "msarthur-vanilla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
