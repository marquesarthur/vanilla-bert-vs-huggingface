{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40eb542c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/8712652\n",
      "\u001b[31m8 \u001b[33m59 \u001b[0m https://dzone.com/articles/android-rotate-and-scale\n",
      "\u001b[31m20 \u001b[33m145 \u001b[0m https://developer.android.com/training/dependency-injection/hilt-android\n",
      "\u001b[31m4 \u001b[33m8 \u001b[0m https://stackoverflow.com/questions/30648172\n",
      "\u001b[31m4 \u001b[33m81 \u001b[0m https://github.com/google/dagger/issues/1991\n",
      "\u001b[31m9 \u001b[33m48 \u001b[0m https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "\u001b[31m6 \u001b[33m33 \u001b[0m https://github.com/realm/realm-java/issues/776\n",
      "\u001b[31m39 \u001b[33m129 \u001b[0m https://developer.android.com/training/permissions/requesting\n",
      "\u001b[31m14 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/5233543\n",
      "\u001b[31m4 \u001b[33m34 \u001b[0m https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "\u001b[31m27 \u001b[33m63 \u001b[0m https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "\u001b[31m9 \u001b[33m161 \u001b[0m https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "\u001b[31m5 \u001b[33m470 \u001b[0m https://developer.android.com/reference/android/widget/TextView\n",
      "\u001b[31m7 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/19025301\n",
      "\u001b[31m17 \u001b[33m33 \u001b[0m https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "\u001b[31m6 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/10108774\n",
      "\u001b[31m4 \u001b[33m12 \u001b[0m https://stackoverflow.com/questions/33241952\n",
      "\u001b[31m5 \u001b[33m47 \u001b[0m https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "\u001b[31m9 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/6442054\n",
      "\u001b[31m3 \u001b[33m22 \u001b[0m https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "\u001b[31m22 \u001b[33m211 \u001b[0m https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "\u001b[31m21 \u001b[33m59 \u001b[0m https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "\u001b[31m8 \u001b[33m95 \u001b[0m https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "\u001b[31m9 \u001b[33m15 \u001b[0m https://developer.android.com/training/volley/request\n",
      "\u001b[31m14 \u001b[33m65 \u001b[0m https://stackoverflow.com/questions/28504524\n",
      "\u001b[31m20 \u001b[33m59 \u001b[0m https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "\u001b[31m5 \u001b[33m97 \u001b[0m https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "\u001b[31m4 \u001b[33m38 \u001b[0m https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "\u001b[31m4 \u001b[33m27 \u001b[0m https://stackoverflow.com/questions/24952513\n",
      "\u001b[31m18 \u001b[33m219 \u001b[0m https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "\u001b[31m3 \u001b[33m72 \u001b[0m https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "\u001b[31m8 \u001b[33m49 \u001b[0m https://developer.android.com/guide/topics/media/mediarecorder\n",
      "\u001b[31m4 \u001b[33m9 \u001b[0m https://stackoverflow.com/questions/6688444\n",
      "\u001b[31m3 \u001b[33m23 \u001b[0m https://github.com/google/oboe/issues/447\n",
      "\u001b[31m4 \u001b[33m131 \u001b[0m https://stackoverflow.com/questions/122105\n",
      "\u001b[31m3 \u001b[33m48 \u001b[0m https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "\u001b[31m3 \u001b[33m36 \u001b[0m https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "\u001b[31m5 \u001b[33m373 \u001b[0m https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "\u001b[31m12 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/35357919\n",
      "\u001b[31m11 \u001b[33m117 \u001b[0m https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "\u001b[31m19 \u001b[33m250 \u001b[0m https://developer.android.com/guide/topics/media/camera\n",
      "\u001b[31m3 \u001b[33m56 \u001b[0m https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "\u001b[31m3 \u001b[33m5 \u001b[0m https://stackoverflow.com/questions/38980595\n",
      "\u001b[31m7 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/8184492\n",
      "\u001b[31m7 \u001b[33m58 \u001b[0m https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "\u001b[31m3 \u001b[33m50 \u001b[0m https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "\u001b[31m9 \u001b[33m32 \u001b[0m https://github.com/google/ExoPlayer/issues/8387\n",
      "\u001b[31m15 \u001b[33m81 \u001b[0m https://developer.android.com/guide/background/threading\n",
      "\u001b[31m6 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/2993085\n",
      "\u001b[31m11 \u001b[33m50 \u001b[0m https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "\u001b[31m10 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/26838730\n",
      "\u001b[31m7 \u001b[33m48 \u001b[0m https://guides.codepath.com/android/Defining-The-ActionBar\n",
      "\u001b[31m7 \u001b[33m283 \u001b[0m https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "\u001b[31m5 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/37096547\n",
      "\u001b[31m7 \u001b[33m179 \u001b[0m https://guides.codepath.com/android/using-the-recyclerview\n",
      "\u001b[31m8 \u001b[33m147 \u001b[0m https://developer.android.com/training/notify-user/build-notification\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/3059155\n",
      "\u001b[31m9 \u001b[33m65 \u001b[0m https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "\u001b[31m5 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/24652078\n",
      "\u001b[31m4 \u001b[33m100 \u001b[0m https://stackoverflow.com/questions/2661536\n",
      "\u001b[31m13 \u001b[33m69 \u001b[0m https://developer.android.com/training/data-storage/sqlite\n",
      "\u001b[31m15 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/4015026\n",
      "\u001b[31m5 \u001b[33m28 \u001b[0m https://stackoverflow.com/questions/23844667\n",
      "\u001b[31m5 \u001b[33m45 \u001b[0m https://github.com/flutter/flutter/issues/11392\n",
      "\u001b[31m4 \u001b[33m23 \u001b[0m https://stackoverflow.com/questions/29738510\n",
      "\u001b[31m5 \u001b[33m54 \u001b[0m https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "\u001b[31m3 \u001b[33m31 \u001b[0m https://stackoverflow.com/questions/47760861\n",
      "\u001b[31m8 \u001b[33m44 \u001b[0m https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/2883355\n",
      "\u001b[31m4 \u001b[33m37 \u001b[0m https://medium.com/android-dev-hacks/rendering-pdf-documents-in-android-using-pdfrenderer-f6d4f730b18\n",
      "\u001b[31m3 \u001b[33m19 \u001b[0m https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/36275986\n",
      "\u001b[31m42 \u001b[33m177 \u001b[0m https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "\u001b[31m9 \u001b[33m36 \u001b[0m https://developer.android.com/training/location/retrieve-current\n",
      "\u001b[31m5 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/46481789\n",
      "\u001b[31m22 \u001b[33m119 \u001b[0m https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "\u001b[31m15 \u001b[33m99 \u001b[0m https://javapapers.com/android/android-location-fused-provider\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m16 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/29923376\n",
      "\u001b[31m4 \u001b[33m13 \u001b[0m https://github.com/google/dagger/issues/671\n",
      "\u001b[31m9 \u001b[33m51 \u001b[0m https://stackoverflow.com/questions/11064244\n",
      "\u001b[31m7 \u001b[33m138 \u001b[0m https://github.com/quarkusio/quarkus/issues/3954\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m3 \u001b[33m4 \u001b[0m https://stackoverflow.com/questions/40168601\n",
      "\u001b[31m3 \u001b[33m14 \u001b[0m https://developer.android.com/training/keyboard-input/commands\n",
      "\u001b[31m20 \u001b[33m54 \u001b[0m https://developer.android.com/training/safetynet/recaptcha\n",
      "\u001b[31m11 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/27297067\n",
      "\u001b[31m6 \u001b[33m72 \u001b[0m https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "\u001b[31m5 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/14347588\n",
      "\u001b[31m31 \u001b[33m163 \u001b[0m https://guides.codepath.com/android/creating-and-using-fragments\n",
      "\u001b[31m5 \u001b[33m57 \u001b[0m https://github.com/signalapp/Signal-Android/issues/3376\n",
      "\u001b[31m22 \u001b[33m104 \u001b[0m https://developer.android.com/reference/org/json/JSONObject\n",
      "\u001b[31m8 \u001b[33m31 \u001b[0m https://guides.codepath.com/android/converting-json-to-models\n",
      "\u001b[31m5 \u001b[33m34 \u001b[0m https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "\u001b[31m8 \u001b[33m42 \u001b[0m https://stackoverflow.com/questions/30362446\n",
      "\u001b[31m10 \u001b[33m36 \u001b[0m https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "\u001b[31m5 \u001b[33m16 \u001b[0m https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "\u001b[31m4 \u001b[33m54 \u001b[0m https://developer.android.com/training/gestures/scroll\n",
      "\u001b[31m4 \u001b[33m16 \u001b[0m https://stackoverflow.com/questions/39588322\n",
      "\u001b[31m7 \u001b[33m146 \u001b[0m https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "\u001b[31m5 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/24313539\n",
      "\u001b[31m12 \u001b[33m77 \u001b[0m https://www.hongkiat.com/blog/solve-android-delayed-notifications\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m4 \u001b[33m40 \u001b[0m https://developer.android.com/training/gestures/scale\n",
      "\u001b[31m6 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/10630373\n",
      "\u001b[31m20 \u001b[33m196 \u001b[0m https://developer.android.com/training/dependency-injection/dagger-android\n",
      "\u001b[31m6 \u001b[33m44 \u001b[0m https://stackoverflow.com/questions/57235136\n",
      "\u001b[31m24 \u001b[33m121 \u001b[0m https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "Sample entry from data:\n",
      "{\n",
      "    \"category_index\": 1,\n",
      "    \"question\": \"Android: rotate canvas around the center of the screen\",\n",
      "    \"source\": \"https://stackoverflow.com/questions/8712652\",\n",
      "    \"text\": \"You have to rotate the canvas first and then draw whatever you want.\",\n",
      "    \"weights\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from Levenshtein import ratio\n",
    "from colorama import Fore, Style\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.level = logging.DEBUG\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "from ds_android import get_input_for_BERT\n",
    "\n",
    "raw_data = get_input_for_BERT()\n",
    "\n",
    "print('Sample entry from data:')\n",
    "print(json.dumps(raw_data[0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "375f416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLoading data from cache\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# If there is a previous execution for the same configuration, we load it from disk\n",
    "\n",
    "# final results are the average of 3 distinct runs of this script.\n",
    "# reason: avoid phishing results when BERT training procedures were exceptionally good\n",
    "NUMBER_OF_RUNS = 3 \n",
    "config_output = 'output/bert_ds_android_base.json'\n",
    "# config_output = 'output/bert_ds_android_fe.json' # for frame-elements filter\n",
    "# config_output = 'output/bert_ds_android_fa.json' # for frame-association filters\n",
    "\n",
    "fold_results = dict()\n",
    "\n",
    "if os.path.isfile(config_output):\n",
    "    logger.info(Fore.YELLOW + \"Loading data from cache\" + Style.RESET_ALL)\n",
    "    with open(config_output) as input_file:\n",
    "        fold_results = json.load(input_file)\n",
    "        \n",
    "if 'venn_diagram_set' not in fold_results:\n",
    "    fold_results['venn_diagram_set'] = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2c243f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface_test/lib/python3.7/site-packages/torch/package/_directory_reader.py:17: UserWarning: Failed to initialize NumPy: module compiled against API version 0xe but this version of numpy is 0xd (Triggered internally at  /tmp/coulombc/pytorch_build_2021-11-09_14-57-01/avx2/python3.7/pytorch/torch/csrc/utils/tensor_numpy.cpp:68.)\n",
      "  _dtype_to_storage = {data_type(0).dtype: data_type for data_type in _storages}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import contextlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "USE_TPU = False\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "# @title Initialize TPU Strategy\n",
    "if USE_TPU:\n",
    "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
    "    tf.contrib.distribute.initialize_tpu_system(resolver)\n",
    "    strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
    "    \n",
    "from TFBertForTaskTextClassification import TFBertForTaskTextClassification\n",
    "from TFBertForTaskTextClassification import TFBertForAndroidTaskTextClassification\n",
    "from TFBertForTaskTextClassification import TFBertForSyntheticTaskTextClassification \n",
    "\n",
    "from metrics import MetricsAggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c144c",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb258ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the model\n",
    "model = TFBertForAndroidTaskTextClassification(model_id = '/home/msarthur/scratch/bert-base-uncased')\n",
    "\n",
    "# Configure filters. All other values are as default\n",
    "model.target_output = 10\n",
    "model.use_frame_filtering = False\n",
    "model.match_frame_from_task = False\n",
    "model.n_undersampling = 4\n",
    "        \n",
    "# Load tokenizer\n",
    "model.tokenizer(local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131f0c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface_test/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "100%|██████████| 7931/7931 [00:00<00:00, 1017621.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1105\n",
      "1     276\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    478\n",
      "1      1\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 4.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/msarthur/hface_test/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at /home/msarthur/scratch/bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 18s 211ms/step - loss: 1.0873 - sparse_categorical_accuracy: 0.4481 - val_loss: 0.6252 - val_sparse_categorical_accuracy: 0.6429\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62522, saving model to best_model\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.9420 - sparse_categorical_accuracy: 0.6926 - val_loss: 0.6040 - val_sparse_categorical_accuracy: 0.6558\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.62522 to 0.60401, saving model to best_model\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.7900 - sparse_categorical_accuracy: 0.7537 - val_loss: 0.5733 - val_sparse_categorical_accuracy: 0.6753\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60401 to 0.57332, saving model to best_model\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 0.6791 - sparse_categorical_accuracy: 0.8014 - val_loss: 0.5595 - val_sparse_categorical_accuracy: 0.7143\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57332 to 0.55954, saving model to best_model\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.5490 - sparse_categorical_accuracy: 0.8732 - val_loss: 0.5612 - val_sparse_categorical_accuracy: 0.7338\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.55954\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.4134 - sparse_categorical_accuracy: 0.9022 - val_loss: 0.5908 - val_sparse_categorical_accuracy: 0.7338\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.55954\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3661 - sparse_categorical_accuracy: 0.9171 - val_loss: 0.6210 - val_sparse_categorical_accuracy: 0.7468\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.55954\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 0.3120 - sparse_categorical_accuracy: 0.9285 - val_loss: 0.6571 - val_sparse_categorical_accuracy: 0.7273\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.55954\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "https://stackoverflow.com/questions/37096547\n",
      "--------------------\n",
      "Y\n",
      "[0s] 16 [1s] 1\n",
      "predicted\n",
      "[0s] 11 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.7059\n",
      "macro_f1: 0.5503\n",
      "Precision: 0.5833\n",
      "Recall: 0.8438\n",
      "F1: 0.5503\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.583\u001b[0m\n",
      "recall:    \u001b[31m0.844\u001b[0m\n",
      "f1-score:  \u001b[31m0.550\u001b[0m\n",
      "next 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface_test/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface_test/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# @title 10-fold cross validation WIP\n",
    "CORPUS = raw_data\n",
    "\n",
    "all_tasks = sorted(list(set([d['question'] for d in raw_data])))\n",
    "rseed = 20210343\n",
    "random.seed(rseed)\n",
    "random.shuffle(all_tasks)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "file_handler = logging.FileHandler('LOG-bert_ds_android.ans')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, random_state=rseed)\n",
    "np_tasks_arr = np.array(all_tasks)\n",
    "\n",
    "\n",
    "idx_split = 0\n",
    "for train_index, test_index in kf.split(np_tasks_arr):\n",
    "\n",
    "    idx_split = str(idx_split)\n",
    "    eval_fold = True\n",
    "    # 10 runs per fold to avoid reporting peek results in a given fold\n",
    "    # if idx_split in fold_results and fold_results[idx_split]['run_cnt'] >= NUMBER_OF_RUNS:\n",
    "    #     logger.info(Fore.RED + f\"Fold {idx_split} FULLY TESTED\" + Style.RESET_ALL)\n",
    "    #     eval_fold = False\n",
    "\n",
    "\n",
    "    if eval_fold:\n",
    "        model.metrics.reset_aggregators()\n",
    "\n",
    "        test_tasks_lst = np_tasks_arr[test_index[:1]].tolist() # TODO: Arthur -- a single task for testing, just for the sake of it...\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split}\" + Style.RESET_ALL)\n",
    "        logger.info('\\n'.join(test_tasks_lst))\n",
    "\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "        df_train, df_val, df_test, weights = model.get_train_val_test(\n",
    "            CORPUS, test_tasks_lst\n",
    "        )\n",
    "        \n",
    "\n",
    "        logger.info('-' * 10)\n",
    "        logger.info(Fore.RED + 'train'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_train.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'test'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_test.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'weights'+ Style.RESET_ALL)\n",
    "        logger.info(str(weights))\n",
    "        logger.info('-' * 10)\n",
    "        \n",
    "        # <------------------------------------------------------------------------- TRAIN\n",
    "\n",
    "        # Encode X_train\n",
    "        train_encodings = model.encode(df_train)\n",
    "        train_labels = df_train['category_index'].tolist()\n",
    "\n",
    "        # Encode X_valid\n",
    "        val_encodings = model.encode(df_val)\n",
    "        val_labels = df_val['category_index'].tolist()\n",
    "\n",
    "\n",
    "        # https://huggingface.co/transformers/custom_datasets.html\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(train_encodings),\n",
    "            train_labels\n",
    "        ))\n",
    "\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(val_encodings),\n",
    "            val_labels\n",
    "        ))\n",
    "\n",
    "\n",
    "        fine_tunned_keras_model = model.build(\n",
    "            train_dataset, val_dataset, weights, \n",
    "            checkpoint_filepath='best_model',\n",
    "            local_files_only=False\n",
    "        )\n",
    "        \n",
    "        \n",
    "        if model.match_frame_from_task:\n",
    "            __frame_pairs = model.fn_frame_pairs.get_most_common_frame_relationships(df_train)\n",
    "            model.sentence_task_frame_pairs = __frame_pairs\n",
    "\n",
    "        # <------------------------------------------------------------------------- TEST\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Testing model\" + Style.RESET_ALL)\n",
    "        for source in df_test[\"source\"].unique():\n",
    "            df_source = df_test[df_test[\"source\"] == source]   \n",
    "            logger.info(source)\n",
    "            \n",
    "            model.test(source, df_source, fine_tunned_keras_model)\n",
    "                        \n",
    "\n",
    "        # <------------------------------------------------------------------------- METRICS   \n",
    "        \n",
    "        prediction_metrics, api_metrics, so_metrics, git_metrics, misc_metrics = model.get_evaluation_metrics()\n",
    "        \n",
    "        MetricsAggregator.add_idx_fold_results(\n",
    "            idx_split, fold_results, prediction_metrics,\n",
    "            api_metrics, so_metrics, git_metrics, misc_metrics\n",
    "        )\n",
    "\n",
    "        fold_results['venn_diagram_set'] += model.metrics.venn_diagram_set\n",
    "        fold_results['venn_diagram_set'] = list(set(fold_results['venn_diagram_set']))\n",
    "\n",
    "\n",
    "        _precision, _recall, _f1score = MetricsAggregator.avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "        logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "        logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "        logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "    idx_split = int(idx_split)\n",
    "    idx_split += 1\n",
    "    logger.info(f\"next {idx_split}\")\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab2a1ca",
   "metadata": {},
   "source": [
    "# Python Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ea9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_dict_for_task(input_task):\n",
    "    input_folder = f'experiment/{input_task}'\n",
    "    encoding = \"UTF-8\" if os.name != \"nt\" else \"mbcs\"\n",
    "    result = []\n",
    "    for task_path in Path(input_folder).rglob('*.json'):\n",
    "        with open(task_path, encoding=encoding) as fi:\n",
    "        # with open(path) as fi:\n",
    "            data = json.load(fi)\n",
    "            for __data in data:\n",
    "                result.append(dict(\n",
    "                    text=__data['text'],\n",
    "                    question=__data['description'],\n",
    "                    task=__data['task'],\n",
    "                    source=__data['source'],\n",
    "                    source_type='misc',\n",
    "                    category_index=0,\n",
    "                    weights=0\n",
    "                ))\n",
    "    return pd.DataFrame.from_dict(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc468e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_data, max_pred_values=10):\n",
    "    preds = model.predict(test_data.batch(1)).logits\n",
    "\n",
    "    # transform to array with probabilities\n",
    "    res = tf.nn.softmax(preds, axis=1).numpy()\n",
    "\n",
    "    y_predict, y_probs = res.argmax(axis=-1), res[:, 1]\n",
    "    aux = [(idx, prob) for idx, prob in enumerate(y_probs)]\n",
    "\n",
    "    cnt = 0\n",
    "    for idx, prob in sorted(aux, key=lambda k: k[1], reverse=True):\n",
    "        cnt += 1\n",
    "        if cnt > max_pred_values:\n",
    "            y_predict[idx] = 0\n",
    "\n",
    "    return y_predict, y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d56eb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_examples(task_title, text, pweights, y_predict, y_probs, k=10):\n",
    "    # get the predicted prob at every index\n",
    "    idx_probs = [(idx, y_predict[idx], y_probs[idx]) for idx, _ in enumerate(y_predict)]\n",
    "\n",
    "    # filter probs for all indexes predicted as relevant\n",
    "    idx_probs = list(filter(lambda k: k[1] == 1, idx_probs))\n",
    "\n",
    "    most_probable = sorted(idx_probs, key=lambda i: i[2], reverse=True)\n",
    "\n",
    "    result = [idx for idx, _, _ in most_probable][:k]\n",
    "\n",
    "    for idx in result:\n",
    "        print((idx,\n",
    "            round(y_probs[idx], 3),\n",
    "            text[idx]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7d1a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(df_data, model, keras_model):\n",
    "    for source in df_data[\"source\"].unique():\n",
    "        df_source = df_data[df_data[\"source\"] == source]   \n",
    "        \n",
    "\n",
    "        test_encodings = model.encode(df_source)\n",
    "        test_labels = df_source['category_index'].tolist()\n",
    "\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(test_encodings),\n",
    "            test_labels\n",
    "        ))\n",
    "\n",
    "        text = df_source['text'].tolist()\n",
    "        task_title = df_source['question'].tolist()[0]    \n",
    "        pweights = df_source['weights'].tolist()\n",
    "\n",
    "        logger.info(task_title)\n",
    "        logger.info(source)\n",
    "        print()\n",
    "\n",
    "        y_predict, y_probs = eval_model(keras_model, test_dataset)\n",
    "        log_examples(task_title, text, pweights, y_predict, y_probs, k=10)\n",
    "\n",
    "        print()\n",
    "        print(\"-\" * 20)\n",
    "        print()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d457155",
   "metadata": {},
   "source": [
    "# Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46963485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a string representing rendezvous address and a list of suggested picnic addresses you must write an algorithm using the geopy module to find the picnic address with the closest distance to the rendezvous address.\n",
      "python - Obtaining latitude and longitude of multiple locations using Geopy - Stack Overflow\n",
      "\n",
      "(20, 0.791, 'I have been trying to use Geopy from python to achieve this.')\n",
      "(36, 0.784, \"In you code it should be something like this - import csv from time import sleep from geopy.geocoders import Nominatim with open ('D: / location_to_lat_lon / tolocate.csv', ` r' ) as fp:\")\n",
      "(44, 0.778, 'Browse other questions tagged python csv geopy or ask your own question.')\n",
      "(63, 0.776, 'Getting SSL Error on AWS EC2 Instance When I Try to Reach GeoPy API')\n",
      "(30, 0.773, 'You are forgetting that location can be None at times due to various reasons including the geocoding service not having geo spatial data for the given address.')\n",
      "(35, 0.762, 'In that case you have to ignore such kind of address.')\n",
      "(34, 0.742, 'Sometimes Actual location i.e latitude and longitude are not available for a particular address.')\n",
      "(12, 0.741, 'Obtaining latitude and longitude of multiple locations using Geopy')\n",
      "(62, 0.696, \"geopy NoneType object has no attribute ` latitude'\")\n",
      "(61, 0.687, 'Printing the country name from Geopy')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing rendezvous address and a list of suggested picnic addresses you must write an algorithm using the geopy module to find the picnic address with the closest distance to the rendezvous address.\n",
      "Geocoding in Python Using Geopy - Python Simplified\n",
      "\n",
      "(22, 0.806, \"If you don't want to use geopy, then you can directly use the API provided by the above services.\")\n",
      "(32, 0.789, \"Let's now apply reverse geocoding to get the address from the given geographic coordinates ( latitude and longitude ).\")\n",
      "(39, 0.772, 'Sometimes you may want to calculate the distance between two addresses given latitude and longitude.')\n",
      "(11, 0.764, 'And finally, we will see how to calculate the distance between the two addresses.')\n",
      "(10, 0.759, 'In this article, you will first understand what geocoding and reverse geocoding are, and then explore the geopy package to convert addresses into latitudes and longitudes and vice versa.')\n",
      "(47, 0.757, 'In this article, you have understood geocoding and reverse geocoding, how to use geopy package for geocoding and reverse geocoding, and then we saw how to calculate the distance between two coordinates.')\n",
      "(29, 0.753, 'Next, you need to pass the address for which you want to get latitude and longitude.')\n",
      "(40, 0.749, 'For this, geopy provides two ways to calculate the distances: geodesic distance or great-circle distance.')\n",
      "(30, 0.747, 'Then the result is stored in the location object using which we can get the required details such as longitude and latitude as below.')\n",
      "(24, 0.746, 'Geocoding ( forward geocoding ) using geopy')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing rendezvous address and a list of suggested picnic addresses you must write an algorithm using the geopy module to find the picnic address with the closest distance to the rendezvous address.\n",
      "python - Calculate point based on distance and direction - Stack Overflow\n",
      "\n",
      "(31, 0.806, 'Okay, seriously, you can get started using geopy.')\n",
      "(39, 0.805, 'You can automate this approach using a simple iterative solver from e.g. SciPy: just find the root of geopy.distance.distance ( ).')\n",
      "(32, 0.798, 'First of all, you need to define your starting point in a coordinate system known to geopy.')\n",
      "(18, 0.796, 'I would like to calculate a point based on direction and distance using GeoDjango or GeoPy.')\n",
      "(27, 0.787, 'Edit 2 Okay, there is an out-of-the-box solution with geopy, it is just not well-documented:')\n",
      "(55, 0.78, 'This snippet shows how to use with the latest ( and future versions of GeoPy - Vincenty will be deprecated in 2.0 )')\n",
      "(69, 0.771, 'Browse other questions tagged python django geodjango geopy or ask your own question.')\n",
      "(61, 0.756, 'I suppose you need to replace location by initial_location or the opposite.')\n",
      "(35, 0.755, 'Or how would we invert the measure function defined in https://code.google.com/p/geopy/source/browse/trunk/geopy/distance.py#217 ?')\n",
      "(50, 0.752, 'now if only geopy had the opposite, the ability to find the vincenty direction between two points ...')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing rendezvous address and a list of suggested picnic addresses you must write an algorithm using the geopy module to find the picnic address with the closest distance to the rendezvous address.\n",
      "Locations in Python (Geocoding w/Geopy) - HolyPython.com\n",
      "\n",
      "(10, 0.808, \"You can check if you have geopy in your libraries by using this code in Python: help ( `` modules'' ) If you can't see geopy in your library selection, it might be time to have it installed.\")\n",
      "(11, 0.803, 'You can do so simply by opening the Anaconda Command Prompt and typing the command below: pip install geopy')\n",
      "(36, 0.797, \"You can also calculate the distance between two locations or points using geopy.distance module.Let's see the distance between a Department Store with Tesla Supercharger near Orly Airport and Paris' finest ice-cream shop Berthillon.\")\n",
      "(37, 0.796, \"Geopy has been very successful at reverse geocoding place names to coordinates, let's see if it can identify exact locations with little information again such as name.\")\n",
      "(20, 0.788, \"Now we will explore Nominatim with Python's geopy library.\")\n",
      "(14, 0.784, 'Geopy supports majority of the major geocoders straight out of the box.')\n",
      "(41, 0.784, \"Let's take a look at what help ( ) function returns on geopy.distance.distance:\")\n",
      "(23, 0.779, \"What would happen if we just pass `` Ben & Jerry's'' as the address to Nominatim using geopy ?\")\n",
      "(9, 0.768, 'Geopy is a Python library that makes geocoding operations very accessible and practical.')\n",
      "(30, 0.766, 'Without even completing the address we are getting accurate results.')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing rendezvous address and a list of suggested picnic addresses you must write an algorithm using the geopy module to find the picnic address with the closest distance to the rendezvous address.\n",
      "geolocation - Python module for getting latitude and longitude from the name of a US city - Stack Overflow\n",
      "\n",
      "(30, 0.795, \"Giving me the error: Using Nominatim with the default `` geopy/1 .17.0'' user_agent is strongly discouraged, as it violates Nominatim's ToS operations.osmfoundation.org/policies/nominatim and may possibly cause 403 and 429 HTTP errors.\")\n",
      "(21, 0.794, 'Have a look at geopy.')\n",
      "(39, 0.765, 'Browse other questions tagged python geolocation geopy or ask your own question.')\n",
      "(47, 0.702, 'geopy.exc.GeocoderAuthenticationFailure: HTTP Error 401: Unauthorized')\n",
      "(20, 0.562, 'This answer is not useful')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing rendezvous address and a list of suggested picnic addresses you must write an algorithm using the geopy module to find the picnic address with the closest distance to the rendezvous address.\n",
      "Python Geopy to find geocode of an Address - AskPython\n",
      "\n",
      "(6, 0.802, 'The figure below gives some idea about function of GeoPy.')\n",
      "(8, 0.785, 'These services provide APIs, GeoPy library provides an implementation of these APIs in a single package.')\n",
      "(30, 0.779, 'Using GeoPy with Pandas Dataframe')\n",
      "(13, 0.776, \"With enough high level idea of what GeoPy does, let's now see how to use it to retrieve geocode of an address.\")\n",
      "(3, 0.772, \"In this article, we will retrieve the geocode of an address using Python's GeoPy library.\")\n",
      "(23, 0.749, \"here we need to provide the coordinates of a point on the earth's surface and the method returns the address associated with the provided lat and lon.\")\n",
      "(21, 0.747, 'Geocoders have least a geocode method, for looking up coordinates from a provided string ( address we want to geocode ).')\n",
      "(4, 0.746, 'GeoPy is not a Geocoding service but simply a python client for several popular geocoding web services.')\n",
      "(24, 0.742, 'Finding Geocode of an address')\n",
      "(36, 0.741, 'if the location of the string is not found it automatically returns None.')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing rendezvous address and a list of suggested picnic addresses you must write an algorithm using the geopy module to find the picnic address with the closest distance to the rendezvous address.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to GeoPy’s documentation! — GeoPy 2.2.0 documentation\n",
      "\n",
      "(151, 0.806, 'Return type None, geopy.location.Location or a list of them, if exactly_one = False.')\n",
      "(490, 0.806, 'Return type geopy.location.Location or a list of them, if exactly_one = False.')\n",
      "(684, 0.804, 'geopy attempts to follow semantic versioning, however some breaking changes are still being made in minor releases, such as:')\n",
      "(691, 0.803, \"For example, geopy.point.Point instances previously did coordinate values normalization, though it's not documented, and it was completely wrong for the latitudes outside the -LSB- -90 ; 90 -RSB- range.\")\n",
      "(644, 0.803, 'Bases: geopy.adapters.BaseSyncAdapter The fallback adapter which uses urllib from the Python standard library, see urllib.request.urlopen ( ).')\n",
      "(34, 0.801, 'Or, if you are ready to wait, you can try geopy.extra.rate _ limiter.')\n",
      "(30, 0.8, 'These services provide APIs, which anyone could implement, and geopy is just a library which provides these implementations for many different services in a single package.')\n",
      "(39, 0.799, 'By default geopy geocoders are synchronous ( i.e. they use an Adapter based on BaseSyncAdapter ).')\n",
      "(466, 0.798, \"location_bias ( geopy.point.Point, list or tuple of ( latitude, longitude ), or string as'' % ( latitude ) s, % ( longitude ) s''. )\")\n",
      "(28, 0.798, 'Geopy Is Not a Service')\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_task = 'distance'\n",
    "\n",
    "df_data = get_dict_for_task(input_task)\n",
    "test_data(df_data, model, fine_tunned_keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31bb9b",
   "metadata": {},
   "source": [
    "# NYTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a465fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a string representing the url for NY Times Today's, you must write a python script using the BeautifulSoup and requests modules to scrap all the headlines of that page.\n",
      "Beautiful Soup: Build a Web Scraper With Python – Real Python\n",
      "\n",
      "(317, 0.808, 'To get the URL instead, you need to extract the value of one of the HTML attributes instead of discarding it.')\n",
      "(319, 0.802, \"The specific URL that you're looking for is the value of the href attribute of the second <a> tag at the bottom the HTML of a single job posting:\")\n",
      "(240, 0.801, 'find_all ( ) on a Beautiful Soup object, which returns an iterable containing all the HTML for all the job listings displayed on that page.')\n",
      "(323, 0.801, \"Then you extracted the href attribute, which contains the URL, using -LSB- `` href'' -RSB- and printed it to your console.\")\n",
      "(331, 0.8, \"Then you're directly extracting the URL using the square-bracket notation and addressing the href attribute ( -LSB- `` href'' -RSB- ).\")\n",
      "(338, 0.799, 'Therefore, you can scrape them using only requests and Beautiful Soup.')\n",
      "(216, 0.799, 'When you add the two highlighted lines of code, you create a Beautiful Soup object that takes page.content, which is the HTML content you scraped earlier, as its input.')\n",
      "(245, 0.799, 'Each job_element is another BeautifulSoup ( ) object.')\n",
      "(18, 0.798, \"Inspect the HTML structure of your target site with your browser's developer tools Decipher data encoded in URLs Use requests and Beautiful Soup for scraping and parsing data from the Web Step through a web scraping pipeline from start to finish Build a script that fetches job offers from the Web and displays relevant information in your console\")\n",
      "(91, 0.795, 'For example, you might find yourself on a details page that has the following URL:')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing the url for NY Times Today's, you must write a python script using the BeautifulSoup and requests modules to scrap all the headlines of that page.\n",
      "Beautiful Soup Documentation — Beautiful Soup 4.9.0 documentation\n",
      "\n",
      "(518, 0.816, 'Note that you must know to call UnicodeDammit.detwingle ( ) on your data before passing it into BeautifulSoup or the UnicodeDammit constructor.')\n",
      "(39, 0.815, \"Python's html.parser BeautifulSoup ( markup, `` html.parser'' )\")\n",
      "(42, 0.815, \"lxml's HTML parser BeautifulSoup ( markup, `` lxml'' )\")\n",
      "(644, 0.815, \"If you get the ImportError `` No module named BeautifulSoup'', your problem is that you're trying to run Beautiful Soup 3 code, but you only have Beautiful Soup 4 installed.\")\n",
      "(27, 0.814, '$ easy_install beautifulsoup4 $ pip install beautifulsoup4 ( The BeautifulSoup package is not what you want.')\n",
      "(358, 0.814, 'The best solution is to call the factory method BeautifulSoup.new _ tag ( ):')\n",
      "(43, 0.813, \"lxml's XML parser BeautifulSoup ( markup, `` lxml-xml'' ) BeautifulSoup ( markup, `` xml'' )\")\n",
      "(430, 0.813, \"If you just need to parse some HTML, you can dump the markup into the BeautifulSoup constructor, and it'll probably be fine.\")\n",
      "(527, 0.813, 'You can shut off this feature by passing store_line_numbers = False ` into the `` BeautifulSoup constructor:')\n",
      "(19, 0.812, \"Running the `` three sisters'' document through Beautiful Soup gives us a BeautifulSoup object, which represents the document as a nested data structure:\")\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing the url for NY Times Today's, you must write a python script using the BeautifulSoup and requests modules to scrap all the headlines of that page.\n",
      "python - How to find children of nodes using BeautifulSoup - Stack Overflow\n",
      "\n",
      "(62, 0.812, 'Browse other questions tagged python html beautifulsoup or ask your own question.')\n",
      "(73, 0.806, \"Terminal won't show print response using BeautifulSoup\")\n",
      "(33, 0.799, 'https://www.crummy.com/software/BeautifulSoup/bs4/doc/#the-recursive-argument In your case as you want link1 which is first direct child:')\n",
      "(75, 0.798, \"BeautifulSoup loop isn't iterating through other nodes\")\n",
      "(72, 0.796, 'How to get only full li tags in beautifulsoup ?')\n",
      "(77, 0.795, 'How to find this generic tag inside a HTML code with BS4 ( beautiful soup )')\n",
      "(12, 0.763, 'How to find children of nodes using BeautifulSoup')\n",
      "(109, 0.762, 'Question feed To subscribe to this RSS feed, copy and paste this URL into your RSS reader.')\n",
      "(38, 0.715, 'This answers the question how to select <a> link1 </a> in the HTML given in the question, but this will FAIL when the first <li\\xa0class=\"test\"> will contain no <a> elements and there are other li elements with test class that contains <a>.')\n",
      "(85, 0.628, 'How to remove an element from a list by index')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing the url for NY Times Today's, you must write a python script using the BeautifulSoup and requests modules to scrap all the headlines of that page.\n",
      "python - How to find elements by class - Stack Overflow\n",
      "\n",
      "(125, 0.811, 'BeautifulSoup Issue: Get exact link url and Title')\n",
      "(107, 0.811, 'Browse other questions tagged python html web-scraping beautifulsoup or ask your own question.')\n",
      "(69, 0.809, \"How to find elements by class I'm having trouble parsing html elements with `` class'' attribute using Beautifulsoup.\")\n",
      "(43, 0.807, \"Supplement to @NunoAndr é's answer for BeautifulSoup 3: soup.findAll ( `` a'', -LCB- ` class' :[ ` stylelistrowone', ` stylelistrow' -RSB- -RCB- ).\")\n",
      "(123, 0.8, 'How to use BeautifulSoup to find an href link with a class')\n",
      "(119, 0.8, 'How do I extract all the links of a certain section of a web page with beautifulsoup ?')\n",
      "(76, 0.799, 'As of BeautifulSoup 4 +, If you have a single class name, you can just pass the class name as parameter like:')\n",
      "(121, 0.798, 'Python: search individual tag through BeautifulSoup')\n",
      "(17, 0.798, \"I'm having trouble parsing HTML elements with `` class'' attribute using Beautifulsoup.\")\n",
      "(47, 0.797, \"Update: 2016 In the latest version of beautifulsoup, the method ` findAll' has been renamed to ` find_all'.\")\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing the url for NY Times Today's, you must write a python script using the BeautifulSoup and requests modules to scrap all the headlines of that page.\n",
      "python - Extracting an attribute value with beautifulsoup - Stack Overflow\n",
      "\n",
      "(82, 0.81, 'How to grap data within a < a href tag with python BeautifulSoup')\n",
      "(86, 0.807, 'Beautifulsoup print value in div')\n",
      "(71, 0.806, 'Browse other questions tagged python parsing attributes beautifulsoup or ask your own question.')\n",
      "(20, 0.804, 'I get a TypeError: list indices must be integers, not str even though from the Beautifulsoup documentation i understand that strings should not be a problem here ... but i a no specialist and i may have misunderstood.')\n",
      "(80, 0.801, 'Extracting an element whose id starts with a certain string using BeautifulSoup in python')\n",
      "(59, 0.798, 'I am using this with Beautifulsoup 4.8.1 to get the value of all class attributes of certain elements:')\n",
      "(12, 0.792, 'Extracting an attribute value with beautifulsoup')\n",
      "(78, 0.788, 'How to get data with BeautifulSoup')\n",
      "(83, 0.785, 'how to get the text of the url while scraping webpage')\n",
      "(79, 0.777, \"How to parse `` data-text'' with beautifulsoup ?\")\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing the url for NY Times Today's, you must write a python script using the BeautifulSoup and requests modules to scrap all the headlines of that page.\n",
      "Tutorial: Web Scraping with Python Using Beautiful Soup – Dataquest\n",
      "\n",
      "(168, 0.814, 'f you instead only want to find the first instance of a tag, you can use the find method, which will return a single BeautifulSoup object:')\n",
      "(223, 0.812, 'To do this, we just treat the BeautifulSoup object like a dictionary, and pass in the attribute we want as a key:')\n",
      "(142, 0.809, 'We can now print out the HTML content of the page, formatted nicely, using the prettify method on the BeautifulSoup object.')\n",
      "(158, 0.808, 'Each item in the list returned by the children property is also a BeautifulSoup object, so we can also call the children method on html.')\n",
      "(141, 0.808, 'We first have to import the library, and create an instance of the BeautifulSoup class to parse our document:')\n",
      "(140, 0.807, 'We can use the BeautifulSoup library to parse this document, and extract the text from the p tag.')\n",
      "(174, 0.807, \"Let's first download the page and create a BeautifulSoup object:\")\n",
      "(150, 0.807, 'As we can see, all of the items are BeautifulSoup objects:')\n",
      "(212, 0.806, 'Create a BeautifulSoup class to parse the page.')\n",
      "(36, 0.798, 'Request the content ( source code ) of a specific URL from the server Download the content that is returned Identify the elements of the page that are part of the table we want')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing the url for NY Times Today's, you must write a python script using the BeautifulSoup and requests modules to scrap all the headlines of that page.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to extract HTTP response body from a Python requests call? - Stack Overflow\n",
      "\n",
      "(52, 0.774, 'Correct way to try/except using Python requests module ?')\n",
      "(79, 0.762, 'Question feed To subscribe to this RSS feed, copy and paste this URL into your RSS reader.')\n",
      "(12, 0.739, 'How to extract HTTP response body from a Python requests call ?')\n",
      "(20, 0.728, 'This should indeed print lots of content, but instead prints nothing.')\n",
      "(47, 0.728, 'how to get response data from a python post request')\n",
      "(30, 0.698, 'You can try this method:')\n",
      "(17, 0.686, \"I'm using the Python requests library.\")\n",
      "(54, 0.664, 'How to upload file with python requests ?')\n",
      "(82, 0.614, 'Follow this question to receive notifications')\n",
      "(48, 0.609, \"Using headers with the Python requests library's get method\")\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing the url for NY Times Today's, you must write a python script using the BeautifulSoup and requests modules to scrap all the headlines of that page.\n",
      "BeautifulSoup tutorial: Scraping web pages with Python | ScrapingBee \n",
      "\n",
      "(9, 0.809, 'Parsing the HTML with BeautifulSoup Now that the HTML is accessible we will use BeautifulSoup to parse it.')\n",
      "(57, 0.809, 'Conclusion In the end, everything you do with pure CSS selectors you can do it with BeautifulSoup4.')\n",
      "(4, 0.808, 'WebScraping with BeautifulSoup Pulling the HTML out BeautifulSoup is not a web scraping library per se.')\n",
      "(3, 0.807, 'In this article, we will see how to extract structured information from web-page leveraging BeautifulSoup and CSS selectors.')\n",
      "(11, 0.803, 'In the rest of this article, we will refer to BeautifulSoup4 as BS4.')\n",
      "(20, 0.798, 'All I have to do is this: Advanced usage BeautifulSoup is a great example of a library that is both easy to use and powerful.')\n",
      "(10, 0.798, \"If you haven't already, you can install the package by doing a simple pip install beautifullsoup4.\")\n",
      "(1, 0.797, 'BeautifulSoup tutorial: Scraping web pages with Python Try ScrapingBee for Free')\n",
      "(21, 0.783, 'You can do much more to select elements using BeautifulSoup.')\n",
      "(30, 0.762, \"For example, let's say that you want to extract the score of a post on the HN homepage, but you can't use class name or id in your code.\")\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing the url for NY Times Today's, you must write a python script using the BeautifulSoup and requests modules to scrap all the headlines of that page.\n",
      "Developer Interface — Requests 2.27.1 documentation\n",
      "\n",
      "(27, 0.79, 'A valid URL is required to make a request.')\n",
      "(67, 0.782, 'Otherwise, we set missing proxy keys for this URL ( in case they were stripped by a previous redirect ).')\n",
      "(223, 0.777, 'Obtain the url to use when making the final request.')\n",
      "(225, 0.764, 'Otherwise, we should only use the path portion of the URL.')\n",
      "(174, 0.759, 'HTTP URL to send the request to.')\n",
      "(205, 0.758, 'url -- The requested URL.')\n",
      "(173, 0.758, 'Prepares the given HTTP URL.')\n",
      "(66, 0.74, 'If we are redirected to a URL covered by NO_PROXY, we strip the proxy configuration.')\n",
      "(224, 0.737, 'If the message is being sent through a HTTP proxy, the full URL has to be used.')\n",
      "(332, 0.713, 'The scheme for a proxy URL is now required.')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing the url for NY Times Today's, you must write a python script using the BeautifulSoup and requests modules to scrap all the headlines of that page.\n",
      "Requests: HTTP for Humans™ — Requests 2.27.1 documentation\n",
      "\n",
      "(12, 0.777, 'Make a Request Passing Parameters In URLs Response Content Binary Response Content JSON Response Content Raw Response Content Custom Headers More complicated POST requests POST a Multipart-Encoded File Response Status Codes Response Headers Cookies Redirection and History Timeouts Errors and Exceptions')\n",
      "(5, 0.74, \"There's no need to manually add query strings to your URLs, or to form-encode your POST data.\")\n",
      "(7, 0.663, \"Requests is ready for today's web.\")\n",
      "(3, 0.616, 'See similar code, sans Requests.')\n",
      "(19, 0.519, \"What are `` hostname doesn't match'' errors ?\")\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_task = 'nytimes'\n",
    "\n",
    "df_data = get_dict_for_task(input_task)\n",
    "test_data(df_data, model, fine_tunned_keras_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b388b9",
   "metadata": {},
   "source": [
    "# Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e658476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n",
      "python - 'Could not interpret input' error with Seaborn when plotting groupbys - Stack Overflow\n",
      "\n",
      "(67, 0.815, 'Plotting a graph between 2 variables using pandas')\n",
      "(21, 0.814, 'python pandas grouping aggregate seaborn')\n",
      "(70, 0.814, 'Pandas Key Error: 0 while plotting a seaborn boxplot')\n",
      "(54, 0.801, 'Browse other questions tagged python pandas grouping aggregate seaborn or ask your own question.')\n",
      "(19, 0.793, 'I can plot it from Pandas no problem ...')\n",
      "(20, 0.786, 'But why do I get this error when I try it in seaborn ?')\n",
      "(12, 0.785, \"` Could not interpret input' error with Seaborn when plotting groupbys\")\n",
      "(28, 0.742, \"You'll obtain the same result.\")\n",
      "(33, 0.722, 'This way you could feed it directly to seaborn.')\n",
      "(75, 0.694, 'ValueError: Could not interpret input in seaborn')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n",
      "seaborn.barplot — seaborn 0.11.2 documentation\n",
      "\n",
      "(11, 0.805, 'In most cases, it is possible to use numpy or Python objects, but pandas objects are preferable because the associated names will be used to annotate the axes.')\n",
      "(56, 0.736, 'Use catplot ( ) to combine a barplot ( ) and a FacetGrid.')\n",
      "(44, 0.728, 'Examples Draw a set of vertical bar plots grouped by a categorical variable:')\n",
      "(7, 0.679, 'Vectors of data represented as lists, numpy arrays, or pandas Series objects passed directly to the x, y, and/or hue parameters.')\n",
      "(52, 0.667, 'Use a different color palette for the bars:')\n",
      "(28, 0.592, 'This is usually inferred based on the type of the input variables, but it can be used to resolve ambiguity when both x and y are numeric or when plotting wide-form data.')\n",
      "(49, 0.579, 'Show the standard error of the mean with the error bars:')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n",
      "python - Difference between \"as_index = False\", and \"reset_index()\" in pandas groupby - Stack Overflow\n",
      "\n",
      "(29, 0.811, 'When both implementation yield the same results, use as_index = False because it will save you some typing and an unnecessary pandas operation ;) However, sometimes, you want to apply more complicated operations on your groups.')\n",
      "(56, 0.81, 'How to set merge multi level column in pandas which does display column name')\n",
      "(58, 0.808, 'pandas groupby without turning grouped by column into index')\n",
      "(57, 0.805, 'Pandas Groupby: Filling index names for all rows')\n",
      "(65, 0.803, \"`` Large data'' workflows using pandas\")\n",
      "(63, 0.799, 'Converting a Pandas GroupBy output from Series to DataFrame')\n",
      "(66, 0.796, 'Get statistics for each group ( such as count, mean, etc ) using pandas GroupBy ?')\n",
      "(47, 0.764, 'Browse other questions tagged python pandas pandas-groupby or ask your own question.')\n",
      "(12, 0.752, \"Difference between `` as_index = False'', and `` reset_index ( )'' in pandas groupby\")\n",
      "(28, 0.657, \"When you use as_index = False, you indicate to groupby ( ) that you don't want to set the column ID as the index ( duh ! )\")\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n",
      "Pandas query(): How to Filter Rows of Pandas Dataframe? - Python and R Tips\n",
      "\n",
      "(10, 0.815, 'Let us first load Pandas.')\n",
      "(20, 0.814, \"data_url = ` http://bit.ly/2cLzoxH'# read data from url as pandas dataframegapminder = pd.read _ csv ( data_url ) print ( gapminder.head ( 3 ) ) country year pop continent lifeExp gdpPercap0 Afghanistan 1952 8425333.0 Asia 28.801 779.4453141 Afghanistan 1957 9240934.0 Asia 30.332 820.8530302 Afghanistan 1962 10267083.0 Asia 31.997 853.100710\")\n",
      "(27, 0.814, 'How To Filter Pandas Dataframe By Values of Column ?')\n",
      "(26, 0.812, 'How to Filter Rows Based on Column Values with query function in Pandas ?')\n",
      "(21, 0.811, '# read data from url as pandas dataframe')\n",
      "(25, 0.81, '# filter rows with Pandas query')\n",
      "(18, 0.81, '# import pandasimport pandas as pd')\n",
      "(28, 0.808, 'How to Drop Rows Based on a Column Value in Pandas Dataframe ?')\n",
      "(31, 0.808, 'Learn Pandas in Python and Tidyverse in R')\n",
      "(16, 0.807, 'Pandas offer many ways to select rows from a dataframe.')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n",
      "How do I select a subset of a DataFrame? — pandas 1.3.5 documentation\n",
      "\n",
      "(15, 0.817, 'This tutorial uses the Titanic data set, stored as CSV.')\n",
      "(30, 0.814, 'As a single column is selected, the returned object is a pandas Series.')\n",
      "(86, 0.812, 'next How to create plots in pandas ?')\n",
      "(38, 0.811, 'The returned data type is a pandas DataFrame:')\n",
      "(47, 0.81, '=, <, < =, ... would work ) is actually a pandas Series of boolean values ( either True or False ) with the same number of rows as the original DataFrame.')\n",
      "(0, 0.81, 'What kind of data does pandas handle ?')\n",
      "(3, 0.808, 'How to create plots in pandas ?')\n",
      "(55, 0.808, \"In this case, the condition inside the selection brackets titanic -LSB- `` Pclass'' -RSB-.\")\n",
      "(34, 0.808, 'A pandas Series is 1-dimensional and only the number of rows is returned.')\n",
      "(33, 0.804, 'DataFrame.shape is an attribute ( remember tutorial on reading and writing, do not use parentheses for attributes ) of a pandas Series and DataFrame containing the number of rows and columns: ( nrows, ncolumns ).')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n",
      "How do I read and write tabular data? — pandas 1.3.5 documentation\n",
      "\n",
      "(22, 0.818, 'I want to analyze the Titanic passenger data, available as a CSV file.')\n",
      "(12, 0.817, 'This tutorial uses the Titanic data set, stored as CSV.')\n",
      "(61, 0.812, 'previous What kind of data does pandas handle ?')\n",
      "(31, 0.811, 'For example, titanic.tail ( 10 ) will return the last 10 rows of the DataFrame.')\n",
      "(0, 0.81, 'What kind of data does pandas handle ?')\n",
      "(3, 0.808, 'How to create plots in pandas ?')\n",
      "(58, 0.808, 'Exporting data out of pandas is provided by different to _ * methods.')\n",
      "(30, 0.807, 'pandas also provides a tail ( ) method.')\n",
      "(27, 0.805, 'I want to see the first 8 rows of a pandas DataFrame.')\n",
      "(39, 0.796, 'My colleague requested the Titanic data as a spreadsheet.')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n",
      "Filter Dataframe Rows Based on Column Values in Pandas | Delft Stack\n",
      "\n",
      "(29, 0.816, 'Select Pandas Rows Based on Multiple Column Values')\n",
      "(18, 0.815, 'In this method, we use pandas.DataFrame.eq ( ) method for the DataFrame column whose values are to be checked to compare element-wise equality in DataFrame.')\n",
      "(5, 0.815, 'Select Pandas Rows Based on Specific Column Value')\n",
      "(32, 0.814, 'Select Pandas Rows Which Contain Any One of Multiple Column Values')\n",
      "(26, 0.814, 'Select Pandas Rows With Column Values Greater Than or Smaller Than Specific Value')\n",
      "(21, 0.813, 'Select Pandas Rows Which Do Not Contain Specific Column Value')\n",
      "(31, 0.813, 'In this section, we will discuss methods to select Pandas rows based on multiple column values.')\n",
      "(36, 0.812, 'Select Pandas Rows Which Does Not Contain Any One of Multiple Specified Column Values')\n",
      "(8, 0.811, 'Select Pandas Rows Which Contain Specific Column Value Filter Using Boolean Indexing')\n",
      "(6, 0.811, 'We can select pandas rows from a DataFrame that contains or does not contain the specific value for a column.')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas.DataFrame.sort_values — pandas 1.3.5 documentation\n",
      "\n",
      "(23, 0.765, '© Copyright 2008-2021, the pandas development team.')\n",
      "(7, 0.712, 'If this is a list of bools, must match the length of the by.')\n",
      "(0, 0.659, 'Sort by the values along either axis.')\n",
      "(18, 0.644, 'It will be applied to each column in by independently.')\n",
      "(3, 0.597, \"if axis is 1 or ` columns' then by may contain column levels and/or index labels.\")\n",
      "(2, 0.576, \"if axis is 0 or ` index' then by may contain index levels and/or column labels.\")\n",
      "(11, 0.502, 'mergesort and stable are the only stable algorithms.')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n",
      "pandas.core.groupby.DataFrameGroupBy.aggregate — pandas 1.3.5 documentation\n",
      "\n",
      "(32, 0.765, '© Copyright 2008-2021, the pandas development team.')\n",
      "(28, 0.76, \"Pandas provides the pandas.NamedAgg namedtuple with the fields -LSB- ` column', ` aggfunc' -RSB- to make it clearer what the arguments are.\")\n",
      "(24, 0.74, 'The aggregation is for each column.')\n",
      "(13, 0.716, 'The values must either be True or False.')\n",
      "(26, 0.607, \"To control the output names with different aggregations per column, pandas supports `` named aggregation''\")\n",
      "(25, 0.59, 'Select a column for aggregation')\n",
      "(6, 0.571, \"If the ` numba' engine is chosen, the function must be a user defined function with values and index as the first and second arguments respectively in the function signature.\")\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n",
      "python - Pandas read_csv from url - Stack Overflow\n",
      "\n",
      "(105, 0.816, 'How to read CSV file from GitHub using pandas')\n",
      "(115, 0.812, 'How to iterate over rows in a DataFrame in Pandas')\n",
      "(116, 0.812, 'Writing a pandas DataFrame to CSV file')\n",
      "(33, 0.811, 'There seems to be some issue reading csv from a URL.')\n",
      "(110, 0.811, 'Selecting multiple columns in a Pandas dataframe')\n",
      "(47, 0.811, 'In the latest version of pandas you can give the url directly i.e. c = pd.read _ csv ( url )')\n",
      "(112, 0.811, 'Delete a column from a Pandas DataFrame')\n",
      "(106, 0.81, 'How to set proxy for Pandas pd.read _ csv')\n",
      "(114, 0.81, 'How do I get the row count of a Pandas DataFrame ?')\n",
      "(118, 0.809, 'Get a list from Pandas DataFrame column headers')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n",
      "python - How do I select rows from a DataFrame based on column values? - Stack Overflow\n",
      "\n",
      "(93, 0.813, 'tl ; dr The Pandas equivalent to')\n",
      "(46, 0.812, 'There are several ways to select rows from a Pandas dataframe:')\n",
      "(151, 0.812, 'How to iterate over rows in a DataFrame in Pandas')\n",
      "(146, 0.812, 'Use a list of values to select rows from a Pandas dataframe')\n",
      "(148, 0.811, 'Delete a column from a Pandas DataFrame')\n",
      "(136, 0.81, 'Select rows from a DataFrame based on multiple values in a column in pandas')\n",
      "(150, 0.81, 'How do I get the row count of a Pandas DataFrame ?')\n",
      "(152, 0.809, 'Get a list from Pandas DataFrame column headers')\n",
      "(98, 0.808, \"It seems like it's the pandas analog to filter in dplyr.\")\n",
      "(145, 0.808, 'Filter pandas DataFrame by substring criteria')\n",
      "\n",
      "--------------------\n",
      "\n",
      "Given a string representing a url for the titanic dataset (in csv format), you must write an algorithm using the pandas and seaborn modules to create a barchart with the aggregate average of the passengers'  fare according to the following constraints\n",
      "How to Make a Seaborn Barplot - Sharp Sight\n",
      "\n",
      "(96, 0.815, \"You can do that with this code: We'll use Pandas and Numpy to create our dataset, and we'll use Seaborn ( obviously ) to create our bar charts.\")\n",
      "(95, 0.815, 'Specifically, you need to import Pandas, Numpy, and Seaborn.')\n",
      "(189, 0.813, 'This tutorial will show you how to make a Seaborn barplot.')\n",
      "(29, 0.813, 'Seaborn works well with DataFrames Perhaps the biggest reasons to use Seaborn is that the syntax was largely designed to work well with Pandas DataFrames.')\n",
      "(53, 0.811, 'Moreover, if you know how to wrangle your data using Pandas, you can calculate even more complicated statistics.')\n",
      "(63, 0.808, \"Technically, this parameter will also recognize an array or a list of arrays, but it's most common to pass a Pandas DataFrame as the argument to the data parameter.\")\n",
      "(23, 0.807, 'With all of the options, why use Seaborn ?')\n",
      "(109, 0.806, \"Now that we have our dataset, let's make some bar charts.\")\n",
      "(16, 0.8, \"Having said that, let's talk about creating bar charts in Python, and in Seaborn.\")\n",
      "(167, 0.797, 'Dodged bar charts like this can be very useful for analyzing categories within categories, and comparing across complex multi-variate groups.')\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_task = 'titanic'\n",
    "\n",
    "df_data = get_dict_for_task(input_task)\n",
    "test_data(df_data, model, fine_tunned_keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e2dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 Arthur hugging",
   "language": "python",
   "name": "msarthur-hface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
