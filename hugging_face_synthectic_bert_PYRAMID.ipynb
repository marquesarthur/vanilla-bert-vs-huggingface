{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marquesarthur/vanilla-bert-vs-huggingface/blob/main/hugging_face_keras_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfNydjdoLcvK"
   },
   "source": [
    "Based on \n",
    "\n",
    "\n",
    "\n",
    "1.   https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379\n",
    "2.   https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/\n",
    "3.   https://huggingface.co/transformers/training.html#fine-tuning-with-keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**problem statement:**\n",
    "\n",
    "\n",
    "*   a developer has to inspect an **artifact X**\n",
    "*   Within the artifact, only a portion of the text is relevant to **input task Y**\n",
    "*   We ought to build a model that establishes relationships between **Y** and **sentences x âˆˆ X** \n",
    "*  The model must determine: **is x relevant to task Y**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Example of a task and an annotated artifact:*\n",
    "\n",
    "<br>\n",
    "\n",
    "[<img src=\"https://i.imgur.com/Zj1317H.jpg\">](https://i.imgur.com/Zj1317H.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* The coloured sentences are sentences annotated as relevant to the input task. \n",
    "* The warmer the color, the more annotators selected that portion of the text. \n",
    "* For simplicity, we process the data and used sentences \n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Ultimately, our data is a tuple representing:*\n",
    "\n",
    "\n",
    "*   **text** = artifact sentence\n",
    "\n",
    "*   **question** = task description\n",
    "\n",
    "*   **source** = URL of the artifact\n",
    "\n",
    "*   **category_index** = whether sentence is relevant [or not] for the input task\n",
    "\n",
    "*   **weights** = number of participants who annotated sentence as relevant\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtFJT5AK6RRc",
    "outputId": "f3eaf1c3-63c2-455e-eaa5-5eb9955afe4b"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "\n",
    "# !pip install transformers\n",
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y80jdm9S6wQA",
    "outputId": "de6caa10-19da-42af-958f-bf19fe70903d"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn tqdm pandas python-Levenshtein path colorama matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q38yIvW87NrN",
    "outputId": "425ff20e-e16f-475a-93fe-221008e32fdc"
   },
   "outputs": [],
   "source": [
    "# @title Download git repo\n",
    "# !git clone https://github.com/marquesarthur/vanilla-bert-vs-huggingface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyrLR-tf8P4Q",
    "outputId": "a2cc52fc-f3e9-4cf0-ce6d-c11cee304c39"
   },
   "outputs": [],
   "source": [
    "# %cd vanilla-bert-vs-huggingface\n",
    "# !git pull\n",
    "# !ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kudd2ZR8tKZ",
    "outputId": "2a38495e-b8e4-43b1-c126-ec92e98b07d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m39 \u001b[33m129 \u001b[0m https://developer.android.com/training/permissions/requesting\n",
      "\u001b[31m14 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/5233543\n",
      "\u001b[31m4 \u001b[33m34 \u001b[0m https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "\u001b[31m27 \u001b[33m63 \u001b[0m https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "\u001b[31m9 \u001b[33m161 \u001b[0m https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "\u001b[31m9 \u001b[33m15 \u001b[0m https://developer.android.com/training/volley/request\n",
      "\u001b[31m14 \u001b[33m65 \u001b[0m https://stackoverflow.com/questions/28504524\n",
      "\u001b[31m20 \u001b[33m59 \u001b[0m https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "\u001b[31m5 \u001b[33m97 \u001b[0m https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "\u001b[31m4 \u001b[33m12 \u001b[0m https://stackoverflow.com/questions/33241952\n",
      "\u001b[31m6 \u001b[33m33 \u001b[0m https://github.com/realm/realm-java/issues/776\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/8712652\n",
      "\u001b[31m8 \u001b[33m59 \u001b[0m https://dzone.com/articles/android-rotate-and-scale\n",
      "\u001b[31m5 \u001b[33m470 \u001b[0m https://developer.android.com/reference/android/widget/TextView\n",
      "\u001b[31m7 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/19025301\n",
      "\u001b[31m8 \u001b[33m95 \u001b[0m https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "\u001b[31m20 \u001b[33m145 \u001b[0m https://developer.android.com/training/dependency-injection/hilt-android\n",
      "\u001b[31m4 \u001b[33m8 \u001b[0m https://stackoverflow.com/questions/30648172\n",
      "\u001b[31m4 \u001b[33m81 \u001b[0m https://github.com/google/dagger/issues/1991\n",
      "\u001b[31m9 \u001b[33m48 \u001b[0m https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "\u001b[31m5 \u001b[33m47 \u001b[0m https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "\u001b[31m9 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/6442054\n",
      "\u001b[31m3 \u001b[33m22 \u001b[0m https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "\u001b[31m22 \u001b[33m211 \u001b[0m https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "\u001b[31m21 \u001b[33m59 \u001b[0m https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "\u001b[31m17 \u001b[33m33 \u001b[0m https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "\u001b[31m6 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/10108774\n",
      "\u001b[31m19 \u001b[33m250 \u001b[0m https://developer.android.com/guide/topics/media/camera\n",
      "\u001b[31m5 \u001b[33m32 \u001b[0m https://github.com/google/ExoPlayer/issues/8387\n",
      "\u001b[31m7 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/8184492\n",
      "\u001b[31m7 \u001b[33m58 \u001b[0m https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "\u001b[31m3 \u001b[33m50 \u001b[0m https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "\u001b[31m3 \u001b[33m56 \u001b[0m https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "\u001b[31m3 \u001b[33m5 \u001b[0m https://stackoverflow.com/questions/38980595\n",
      "\u001b[31m4 \u001b[33m38 \u001b[0m https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "\u001b[31m8 \u001b[33m36 \u001b[0m https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "\u001b[31m4 \u001b[33m131 \u001b[0m https://stackoverflow.com/questions/122105\n",
      "\u001b[31m3 \u001b[33m48 \u001b[0m https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "\u001b[31m8 \u001b[33m49 \u001b[0m https://developer.android.com/guide/topics/media/mediarecorder\n",
      "\u001b[31m4 \u001b[33m9 \u001b[0m https://stackoverflow.com/questions/6688444\n",
      "\u001b[31m3 \u001b[33m23 \u001b[0m https://github.com/google/oboe/issues/447\n",
      "\u001b[31m4 \u001b[33m27 \u001b[0m https://stackoverflow.com/questions/24952513\n",
      "\u001b[31m18 \u001b[33m219 \u001b[0m https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "\u001b[31m3 \u001b[33m72 \u001b[0m https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "\u001b[31m5 \u001b[33m373 \u001b[0m https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "\u001b[31m12 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/35357919\n",
      "\u001b[31m11 \u001b[33m117 \u001b[0m https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "\u001b[31m8 \u001b[33m147 \u001b[0m https://developer.android.com/training/notify-user/build-notification\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/3059155\n",
      "\u001b[31m10 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/26838730\n",
      "\u001b[31m7 \u001b[33m48 \u001b[0m https://guides.codepath.com/android/Defining-The-ActionBar\n",
      "\u001b[31m7 \u001b[33m283 \u001b[0m https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "\u001b[31m5 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/37096547\n",
      "\u001b[31m7 \u001b[33m179 \u001b[0m https://guides.codepath.com/android/using-the-recyclerview\n",
      "\u001b[31m3 \u001b[33m31 \u001b[0m https://stackoverflow.com/questions/47760861\n",
      "\u001b[31m13 \u001b[33m69 \u001b[0m https://developer.android.com/training/data-storage/sqlite\n",
      "\u001b[31m15 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/4015026\n",
      "\u001b[31m15 \u001b[33m81 \u001b[0m https://developer.android.com/guide/background/threading\n",
      "\u001b[31m6 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/2993085\n",
      "\u001b[31m11 \u001b[33m50 \u001b[0m https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "\u001b[31m5 \u001b[33m28 \u001b[0m https://stackoverflow.com/questions/23844667\n",
      "\u001b[31m5 \u001b[33m45 \u001b[0m https://github.com/flutter/flutter/issues/11392\n",
      "\u001b[31m4 \u001b[33m23 \u001b[0m https://stackoverflow.com/questions/29738510\n",
      "\u001b[31m5 \u001b[33m54 \u001b[0m https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "\u001b[31m4 \u001b[33m100 \u001b[0m https://stackoverflow.com/questions/2661536\n",
      "\u001b[31m9 \u001b[33m65 \u001b[0m https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "\u001b[31m5 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/24652078\n",
      "\u001b[31m8 \u001b[33m44 \u001b[0m https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/2883355\n",
      "\u001b[31m7 \u001b[33m24 \u001b[0m https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "\u001b[31m9 \u001b[33m51 \u001b[0m https://stackoverflow.com/questions/11064244\n",
      "\u001b[31m7 \u001b[33m138 \u001b[0m https://github.com/quarkusio/quarkus/issues/3954\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m16 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/29923376\n",
      "\u001b[31m4 \u001b[33m13 \u001b[0m https://github.com/google/dagger/issues/671\n",
      "\u001b[31m3 \u001b[33m19 \u001b[0m https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/36275986\n",
      "\u001b[31m42 \u001b[33m177 \u001b[0m https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "\u001b[31m9 \u001b[33m36 \u001b[0m https://developer.android.com/training/location/retrieve-current\n",
      "\u001b[31m5 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/46481789\n",
      "\u001b[31m22 \u001b[33m119 \u001b[0m https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "\u001b[31m15 \u001b[33m99 \u001b[0m https://javapapers.com/android/android-location-fused-provider\n",
      "\u001b[31m3 \u001b[33m14 \u001b[0m https://developer.android.com/training/keyboard-input/commands\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m3 \u001b[33m4 \u001b[0m https://stackoverflow.com/questions/40168601\n",
      "\u001b[31m20 \u001b[33m54 \u001b[0m https://developer.android.com/training/safetynet/recaptcha\n",
      "\u001b[31m11 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/27297067\n",
      "\u001b[31m8 \u001b[33m42 \u001b[0m https://stackoverflow.com/questions/30362446\n",
      "\u001b[31m10 \u001b[33m36 \u001b[0m https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "\u001b[31m5 \u001b[33m16 \u001b[0m https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "\u001b[31m5 \u001b[33m57 \u001b[0m https://github.com/signalapp/Signal-Android/issues/3376\n",
      "\u001b[31m5 \u001b[33m34 \u001b[0m https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "\u001b[31m22 \u001b[33m104 \u001b[0m https://developer.android.com/reference/org/json/JSONObject\n",
      "\u001b[31m8 \u001b[33m31 \u001b[0m https://guides.codepath.com/android/converting-json-to-models\n",
      "\u001b[31m7 \u001b[33m146 \u001b[0m https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "\u001b[31m5 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/24313539\n",
      "\u001b[31m12 \u001b[33m77 \u001b[0m https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "\u001b[31m6 \u001b[33m72 \u001b[0m https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "\u001b[31m5 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/14347588\n",
      "\u001b[31m31 \u001b[33m163 \u001b[0m https://guides.codepath.com/android/creating-and-using-fragments\n",
      "\u001b[31m4 \u001b[33m40 \u001b[0m https://developer.android.com/training/gestures/scale\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m6 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/10630373\n",
      "\u001b[31m4 \u001b[33m54 \u001b[0m https://developer.android.com/training/gestures/scroll\n",
      "\u001b[31m4 \u001b[33m16 \u001b[0m https://stackoverflow.com/questions/39588322\n",
      "\u001b[31m20 \u001b[33m196 \u001b[0m https://developer.android.com/training/dependency-injection/dagger-android\n",
      "\u001b[31m6 \u001b[33m44 \u001b[0m https://stackoverflow.com/questions/57235136\n",
      "\u001b[31m24 \u001b[33m121 \u001b[0m https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "Sample entry from data:\n",
      "{\n",
      "    \"category_index\": 1,\n",
      "    \"question\": \"Permission Denial when trying to access contacts in Android\",\n",
      "    \"source\": \"https://developer.android.com/training/permissions/requesting\",\n",
      "    \"text\": \"Every Android app runs in a limited-access sandbox.\",\n",
      "    \"weights\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# @title Import data as JSON\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from Levenshtein import ratio\n",
    "from colorama import Fore, Style\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.level = logging.DEBUG\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "from ds_android import get_input_for_BERT\n",
    "\n",
    "raw_data = get_input_for_BERT()\n",
    "\n",
    "print('Sample entry from data:')\n",
    "print(json.dumps(raw_data[0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b_GXczz9CGs",
    "outputId": "2f6b91cb-8396-41af-e299-61360817d8b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution\n",
      "\n",
      "not-relevant -- 88%\n",
      "RELEVANT ------ 12%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "cnt = Counter([d['category_index'] for d in raw_data])\n",
    "\n",
    "total = sum(cnt.values())\n",
    "\n",
    "labels_cnt = [cnt[0] / float(total), cnt[1] / float(total)]\n",
    "print('label distribution')\n",
    "print('')\n",
    "print('not-relevant -- {:.0f}%'.format(labels_cnt[0] * 100))\n",
    "print('RELEVANT ------ {:.0f}%'.format(labels_cnt[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seframes = {}\n",
    "with open('seframes.json') as input_file:\n",
    "    seframes = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_meaningful_frame(text):    \n",
    "    meaning_frames = [\n",
    "        'Temporal_collocation', 'Execution', 'Using', 'Intentionally_act',\n",
    "        'Being_obligated', 'Likelihood', 'Causation', 'Required_event',\n",
    "        'Desiring', 'Awareness', 'Grasp', 'Attempt'\n",
    "    ]\n",
    "    \n",
    "    if text in seframes:\n",
    "        text_labels = seframes[text]\n",
    "        if any([elem in meaning_frames for elem in text_labels]):\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLoading data from cache\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fold_results = dict()\n",
    "if os.path.isfile('bert_ds_synthetic_pyramid.json'):\n",
    "    logger.info(Fore.YELLOW + \"Loading data from cache\" + Style.RESET_ALL)\n",
    "    with open('bert_ds_synthetic_pyramid.json') as input_file:\n",
    "        fold_results = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1l5DIHP_FUb",
    "outputId": "7f1648d0-2582-43a8-c1fc-50095d78892b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n"
     ]
    }
   ],
   "source": [
    "# @title Set environment variables\n",
    "\n",
    "model_id = 'bert-base-uncased'\n",
    "# model_id = 'distilbert-base-uncased'\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "USE_TPU = False\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "# @title Initialize TPU Strategy\n",
    "if USE_TPU:\n",
    "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
    "    tf.contrib.distribute.initialize_tpu_system(resolver)\n",
    "    strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
    "\n",
    "# sklearn libs\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "# Hugging face imports\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification, TFBertForSequenceClassification\n",
    "from transformers import TFDistilBertModel, DistilBertConfig\n",
    "from transformers import DistilBertTokenizerFast, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Model parameters\n",
    "\n",
    "# Bert Model Constants\n",
    "SEQ_LEN = 64 # 128\n",
    "BATCH_SIZE = 64 # 64 32 larger batch size causes OOM errors\n",
    "EPOCHS = 10 # 3 4\n",
    "LR = 1e-5 # 2e-5\n",
    "\n",
    "# 3e-4, 1e-4, 5e-5, 3e-5\n",
    "# My own constants\n",
    "# USE_FRAME_FILTERING = False\n",
    "# UNDERSAMPLING = True\n",
    "# N_UNDERSAMPLING = 2 # ratio of how many samples from 0-class, to 1-class, e.g.: 2:1\n",
    "# USE_DS_SYNTHETIC = False\n",
    "\n",
    "USE_FRAME_FILTERING = False\n",
    "UNDERSAMPLING = True\n",
    "N_UNDERSAMPLING = 2 # ratio of how many samples from 0-class, to 1-class, e.g.: 2:1\n",
    "USE_DS_SYNTHETIC = False\n",
    "MIN_W = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1T9xPdXp_kt9"
   },
   "outputs": [],
   "source": [
    "# @title JSON to dataframe helper functions\n",
    "def undersample_df(df, n_times=3):\n",
    "    class_0,class_1 = df.category_index.value_counts()\n",
    "    c0 = df[df['category_index'] == 0]\n",
    "    c1 = df[df['category_index'] == 1]\n",
    "    df_0 = c0.sample(int(n_times * class_1))\n",
    "    \n",
    "    undersampled_df = pd.concat([df_0, c1],axis=0)\n",
    "    return undersampled_df\n",
    "\n",
    "def get_ds_synthetic_data(min_w=MIN_W, undersample_n=2):\n",
    "    short_task = {\n",
    "      \"bugzilla\": \"\"\"How to query bugs using the custom fields with the Bugzilla REST API?\"\"\",\n",
    "      \"databases\": \"\"\"Which technology should be adopted for the database layer abstraction: Object/Relational Mapping (ORM) or a Java Database Connectivity API (JDBC)?\"\"\",\n",
    "      \"gpmdpu\": \"\"\"Can I bind the cmd key to the GPMDPU shortcuts?\"\"\",\n",
    "      \"lucene\": \"\"\"How does Lucene compute similarity scores for the BM25 similarity?\"\"\",\n",
    "      \"networking\": \"\"\"Which technology should be adopted for the notification system, Server-Sent Events (SSE) or WebSockets?\"\"\",\n",
    "    }\n",
    "\n",
    "    with open('relevance_corpus.json') as ipf:\n",
    "        aux = json.load(ipf)\n",
    "        raw_data = defaultdict(list)\n",
    "        for d in aux:\n",
    "            if d['task'] == 'yargs':\n",
    "                continue\n",
    "\n",
    "            raw_data['text'].append(d['text'])\n",
    "            raw_data['question'].append(short_task[d['task']])\n",
    "            raw_data['source'].append(d['source'])\n",
    "            raw_data['category_index'].append(1 if d['weight'] > min_w else 0)\n",
    "            raw_data['weights'].append(d['weight'] if d['weight'] > min_w else 0)\n",
    "            raw_data['source_type'].append('synthetic_dataset')\n",
    " \n",
    "        data = pd.DataFrame.from_dict(raw_data)\n",
    "        data = undersample_df(data, n_times=undersample_n)\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "      \n",
    "    return data\n",
    "\n",
    "def get_class_weights(y, smooth_factor=0, upper_bound=5.0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    clazz = {cls: float(majority / count) for cls, count in counter.items()}\n",
    "    result = {}\n",
    "    for key, value in clazz.items():\n",
    "        if value > upper_bound:\n",
    "            value = upper_bound\n",
    "        \n",
    "        result[key] = value\n",
    "    return result\n",
    "\n",
    "def add_raw_data(result, data):\n",
    "    s = data['source']\n",
    "    if 'docs.oracle' in s or 'developer.android' in s:\n",
    "        source_type = 'api'\n",
    "    elif 'stackoverflow.com' in s:\n",
    "        source_type = 'so'\n",
    "    elif 'github.com' in s:\n",
    "        source_type = 'git'\n",
    "    else:\n",
    "        source_type = 'misc'\n",
    "    pyramid = 1 if data['weights'] > 1 else 0\n",
    "    \n",
    "    result['text'].append(data['text'])\n",
    "    result['question'].append(data['question'])\n",
    "    result['source'].append(data['source'])\n",
    "    result['category_index'].append(pyramid)\n",
    "    result['weights'].append(data['weights'])\n",
    "    result['source_type'].append(source_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837,
     "referenced_widgets": [
      "8c7cf993674145ffb7bb876e5591f6ca",
      "67f208ba489343dfa195c1dd915f3efe",
      "35a9eeb0acdb44738a6ad7fbf6d99b2b",
      "153c3ed5c6314a49a5a37ad976417142",
      "82b7fc20b50c44b2bd84b3bf882cdd43",
      "16b6cfa829ad43778c079452df231a3d",
      "a2a36eb594654c65acd584d9d4ebea20",
      "3950e2a7832c4dce8fd8209d6322a1f7",
      "d32667132d604faeb419bbf9851c1bd8",
      "262cc50dd08f49f78b781c2ce96a4ad7",
      "f305b344487a4b598a7d41b007e49abd",
      "c18a3a9fc6d54b9f848e4454e1e36c21",
      "a8fd8b38a6b84be7b83b2f4df590fada",
      "5c6bfb038756422bb00be1349db7750b",
      "6cf29b5d508a4e2082751ccc7fa2f625",
      "c4c410ab0c994a229a49b8baee221de4",
      "9e99fb1211ba43459ee78dd64ab8c30e",
      "71a15c5a038f451f8ee64ce046488f71",
      "c586016d3b594c6299cab2384f4c10aa",
      "d03c894896ad4ed6b48f19a70fbdf2af",
      "3ccd384305c44ee3a86f47a2b994fbf9",
      "23531989ef014d7db16b220bb807c8fd",
      "e0e88103f9684ffdb957357222bbaaf7",
      "c5b9bf1f3ae343ce97982c7802cfdc94",
      "a66943be0fc0423880cb2bd63a1ea2d2",
      "8c2b37becdef45bba205dfb20f8e37b2",
      "baffabe6cabf48f5b0b6523ea92aee78",
      "997b8c940317448c9409a2dee15fc519",
      "b12b35cc52454a249c97f695409d24ce",
      "b6d9e21208294428a3f5572bbbd8b0b9",
      "d15e557fc621427a8295eecdc1e781a8",
      "b4276b6a5eac4023955218db6f78c84a",
      "c4b0a1b67d304afda6ee4e52095584cc",
      "901557318fb947dfa082f0cbf2d7365b",
      "0efe94b613f44c029f2e9bd05696ad32",
      "5a38bc7017d545e2b44ad6ab0b2d937b",
      "b3db733aacf94a3c94519d70a7a56d7a",
      "394b7988d36849b7b2c82872ae8d489d",
      "d3e13535de4b44bb9139c3911684cee8",
      "6ccdfb754c12418c9438ac218a172e63",
      "929799bd24fb411bb4686988f2ae8996",
      "4bd0f4c575714ad7848e818a576ee00a",
      "0466163ff4a945798423387d1ac900c8",
      "17cfaa41c53842618c728987a81a44da"
     ]
    },
    "id": "r_y7xwmxAT39",
    "outputId": "ba094ca3-4ef3-41c0-da55-0e07626c7fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# @title Tokenizer\n",
    "\n",
    "print(model_id)\n",
    "if model_id == 'distilbert-base-uncased':\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)\n",
    "else:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HdAYw7lBAmlO"
   },
   "outputs": [],
   "source": [
    "# @title data encoder\n",
    "\n",
    "def _encode(tokenizer, dataframe, max_length=SEQ_LEN):\n",
    "    \n",
    "    seq_a = dataframe['text'].tolist()\n",
    "    seq_b = dataframe['question'].tolist()\n",
    "    \n",
    "    return tokenizer(seq_a, seq_b, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "def to_one_hot_encoding(data, nb_classes = 2):\n",
    "    targets = np.array([data]).reshape(-1)\n",
    "    one_hot_targets = np.eye(nb_classes)[targets]\n",
    "    return one_hot_targets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "y-5ROuqDBU9X"
   },
   "outputs": [],
   "source": [
    "# @title Metrics & Logging functions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "recommendation_metrics = defaultdict(list)\n",
    "prediction_metrics = defaultdict(list)\n",
    "api_metrics = defaultdict(list)\n",
    "so_metrics = defaultdict(list)\n",
    "git_metrics = defaultdict(list)\n",
    "misc_metrics = defaultdict(list)\n",
    "\n",
    "classification_report_lst = []\n",
    "log_examples_lst = []\n",
    "source_lst = []\n",
    "venn_diagram_set = []\n",
    "\n",
    "def aggregate_macro_metrics(store_at, precision, recall, fscore):   \n",
    "    store_at['precision'].append(precision)\n",
    "    store_at['recall'].append(recall)\n",
    "    store_at['fscore'].append(fscore)\n",
    "    \n",
    "    \n",
    "def aggregate_macro_source_metrics(precision, recall, fscore, source):\n",
    "    s = source\n",
    "    if 'docs.oracle' in s or 'developer.android' in s:\n",
    "        aggregate_macro_metrics(api_metrics, precision, recall, fscore)\n",
    "    elif 'stackoverflow.com' in s:\n",
    "        aggregate_macro_metrics(so_metrics, precision, recall, fscore)\n",
    "    elif 'github.com' in s:\n",
    "        aggregate_macro_metrics(git_metrics, precision, recall, fscore)        \n",
    "    elif  'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
    "        aggregate_macro_metrics(misc_metrics, precision, recall, fscore)\n",
    "    \n",
    "\n",
    "def aggregate_recommendation_metrics(store_at, k, precision_at_k, pyramid_precision_at_k):\n",
    "    store_at['k'].append(k)\n",
    "    store_at['precision'].append(precision_at_k)\n",
    "    store_at['âˆ† precision'].append(pyramid_precision_at_k)\n",
    "    \n",
    "def aggregate_report_metrics(clz_report):\n",
    "    relevant_label = str(1)\n",
    "    if relevant_label in clz_report:\n",
    "        for _key in ['precision', 'recall']:\n",
    "            if _key in clz_report[relevant_label]:\n",
    "                clz_report_lst[_key].append(clz_report[relevant_label][_key])    \n",
    "                \n",
    "def log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10):\n",
    "    # get the predicted prob at every index\n",
    "    idx_probs = [(idx, y_predict[idx], y_probs[idx]) for idx, _ in enumerate(y_predict)]\n",
    "    \n",
    "    # filter probs for all indexes predicted as relevant  \n",
    "    idx_probs = list(filter(lambda k: k[1] == 1, idx_probs))\n",
    "    \n",
    "    most_probable = sorted(idx_probs, key=lambda i: i[2], reverse=True)\n",
    "    \n",
    "    result = [idx for idx, _, _ in most_probable][:k]\n",
    "    \n",
    "    for idx in result:\n",
    "        log_examples_lst.append((\n",
    "            source, \n",
    "            task_title,\n",
    "            pweights[idx],\n",
    "            y_predict[idx],\n",
    "            y_probs[idx],\n",
    "            text[idx]\n",
    "        ))\n",
    "        \n",
    "def log_venn_diagram(y_true, y_predicted, text):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        for _true, _predict, _t in zip(y_true, y_predicted, text):\n",
    "            if _true == 1 and _predict == 1:\n",
    "                cnt += 1\n",
    "                venn_diagram_set.append(_t)\n",
    "    except Exception as ex:\n",
    "        logger.info(str(ex))\n",
    "    logger.info(Fore.RED + str(cnt) + Style.RESET_ALL + \" entries logged\")\n",
    "\n",
    "    \n",
    "def avg_macro_metric_for(data):\n",
    "    __precision = data['precision']\n",
    "    __recall = data['recall']\n",
    "    __fscore = data['fscore']\n",
    "\n",
    "    return np.mean(__precision), np.mean(__recall), np.mean(__fscore)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4E1IN6UoPq96"
   },
   "outputs": [],
   "source": [
    "#@title Training procedures\n",
    "\n",
    "def get_train_val_test(task_uid, size=0.9, undersample=False, aug=True, undersample_n=3, min_w=2):\n",
    "    if not isinstance(task_uid, list):\n",
    "        task_uid = [task_uid]\n",
    "        \n",
    "    train_data_raw = defaultdict(list)\n",
    "    test_data_raw = defaultdict(list)\n",
    "    \n",
    "    for _data in tqdm(CORPUS):\n",
    "        if _data['question'] in task_uid:\n",
    "            add_raw_data(test_data_raw, _data)\n",
    "        \n",
    "    \n",
    "    train_val = get_ds_synthetic_data(undersample_n=undersample_n, min_w=min_w)\n",
    "    test = pd.DataFrame.from_dict(test_data_raw)\n",
    "    \n",
    "    # https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "    #  randomize rows....    \n",
    "    train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "    test = test.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    print(train_val['category_index'].value_counts())\n",
    "\n",
    "    \n",
    "    weights = get_class_weights(train_val['category_index'].tolist())\n",
    "    \n",
    "    train, val = train_test_split(\n",
    "        train_val, \n",
    "        stratify=train_val['category_index'].tolist(), \n",
    "        train_size=size\n",
    "    )\n",
    "    \n",
    "    return train, val, test, weights        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_predictions(task_title, text, y_predict, y_probs, relevant_class=1):\n",
    "    result = []\n",
    "    \n",
    "    for _t, _y, _prob in zip(text, y_predict, y_probs):\n",
    "        if _y == relevant_class:\n",
    "            if has_meaningful_frame(_t):\n",
    "                result.append(_y)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        else:\n",
    "            result.append(_y)\n",
    "    \n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vFePvH5vBVA7"
   },
   "outputs": [],
   "source": [
    "# @title Testing procedures\n",
    "\n",
    "# https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7\n",
    "def eval_model(model, test_data):\n",
    "    preds = model.predict(test_data.batch(1)).logits  \n",
    "    \n",
    "    #transform to array with probabilities\n",
    "    res = tf.nn.softmax(preds, axis=1).numpy()      \n",
    "\n",
    "    return res.argmax(axis=-1), res[:, 1]\n",
    "\n",
    "def test_model(source, df_test, model, tokenizer, pos_filter=False):\n",
    "    \n",
    "    df_source = df_test[df_test[\"source\"] == source]   \n",
    "    task_title = df_source['question'].tolist()[0]\n",
    "    text = df_source['text'].tolist()\n",
    "    pweights = df_source['weights'].tolist()\n",
    "    \n",
    "    # Encode X_test\n",
    "    test_encodings = _encode(tokenizer, df_source)\n",
    "    test_labels = df_source['category_index'].tolist()\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        dict(test_encodings),\n",
    "        test_labels\n",
    "    ))\n",
    "    \n",
    "    y_true = [y.numpy() for x, y in test_dataset]\n",
    "    \n",
    "    # <= 0  means that an artifact has no relevant information highlighted \n",
    "    # by two or more annotators. these artifacts are ignored\n",
    "    if len(list(filter(lambda k: k == 1, y_true))) > 0:\n",
    "        y_predict, y_probs = eval_model(model, test_dataset)\n",
    "\n",
    "        if pos_filter:\n",
    "            y_predict = update_predictions(task_title, text, y_predict, y_probs)\n",
    "\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_predict)\n",
    "        macro_f1 = f1_score(y_true, y_predict, average='macro')\n",
    "\n",
    "        classification_report_lst.append(classification_report(y_true, y_predict))\n",
    "        aggregate_report_metrics(classification_report(y_true, y_predict, output_dict=True))\n",
    "\n",
    "\n",
    "        logger.info(\"-\" * 20)    \n",
    "\n",
    "        logger.info(\"Y\")\n",
    "        logger.info(\"[0s] {} [1s] {}\".format(\n",
    "            len(list(filter(lambda k: k== 0, y_true))),\n",
    "            len(list(filter(lambda k: k== 1, y_true)))\n",
    "        ))\n",
    "\n",
    "\n",
    "        logger.info(\"predicted\")\n",
    "        logger.info(\"[0s] {} [1s] {}\".format(\n",
    "            len(list(filter(lambda k: k== 0, y_predict))),\n",
    "            len(list(filter(lambda k: k== 1, y_predict)))\n",
    "        ))\n",
    "\n",
    "        logger.info(\"-\" * 20)\n",
    "\n",
    "        logger.info(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "        logger.info(\"macro_f1: {:.4f}\".format(macro_f1))\n",
    "\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(y_true, y_predict, average='macro')\n",
    "\n",
    "        aggregate_macro_metrics(prediction_metrics, precision, recall, fscore)\n",
    "        aggregate_macro_source_metrics(precision, recall, fscore, source)\n",
    "\n",
    "        logger.info(\"Precision: {:.4f}\".format(precision))\n",
    "        logger.info(\"Recall: {:.4f}\".format(recall))\n",
    "        logger.info(\"F1: {:.4f}\".format(fscore))\n",
    "\n",
    "        log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10)\n",
    "        log_venn_diagram(y_true, y_predict, text)\n",
    "        source_lst.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_idx_fold_results(idx_split, store_at):\n",
    "    if idx_split not in store_at:\n",
    "        store_at[idx_split] = dict()\n",
    "        store_at[idx_split]['run_cnt'] = 0\n",
    "        store_at[idx_split]['overall'] = defaultdict(list)\n",
    "        store_at[idx_split]['api'] = defaultdict(list)\n",
    "        store_at[idx_split]['so'] = defaultdict(list)\n",
    "        store_at[idx_split]['git'] = defaultdict(list)\n",
    "        store_at[idx_split]['misc'] = defaultdict(list)\n",
    "    \n",
    "    store_at[idx_split]['run_cnt'] += 1\n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "    store_at[idx_split]['overall']['precision'].append(_precision)\n",
    "    store_at[idx_split]['overall']['recall'].append(_recall)\n",
    "    store_at[idx_split]['overall']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(api_metrics)\n",
    "    store_at[idx_split]['api']['precision'].append(_precision)\n",
    "    store_at[idx_split]['api']['recall'].append(_recall)\n",
    "    store_at[idx_split]['api']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(so_metrics)\n",
    "    store_at[idx_split]['so']['precision'].append(_precision)\n",
    "    store_at[idx_split]['so']['recall'].append(_recall)\n",
    "    store_at[idx_split]['so']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(git_metrics)\n",
    "    store_at[idx_split]['git']['precision'].append(_precision)\n",
    "    store_at[idx_split]['git']['recall'].append(_recall)\n",
    "    store_at[idx_split]['git']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(misc_metrics)\n",
    "    store_at[idx_split]['misc']['precision'].append(_precision)\n",
    "    store_at[idx_split]['misc']['recall'].append(_recall)\n",
    "    store_at[idx_split]['misc']['fscore'].append(_f1score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TFBertForSequenceClassification.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "03ddd131c9f0446eb83bb6dabee9a832",
      "3518f71b0e4540be8b17a3fe72182cb4",
      "a5ccb838d3704546937e925e456830be",
      "8181fd24b3624c1b9c6a9d0302f43a56",
      "f02cf8090f8d463eb7eeb59743a87276",
      "c9ef3ce0ace649c5a53e2244ba0dbb32",
      "702a74b6e6e44d6b8ad68347f1a4b5fb",
      "3d84c022c44141268ef2c8d5e0190404",
      "40c212c9b352401697860624a6c54b1c",
      "1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "911177bb86c749a0bd774cd3b7f9d302"
     ]
    },
    "id": "1oZGDUKnB1gw",
    "outputId": "21690a29-4add-4780-f87f-fa497b87d5e1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n",
      "Hide MarkerView when nothing selected\n",
      "How to check programmatically whether app is running in debug mode or not?\n",
      "JSONObject parse dictionary objects\n",
      "Want to add drawable icons insteadof colorful dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 2410575.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    470\n",
      "1    235\n",
      "Name: category_index, dtype: int64\n",
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    423\n",
      "1    211\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    706\n",
      "1     29\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2ae1540443d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2ae1540443d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9629 - sparse_categorical_accuracy: 0.6593The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67945, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.9629 - sparse_categorical_accuracy: 0.6593 - val_loss: 0.6795 - val_sparse_categorical_accuracy: 0.5915\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8989 - sparse_categorical_accuracy: 0.5615\n",
      "Epoch 00002: val_loss improved from 0.67945 to 0.67451, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 7s 714ms/step - loss: 0.8989 - sparse_categorical_accuracy: 0.5615 - val_loss: 0.6745 - val_sparse_categorical_accuracy: 0.5915\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8374 - sparse_categorical_accuracy: 0.6845\n",
      "Epoch 00003: val_loss improved from 0.67451 to 0.66755, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 9s 914ms/step - loss: 0.8374 - sparse_categorical_accuracy: 0.6845 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.6056\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7770 - sparse_categorical_accuracy: 0.7256\n",
      "Epoch 00004: val_loss improved from 0.66755 to 0.64045, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 516ms/step - loss: 0.7770 - sparse_categorical_accuracy: 0.7256 - val_loss: 0.6404 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7247 - sparse_categorical_accuracy: 0.7839\n",
      "Epoch 00005: val_loss improved from 0.64045 to 0.60823, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 513ms/step - loss: 0.7247 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.6082 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6438 - sparse_categorical_accuracy: 0.8091\n",
      "Epoch 00006: val_loss improved from 0.60823 to 0.60192, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 506ms/step - loss: 0.6438 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.6019 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5574 - sparse_categorical_accuracy: 0.8454\n",
      "Epoch 00007: val_loss improved from 0.60192 to 0.58618, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 9s 912ms/step - loss: 0.5574 - sparse_categorical_accuracy: 0.8454 - val_loss: 0.5862 - val_sparse_categorical_accuracy: 0.7183\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4710 - sparse_categorical_accuracy: 0.8738\n",
      "Epoch 00008: val_loss improved from 0.58618 to 0.55731, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 500ms/step - loss: 0.4710 - sparse_categorical_accuracy: 0.8738 - val_loss: 0.5573 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3962 - sparse_categorical_accuracy: 0.9038\n",
      "Epoch 00009: val_loss improved from 0.55731 to 0.52349, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 507ms/step - loss: 0.3962 - sparse_categorical_accuracy: 0.9038 - val_loss: 0.5235 - val_sparse_categorical_accuracy: 0.7606\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3458 - sparse_categorical_accuracy: 0.9148\n",
      "Epoch 00010: val_loss did not improve from 0.52349\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.3458 - sparse_categorical_accuracy: 0.9148 - val_loss: 0.5503 - val_sparse_categorical_accuracy: 0.7606\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "https://stackoverflow.com/questions/23844667\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 24 [1s] 4\n",
      "predicted\n",
      "[0s] 25 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.8929\n",
      "macro_f1: 0.7551\n",
      "Precision: 0.7933\n",
      "Recall: 0.7292\n",
      "F1: 0.7551\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 87 [1s] 17\n",
      "predicted\n",
      "[0s] 46 [1s] 58\n",
      "--------------------\n",
      "Accuracy: 0.3558\n",
      "macro_f1: 0.3015\n",
      "Precision: 0.3932\n",
      "Recall: 0.3073\n",
      "F1: 0.3015\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "--------------------\n",
      "Y\n",
      "[0s] 31 [1s] 5\n",
      "predicted\n",
      "[0s] 33 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.7778\n",
      "macro_f1: 0.4375\n",
      "Precision: 0.4242\n",
      "Recall: 0.4516\n",
      "F1: 0.4375\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 2\n",
      "predicted\n",
      "[0s] 5 [1s] 26\n",
      "--------------------\n",
      "Accuracy: 0.2258\n",
      "macro_f1: 0.2185\n",
      "Precision: 0.5385\n",
      "Recall: 0.5862\n",
      "F1: 0.2185\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/37096547\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 16 [1s] 1\n",
      "predicted\n",
      "[0s] 16 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.8824\n",
      "macro_f1: 0.4688\n",
      "Precision: 0.4688\n",
      "Recall: 0.4688\n",
      "F1: 0.4688\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/33241952\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.524\u001b[0m\n",
      "recall:    \u001b[31m0.509\u001b[0m\n",
      "f1-score:  \u001b[31m0.436\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.393\u001b[0m\n",
      "recall:    \u001b[31m0.307\u001b[0m\n",
      "f1-score:  \u001b[31m0.301\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.631\u001b[0m\n",
      "recall:    \u001b[31m0.599\u001b[0m\n",
      "f1-score:  \u001b[31m0.612\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.424\u001b[0m\n",
      "recall:    \u001b[31m0.452\u001b[0m\n",
      "f1-score:  \u001b[31m0.438\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.538\u001b[0m\n",
      "recall:    \u001b[31m0.586\u001b[0m\n",
      "f1-score:  \u001b[31m0.218\u001b[0m\n",
      "next 1\n",
      "\n",
      "\u001b[31mFold 1\u001b[0m\n",
      " height must be > 0\n",
      "Write and Read a json data to internal storage android\n",
      "Android PDF Rendering\n",
      "How can I hide a fragment on start of my MainActivity( or the application)?\n",
      "polymorphic deserialization of JSON with jackson, property type becomes &quot;null&quot;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 2417770.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    470\n",
      "1    235\n",
      "Name: category_index, dtype: int64\n",
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    423\n",
      "1    211\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    722\n",
      "1     38\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9448 - sparse_categorical_accuracy: 0.5994The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68205, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.9448 - sparse_categorical_accuracy: 0.5994 - val_loss: 0.6821 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8713 - sparse_categorical_accuracy: 0.6073\n",
      "Epoch 00002: val_loss improved from 0.68205 to 0.68155, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 7s 709ms/step - loss: 0.8713 - sparse_categorical_accuracy: 0.6073 - val_loss: 0.6815 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8461 - sparse_categorical_accuracy: 0.6703\n",
      "Epoch 00003: val_loss improved from 0.68155 to 0.65555, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 505ms/step - loss: 0.8461 - sparse_categorical_accuracy: 0.6703 - val_loss: 0.6556 - val_sparse_categorical_accuracy: 0.6197\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8005 - sparse_categorical_accuracy: 0.7082\n",
      "Epoch 00004: val_loss did not improve from 0.65555\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.8005 - sparse_categorical_accuracy: 0.7082 - val_loss: 0.6665 - val_sparse_categorical_accuracy: 0.6479\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7485 - sparse_categorical_accuracy: 0.7760\n",
      "Epoch 00005: val_loss did not improve from 0.65555\n",
      "10/10 [==============================] - 2s 241ms/step - loss: 0.7485 - sparse_categorical_accuracy: 0.7760 - val_loss: 0.6765 - val_sparse_categorical_accuracy: 0.6338\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6676 - sparse_categorical_accuracy: 0.7950\n",
      "Epoch 00006: val_loss improved from 0.65555 to 0.64358, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 495ms/step - loss: 0.6676 - sparse_categorical_accuracy: 0.7950 - val_loss: 0.6436 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5894 - sparse_categorical_accuracy: 0.8265\n",
      "Epoch 00007: val_loss improved from 0.64358 to 0.52523, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 499ms/step - loss: 0.5894 - sparse_categorical_accuracy: 0.8265 - val_loss: 0.5252 - val_sparse_categorical_accuracy: 0.7746\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5166 - sparse_categorical_accuracy: 0.8659\n",
      "Epoch 00008: val_loss did not improve from 0.52523\n",
      "10/10 [==============================] - 2s 241ms/step - loss: 0.5166 - sparse_categorical_accuracy: 0.8659 - val_loss: 0.7043 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4165 - sparse_categorical_accuracy: 0.9038\n",
      "Epoch 00009: val_loss did not improve from 0.52523\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.4165 - sparse_categorical_accuracy: 0.9038 - val_loss: 0.6390 - val_sparse_categorical_accuracy: 0.7042\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3698 - sparse_categorical_accuracy: 0.9196\n",
      "Epoch 00010: val_loss did not improve from 0.52523\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.3698 - sparse_categorical_accuracy: 0.9196 - val_loss: 0.5477 - val_sparse_categorical_accuracy: 0.7746\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 8\n",
      "predicted\n",
      "[0s] 28 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.4545\n",
      "macro_f1: 0.3125\n",
      "Precision: 0.3571\n",
      "Recall: 0.2778\n",
      "F1: 0.3125\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 2\n",
      "predicted\n",
      "[0s] 24 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.4680\n",
      "Precision: 0.5208\n",
      "Recall: 0.5882\n",
      "F1: 0.4680\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "https://medium.com/@chahat.jain0/rendering-a-pdf-document-in-android-activity-fragment-using-pdfrenderer-442462cb8f9a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 22 [1s] 2\n",
      "predicted\n",
      "[0s] 23 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.8750\n",
      "macro_f1: 0.4667\n",
      "Precision: 0.4565\n",
      "Recall: 0.4773\n",
      "F1: 0.4667\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/14347588\n",
      "--------------------\n",
      "Y\n",
      "[0s] 21 [1s] 4\n",
      "predicted\n",
      "[0s] 22 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.8000\n",
      "macro_f1: 0.5847\n",
      "Precision: 0.5985\n",
      "Recall: 0.5774\n",
      "F1: 0.5847\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/creating-and-using-fragments\n",
      "--------------------\n",
      "Y\n",
      "[0s] 153 [1s] 10\n",
      "predicted\n",
      "[0s] 122 [1s] 41\n",
      "--------------------\n",
      "Accuracy: 0.6871\n",
      "macro_f1: 0.4073\n",
      "Precision: 0.4590\n",
      "Recall: 0.3660\n",
      "F1: 0.4073\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 3\n",
      "predicted\n",
      "[0s] 14 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.6875\n",
      "macro_f1: 0.4074\n",
      "Precision: 0.3929\n",
      "Recall: 0.4231\n",
      "F1: 0.4074\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/7/docs/api/java/awt/Rectangle.html\n",
      "https://stackoverflow.com/questions/2883355\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 22 [1s] 2\n",
      "predicted\n",
      "[0s] 21 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.7917\n",
      "macro_f1: 0.4419\n",
      "Precision: 0.4524\n",
      "Recall: 0.4318\n",
      "F1: 0.4419\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30362446\n",
      "--------------------\n",
      "Y\n",
      "[0s] 39 [1s] 3\n",
      "predicted\n",
      "[0s] 37 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.8095\n",
      "macro_f1: 0.4474\n",
      "Precision: 0.4595\n",
      "Recall: 0.4359\n",
      "F1: 0.4474\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/40168601\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 2 [1s] 2\n",
      "predicted\n",
      "[0s] 4 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.5000\n",
      "macro_f1: 0.3333\n",
      "Precision: 0.2500\n",
      "Recall: 0.5000\n",
      "F1: 0.3333\n",
      "\u001b[31m0\u001b[0m entries logged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stackoverflow.com/questions/38980595\n",
      "--------------------\n",
      "Y\n",
      "[0s] 3 [1s] 2\n",
      "predicted\n",
      "[0s] 3 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.2000\n",
      "macro_f1: 0.1667\n",
      "Precision: 0.1667\n",
      "Recall: 0.1667\n",
      "F1: 0.1667\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.411\u001b[0m\n",
      "recall:    \u001b[31m0.424\u001b[0m\n",
      "f1-score:  \u001b[31m0.404\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.357\u001b[0m\n",
      "recall:    \u001b[31m0.278\u001b[0m\n",
      "f1-score:  \u001b[31m0.313\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.385\u001b[0m\n",
      "recall:    \u001b[31m0.422\u001b[0m\n",
      "f1-score:  \u001b[31m0.395\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.521\u001b[0m\n",
      "recall:    \u001b[31m0.588\u001b[0m\n",
      "f1-score:  \u001b[31m0.468\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.436\u001b[0m\n",
      "recall:    \u001b[31m0.422\u001b[0m\n",
      "f1-score:  \u001b[31m0.427\u001b[0m\n",
      "next 2\n",
      "\n",
      "\u001b[31mFold 2\u001b[0m\n",
      "How to Integrate reCAPTCHA 2.0 in Android\n",
      "How can I make this rxjava zip to run in parallel?\n",
      "Permission Denial when trying to access contacts in Android\n",
      "keyUp called when key is still pressed\n",
      "Donâ€™t leak MockWebServer ports across tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 2070738.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    470\n",
      "1    235\n",
      "Name: category_index, dtype: int64\n",
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    423\n",
      "1    211\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1304\n",
      "1      54\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9571 - sparse_categorical_accuracy: 0.6356The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66831, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 8s 790ms/step - loss: 0.9571 - sparse_categorical_accuracy: 0.6356 - val_loss: 0.6683 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8899 - sparse_categorical_accuracy: 0.5899\n",
      "Epoch 00002: val_loss did not improve from 0.66831\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.8899 - sparse_categorical_accuracy: 0.5899 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.5634\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8647 - sparse_categorical_accuracy: 0.6057\n",
      "Epoch 00003: val_loss improved from 0.66831 to 0.65573, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 500ms/step - loss: 0.8647 - sparse_categorical_accuracy: 0.6057 - val_loss: 0.6557 - val_sparse_categorical_accuracy: 0.6056\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8424 - sparse_categorical_accuracy: 0.6703\n",
      "Epoch 00004: val_loss improved from 0.65573 to 0.65384, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 493ms/step - loss: 0.8424 - sparse_categorical_accuracy: 0.6703 - val_loss: 0.6538 - val_sparse_categorical_accuracy: 0.6338\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7948 - sparse_categorical_accuracy: 0.7050\n",
      "Epoch 00005: val_loss improved from 0.65384 to 0.63780, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 7s 677ms/step - loss: 0.7948 - sparse_categorical_accuracy: 0.7050 - val_loss: 0.6378 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7532 - sparse_categorical_accuracy: 0.7082\n",
      "Epoch 00006: val_loss improved from 0.63780 to 0.60165, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 491ms/step - loss: 0.7532 - sparse_categorical_accuracy: 0.7082 - val_loss: 0.6017 - val_sparse_categorical_accuracy: 0.7042\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6920 - sparse_categorical_accuracy: 0.7839\n",
      "Epoch 00007: val_loss did not improve from 0.60165\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.6920 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.6332 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6267 - sparse_categorical_accuracy: 0.8028\n",
      "Epoch 00008: val_loss did not improve from 0.60165\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.6267 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.6292 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5435 - sparse_categorical_accuracy: 0.8580\n",
      "Epoch 00009: val_loss did not improve from 0.60165\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.5435 - sparse_categorical_accuracy: 0.8580 - val_loss: 0.6371 - val_sparse_categorical_accuracy: 0.7324\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4661 - sparse_categorical_accuracy: 0.8849Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.60165\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 0.4661 - sparse_categorical_accuracy: 0.8849 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "https://developer.android.com/training/permissions/requesting\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 114 [1s] 15\n",
      "predicted\n",
      "[0s] 92 [1s] 37\n",
      "--------------------\n",
      "Accuracy: 0.5969\n",
      "macro_f1: 0.3738\n",
      "Precision: 0.4185\n",
      "Recall: 0.3377\n",
      "F1: 0.3738\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/training/safetynet/recaptcha\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 6\n",
      "predicted\n",
      "[0s] 30 [1s] 24\n",
      "--------------------\n",
      "Accuracy: 0.5185\n",
      "macro_f1: 0.4000\n",
      "Precision: 0.4750\n",
      "Recall: 0.4375\n",
      "F1: 0.4000\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/35357919\n",
      "--------------------\n",
      "Y\n",
      "[0s] 49 [1s] 4\n",
      "predicted\n",
      "[0s] 51 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.8868\n",
      "macro_f1: 0.4700\n",
      "Precision: 0.4608\n",
      "Recall: 0.4796\n",
      "F1: 0.4700\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "--------------------\n",
      "Y\n",
      "[0s] 158 [1s] 3\n",
      "predicted\n",
      "[0s] 145 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.8820\n",
      "macro_f1: 0.4686\n",
      "Precision: 0.4897\n",
      "Recall: 0.4494\n",
      "F1: 0.4686\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "--------------------\n",
      "Y\n",
      "[0s] 70 [1s] 2\n",
      "predicted\n",
      "[0s] 70 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.9444\n",
      "macro_f1: 0.4857\n",
      "Precision: 0.4857\n",
      "Recall: 0.4857\n",
      "F1: 0.4857\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 116 [1s] 1\n",
      "predicted\n",
      "[0s] 105 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.8889\n",
      "macro_f1: 0.4706\n",
      "Precision: 0.4952\n",
      "Recall: 0.4483\n",
      "F1: 0.4706\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 3\n",
      "predicted\n",
      "[0s] 9 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.4286\n",
      "macro_f1: 0.3000\n",
      "Precision: 0.3333\n",
      "Recall: 0.2727\n",
      "F1: 0.3000\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "--------------------\n",
      "Y\n",
      "[0s] 59 [1s] 4\n",
      "predicted\n",
      "[0s] 38 [1s] 25\n",
      "--------------------\n",
      "Accuracy: 0.6349\n",
      "macro_f1: 0.4849\n",
      "Precision: 0.5468\n",
      "Recall: 0.6886\n",
      "F1: 0.4849\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/27297067\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 8\n",
      "predicted\n",
      "[0s] 13 [1s] 8\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6190\n",
      "macro_f1: 0.5962\n",
      "Precision: 0.5962\n",
      "Recall: 0.5962\n",
      "F1: 0.5962\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24952513\n",
      "https://stackoverflow.com/questions/5233543\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 8\n",
      "predicted\n",
      "[0s] 17 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.6190\n",
      "macro_f1: 0.5333\n",
      "Precision: 0.5735\n",
      "Recall: 0.5481\n",
      "F1: 0.5333\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.487\u001b[0m\n",
      "recall:    \u001b[31m0.474\u001b[0m\n",
      "f1-score:  \u001b[31m0.458\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.409\u001b[0m\n",
      "recall:    \u001b[31m0.349\u001b[0m\n",
      "f1-score:  \u001b[31m0.358\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.543\u001b[0m\n",
      "recall:    \u001b[31m0.541\u001b[0m\n",
      "f1-score:  \u001b[31m0.533\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.504\u001b[0m\n",
      "recall:    \u001b[31m0.518\u001b[0m\n",
      "f1-score:  \u001b[31m0.477\u001b[0m\n",
      "next 3\n",
      "\n",
      "\u001b[31mFold 3\u001b[0m\n",
      "Is there an accepted best-practice on making asynchronous HTTP requests in Android?\n",
      "How to set a minimum crop window ?\n",
      "Camera API: Cross device issues\n",
      "Quick Actions don't get displayed on Android 7.0\n",
      "Application icon doesn&#39;t show up in Android action bar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 2180024.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    470\n",
      "1    235\n",
      "Name: category_index, dtype: int64\n",
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    423\n",
      "1    211\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    781\n",
      "1     37\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9008 - sparse_categorical_accuracy: 0.5268The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64047, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 8s 786ms/step - loss: 0.9008 - sparse_categorical_accuracy: 0.5268 - val_loss: 0.6405 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8394 - sparse_categorical_accuracy: 0.6672\n",
      "Epoch 00002: val_loss improved from 0.64047 to 0.61779, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 493ms/step - loss: 0.8394 - sparse_categorical_accuracy: 0.6672 - val_loss: 0.6178 - val_sparse_categorical_accuracy: 0.7042\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7918 - sparse_categorical_accuracy: 0.7161\n",
      "Epoch 00003: val_loss improved from 0.61779 to 0.59269, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 490ms/step - loss: 0.7918 - sparse_categorical_accuracy: 0.7161 - val_loss: 0.5927 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7292 - sparse_categorical_accuracy: 0.7555\n",
      "Epoch 00004: val_loss improved from 0.59269 to 0.59227, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 6s 646ms/step - loss: 0.7292 - sparse_categorical_accuracy: 0.7555 - val_loss: 0.5923 - val_sparse_categorical_accuracy: 0.6479\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6589 - sparse_categorical_accuracy: 0.7902\n",
      "Epoch 00005: val_loss improved from 0.59227 to 0.59125, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 491ms/step - loss: 0.6589 - sparse_categorical_accuracy: 0.7902 - val_loss: 0.5912 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5751 - sparse_categorical_accuracy: 0.8202\n",
      "Epoch 00006: val_loss did not improve from 0.59125\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.5751 - sparse_categorical_accuracy: 0.8202 - val_loss: 0.6144 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5070 - sparse_categorical_accuracy: 0.8533\n",
      "Epoch 00007: val_loss did not improve from 0.59125\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.5070 - sparse_categorical_accuracy: 0.8533 - val_loss: 0.6691 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4403 - sparse_categorical_accuracy: 0.8880\n",
      "Epoch 00008: val_loss did not improve from 0.59125\n",
      "10/10 [==============================] - 2s 242ms/step - loss: 0.4403 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.6695 - val_sparse_categorical_accuracy: 0.6338\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4402 - sparse_categorical_accuracy: 0.8707Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.59125\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.4402 - sparse_categorical_accuracy: 0.8707 - val_loss: 0.7193 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/guide/topics/media/camera\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 239 [1s] 11\n",
      "predicted\n",
      "[0s] 44 [1s] 206\n",
      "--------------------\n",
      "Accuracy: 0.2120\n",
      "macro_f1: 0.1980\n",
      "Precision: 0.5129\n",
      "Recall: 0.5445\n",
      "F1: 0.1980\n",
      "\u001b[31m10\u001b[0m entries logged\n",
      "https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "https://guides.codepath.com/android/Defining-The-ActionBar\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 44 [1s] 4\n",
      "predicted\n",
      "[0s] 12 [1s] 36\n",
      "--------------------\n",
      "Accuracy: 0.3333\n",
      "macro_f1: 0.3143\n",
      "Precision: 0.5556\n",
      "Recall: 0.6364\n",
      "F1: 0.3143\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "--------------------\n",
      "Y\n",
      "[0s] 52 [1s] 7\n",
      "predicted\n",
      "[0s] 23 [1s] 36\n",
      "--------------------\n",
      "Accuracy: 0.4068\n",
      "macro_f1: 0.3597\n",
      "Precision: 0.4903\n",
      "Recall: 0.4780\n",
      "F1: 0.3597\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://developer.android.com/training/volley/request\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 2\n",
      "predicted\n",
      "[0s] 3 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.3333\n",
      "macro_f1: 0.3304\n",
      "Precision: 0.5833\n",
      "Recall: 0.6154\n",
      "F1: 0.3304\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/training/notify-user/build-notification\n",
      "--------------------\n",
      "Y\n",
      "[0s] 145 [1s] 2\n",
      "predicted\n",
      "[0s] 76 [1s] 71\n",
      "--------------------\n",
      "Accuracy: 0.5306\n",
      "macro_f1: 0.3713\n",
      "Precision: 0.5141\n",
      "Recall: 0.7621\n",
      "F1: 0.3713\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/28504524\n",
      "--------------------\n",
      "Y\n",
      "[0s] 61 [1s] 4\n",
      "predicted\n",
      "[0s] 48 [1s] 17\n",
      "--------------------\n",
      "Accuracy: 0.7077\n",
      "macro_f1: 0.4605\n",
      "Precision: 0.4982\n",
      "Recall: 0.4939\n",
      "F1: 0.4605\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/26838730\n",
      "--------------------\n",
      "Y\n",
      "[0s] 18 [1s] 7\n",
      "predicted\n",
      "[0s] 11 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.5600\n",
      "macro_f1: 0.5484\n",
      "Precision: 0.5877\n",
      "Recall: 0.6071\n",
      "F1: 0.5484\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/3059155\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.535\u001b[0m\n",
      "recall:    \u001b[31m0.591\u001b[0m\n",
      "f1-score:  \u001b[31m0.369\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.537\u001b[0m\n",
      "recall:    \u001b[31m0.641\u001b[0m\n",
      "f1-score:  \u001b[31m0.300\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.543\u001b[0m\n",
      "recall:    \u001b[31m0.550\u001b[0m\n",
      "f1-score:  \u001b[31m0.504\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.523\u001b[0m\n",
      "recall:    \u001b[31m0.557\u001b[0m\n",
      "f1-score:  \u001b[31m0.337\u001b[0m\n",
      "next 4\n",
      "\n",
      "\u001b[31mFold 4\u001b[0m\n",
      "Android: rotate canvas around the center of the screen\n",
      "TS shows numbers instead of contact names in notifications\n",
      "No lock screen controls ever\n",
      "Enums support with Realm?\n",
      "Sound panning should work for stereo files (and if not, add it to the docs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 2508345.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    470\n",
      "1    235\n",
      "Name: category_index, dtype: int64\n",
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    423\n",
      "1    211\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    265\n",
      "1     11\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9014 - sparse_categorical_accuracy: 0.5268The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64091, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 8s 798ms/step - loss: 0.9014 - sparse_categorical_accuracy: 0.5268 - val_loss: 0.6409 - val_sparse_categorical_accuracy: 0.7183\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8452 - sparse_categorical_accuracy: 0.6893\n",
      "Epoch 00002: val_loss improved from 0.64091 to 0.62801, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.8452 - sparse_categorical_accuracy: 0.6893 - val_loss: 0.6280 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7689 - sparse_categorical_accuracy: 0.7082\n",
      "Epoch 00003: val_loss improved from 0.62801 to 0.58314, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 504ms/step - loss: 0.7689 - sparse_categorical_accuracy: 0.7082 - val_loss: 0.5831 - val_sparse_categorical_accuracy: 0.7042\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7304 - sparse_categorical_accuracy: 0.7429\n",
      "Epoch 00004: val_loss did not improve from 0.58314\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.7304 - sparse_categorical_accuracy: 0.7429 - val_loss: 0.5867 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6609 - sparse_categorical_accuracy: 0.7681\n",
      "Epoch 00005: val_loss improved from 0.58314 to 0.52291, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 495ms/step - loss: 0.6609 - sparse_categorical_accuracy: 0.7681 - val_loss: 0.5229 - val_sparse_categorical_accuracy: 0.7465\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6074 - sparse_categorical_accuracy: 0.7950\n",
      "Epoch 00006: val_loss improved from 0.52291 to 0.51267, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 498ms/step - loss: 0.6074 - sparse_categorical_accuracy: 0.7950 - val_loss: 0.5127 - val_sparse_categorical_accuracy: 0.7746\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5354 - sparse_categorical_accuracy: 0.8312\n",
      "Epoch 00007: val_loss improved from 0.51267 to 0.49890, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 493ms/step - loss: 0.5354 - sparse_categorical_accuracy: 0.8312 - val_loss: 0.4989 - val_sparse_categorical_accuracy: 0.7746\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4797 - sparse_categorical_accuracy: 0.8454\n",
      "Epoch 00008: val_loss did not improve from 0.49890\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.4797 - sparse_categorical_accuracy: 0.8454 - val_loss: 0.5282 - val_sparse_categorical_accuracy: 0.7746\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4346 - sparse_categorical_accuracy: 0.8691\n",
      "Epoch 00009: val_loss did not improve from 0.49890\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.4346 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.5289 - val_sparse_categorical_accuracy: 0.7746\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3835 - sparse_categorical_accuracy: 0.8880\n",
      "Epoch 00010: val_loss did not improve from 0.49890\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.3835 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.5636 - val_sparse_categorical_accuracy: 0.7324\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/24652078\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 8 [1s] 3\n",
      "predicted\n",
      "[0s] 5 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.7273\n",
      "macro_f1: 0.7179\n",
      "Precision: 0.7500\n",
      "Recall: 0.8125\n",
      "F1: 0.7179\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://dzone.com/articles/android-rotate-and-scale\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 58 [1s] 1\n",
      "predicted\n",
      "[0s] 23 [1s] 36\n",
      "--------------------\n",
      "Accuracy: 0.4068\n",
      "macro_f1: 0.3110\n",
      "Precision: 0.5139\n",
      "Recall: 0.6983\n",
      "F1: 0.3110\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/signalapp/Signal-Android/issues/3376\n",
      "--------------------\n",
      "Y\n",
      "[0s] 54 [1s] 3\n",
      "predicted\n",
      "[0s] 39 [1s] 18\n",
      "--------------------\n",
      "Accuracy: 0.7368\n",
      "macro_f1: 0.5622\n",
      "Precision: 0.5833\n",
      "Recall: 0.8611\n",
      "F1: 0.5622\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "https://github.com/realm/realm-java/issues/776\n",
      "--------------------\n",
      "Y\n",
      "[0s] 31 [1s] 2\n",
      "predicted\n",
      "[0s] 8 [1s] 25\n",
      "--------------------\n",
      "Accuracy: 0.2424\n",
      "macro_f1: 0.2165\n",
      "Precision: 0.4575\n",
      "Recall: 0.3629\n",
      "F1: 0.2165\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/8712652\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 15 [1s] 2\n",
      "predicted\n",
      "[0s] 4 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.3529\n",
      "macro_f1: 0.3439\n",
      "Precision: 0.5769\n",
      "Recall: 0.6333\n",
      "F1: 0.3439\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.576\u001b[0m\n",
      "recall:    \u001b[31m0.674\u001b[0m\n",
      "f1-score:  \u001b[31m0.430\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.663\u001b[0m\n",
      "recall:    \u001b[31m0.723\u001b[0m\n",
      "f1-score:  \u001b[31m0.531\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.520\u001b[0m\n",
      "recall:    \u001b[31m0.612\u001b[0m\n",
      "f1-score:  \u001b[31m0.389\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.514\u001b[0m\n",
      "recall:    \u001b[31m0.698\u001b[0m\n",
      "f1-score:  \u001b[31m0.311\u001b[0m\n",
      "next 5\n",
      "\n",
      "\u001b[31mFold 5\u001b[0m\n",
      "Different actions from contact info depending on whether hitting back key or back arrow in top left\n",
      "Unlimited/Dynamic ViewPager in both directions\n",
      "Java: Efficient ArrayList filtering?\n",
      "shouldn't snackbar DSL helpers take CharSequence?\n",
      "Not receiving notifications when phone is locked and connected through WIFI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 2261371.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    470\n",
      "1    235\n",
      "Name: category_index, dtype: int64\n",
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    423\n",
      "1    211\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    770\n",
      "1     33\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9635 - sparse_categorical_accuracy: 0.6278The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67919, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 8s 820ms/step - loss: 0.9635 - sparse_categorical_accuracy: 0.6278 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.6056\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8680 - sparse_categorical_accuracy: 0.6845\n",
      "Epoch 00002: val_loss did not improve from 0.67919\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.8680 - sparse_categorical_accuracy: 0.6845 - val_loss: 0.6963 - val_sparse_categorical_accuracy: 0.5352\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8138 - sparse_categorical_accuracy: 0.7208\n",
      "Epoch 00003: val_loss did not improve from 0.67919\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.8138 - sparse_categorical_accuracy: 0.7208 - val_loss: 0.7478 - val_sparse_categorical_accuracy: 0.5493\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7772 - sparse_categorical_accuracy: 0.7366\n",
      "Epoch 00004: val_loss did not improve from 0.67919\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.7772 - sparse_categorical_accuracy: 0.7366 - val_loss: 0.7140 - val_sparse_categorical_accuracy: 0.5634\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6932 - sparse_categorical_accuracy: 0.8013Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.67919\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.7398 - val_sparse_categorical_accuracy: 0.6056\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/10108774\n",
      "https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 144 [1s] 2\n",
      "predicted\n",
      "[0s] 142 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.9589\n",
      "macro_f1: 0.4895\n",
      "Precision: 0.4930\n",
      "Recall: 0.4861\n",
      "F1: 0.4895\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 75 [1s] 2\n",
      "predicted\n",
      "[0s] 69 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.8701\n",
      "macro_f1: 0.4653\n",
      "Precision: 0.4855\n",
      "Recall: 0.4467\n",
      "F1: 0.4653\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/122105\n",
      "--------------------\n",
      "Y\n",
      "[0s] 130 [1s] 1\n",
      "predicted\n",
      "[0s] 130 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.9847\n",
      "macro_f1: 0.4962\n",
      "Precision: 0.4962\n",
      "Recall: 0.4962\n",
      "F1: 0.4962\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 2\n",
      "predicted\n",
      "[0s] 35 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.8684\n",
      "macro_f1: 0.4648\n",
      "Precision: 0.4714\n",
      "Recall: 0.4583\n",
      "F1: 0.4648\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24313539\n",
      "--------------------\n",
      "Y\n",
      "[0s] 51 [1s] 4\n",
      "predicted\n",
      "[0s] 43 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.7455\n",
      "macro_f1: 0.4880\n",
      "Precision: 0.5068\n",
      "Recall: 0.5172\n",
      "F1: 0.4880\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 165 [1s] 12\n",
      "predicted\n",
      "[0s] 155 [1s] 22\n",
      "--------------------\n",
      "Accuracy: 0.8418\n",
      "macro_f1: 0.5445\n",
      "Precision: 0.5391\n",
      "Recall: 0.5674\n",
      "F1: 0.5445\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "--------------------\n",
      "Y\n",
      "[0s] 25 [1s] 8\n",
      "predicted\n",
      "[0s] 31 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.7576\n",
      "macro_f1: 0.5286\n",
      "Precision: 0.6371\n",
      "Recall: 0.5425\n",
      "F1: 0.5286\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/36275986\n",
      "--------------------\n",
      "Y\n",
      "[0s] 22 [1s] 2\n",
      "predicted\n",
      "[0s] 15 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.5417\n",
      "macro_f1: 0.3514\n",
      "Precision: 0.4333\n",
      "Recall: 0.2955\n",
      "F1: 0.3514\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.508\u001b[0m\n",
      "recall:    \u001b[31m0.476\u001b[0m\n",
      "f1-score:  \u001b[31m0.479\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.534\u001b[0m\n",
      "recall:    \u001b[31m0.496\u001b[0m\n",
      "f1-score:  \u001b[31m0.494\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.479\u001b[0m\n",
      "recall:    \u001b[31m0.436\u001b[0m\n",
      "f1-score:  \u001b[31m0.445\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.512\u001b[0m\n",
      "recall:    \u001b[31m0.507\u001b[0m\n",
      "f1-score:  \u001b[31m0.505\u001b[0m\n",
      "next 6\n",
      "\n",
      "\u001b[31mFold 6\u001b[0m\n",
      "Generating an error when using Provider for scoped instances\n",
      "Why settings.xml layout is overlapping the ActionBar/Toolbar?\n",
      "Explanation of the getView() method of an ArrayAdapter\n",
      "Dagger 2 doesn't implement some of the component methods in Android project with custom annotation processor\n",
      "Android - Jackson JSON parser returns null value in &#39;release&#39; builds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 1943043.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    470\n",
      "1    235\n",
      "Name: category_index, dtype: int64\n",
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    423\n",
      "1    211\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1237\n",
      "1      44\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9226 - sparse_categorical_accuracy: 0.5315The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64483, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 8s 817ms/step - loss: 0.9226 - sparse_categorical_accuracy: 0.5315 - val_loss: 0.6448 - val_sparse_categorical_accuracy: 0.7183\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8644 - sparse_categorical_accuracy: 0.6909\n",
      "Epoch 00002: val_loss improved from 0.64483 to 0.62704, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 10s 984ms/step - loss: 0.8644 - sparse_categorical_accuracy: 0.6909 - val_loss: 0.6270 - val_sparse_categorical_accuracy: 0.7042\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8145 - sparse_categorical_accuracy: 0.7035\n",
      "Epoch 00003: val_loss improved from 0.62704 to 0.60200, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 495ms/step - loss: 0.8145 - sparse_categorical_accuracy: 0.7035 - val_loss: 0.6020 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7776 - sparse_categorical_accuracy: 0.7271\n",
      "Epoch 00004: val_loss improved from 0.60200 to 0.56221, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 486ms/step - loss: 0.7776 - sparse_categorical_accuracy: 0.7271 - val_loss: 0.5622 - val_sparse_categorical_accuracy: 0.7042\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7221 - sparse_categorical_accuracy: 0.7744\n",
      "Epoch 00005: val_loss improved from 0.56221 to 0.52612, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 501ms/step - loss: 0.7221 - sparse_categorical_accuracy: 0.7744 - val_loss: 0.5261 - val_sparse_categorical_accuracy: 0.7606\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6753 - sparse_categorical_accuracy: 0.7729\n",
      "Epoch 00006: val_loss did not improve from 0.52612\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.6753 - sparse_categorical_accuracy: 0.7729 - val_loss: 0.5419 - val_sparse_categorical_accuracy: 0.7042\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6291 - sparse_categorical_accuracy: 0.8076\n",
      "Epoch 00007: val_loss did not improve from 0.52612\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.6291 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.5469 - val_sparse_categorical_accuracy: 0.7042\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5800 - sparse_categorical_accuracy: 0.8186\n",
      "Epoch 00008: val_loss improved from 0.52612 to 0.50968, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 487ms/step - loss: 0.5800 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.5097 - val_sparse_categorical_accuracy: 0.7183\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5338 - sparse_categorical_accuracy: 0.8423\n",
      "Epoch 00009: val_loss did not improve from 0.50968\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.5338 - sparse_categorical_accuracy: 0.8423 - val_loss: 0.5374 - val_sparse_categorical_accuracy: 0.7324\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4754 - sparse_categorical_accuracy: 0.8549\n",
      "Epoch 00010: val_loss did not improve from 0.50968\n",
      "10/10 [==============================] - 2s 242ms/step - loss: 0.4754 - sparse_categorical_accuracy: 0.8549 - val_loss: 0.5242 - val_sparse_categorical_accuracy: 0.7042\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 203 [1s] 8\n",
      "predicted\n",
      "[0s] 123 [1s] 88\n",
      "--------------------\n",
      "Accuracy: 0.6114\n",
      "macro_f1: 0.4471\n",
      "Precision: 0.5357\n",
      "Recall: 0.7380\n",
      "F1: 0.4471\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "https://github.com/quarkusio/quarkus/issues/3954\n",
      "https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "https://developer.android.com/training/dependency-injection/dagger-android\n",
      "--------------------\n",
      "Y\n",
      "[0s] 195 [1s] 1\n",
      "predicted\n",
      "[0s] 32 [1s] 164\n",
      "--------------------\n",
      "Accuracy: 0.1684\n",
      "macro_f1: 0.1470\n",
      "Precision: 0.5030\n",
      "Recall: 0.5821\n",
      "F1: 0.1470\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "--------------------\n",
      "Y\n",
      "[0s] 47 [1s] 12\n",
      "predicted\n",
      "[0s] 15 [1s] 44\n",
      "--------------------\n",
      "Accuracy: 0.3559\n",
      "macro_f1: 0.3543\n",
      "Precision: 0.5023\n",
      "Recall: 0.5027\n",
      "F1: 0.3543\n",
      "\u001b[31m9\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "--------------------\n",
      "Y\n",
      "[0s] 44 [1s] 3\n",
      "predicted\n",
      "[0s] 7 [1s] 40\n",
      "--------------------\n",
      "Accuracy: 0.2128\n",
      "macro_f1: 0.2070\n",
      "Precision: 0.5375\n",
      "Recall: 0.5795\n",
      "F1: 0.2070\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "https://stackoverflow.com/questions/6442054\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 14 [1s] 7\n",
      "predicted\n",
      "[0s] 5 [1s] 16\n",
      "--------------------\n",
      "Accuracy: 0.3810\n",
      "macro_f1: 0.3753\n",
      "Precision: 0.4562\n",
      "Recall: 0.4643\n",
      "F1: 0.3753\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/57235136\n",
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 3\n",
      "predicted\n",
      "[0s] 18 [1s] 26\n",
      "--------------------\n",
      "Accuracy: 0.4773\n",
      "macro_f1: 0.4085\n",
      "Precision: 0.5577\n",
      "Recall: 0.7195\n",
      "F1: 0.4085\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/29738510\n",
      "--------------------\n",
      "Y\n",
      "[0s] 21 [1s] 2\n",
      "predicted\n",
      "[0s] 18 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.6957\n",
      "macro_f1: 0.4103\n",
      "Precision: 0.4444\n",
      "Recall: 0.3810\n",
      "F1: 0.4103\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/11064244\n",
      "--------------------\n",
      "Y\n",
      "[0s] 47 [1s] 4\n",
      "predicted\n",
      "[0s] 34 [1s] 17\n",
      "--------------------\n",
      "Accuracy: 0.7451\n",
      "macro_f1: 0.6102\n",
      "Precision: 0.6176\n",
      "Recall: 0.8617\n",
      "F1: 0.6102\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/29923376\n",
      "--------------------\n",
      "Y\n",
      "[0s] 28 [1s] 4\n",
      "predicted\n",
      "[0s] 9 [1s] 23\n",
      "--------------------\n",
      "Accuracy: 0.4062\n",
      "macro_f1: 0.3914\n",
      "Precision: 0.5870\n",
      "Recall: 0.6607\n",
      "F1: 0.3914\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://github.com/google/dagger/issues/671\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.527\u001b[0m\n",
      "recall:    \u001b[31m0.610\u001b[0m\n",
      "f1-score:  \u001b[31m0.372\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.520\u001b[0m\n",
      "recall:    \u001b[31m0.581\u001b[0m\n",
      "f1-score:  \u001b[31m0.177\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.533\u001b[0m\n",
      "recall:    \u001b[31m0.617\u001b[0m\n",
      "f1-score:  \u001b[31m0.439\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.519\u001b[0m\n",
      "recall:    \u001b[31m0.620\u001b[0m\n",
      "f1-score:  \u001b[31m0.401\u001b[0m\n",
      "next 7\n",
      "\n",
      "\u001b[31mFold 7\u001b[0m\n",
      "Doesn't scroll properly inside ViewPager\n",
      "The gravity is not working on the TextView in some situation.\n",
      "Support for GoogleApiClient and new FusedLocationProviderApi\n",
      "How to record phone calls in Android\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 2180024.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    470\n",
      "1    235\n",
      "Name: category_index, dtype: int64\n",
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    423\n",
      "1    211\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    892\n",
      "1     29\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9453 - sparse_categorical_accuracy: 0.6183The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67205, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.9453 - sparse_categorical_accuracy: 0.6183 - val_loss: 0.6720 - val_sparse_categorical_accuracy: 0.6338\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8911 - sparse_categorical_accuracy: 0.5773\n",
      "Epoch 00002: val_loss improved from 0.67205 to 0.66128, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 6s 570ms/step - loss: 0.8911 - sparse_categorical_accuracy: 0.5773 - val_loss: 0.6613 - val_sparse_categorical_accuracy: 0.6197\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8584 - sparse_categorical_accuracy: 0.6735\n",
      "Epoch 00003: val_loss improved from 0.66128 to 0.63459, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 500ms/step - loss: 0.8584 - sparse_categorical_accuracy: 0.6735 - val_loss: 0.6346 - val_sparse_categorical_accuracy: 0.6197\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8246 - sparse_categorical_accuracy: 0.6703\n",
      "Epoch 00004: val_loss improved from 0.63459 to 0.61624, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 491ms/step - loss: 0.8246 - sparse_categorical_accuracy: 0.6703 - val_loss: 0.6162 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7686 - sparse_categorical_accuracy: 0.7145\n",
      "Epoch 00005: val_loss improved from 0.61624 to 0.60337, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 489ms/step - loss: 0.7686 - sparse_categorical_accuracy: 0.7145 - val_loss: 0.6034 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6977 - sparse_categorical_accuracy: 0.7823\n",
      "Epoch 00006: val_loss improved from 0.60337 to 0.60129, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 485ms/step - loss: 0.6977 - sparse_categorical_accuracy: 0.7823 - val_loss: 0.6013 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6212 - sparse_categorical_accuracy: 0.8265\n",
      "Epoch 00007: val_loss did not improve from 0.60129\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.6212 - sparse_categorical_accuracy: 0.8265 - val_loss: 0.6339 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5622 - sparse_categorical_accuracy: 0.8391\n",
      "Epoch 00008: val_loss did not improve from 0.60129\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.5622 - sparse_categorical_accuracy: 0.8391 - val_loss: 0.6127 - val_sparse_categorical_accuracy: 0.7183\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4760 - sparse_categorical_accuracy: 0.8738\n",
      "Epoch 00009: val_loss did not improve from 0.60129\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.4760 - sparse_categorical_accuracy: 0.8738 - val_loss: 0.6027 - val_sparse_categorical_accuracy: 0.7465\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4123 - sparse_categorical_accuracy: 0.8959Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.60129\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.4123 - sparse_categorical_accuracy: 0.8959 - val_loss: 0.6969 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 113 [1s] 6\n",
      "predicted\n",
      "[0s] 83 [1s] 36\n",
      "--------------------\n",
      "Accuracy: 0.6975\n",
      "macro_f1: 0.4796\n",
      "Precision: 0.5236\n",
      "Recall: 0.6040\n",
      "F1: 0.4796\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/widget/TextView\n",
      "--------------------\n",
      "Y\n",
      "[0s] 468 [1s] 2\n",
      "predicted\n",
      "[0s] 290 [1s] 180\n",
      "--------------------\n",
      "Accuracy: 0.6213\n",
      "macro_f1: 0.3936\n",
      "Precision: 0.5056\n",
      "Recall: 0.8098\n",
      "F1: 0.3936\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/training/location/retrieve-current\n",
      "https://developer.android.com/training/gestures/scroll\n",
      "https://stackoverflow.com/questions/46481789\n",
      "https://stackoverflow.com/questions/19025301\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 5 [1s] 6\n",
      "predicted\n",
      "[0s] 10 [1s] 1\n",
      "--------------------\n",
      "Accuracy: 0.3636\n",
      "macro_f1: 0.2667\n",
      "Precision: 0.2000\n",
      "Recall: 0.4000\n",
      "F1: 0.2667\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/39588322\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 13 [1s] 3\n",
      "predicted\n",
      "[0s] 14 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.8125\n",
      "macro_f1: 0.6444\n",
      "Precision: 0.6786\n",
      "Recall: 0.6282\n",
      "F1: 0.6444\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/google/oboe/issues/447\n",
      "--------------------\n",
      "Y\n",
      "[0s] 21 [1s] 2\n",
      "predicted\n",
      "[0s] 21 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.8261\n",
      "macro_f1: 0.4524\n",
      "Precision: 0.4524\n",
      "Recall: 0.4524\n",
      "F1: 0.4524\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/media/mediarecorder\n",
      "--------------------\n",
      "Y\n",
      "[0s] 45 [1s] 4\n",
      "predicted\n",
      "[0s] 29 [1s] 20\n",
      "--------------------\n",
      "Accuracy: 0.5510\n",
      "macro_f1: 0.3930\n",
      "Precision: 0.4733\n",
      "Recall: 0.4139\n",
      "F1: 0.3930\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://javapapers.com/android/android-location-fused-provider\n",
      "--------------------\n",
      "Y\n",
      "[0s] 97 [1s] 2\n",
      "predicted\n",
      "[0s] 86 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.8485\n",
      "macro_f1: 0.4590\n",
      "Precision: 0.4884\n",
      "Recall: 0.4330\n",
      "F1: 0.4590\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/6688444\n",
      "--------------------\n",
      "Y\n",
      "[0s] 5 [1s] 4\n",
      "predicted\n",
      "[0s] 9 [1s] 0\n",
      "--------------------\n",
      "Accuracy: 0.5556\n",
      "macro_f1: 0.3571\n",
      "Precision: 0.2778\n",
      "Recall: 0.5000\n",
      "F1: 0.3571\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.450\u001b[0m\n",
      "recall:    \u001b[31m0.530\u001b[0m\n",
      "f1-score:  \u001b[31m0.431\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.489\u001b[0m\n",
      "recall:    \u001b[31m0.612\u001b[0m\n",
      "f1-score:  \u001b[31m0.393\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.385\u001b[0m\n",
      "recall:    \u001b[31m0.509\u001b[0m\n",
      "f1-score:  \u001b[31m0.423\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.452\u001b[0m\n",
      "recall:    \u001b[31m0.452\u001b[0m\n",
      "f1-score:  \u001b[31m0.452\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.506\u001b[0m\n",
      "recall:    \u001b[31m0.518\u001b[0m\n",
      "f1-score:  \u001b[31m0.469\u001b[0m\n",
      "next 8\n",
      "\n",
      "\u001b[31mFold 8\u001b[0m\n",
      "SeekTo Position of cutted song not working\n",
      "Android Gallery with pinch zoom\n",
      "Wait for 2 async REST calls to result in success or error\n",
      "how  to set Screenshot frame size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 2476362.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    470\n",
      "1    235\n",
      "Name: category_index, dtype: int64\n",
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    423\n",
      "1    211\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    381\n",
      "1      7\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8969 - sparse_categorical_accuracy: 0.5442The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63869, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 8s 770ms/step - loss: 0.8969 - sparse_categorical_accuracy: 0.5442 - val_loss: 0.6387 - val_sparse_categorical_accuracy: 0.6620\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8336 - sparse_categorical_accuracy: 0.7003\n",
      "Epoch 00002: val_loss improved from 0.63869 to 0.62300, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 490ms/step - loss: 0.8336 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.6230 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7750 - sparse_categorical_accuracy: 0.6861\n",
      "Epoch 00003: val_loss improved from 0.62300 to 0.59711, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 6s 641ms/step - loss: 0.7750 - sparse_categorical_accuracy: 0.6861 - val_loss: 0.5971 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7119 - sparse_categorical_accuracy: 0.7476\n",
      "Epoch 00004: val_loss improved from 0.59711 to 0.57602, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 549ms/step - loss: 0.7119 - sparse_categorical_accuracy: 0.7476 - val_loss: 0.5760 - val_sparse_categorical_accuracy: 0.7183\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6587 - sparse_categorical_accuracy: 0.7713\n",
      "Epoch 00005: val_loss did not improve from 0.57602\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.6587 - sparse_categorical_accuracy: 0.7713 - val_loss: 0.6023 - val_sparse_categorical_accuracy: 0.7042\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5792 - sparse_categorical_accuracy: 0.8076\n",
      "Epoch 00006: val_loss did not improve from 0.57602\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.5792 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.5896 - val_sparse_categorical_accuracy: 0.7183\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5270 - sparse_categorical_accuracy: 0.8360\n",
      "Epoch 00007: val_loss did not improve from 0.57602\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.5270 - sparse_categorical_accuracy: 0.8360 - val_loss: 0.6139 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4812 - sparse_categorical_accuracy: 0.8675Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.57602\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.4812 - sparse_categorical_accuracy: 0.8675 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 2\n",
      "predicted\n",
      "[0s] 42 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.8000\n",
      "macro_f1: 0.4444\n",
      "Precision: 0.4762\n",
      "Recall: 0.4167\n",
      "F1: 0.4444\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/training/gestures/scale\n",
      "https://github.com/google/ExoPlayer/issues/8387\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 31 [1s] 1\n",
      "predicted\n",
      "[0s] 21 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.6250\n",
      "macro_f1: 0.3846\n",
      "Precision: 0.4762\n",
      "Recall: 0.3226\n",
      "F1: 0.3846\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2661536\n",
      "--------------------\n",
      "Y\n",
      "[0s] 99 [1s] 1\n",
      "predicted\n",
      "[0s] 55 [1s] 45\n",
      "--------------------\n",
      "Accuracy: 0.5600\n",
      "macro_f1: 0.3789\n",
      "Precision: 0.5111\n",
      "Recall: 0.7778\n",
      "F1: 0.3789\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2993085\n",
      "https://developer.android.com/guide/background/threading\n",
      "https://stackoverflow.com/questions/10630373\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 3\n",
      "predicted\n",
      "[0s] 23 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.7500\n",
      "macro_f1: 0.5897\n",
      "Precision: 0.5894\n",
      "Recall: 0.7126\n",
      "F1: 0.5897\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.513\u001b[0m\n",
      "recall:    \u001b[31m0.557\u001b[0m\n",
      "f1-score:  \u001b[31m0.449\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.550\u001b[0m\n",
      "recall:    \u001b[31m0.745\u001b[0m\n",
      "f1-score:  \u001b[31m0.484\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.476\u001b[0m\n",
      "recall:    \u001b[31m0.323\u001b[0m\n",
      "f1-score:  \u001b[31m0.385\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.476\u001b[0m\n",
      "recall:    \u001b[31m0.417\u001b[0m\n",
      "f1-score:  \u001b[31m0.444\u001b[0m\n",
      "next 9\n",
      "\n",
      "\u001b[31mFold 9\u001b[0m\n",
      "Android SQLite performance in complex queries\n",
      "Custom Annotations in Retrofit 2.0\n",
      "Android App Retrieve Data from Server but in a Secure way\n",
      "Hilt: How to prevent Hilt from picking dependency from a library?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7918/7918 [00:00<00:00, 2469365.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    470\n",
      "1    235\n",
      "Name: category_index, dtype: int64\n",
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    423\n",
      "1    211\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    553\n",
      "1     25\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9297 - sparse_categorical_accuracy: 0.5347The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65523, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 9s 936ms/step - loss: 0.9297 - sparse_categorical_accuracy: 0.5347 - val_loss: 0.6552 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8769 - sparse_categorical_accuracy: 0.6861\n",
      "Epoch 00002: val_loss improved from 0.65523 to 0.62484, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 499ms/step - loss: 0.8769 - sparse_categorical_accuracy: 0.6861 - val_loss: 0.6248 - val_sparse_categorical_accuracy: 0.6761\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.8218 - sparse_categorical_accuracy: 0.7098\n",
      "Epoch 00003: val_loss improved from 0.62484 to 0.60488, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 536ms/step - loss: 0.8218 - sparse_categorical_accuracy: 0.7098 - val_loss: 0.6049 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7926 - sparse_categorical_accuracy: 0.7240\n",
      "Epoch 00004: val_loss improved from 0.60488 to 0.55466, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 508ms/step - loss: 0.7926 - sparse_categorical_accuracy: 0.7240 - val_loss: 0.5547 - val_sparse_categorical_accuracy: 0.7183\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7224 - sparse_categorical_accuracy: 0.7350\n",
      "Epoch 00005: val_loss did not improve from 0.55466\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.7224 - sparse_categorical_accuracy: 0.7350 - val_loss: 0.5880 - val_sparse_categorical_accuracy: 0.6479\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6655 - sparse_categorical_accuracy: 0.7634\n",
      "Epoch 00006: val_loss improved from 0.55466 to 0.53258, saving model to /home/msarthur/scratch/best_synthetic_pyramid_model\n",
      "10/10 [==============================] - 5s 522ms/step - loss: 0.6655 - sparse_categorical_accuracy: 0.7634 - val_loss: 0.5326 - val_sparse_categorical_accuracy: 0.7324\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5942 - sparse_categorical_accuracy: 0.8170\n",
      "Epoch 00007: val_loss did not improve from 0.53258\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.5942 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.5523 - val_sparse_categorical_accuracy: 0.7042\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5311 - sparse_categorical_accuracy: 0.8360\n",
      "Epoch 00008: val_loss did not improve from 0.53258\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.5311 - sparse_categorical_accuracy: 0.8360 - val_loss: 0.5521 - val_sparse_categorical_accuracy: 0.7183\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4635 - sparse_categorical_accuracy: 0.8691\n",
      "Epoch 00009: val_loss did not improve from 0.53258\n",
      "10/10 [==============================] - 2s 241ms/step - loss: 0.4635 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.5534 - val_sparse_categorical_accuracy: 0.7324\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4164 - sparse_categorical_accuracy: 0.8833Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.53258\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.4164 - sparse_categorical_accuracy: 0.8833 - val_loss: 0.5999 - val_sparse_categorical_accuracy: 0.7042\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "https://stackoverflow.com/questions/4015026\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 26 [1s] 9\n",
      "predicted\n",
      "[0s] 4 [1s] 31\n",
      "--------------------\n",
      "Accuracy: 0.3714\n",
      "macro_f1: 0.3583\n",
      "Precision: 0.6452\n",
      "Recall: 0.5769\n",
      "F1: 0.3583\n",
      "\u001b[31m9\u001b[0m entries logged\n",
      "https://github.com/google/dagger/issues/1991\n",
      "https://developer.android.com/training/dependency-injection/hilt-android\n",
      "--------------------\n",
      "Y\n",
      "[0s] 141 [1s] 4\n",
      "predicted\n",
      "[0s] 18 [1s] 127\n",
      "--------------------\n",
      "Accuracy: 0.1241\n",
      "macro_f1: 0.1159\n",
      "Precision: 0.4523\n",
      "Recall: 0.3067\n",
      "F1: 0.1159\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/8184492\n",
      "--------------------\n",
      "Y\n",
      "[0s] 50 [1s] 3\n",
      "predicted\n",
      "[0s] 29 [1s] 24\n",
      "--------------------\n",
      "Accuracy: 0.5660\n",
      "macro_f1: 0.4285\n",
      "Precision: 0.5244\n",
      "Recall: 0.6133\n",
      "F1: 0.4285\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/training/data-storage/sqlite\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 67 [1s] 2\n",
      "predicted\n",
      "[0s] 14 [1s] 55\n",
      "--------------------\n",
      "Accuracy: 0.2319\n",
      "macro_f1: 0.2079\n",
      "Precision: 0.5182\n",
      "Recall: 0.6045\n",
      "F1: 0.2079\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 45 [1s] 3\n",
      "predicted\n",
      "[0s] 20 [1s] 28\n",
      "--------------------\n",
      "Accuracy: 0.4375\n",
      "macro_f1: 0.3568\n",
      "Precision: 0.5107\n",
      "Recall: 0.5444\n",
      "F1: 0.3568\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/47760861\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 2\n",
      "predicted\n",
      "[0s] 11 [1s] 20\n",
      "--------------------\n",
      "Accuracy: 0.4194\n",
      "macro_f1: 0.3659\n",
      "Precision: 0.5500\n",
      "Recall: 0.6897\n",
      "F1: 0.3659\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "--------------------\n",
      "Y\n",
      "[0s] 48 [1s] 2\n",
      "predicted\n",
      "[0s] 31 [1s] 19\n",
      "--------------------\n",
      "Accuracy: 0.5800\n",
      "macro_f1: 0.3671\n",
      "Precision: 0.4677\n",
      "Recall: 0.3021\n",
      "F1: 0.3671\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30648172\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.524\u001b[0m\n",
      "recall:    \u001b[31m0.520\u001b[0m\n",
      "f1-score:  \u001b[31m0.314\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.485\u001b[0m\n",
      "recall:    \u001b[31m0.456\u001b[0m\n",
      "f1-score:  \u001b[31m0.162\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.573\u001b[0m\n",
      "recall:    \u001b[31m0.627\u001b[0m\n",
      "f1-score:  \u001b[31m0.384\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.489\u001b[0m\n",
      "recall:    \u001b[31m0.423\u001b[0m\n",
      "f1-score:  \u001b[31m0.362\u001b[0m\n",
      "next 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# @title 10-fold cross validation WIP\n",
    "CORPUS = raw_data\n",
    "\n",
    "all_tasks = sorted(list(set([d['question'] for d in raw_data])))\n",
    "rseed = 20210343\n",
    "random.seed(rseed)\n",
    "random.shuffle(all_tasks)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "file_handler = logging.FileHandler('/home/msarthur/scratch/LOG-bert_ds_synthetic_pyramid.ans')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, random_state=rseed)\n",
    "np_tasks_arr = np.array(all_tasks)\n",
    "\n",
    "\n",
    "\n",
    "idx_split = 0\n",
    "for train_index, test_index in kf.split(np_tasks_arr):\n",
    "\n",
    "    idx_split = str(idx_split)\n",
    "    eval_fold = True\n",
    "    # 10 runs per fold to avoid reporting peek results in a given fold\n",
    "    if idx_split in fold_results and fold_results[idx_split]['run_cnt'] >= 10:\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split} FULLY TESTED\" + Style.RESET_ALL)\n",
    "        eval_fold = False\n",
    "\n",
    "\n",
    "    if eval_fold:\n",
    "        # <------------------------------------------------------------------------- EVAL VARIABLES\n",
    "        recommendation_metrics = defaultdict(list)\n",
    "        prediction_metrics = defaultdict(list)\n",
    "        api_metrics = defaultdict(list)\n",
    "        so_metrics = defaultdict(list)\n",
    "        git_metrics = defaultdict(list)\n",
    "        misc_metrics = defaultdict(list)\n",
    "        random_prediction_metrics = defaultdict(list)\n",
    "        clz_report_lst = defaultdict(list)\n",
    "\n",
    "        classification_report_lst = []\n",
    "        log_examples_lst = []\n",
    "        source_lst = []\n",
    "        venn_diagram_set = []\n",
    "        # <------------------------------------------------------------------------- EVAL VARIABLES\n",
    "\n",
    "\n",
    "        test_tasks_lst = np_tasks_arr[test_index].tolist()\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split}\" + Style.RESET_ALL)\n",
    "        logger.info('\\n'.join(test_tasks_lst))\n",
    "\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "        df_train, df_val, df_test, weights = get_train_val_test(\n",
    "            test_tasks_lst,\n",
    "            aug=USE_DS_SYNTHETIC,\n",
    "            undersample=UNDERSAMPLING, \n",
    "            undersample_n=N_UNDERSAMPLING\n",
    "        )\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "\n",
    "        logger.info('-' * 10)\n",
    "        logger.info(Fore.RED + 'train'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_train.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'test'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_test.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'weights'+ Style.RESET_ALL)\n",
    "        logger.info(str(weights))\n",
    "        logger.info('-' * 10)\n",
    "\n",
    "\n",
    "        # Encode X_train\n",
    "        train_encodings = _encode(tokenizer, df_train)\n",
    "        train_labels = df_train['category_index'].tolist()\n",
    "\n",
    "        # Encode X_valid\n",
    "        val_encodings = _encode(tokenizer, df_val)\n",
    "        val_labels = df_val['category_index'].tolist()\n",
    "\n",
    "\n",
    "        # https://huggingface.co/transformers/custom_datasets.html\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(train_encodings),\n",
    "            train_labels\n",
    "        ))\n",
    "\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(val_encodings),\n",
    "            val_labels\n",
    "        ))\n",
    "\n",
    "\n",
    "        if model_id == 'distilbert-base-uncased':\n",
    "            model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "                model_id, cache_dir='/home/msarthur/scratch'\n",
    "            )\n",
    "        else:\n",
    "            model = TFBertForSequenceClassification.from_pretrained(\n",
    "                model_id, cache_dir='/home/msarthur/scratch', local_files_only=True\n",
    "            )\n",
    "\n",
    "        # freeze all the parameters\n",
    "        # for param in model.parameters():\n",
    "        #   param.requires_grad = False\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "        METRICS = [\n",
    "            tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        ]\n",
    "\n",
    "        early_stopper = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', mode='min', patience=4, \n",
    "            verbose=1, restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
    "        checkpoint_filepath = '/home/msarthur/scratch/best_synthetic_pyramid_model'\n",
    "\n",
    "        mc = tf.keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath, \n",
    "            monitor='val_loss', mode='min', verbose=1, \n",
    "            save_best_only=True,\n",
    "            save_weights_only=True\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_fn,\n",
    "            metrics=METRICS\n",
    "        )\n",
    "\n",
    "        # https://discuss.huggingface.co/t/how-to-dealing-with-data-imbalance/393/3\n",
    "        # https://wandb.ai/ayush-thakur/huggingface/reports/Early-Stopping-in-HuggingFace-Examples--Vmlldzo0MzE2MTM\n",
    "        model.fit(\n",
    "            train_dataset.shuffle(1000).batch(BATCH_SIZE), \n",
    "            epochs=EPOCHS, \n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_weight=weights,\n",
    "            validation_data=val_dataset.shuffle(1000).batch(BATCH_SIZE),\n",
    "            callbacks=[early_stopper, mc]\n",
    "        )\n",
    "\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Testing model\" + Style.RESET_ALL)\n",
    "        for source in df_test[\"source\"].unique():\n",
    "            df_source = df_test[df_test[\"source\"] == source]   \n",
    "            logger.info(source)\n",
    "            test_model(source, df_source, model, tokenizer, pos_filter=USE_FRAME_FILTERING)\n",
    "\n",
    "        add_idx_fold_results(idx_split, fold_results)\n",
    "        if 'venn_diagram_set' not in fold_results:\n",
    "            fold_results['venn_diagram_set'] = []\n",
    "\n",
    "        fold_results['venn_diagram_set'] += venn_diagram_set\n",
    "        fold_results['venn_diagram_set'] = list(set(fold_results['venn_diagram_set']))\n",
    "\n",
    "\n",
    "        _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "        logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "        logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "        logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        log_sources_data = [api_metrics, so_metrics, git_metrics, misc_metrics]\n",
    "        log_sources_ids = ['api_metrics', 'so_metrics', 'git_metrics', 'misc_metrics']\n",
    "\n",
    "        for _id, __data in zip(log_sources_ids, log_sources_data):\n",
    "            _precision, _recall, _f1score = avg_macro_metric_for(__data)\n",
    "\n",
    "            logger.info(\"\")\n",
    "            logger.info(Fore.YELLOW + f\"{_id}\" + Style.RESET_ALL)\n",
    "            logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "            logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "            logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "    idx_split = int(idx_split)\n",
    "    idx_split += 1\n",
    "    logger.info(f\"next {idx_split}\")\n",
    "#     break\n",
    "#         if idx_split >= 7:\n",
    "#             logger.info(f\"breaking at {idx_split}\")\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m0\u001b[0m\n",
      "precision: \u001b[31m0.524\u001b[0m [0.52]\n",
      "recall:    \u001b[31m0.509\u001b[0m [0.51]\n",
      "f1-score:  \u001b[31m0.436\u001b[0m [0.44]\n",
      "\u001b[33m1\u001b[0m\n",
      "precision: \u001b[31m0.411\u001b[0m [0.41]\n",
      "recall:    \u001b[31m0.424\u001b[0m [0.42]\n",
      "f1-score:  \u001b[31m0.404\u001b[0m [0.4]\n",
      "\u001b[33m2\u001b[0m\n",
      "precision: \u001b[31m0.487\u001b[0m [0.49]\n",
      "recall:    \u001b[31m0.474\u001b[0m [0.47]\n",
      "f1-score:  \u001b[31m0.458\u001b[0m [0.46]\n",
      "\u001b[33m3\u001b[0m\n",
      "precision: \u001b[31m0.535\u001b[0m [0.53]\n",
      "recall:    \u001b[31m0.591\u001b[0m [0.59]\n",
      "f1-score:  \u001b[31m0.369\u001b[0m [0.37]\n",
      "\u001b[33m4\u001b[0m\n",
      "precision: \u001b[31m0.576\u001b[0m [0.58]\n",
      "recall:    \u001b[31m0.674\u001b[0m [0.67]\n",
      "f1-score:  \u001b[31m0.430\u001b[0m [0.43]\n",
      "\u001b[33m5\u001b[0m\n",
      "precision: \u001b[31m0.508\u001b[0m [0.51]\n",
      "recall:    \u001b[31m0.476\u001b[0m [0.48]\n",
      "f1-score:  \u001b[31m0.479\u001b[0m [0.48]\n",
      "\u001b[33m6\u001b[0m\n",
      "precision: \u001b[31m0.527\u001b[0m [0.53]\n",
      "recall:    \u001b[31m0.610\u001b[0m [0.61]\n",
      "f1-score:  \u001b[31m0.372\u001b[0m [0.37]\n",
      "\u001b[33m7\u001b[0m\n",
      "precision: \u001b[31m0.450\u001b[0m [0.45]\n",
      "recall:    \u001b[31m0.530\u001b[0m [0.53]\n",
      "f1-score:  \u001b[31m0.431\u001b[0m [0.43]\n",
      "\u001b[33m8\u001b[0m\n",
      "precision: \u001b[31m0.513\u001b[0m [0.51]\n",
      "recall:    \u001b[31m0.557\u001b[0m [0.56]\n",
      "f1-score:  \u001b[31m0.449\u001b[0m [0.45]\n",
      "\u001b[33m9\u001b[0m\n",
      "precision: \u001b[31m0.524\u001b[0m [0.52]\n",
      "recall:    \u001b[31m0.520\u001b[0m [0.52]\n",
      "f1-score:  \u001b[31m0.314\u001b[0m [0.31]\n",
      "\n",
      "\n",
      "\u001b[31mAGGREGATED METRICS\u001b[0m\n",
      "\n",
      "precision: \u001b[31m0.506\u001b[0m\n",
      "recall:    \u001b[31m0.537\u001b[0m\n",
      "f1-score:  \u001b[31m0.414\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "__precision, __recall, __fscore = [], [], []\n",
    "\n",
    "for key_i, value in fold_results.items():\n",
    "    if isinstance(value, dict):\n",
    "        for key_j, __data in value.items():\n",
    "            if key_j == 'overall':\n",
    "                logger.info(Fore.YELLOW + f\"{key_i}\" + Style.RESET_ALL)\n",
    "                logger.info(\"precision: \" + Fore.RED +\n",
    "                            \"{:.3f}\".format(np.mean(__data['precision'])) + Style.RESET_ALL +\n",
    "                           f\" {str([round(x, 2) for x in __data['precision']])}\")\n",
    "                logger.info(\"recall:    \" + Fore.RED +\n",
    "                            \"{:.3f}\".format(np.mean(__data['recall'])) + Style.RESET_ALL+\n",
    "                           f\" {str([round(x, 2) for x in __data['recall']])}\")\n",
    "                logger.info(\"f1-score:  \" + \n",
    "                            Fore.RED + \"{:.3f}\".format(np.mean(__data['fscore'])) + Style.RESET_ALL+\n",
    "                           f\" {str([round(x, 2) for x in __data['fscore']])}\")\n",
    "                \n",
    "                __precision += __data['precision']\n",
    "                __recall += __data['recall']\n",
    "                __fscore += __data['fscore']\n",
    "                \n",
    "__precision = [x for x in __precision if str(x) != 'nan']\n",
    "__recall = [x for x in __recall if str(x) != 'nan']\n",
    "__fscore = [x for x in __fscore if str(x) != 'nan']\n",
    "\n",
    "\n",
    "logger.info(\"\\n\")\n",
    "logger.info(Fore.RED + \"AGGREGATED METRICS\" + Style.RESET_ALL)\n",
    "logger.info(\"\\nprecision: \" + Fore.RED + \"{:.3f}\".format(np.mean(__precision)) + Style.RESET_ALL)\n",
    "logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(np.mean(__recall)) + Style.RESET_ALL)\n",
    "logger.info(\"f1-score:  \" +  Fore.RED + \"{:.3f}\".format(np.mean(__fscore)) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCaching results\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(Fore.YELLOW + \"Caching results\" + Style.RESET_ALL)\n",
    "with open('bert_ds_synthetic_pyramid.json', 'w') as fo:\n",
    "    json.dump(fold_results, fo, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for source in df_test[\"source\"].unique():\n",
    "#     df_source = df_test[df_test[\"source\"] == source]   \n",
    "#     logger.info(source)\n",
    "#     test_model(source, df_source, model, tokenizer, pos_filter=True)\n",
    "#     cnt += 1\n",
    "#     if cnt >= 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cYVkKLe-B1j0"
   },
   "outputs": [],
   "source": [
    "#@title Metrics report\n",
    "# logger.info(json.dumps(fold_results, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(api_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"API metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(so_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"SO metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(git_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"GIT metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(misc_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"MISC metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUOGnWgIMYLN"
   },
   "outputs": [],
   "source": [
    "def examples_per_source_type(source_type='misc', n_samples=None):\n",
    "    _sources = list(set([x[0] for x in log_examples_lst]))\n",
    "\n",
    "    _template = \"[w={}]\" + Fore.RED + \"[y={}]\" + Fore.YELLOW + \"[p={:.4f}]\" + Style.RESET_ALL + \" {}\"\n",
    "\n",
    "    idx = 0\n",
    "    for s in _sources:\n",
    "        examples_in_source = []\n",
    "        if source_type == 'api' and ('docs.oracle' in s or 'developer.android' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'so' and ('stackoverflow.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]            \n",
    "            idx += 1\n",
    "        elif source_type == 'git' and ('github.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'misc' and 'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        if not examples_in_source:\n",
    "            continue\n",
    "        logger.info('')\n",
    "        logger.info(Fore.RED + f\"{task_title}\" + Style.RESET_ALL)    \n",
    "        logger.info(s)\n",
    "        logger.info('')\n",
    "\n",
    "        for _, _, pweights, y_predict, y_probs, text in examples_in_source:\n",
    "            logger.info(_template.format(pweights, y_predict, y_probs, text))\n",
    "            logger.info('')\n",
    "        logger.info('-' * 20)\n",
    "      \n",
    "        if n_samples and idx >= n_samples:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fjg9kKaDM0fo"
   },
   "outputs": [],
   "source": [
    "#@title Sample prediction outputs for API sources\n",
    "\n",
    "logger.info(Fore.RED + \"API\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='api', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDBgOWQXNW1i"
   },
   "outputs": [],
   "source": [
    "#@title Sample prediction outputs for GIT sources\n",
    "\n",
    "logger.info(Fore.RED + \"GIT\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='git', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4Bqx8AbNoV_"
   },
   "outputs": [],
   "source": [
    "#@title Sample prediction outputs for SO sources\n",
    "\n",
    "logger.info(Fore.RED + \"SO\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='so', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_mgLqe0N-hs"
   },
   "outputs": [],
   "source": [
    "#@title Sample prediction outputs for MISC sources\n",
    "\n",
    "logger.info(Fore.RED + \"MISC\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='misc', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(Fore.RED + f\"{len(fold_results['venn_diagram_set'])} entries VENN SET\" + Style.RESET_ALL)\n",
    "for _t in fold_results['venn_diagram_set']:\n",
    "    logger.info(_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM51gMzrDUJf4OiiaquqBe4",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hugging-face-keras-bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7 Arthur hugging",
   "language": "python",
   "name": "msarthur-hface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03ddd131c9f0446eb83bb6dabee9a832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3518f71b0e4540be8b17a3fe72182cb4",
       "IPY_MODEL_a5ccb838d3704546937e925e456830be",
       "IPY_MODEL_8181fd24b3624c1b9c6a9d0302f43a56"
      ],
      "layout": "IPY_MODEL_f02cf8090f8d463eb7eeb59743a87276"
     }
    },
    "0466163ff4a945798423387d1ac900c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0efe94b613f44c029f2e9bd05696ad32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3e13535de4b44bb9139c3911684cee8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6ccdfb754c12418c9438ac218a172e63",
      "value": "Downloading: 100%"
     }
    },
    "153c3ed5c6314a49a5a37ad976417142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_262cc50dd08f49f78b781c2ce96a4ad7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f305b344487a4b598a7d41b007e49abd",
      "value": " 232k/232k [00:00&lt;00:00, 286kB/s]"
     }
    },
    "16b6cfa829ad43778c079452df231a3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17cfaa41c53842618c728987a81a44da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fc2d9969ea34bb3bb6e9f0260c2a75c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23531989ef014d7db16b220bb807c8fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "262cc50dd08f49f78b781c2ce96a4ad7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3518f71b0e4540be8b17a3fe72182cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9ef3ce0ace649c5a53e2244ba0dbb32",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_702a74b6e6e44d6b8ad68347f1a4b5fb",
      "value": "Downloading: 100%"
     }
    },
    "35a9eeb0acdb44738a6ad7fbf6d99b2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3950e2a7832c4dce8fd8209d6322a1f7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d32667132d604faeb419bbf9851c1bd8",
      "value": 231508
     }
    },
    "394b7988d36849b7b2c82872ae8d489d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3950e2a7832c4dce8fd8209d6322a1f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ccd384305c44ee3a86f47a2b994fbf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d84c022c44141268ef2c8d5e0190404": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40c212c9b352401697860624a6c54b1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4bd0f4c575714ad7848e818a576ee00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a38bc7017d545e2b44ad6ab0b2d937b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_929799bd24fb411bb4686988f2ae8996",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bd0f4c575714ad7848e818a576ee00a",
      "value": 570
     }
    },
    "5c6bfb038756422bb00be1349db7750b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c586016d3b594c6299cab2384f4c10aa",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d03c894896ad4ed6b48f19a70fbdf2af",
      "value": 466062
     }
    },
    "67f208ba489343dfa195c1dd915f3efe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16b6cfa829ad43778c079452df231a3d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a2a36eb594654c65acd584d9d4ebea20",
      "value": "Downloading: 100%"
     }
    },
    "6ccdfb754c12418c9438ac218a172e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cf29b5d508a4e2082751ccc7fa2f625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ccd384305c44ee3a86f47a2b994fbf9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_23531989ef014d7db16b220bb807c8fd",
      "value": " 466k/466k [00:00&lt;00:00, 637kB/s]"
     }
    },
    "702a74b6e6e44d6b8ad68347f1a4b5fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71a15c5a038f451f8ee64ce046488f71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8181fd24b3624c1b9c6a9d0302f43a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_911177bb86c749a0bd774cd3b7f9d302",
      "value": " 536M/536M [00:12&lt;00:00, 40.9MB/s]"
     }
    },
    "82b7fc20b50c44b2bd84b3bf882cdd43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c2b37becdef45bba205dfb20f8e37b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4276b6a5eac4023955218db6f78c84a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c4b0a1b67d304afda6ee4e52095584cc",
      "value": " 28.0/28.0 [00:00&lt;00:00, 631B/s]"
     }
    },
    "8c7cf993674145ffb7bb876e5591f6ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67f208ba489343dfa195c1dd915f3efe",
       "IPY_MODEL_35a9eeb0acdb44738a6ad7fbf6d99b2b",
       "IPY_MODEL_153c3ed5c6314a49a5a37ad976417142"
      ],
      "layout": "IPY_MODEL_82b7fc20b50c44b2bd84b3bf882cdd43"
     }
    },
    "901557318fb947dfa082f0cbf2d7365b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0efe94b613f44c029f2e9bd05696ad32",
       "IPY_MODEL_5a38bc7017d545e2b44ad6ab0b2d937b",
       "IPY_MODEL_b3db733aacf94a3c94519d70a7a56d7a"
      ],
      "layout": "IPY_MODEL_394b7988d36849b7b2c82872ae8d489d"
     }
    },
    "911177bb86c749a0bd774cd3b7f9d302": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "929799bd24fb411bb4686988f2ae8996": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "997b8c940317448c9409a2dee15fc519": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e99fb1211ba43459ee78dd64ab8c30e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2a36eb594654c65acd584d9d4ebea20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5ccb838d3704546937e925e456830be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d84c022c44141268ef2c8d5e0190404",
      "max": 536063208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40c212c9b352401697860624a6c54b1c",
      "value": 536063208
     }
    },
    "a66943be0fc0423880cb2bd63a1ea2d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6d9e21208294428a3f5572bbbd8b0b9",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d15e557fc621427a8295eecdc1e781a8",
      "value": 28
     }
    },
    "a8fd8b38a6b84be7b83b2f4df590fada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e99fb1211ba43459ee78dd64ab8c30e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_71a15c5a038f451f8ee64ce046488f71",
      "value": "Downloading: 100%"
     }
    },
    "b12b35cc52454a249c97f695409d24ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3db733aacf94a3c94519d70a7a56d7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0466163ff4a945798423387d1ac900c8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_17cfaa41c53842618c728987a81a44da",
      "value": " 570/570 [00:00&lt;00:00, 17.0kB/s]"
     }
    },
    "b4276b6a5eac4023955218db6f78c84a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d9e21208294428a3f5572bbbd8b0b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baffabe6cabf48f5b0b6523ea92aee78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18a3a9fc6d54b9f848e4454e1e36c21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8fd8b38a6b84be7b83b2f4df590fada",
       "IPY_MODEL_5c6bfb038756422bb00be1349db7750b",
       "IPY_MODEL_6cf29b5d508a4e2082751ccc7fa2f625"
      ],
      "layout": "IPY_MODEL_c4c410ab0c994a229a49b8baee221de4"
     }
    },
    "c4b0a1b67d304afda6ee4e52095584cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4c410ab0c994a229a49b8baee221de4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c586016d3b594c6299cab2384f4c10aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5b9bf1f3ae343ce97982c7802cfdc94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_997b8c940317448c9409a2dee15fc519",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b12b35cc52454a249c97f695409d24ce",
      "value": "Downloading: 100%"
     }
    },
    "c9ef3ce0ace649c5a53e2244ba0dbb32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d03c894896ad4ed6b48f19a70fbdf2af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d15e557fc621427a8295eecdc1e781a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d32667132d604faeb419bbf9851c1bd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3e13535de4b44bb9139c3911684cee8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0e88103f9684ffdb957357222bbaaf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5b9bf1f3ae343ce97982c7802cfdc94",
       "IPY_MODEL_a66943be0fc0423880cb2bd63a1ea2d2",
       "IPY_MODEL_8c2b37becdef45bba205dfb20f8e37b2"
      ],
      "layout": "IPY_MODEL_baffabe6cabf48f5b0b6523ea92aee78"
     }
    },
    "f02cf8090f8d463eb7eeb59743a87276": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f305b344487a4b598a7d41b007e49abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
