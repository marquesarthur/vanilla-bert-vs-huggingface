{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marquesarthur/vanilla-bert-vs-huggingface/blob/main/hugging_face_keras_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfNydjdoLcvK"
   },
   "source": [
    "Based on \n",
    "\n",
    "\n",
    "\n",
    "1.   https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379\n",
    "2.   https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/\n",
    "3.   https://huggingface.co/transformers/training.html#fine-tuning-with-keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**problem statement:**\n",
    "\n",
    "\n",
    "*   a developer has to inspect an **artifact X**\n",
    "*   Within the artifact, only a portion of the text is relevant to **input task Y**\n",
    "*   We ought to build a model that establishes relationships between **Y** and **sentences x âˆˆ X** \n",
    "*  The model must determine: **is x relevant to task Y**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Example of a task and an annotated artifact:*\n",
    "\n",
    "<br>\n",
    "\n",
    "[<img src=\"https://i.imgur.com/Zj1317H.jpg\">](https://i.imgur.com/Zj1317H.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* The coloured sentences are sentences annotated as relevant to the input task. \n",
    "* The warmer the color, the more annotators selected that portion of the text. \n",
    "* For simplicity, we process the data and used sentences \n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "*Ultimately, our data is a tuple representing:*\n",
    "\n",
    "\n",
    "*   **text** = artifact sentence\n",
    "\n",
    "*   **question** = task description\n",
    "\n",
    "*   **source** = URL of the artifact\n",
    "\n",
    "*   **category_index** = whether sentence is relevant [or not] for the input task\n",
    "\n",
    "*   **weights** = number of participants who annotated sentence as relevant\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtFJT5AK6RRc",
    "outputId": "f3eaf1c3-63c2-455e-eaa5-5eb9955afe4b"
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "\n",
    "# !pip install transformers\n",
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y80jdm9S6wQA",
    "outputId": "de6caa10-19da-42af-958f-bf19fe70903d"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn tqdm pandas python-Levenshtein path colorama matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q38yIvW87NrN",
    "outputId": "425ff20e-e16f-475a-93fe-221008e32fdc"
   },
   "outputs": [],
   "source": [
    "# @title Download git repo\n",
    "# !git clone https://github.com/marquesarthur/vanilla-bert-vs-huggingface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyrLR-tf8P4Q",
    "outputId": "a2cc52fc-f3e9-4cf0-ce6d-c11cee304c39"
   },
   "outputs": [],
   "source": [
    "# %cd vanilla-bert-vs-huggingface\n",
    "# !git pull\n",
    "# !ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kudd2ZR8tKZ",
    "outputId": "2a38495e-b8e4-43b1-c126-ec92e98b07d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m39 \u001b[33m129 \u001b[0m https://developer.android.com/training/permissions/requesting\n",
      "\u001b[31m14 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/5233543\n",
      "\u001b[31m4 \u001b[33m34 \u001b[0m https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "\u001b[31m27 \u001b[33m63 \u001b[0m https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "\u001b[31m9 \u001b[33m161 \u001b[0m https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "\u001b[31m9 \u001b[33m15 \u001b[0m https://developer.android.com/training/volley/request\n",
      "\u001b[31m14 \u001b[33m65 \u001b[0m https://stackoverflow.com/questions/28504524\n",
      "\u001b[31m20 \u001b[33m59 \u001b[0m https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "\u001b[31m5 \u001b[33m97 \u001b[0m https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "\u001b[31m4 \u001b[33m12 \u001b[0m https://stackoverflow.com/questions/33241952\n",
      "\u001b[31m6 \u001b[33m33 \u001b[0m https://github.com/realm/realm-java/issues/776\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/8712652\n",
      "\u001b[31m8 \u001b[33m59 \u001b[0m https://dzone.com/articles/android-rotate-and-scale\n",
      "\u001b[31m5 \u001b[33m470 \u001b[0m https://developer.android.com/reference/android/widget/TextView\n",
      "\u001b[31m7 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/19025301\n",
      "\u001b[31m8 \u001b[33m95 \u001b[0m https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "\u001b[31m20 \u001b[33m145 \u001b[0m https://developer.android.com/training/dependency-injection/hilt-android\n",
      "\u001b[31m4 \u001b[33m8 \u001b[0m https://stackoverflow.com/questions/30648172\n",
      "\u001b[31m4 \u001b[33m81 \u001b[0m https://github.com/google/dagger/issues/1991\n",
      "\u001b[31m9 \u001b[33m48 \u001b[0m https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "\u001b[31m5 \u001b[33m47 \u001b[0m https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "\u001b[31m9 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/6442054\n",
      "\u001b[31m3 \u001b[33m22 \u001b[0m https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "\u001b[31m22 \u001b[33m211 \u001b[0m https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "\u001b[31m21 \u001b[33m59 \u001b[0m https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "\u001b[31m17 \u001b[33m33 \u001b[0m https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "\u001b[31m6 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/10108774\n",
      "\u001b[31m19 \u001b[33m250 \u001b[0m https://developer.android.com/guide/topics/media/camera\n",
      "\u001b[31m9 \u001b[33m32 \u001b[0m https://github.com/google/ExoPlayer/issues/8387\n",
      "\u001b[31m7 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/8184492\n",
      "\u001b[31m7 \u001b[33m58 \u001b[0m https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "\u001b[31m3 \u001b[33m50 \u001b[0m https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "\u001b[31m3 \u001b[33m5 \u001b[0m https://stackoverflow.com/questions/38980595\n",
      "\u001b[31m4 \u001b[33m38 \u001b[0m https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "\u001b[31m8 \u001b[33m36 \u001b[0m https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "\u001b[31m7 \u001b[33m64 \u001b[0m https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html\n",
      "\u001b[31m4 \u001b[33m131 \u001b[0m https://stackoverflow.com/questions/122105\n",
      "\u001b[31m3 \u001b[33m48 \u001b[0m https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "\u001b[31m8 \u001b[33m49 \u001b[0m https://developer.android.com/guide/topics/media/mediarecorder\n",
      "\u001b[31m4 \u001b[33m9 \u001b[0m https://stackoverflow.com/questions/6688444\n",
      "\u001b[31m4 \u001b[33m27 \u001b[0m https://stackoverflow.com/questions/24952513\n",
      "\u001b[31m18 \u001b[33m219 \u001b[0m https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "\u001b[31m3 \u001b[33m72 \u001b[0m https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "\u001b[31m5 \u001b[33m373 \u001b[0m https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "\u001b[31m12 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/35357919\n",
      "\u001b[31m11 \u001b[33m117 \u001b[0m https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "\u001b[31m8 \u001b[33m147 \u001b[0m https://developer.android.com/training/notify-user/build-notification\n",
      "\u001b[31m3 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/3059155\n",
      "\u001b[31m10 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/26838730\n",
      "\u001b[31m7 \u001b[33m48 \u001b[0m https://guides.codepath.com/android/Defining-The-ActionBar\n",
      "\u001b[31m7 \u001b[33m283 \u001b[0m https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "\u001b[31m5 \u001b[33m17 \u001b[0m https://stackoverflow.com/questions/37096547\n",
      "\u001b[31m7 \u001b[33m179 \u001b[0m https://guides.codepath.com/android/using-the-recyclerview\n",
      "\u001b[31m3 \u001b[33m31 \u001b[0m https://stackoverflow.com/questions/47760861\n",
      "\u001b[31m13 \u001b[33m69 \u001b[0m https://developer.android.com/training/data-storage/sqlite\n",
      "\u001b[31m15 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/4015026\n",
      "\u001b[31m15 \u001b[33m81 \u001b[0m https://developer.android.com/guide/background/threading\n",
      "\u001b[31m6 \u001b[33m53 \u001b[0m https://stackoverflow.com/questions/2993085\n",
      "\u001b[31m11 \u001b[33m50 \u001b[0m https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "\u001b[31m5 \u001b[33m28 \u001b[0m https://stackoverflow.com/questions/23844667\n",
      "\u001b[31m5 \u001b[33m45 \u001b[0m https://github.com/flutter/flutter/issues/11392\n",
      "\u001b[31m4 \u001b[33m23 \u001b[0m https://stackoverflow.com/questions/29738510\n",
      "\u001b[31m5 \u001b[33m54 \u001b[0m https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "\u001b[31m4 \u001b[33m100 \u001b[0m https://stackoverflow.com/questions/2661536\n",
      "\u001b[31m9 \u001b[33m65 \u001b[0m https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "\u001b[31m5 \u001b[33m11 \u001b[0m https://stackoverflow.com/questions/24652078\n",
      "\u001b[31m8 \u001b[33m44 \u001b[0m https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/2883355\n",
      "\u001b[31m4 \u001b[33m37 \u001b[0m https://medium.com/android-dev-hacks/rendering-pdf-documents-in-android-using-pdfrenderer-f6d4f730b18\n",
      "\u001b[31m9 \u001b[33m51 \u001b[0m https://stackoverflow.com/questions/11064244\n",
      "\u001b[31m7 \u001b[33m138 \u001b[0m https://github.com/quarkusio/quarkus/issues/3954\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m16 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/29923376\n",
      "\u001b[31m4 \u001b[33m13 \u001b[0m https://github.com/google/dagger/issues/671\n",
      "\u001b[31m3 \u001b[33m19 \u001b[0m https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "\u001b[31m5 \u001b[33m24 \u001b[0m https://stackoverflow.com/questions/36275986\n",
      "\u001b[31m42 \u001b[33m177 \u001b[0m https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "\u001b[31m9 \u001b[33m36 \u001b[0m https://developer.android.com/training/location/retrieve-current\n",
      "\u001b[31m5 \u001b[33m35 \u001b[0m https://stackoverflow.com/questions/46481789\n",
      "\u001b[31m22 \u001b[33m119 \u001b[0m https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "\u001b[31m15 \u001b[33m99 \u001b[0m https://javapapers.com/android/android-location-fused-provider\n",
      "\u001b[31m3 \u001b[33m14 \u001b[0m https://developer.android.com/training/keyboard-input/commands\n",
      "\u001b[31m7 \u001b[33m249 \u001b[0m https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "\u001b[31m3 \u001b[33m4 \u001b[0m https://stackoverflow.com/questions/40168601\n",
      "\u001b[31m20 \u001b[33m54 \u001b[0m https://developer.android.com/training/safetynet/recaptcha\n",
      "\u001b[31m11 \u001b[33m21 \u001b[0m https://stackoverflow.com/questions/27297067\n",
      "\u001b[31m8 \u001b[33m42 \u001b[0m https://stackoverflow.com/questions/30362446\n",
      "\u001b[31m10 \u001b[33m36 \u001b[0m https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "\u001b[31m5 \u001b[33m16 \u001b[0m https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "\u001b[31m5 \u001b[33m57 \u001b[0m https://github.com/signalapp/Signal-Android/issues/3376\n",
      "\u001b[31m5 \u001b[33m34 \u001b[0m https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "\u001b[31m22 \u001b[33m104 \u001b[0m https://developer.android.com/reference/org/json/JSONObject\n",
      "\u001b[31m8 \u001b[33m31 \u001b[0m https://guides.codepath.com/android/converting-json-to-models\n",
      "\u001b[31m7 \u001b[33m146 \u001b[0m https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "\u001b[31m5 \u001b[33m55 \u001b[0m https://stackoverflow.com/questions/24313539\n",
      "\u001b[31m12 \u001b[33m77 \u001b[0m https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "\u001b[31m6 \u001b[33m72 \u001b[0m https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "\u001b[31m5 \u001b[33m25 \u001b[0m https://stackoverflow.com/questions/14347588\n",
      "\u001b[31m31 \u001b[33m163 \u001b[0m https://guides.codepath.com/android/creating-and-using-fragments\n",
      "\u001b[31m4 \u001b[33m40 \u001b[0m https://developer.android.com/training/gestures/scale\n",
      "\u001b[31m6 \u001b[33m32 \u001b[0m https://stackoverflow.com/questions/10630373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m4 \u001b[33m54 \u001b[0m https://developer.android.com/training/gestures/scroll\n",
      "\u001b[31m4 \u001b[33m16 \u001b[0m https://stackoverflow.com/questions/39588322\n",
      "\u001b[31m20 \u001b[33m196 \u001b[0m https://developer.android.com/training/dependency-injection/dagger-android\n",
      "\u001b[31m6 \u001b[33m44 \u001b[0m https://stackoverflow.com/questions/57235136\n",
      "\u001b[31m24 \u001b[33m121 \u001b[0m https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "Sample entry from data:\n",
      "{\n",
      "    \"category_index\": 1,\n",
      "    \"question\": \"Permission Denial when trying to access contacts in Android\",\n",
      "    \"source\": \"https://developer.android.com/training/permissions/requesting\",\n",
      "    \"text\": \"Every Android app runs in a limited-access sandbox.\",\n",
      "    \"weights\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# @title Import data as JSON\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from Levenshtein import ratio\n",
    "from colorama import Fore, Style\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.level = logging.DEBUG\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "from ds_android import get_input_for_BERT\n",
    "\n",
    "raw_data = get_input_for_BERT()\n",
    "\n",
    "print('Sample entry from data:')\n",
    "print(json.dumps(raw_data[0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b_GXczz9CGs",
    "outputId": "2f6b91cb-8396-41af-e299-61360817d8b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution\n",
      "\n",
      "not-relevant -- 87%\n",
      "RELEVANT ------ 13%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "cnt = Counter([d['category_index'] for d in raw_data])\n",
    "\n",
    "total = sum(cnt.values())\n",
    "\n",
    "labels_cnt = [cnt[0] / float(total), cnt[1] / float(total)]\n",
    "print('label distribution')\n",
    "print('')\n",
    "print('not-relevant -- {:.0f}%'.format(labels_cnt[0] * 100))\n",
    "print('RELEVANT ------ {:.0f}%'.format(labels_cnt[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seframes = {}\n",
    "with open('seframes.json') as input_file:\n",
    "    seframes = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_meaningful_frame(text):    \n",
    "    meaning_frames = [\n",
    "        'Using', 'Being_obligated', 'Required_event', 'Causation', 'Attempt', 'Execution'\n",
    "    ]\n",
    "    \n",
    "    if text in seframes:\n",
    "        text_labels = seframes[text]\n",
    "        if any([elem in meaning_frames for elem in text_labels]):\n",
    "            return True\n",
    "    \n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_results = dict()\n",
    "# if os.path.isfile('bert_ds_android_w_frames.json'):\n",
    "#     logger.info(Fore.YELLOW + \"Loading data from cache\" + Style.RESET_ALL)\n",
    "#     with open('bert_ds_android.json') as input_file:\n",
    "#         fold_results = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1l5DIHP_FUb",
    "outputId": "7f1648d0-2582-43a8-c1fc-50095d78892b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n"
     ]
    }
   ],
   "source": [
    "# @title Set environment variables\n",
    "\n",
    "model_id = 'bert-base-uncased'\n",
    "# model_id = 'distilbert-base-uncased'\n",
    "\n",
    "import os\n",
    "import contextlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "USE_TPU = False\n",
    "os.environ['TF_KERAS'] = '1'\n",
    "\n",
    "# @title Initialize TPU Strategy\n",
    "if USE_TPU:\n",
    "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
    "    tf.contrib.distribute.initialize_tpu_system(resolver)\n",
    "    strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
    "\n",
    "# sklearn libs\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Tensorflow Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "# Hugging face imports\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification, TFBertForSequenceClassification\n",
    "from transformers import TFDistilBertModel, DistilBertConfig\n",
    "from transformers import DistilBertTokenizerFast, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Model parameters\n",
    "\n",
    "# Bert Model Constants\n",
    "SEQ_LEN = 64 # 128\n",
    "BATCH_SIZE = 64 # 64 32 larger batch size causes OOM errors\n",
    "EPOCHS = 10 # 3 4\n",
    "LR = 1e-5 # 2e-5\n",
    "\n",
    "# 3e-4, 1e-4, 5e-5, 3e-5\n",
    "# My own constants\n",
    "# USE_FRAME_FILTERING = False\n",
    "# UNDERSAMPLING = True\n",
    "# N_UNDERSAMPLING = 2 # ratio of how many samples from 0-class, to 1-class, e.g.: 2:1\n",
    "# USE_DS_SYNTHETIC = False\n",
    "\n",
    "USE_FRAME_FILTERING = True\n",
    "MATCH_FRAME_FROM_TASK = False\n",
    "USE_PYRAMID = True\n",
    "\n",
    "UNDERSAMPLING = True\n",
    "N_UNDERSAMPLING = 2 # ratio of how many samples from 0-class, to 1-class, e.g.: 2:1\n",
    "USE_DS_SYNTHETIC = False\n",
    "MIN_W = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1T9xPdXp_kt9"
   },
   "outputs": [],
   "source": [
    "# @title JSON to dataframe helper functions\n",
    "def undersample_df(df, n_times=3):\n",
    "    class_0,class_1 = df.category_index.value_counts()\n",
    "    c0 = df[df['category_index'] == 0]\n",
    "    c1 = df[df['category_index'] == 1]\n",
    "    df_0 = c0.sample(int(n_times * class_1))\n",
    "    \n",
    "    undersampled_df = pd.concat([df_0, c1],axis=0)\n",
    "    return undersampled_df\n",
    "\n",
    "def get_ds_synthetic_data(min_w=MIN_W):\n",
    "    short_task = {\n",
    "      \"bugzilla\": \"\"\"How to query bugs using the custom fields with the Bugzilla REST API?\"\"\",\n",
    "      \"databases\": \"\"\"Which technology should be adopted for the database layer abstraction: Object/Relational Mapping (ORM) or a Java Database Connectivity API (JDBC)?\"\"\",\n",
    "      \"gpmdpu\": \"\"\"Can I bind the cmd key to the GPMDPU shortcuts?\"\"\",\n",
    "      \"lucene\": \"\"\"How does Lucene compute similarity scores for the BM25 similarity?\"\"\",\n",
    "      \"networking\": \"\"\"Which technology should be adopted for the notification system, Server-Sent Events (SSE) or WebSockets?\"\"\",\n",
    "    }\n",
    "\n",
    "    with open('relevance_corpus.json') as ipf:\n",
    "        aux = json.load(ipf)\n",
    "        raw_data = defaultdict(list)\n",
    "        for d in aux:\n",
    "            if d['task'] == 'yargs':\n",
    "                continue\n",
    "\n",
    "            raw_data['text'].append(d['text'])\n",
    "            raw_data['question'].append(short_task[d['task']])\n",
    "            raw_data['source'].append(d['source'])\n",
    "            raw_data['category_index'].append(1 if d['weight'] > min_w else 0)\n",
    "            raw_data['weights'].append(d['weight'] if d['weight'] > min_w else 0)\n",
    " \n",
    "        data = pd.DataFrame.from_dict(raw_data)\n",
    "        data = undersample_df(data, n_times=1)\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "      \n",
    "    return data\n",
    "\n",
    "def get_class_weights(y, smooth_factor=0, upper_bound=5.0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    clazz = {cls: float(majority / count) for cls, count in counter.items()}\n",
    "    result = {}\n",
    "    for key, value in clazz.items():\n",
    "        if value > upper_bound:\n",
    "            value = upper_bound\n",
    "        \n",
    "        result[key] = value\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def add_raw_data(result, data, use_pyramid=False):\n",
    "    s = data['source']\n",
    "    if 'docs.oracle' in s or 'developer.android' in s:\n",
    "        source_type = 'api'\n",
    "    elif 'stackoverflow.com' in s:\n",
    "        source_type = 'so'\n",
    "    elif 'github.com' in s:\n",
    "        source_type = 'git'\n",
    "    else:\n",
    "        source_type = 'misc'\n",
    "    \n",
    "    if use_pyramid:\n",
    "        pyramid = data['category_index']\n",
    "    else:\n",
    "        pyramid = 1 if data['weights'] > 1 else 0        \n",
    "    \n",
    "    result['text'].append(data['text'])\n",
    "    result['question'].append(data['question'])\n",
    "    result['source'].append(data['source'])\n",
    "    result['category_index'].append(pyramid)\n",
    "    result['weights'].append(data['weights'])\n",
    "    result['source_type'].append(source_type)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837,
     "referenced_widgets": [
      "8c7cf993674145ffb7bb876e5591f6ca",
      "67f208ba489343dfa195c1dd915f3efe",
      "35a9eeb0acdb44738a6ad7fbf6d99b2b",
      "153c3ed5c6314a49a5a37ad976417142",
      "82b7fc20b50c44b2bd84b3bf882cdd43",
      "16b6cfa829ad43778c079452df231a3d",
      "a2a36eb594654c65acd584d9d4ebea20",
      "3950e2a7832c4dce8fd8209d6322a1f7",
      "d32667132d604faeb419bbf9851c1bd8",
      "262cc50dd08f49f78b781c2ce96a4ad7",
      "f305b344487a4b598a7d41b007e49abd",
      "c18a3a9fc6d54b9f848e4454e1e36c21",
      "a8fd8b38a6b84be7b83b2f4df590fada",
      "5c6bfb038756422bb00be1349db7750b",
      "6cf29b5d508a4e2082751ccc7fa2f625",
      "c4c410ab0c994a229a49b8baee221de4",
      "9e99fb1211ba43459ee78dd64ab8c30e",
      "71a15c5a038f451f8ee64ce046488f71",
      "c586016d3b594c6299cab2384f4c10aa",
      "d03c894896ad4ed6b48f19a70fbdf2af",
      "3ccd384305c44ee3a86f47a2b994fbf9",
      "23531989ef014d7db16b220bb807c8fd",
      "e0e88103f9684ffdb957357222bbaaf7",
      "c5b9bf1f3ae343ce97982c7802cfdc94",
      "a66943be0fc0423880cb2bd63a1ea2d2",
      "8c2b37becdef45bba205dfb20f8e37b2",
      "baffabe6cabf48f5b0b6523ea92aee78",
      "997b8c940317448c9409a2dee15fc519",
      "b12b35cc52454a249c97f695409d24ce",
      "b6d9e21208294428a3f5572bbbd8b0b9",
      "d15e557fc621427a8295eecdc1e781a8",
      "b4276b6a5eac4023955218db6f78c84a",
      "c4b0a1b67d304afda6ee4e52095584cc",
      "901557318fb947dfa082f0cbf2d7365b",
      "0efe94b613f44c029f2e9bd05696ad32",
      "5a38bc7017d545e2b44ad6ab0b2d937b",
      "b3db733aacf94a3c94519d70a7a56d7a",
      "394b7988d36849b7b2c82872ae8d489d",
      "d3e13535de4b44bb9139c3911684cee8",
      "6ccdfb754c12418c9438ac218a172e63",
      "929799bd24fb411bb4686988f2ae8996",
      "4bd0f4c575714ad7848e818a576ee00a",
      "0466163ff4a945798423387d1ac900c8",
      "17cfaa41c53842618c728987a81a44da"
     ]
    },
    "id": "r_y7xwmxAT39",
    "outputId": "ba094ca3-4ef3-41c0-da55-0e07626c7fd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# @title Tokenizer\n",
    "\n",
    "print(model_id)\n",
    "if model_id == 'distilbert-base-uncased':\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)\n",
    "else:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HdAYw7lBAmlO"
   },
   "outputs": [],
   "source": [
    "# @title data encoder\n",
    "\n",
    "def _encode(tokenizer, dataframe, max_length=SEQ_LEN):\n",
    "    \n",
    "    seq_a = dataframe['text'].tolist()\n",
    "    seq_b = dataframe['question'].tolist()\n",
    "    \n",
    "    return tokenizer(seq_a, seq_b, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "def to_one_hot_encoding(data, nb_classes = 2):\n",
    "    targets = np.array([data]).reshape(-1)\n",
    "    one_hot_targets = np.eye(nb_classes)[targets]\n",
    "    return one_hot_targets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "y-5ROuqDBU9X"
   },
   "outputs": [],
   "source": [
    "# @title Metrics & Logging functions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "recommendation_metrics = defaultdict(list)\n",
    "prediction_metrics = defaultdict(list)\n",
    "api_metrics = defaultdict(list)\n",
    "so_metrics = defaultdict(list)\n",
    "git_metrics = defaultdict(list)\n",
    "misc_metrics = defaultdict(list)\n",
    "\n",
    "classification_report_lst = []\n",
    "log_examples_lst = []\n",
    "source_lst = []\n",
    "venn_diagram_set = []\n",
    "\n",
    "def aggregate_macro_metrics(store_at, precision, recall, fscore):   \n",
    "    store_at['precision'].append(precision)\n",
    "    store_at['recall'].append(recall)\n",
    "    store_at['fscore'].append(fscore)\n",
    "    \n",
    "    \n",
    "def aggregate_macro_source_metrics(precision, recall, fscore, source):\n",
    "    s = source\n",
    "    if 'docs.oracle' in s or 'developer.android' in s:\n",
    "        aggregate_macro_metrics(api_metrics, precision, recall, fscore)\n",
    "    elif 'stackoverflow.com' in s:\n",
    "        aggregate_macro_metrics(so_metrics, precision, recall, fscore)\n",
    "    elif 'github.com' in s:\n",
    "        aggregate_macro_metrics(git_metrics, precision, recall, fscore)        \n",
    "    elif  'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
    "        aggregate_macro_metrics(misc_metrics, precision, recall, fscore)\n",
    "    \n",
    "\n",
    "def aggregate_recommendation_metrics(store_at, k, precision_at_k, pyramid_precision_at_k):\n",
    "    store_at['k'].append(k)\n",
    "    store_at['precision'].append(precision_at_k)\n",
    "    store_at['âˆ† precision'].append(pyramid_precision_at_k)\n",
    "    \n",
    "def aggregate_report_metrics(clz_report):\n",
    "    relevant_label = str(1)\n",
    "    if relevant_label in clz_report:\n",
    "        for _key in ['precision', 'recall']:\n",
    "            if _key in clz_report[relevant_label]:\n",
    "                clz_report_lst[_key].append(clz_report[relevant_label][_key])    \n",
    "                \n",
    "def log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10):\n",
    "    # get the predicted prob at every index\n",
    "    idx_probs = [(idx, y_predict[idx], y_probs[idx]) for idx, _ in enumerate(y_predict)]\n",
    "    \n",
    "    # filter probs for all indexes predicted as relevant  \n",
    "    idx_probs = list(filter(lambda k: k[1] == 1, idx_probs))\n",
    "    \n",
    "    most_probable = sorted(idx_probs, key=lambda i: i[2], reverse=True)\n",
    "    \n",
    "    result = [idx for idx, _, _ in most_probable][:k]\n",
    "    \n",
    "    for idx in result:\n",
    "        log_examples_lst.append((\n",
    "            source, \n",
    "            task_title,\n",
    "            pweights[idx],\n",
    "            y_predict[idx],\n",
    "            y_probs[idx],\n",
    "            text[idx]\n",
    "        ))\n",
    "        \n",
    "def log_venn_diagram(y_true, y_predicted, text):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        for _true, _predict, _t in zip(y_true, y_predicted, text):\n",
    "            if _true == 1 and _predict == 1:\n",
    "                cnt += 1\n",
    "                venn_diagram_set.append(_t)\n",
    "    except Exception as ex:\n",
    "        logger.info(str(ex))\n",
    "    logger.info(Fore.RED + str(cnt) + Style.RESET_ALL + \" entries logged\")\n",
    "\n",
    "    \n",
    "def avg_macro_metric_for(data):\n",
    "    __precision = data['precision']\n",
    "    __recall = data['recall']\n",
    "    __fscore = data['fscore']\n",
    "\n",
    "    return np.mean(__precision), np.mean(__recall), np.mean(__fscore)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4E1IN6UoPq96"
   },
   "outputs": [],
   "source": [
    "#@title Training procedures\n",
    "\n",
    "def get_train_val_test(task_uid, size=0.9, undersample=False, aug=True, undersample_n=3):\n",
    "    if not isinstance(task_uid, list):\n",
    "        task_uid = [task_uid]\n",
    "        \n",
    "    train_data_raw = defaultdict(list)\n",
    "    test_data_raw = defaultdict(list)\n",
    "    \n",
    "    for _data in tqdm(CORPUS):\n",
    "        if _data['question'] in task_uid:\n",
    "            add_raw_data(test_data_raw, _data, use_pyramid=USE_PYRAMID)\n",
    "        else:\n",
    "            add_raw_data(train_data_raw, _data, use_pyramid=USE_PYRAMID)\n",
    "    \n",
    "    train_val = pd.DataFrame.from_dict(train_data_raw)\n",
    "    test = pd.DataFrame.from_dict(test_data_raw)\n",
    "    \n",
    "    # https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "    #  randomize rows....    \n",
    "    train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "    test = test.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    if undersample:\n",
    "        train_val = undersample_df(train_val, n_times=undersample_n)\n",
    "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    if aug:\n",
    "        train_val = pd.concat([train_val, get_ds_synthetic_data()],axis=0)\n",
    "        train_val = train_val.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    weights = get_class_weights(train_val['category_index'].tolist())\n",
    "    \n",
    "    train, val = train_test_split(\n",
    "        train_val, \n",
    "        stratify=train_val['category_index'].tolist(), \n",
    "        train_size=size\n",
    "    )\n",
    "    \n",
    "    return train, val, test, weights        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, product\n",
    "\n",
    "\n",
    "def get_most_common_frame_relationships(df_train):\n",
    "    frame_task_pairs = []\n",
    "    df_filtered = df_train[df_train['category_index'] == 1]\n",
    "    for __task, __text in zip(df_filtered['question'].tolist(), df_filtered['text'].tolist()):\n",
    "\n",
    "        task_labels, text_labels = [], []\n",
    "        if __task in seframes:\n",
    "            task_labels = seframes[__task]\n",
    "\n",
    "        if __text in seframes:\n",
    "            text_labels = seframes[__text]\n",
    "\n",
    "        if task_labels and text_labels:\n",
    "            all_pairs = list(product(task_labels, text_labels))\n",
    "            frame_task_pairs += all_pairs\n",
    "\n",
    "    most_common_frame_relationships = [pair for pair, cnt in Counter(frame_task_pairs).most_common(100)]\n",
    "    return most_common_frame_relationships\n",
    "\n",
    "def has_common_task_frame(task_title, text, most_common_frame_relationships):\n",
    "    task_labels, text_labels = [], []\n",
    "    if task_title in seframes:\n",
    "        task_labels = seframes[task_title]\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    if text in seframes:\n",
    "        text_labels = seframes[text]\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "        \n",
    "    all_pairs = list(product(task_labels, text_labels))\n",
    "    has_frame_match = any([elem in most_common_frame_relationships for elem in all_pairs])\n",
    "    \n",
    "    return has_frame_match\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_predictions(task_title, text, y_true, y_predict, y_probs, relevant_class=1, max_pred_values=10):\n",
    "    y_true_prime = []\n",
    "    y_predict_prime = []\n",
    "        \n",
    "    \n",
    "    # update probs after k = 10, same as in eval_model \n",
    "    aux = [(idx, prob) for idx, prob in enumerate(y_probs)]\n",
    "    \n",
    "    cnt = 0\n",
    "    for idx, prob in sorted(aux, key=lambda k: k[1], reverse=True):\n",
    "        y_true_prime.append(y_true[idx])\n",
    "        _t = text[idx]\n",
    "        \n",
    "        cnt += 1\n",
    "        if cnt > max_pred_values:\n",
    "            y_predict_prime.append(y_predict[idx])\n",
    "        else:\n",
    "            if has_meaningful_frame(_t):\n",
    "                y_predict_prime.append(max(y_predict[idx], relevant_class))\n",
    "            else:\n",
    "                y_predict_prime.append(y_predict[idx])\n",
    "                \n",
    "    \n",
    "    return y_true_prime, y_predict_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_predictions_with_task(task_title, text, y_true, y_predict, y_probs, task_filter, relevant_class=1, max_pred_values=10):\n",
    "    y_true_prime = []\n",
    "    y_predict_prime = []\n",
    "        \n",
    "    \n",
    "    # update probs after k = 10, same as in eval_model \n",
    "    aux = [(idx, prob) for idx, prob in enumerate(y_probs)]\n",
    "    max_pred_values = max(int(len(text) * 0.15), 10)\n",
    "    \n",
    "    cnt = 0\n",
    "    for idx, prob in sorted(aux, key=lambda k: k[1], reverse=True):\n",
    "        y_true_prime.append(y_true[idx])\n",
    "        _t = text[idx]\n",
    "        \n",
    "        cnt += 1\n",
    "        if cnt > max_pred_values:\n",
    "            y_predict_prime.append(y_predict[idx])\n",
    "        else:\n",
    "            if has_common_task_frame(task_title, _t, task_filter):\n",
    "                y_predict_prime.append(max(y_predict[idx], relevant_class))\n",
    "            else:\n",
    "                y_predict_prime.append(y_predict[idx])\n",
    "                \n",
    "    \n",
    "    return y_true_prime, y_predict_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "vFePvH5vBVA7"
   },
   "outputs": [],
   "source": [
    "# @title Testing procedures\n",
    "\n",
    "# https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7\n",
    "def eval_model(model, test_data, max_pred_values=10):\n",
    "    preds = model.predict(test_data.batch(1)).logits  \n",
    "    \n",
    "    #transform to array with probabilities\n",
    "    res = tf.nn.softmax(preds, axis=1).numpy()      \n",
    "\n",
    "    y_predict, y_probs = res.argmax(axis=-1), res[:, 1]\n",
    "    aux = [(idx, prob) for idx, prob in enumerate(y_probs)]\n",
    "    \n",
    "    max_pred_values = max(int(len(y_predict) * 0.15), 10)\n",
    "    \n",
    "    cnt = 0\n",
    "    for idx, prob in sorted(aux, key=lambda k: k[1], reverse=True):\n",
    "#         if cnt < max_pred_values:\n",
    "#             logger.info(f\"DEBUG : {y_predict[idx]} {round(prob, 4)}\")\n",
    "        \n",
    "        cnt += 1\n",
    "        if cnt > max_pred_values:\n",
    "            y_predict[idx] = 0\n",
    "            \n",
    "    \n",
    "    return y_predict, y_probs\n",
    "    \n",
    "\n",
    "def test_model(source, df_test, model, tokenizer, pos_filter=False, task_filter=None):\n",
    "    \n",
    "    df_source = df_test[df_test[\"source\"] == source]   \n",
    "    task_title = df_source['question'].tolist()[0]\n",
    "    text = df_source['text'].tolist()\n",
    "    pweights = df_source['weights'].tolist()\n",
    "    \n",
    "    # Encode X_test\n",
    "    test_encodings = _encode(tokenizer, df_source)\n",
    "    test_labels = df_source['category_index'].tolist()\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        dict(test_encodings),\n",
    "        test_labels\n",
    "    ))\n",
    "    \n",
    "    y_true = [y.numpy() for x, y in test_dataset]\n",
    "    \n",
    "    if any([k == 1 for k in y_true]): # means that this source has at least one annotated sentence\n",
    "        y_predict, y_probs = eval_model(model, test_dataset)\n",
    "\n",
    "    \n",
    "        if task_filter:\n",
    "            y_true, y_predict = update_predictions_with_task(task_title, text, y_true, y_predict, y_probs, task_filter)\n",
    "            \n",
    "        if pos_filter:\n",
    "            y_true, y_predict = update_predictions(task_title, text, y_true, y_predict, y_probs)\n",
    "\n",
    "\n",
    "        if len(y_true) > 0 and len(y_predict) > 0:\n",
    "            accuracy = accuracy_score(y_true, y_predict)\n",
    "            macro_f1 = f1_score(y_true, y_predict, average='macro')\n",
    "\n",
    "            classification_report_lst.append(classification_report(y_true, y_predict))\n",
    "            aggregate_report_metrics(classification_report(y_true, y_predict, output_dict=True))\n",
    "\n",
    "\n",
    "            logger.info(\"-\" * 20)    \n",
    "\n",
    "            logger.info(\"Y\")\n",
    "            logger.info(\"[0s] {} [1s] {}\".format(\n",
    "                len(list(filter(lambda k: k== 0, y_true))),\n",
    "                len(list(filter(lambda k: k== 1, y_true)))\n",
    "            ))\n",
    "\n",
    "\n",
    "            logger.info(\"predicted\")\n",
    "            logger.info(\"[0s] {} [1s] {}\".format(\n",
    "                len(list(filter(lambda k: k== 0, y_predict))),\n",
    "                len(list(filter(lambda k: k== 1, y_predict)))\n",
    "            ))\n",
    "\n",
    "            logger.info(\"-\" * 20)\n",
    "\n",
    "            logger.info(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "            logger.info(\"macro_f1: {:.4f}\".format(macro_f1))\n",
    "\n",
    "            precision, recall, fscore, _ = precision_recall_fscore_support(y_true, y_predict, average='macro')\n",
    "\n",
    "            aggregate_macro_metrics(prediction_metrics, precision, recall, fscore)\n",
    "            aggregate_macro_source_metrics(precision, recall, fscore, source)\n",
    "\n",
    "            logger.info(\"Precision: {:.4f}\".format(precision))\n",
    "            logger.info(\"Recall: {:.4f}\".format(recall))\n",
    "            logger.info(\"F1: {:.4f}\".format(fscore))\n",
    "\n",
    "            log_examples(task_title, source, text, pweights, y_predict, y_probs, k=10)\n",
    "            log_venn_diagram(y_true, y_predict, text)\n",
    "            source_lst.append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_idx_fold_results(idx_split, store_at):\n",
    "    if idx_split not in store_at:\n",
    "        store_at[idx_split] = dict()\n",
    "        store_at[idx_split]['run_cnt'] = 0\n",
    "        store_at[idx_split]['overall'] = defaultdict(list)\n",
    "        store_at[idx_split]['api'] = defaultdict(list)\n",
    "        store_at[idx_split]['so'] = defaultdict(list)\n",
    "        store_at[idx_split]['git'] = defaultdict(list)\n",
    "        store_at[idx_split]['misc'] = defaultdict(list)\n",
    "    \n",
    "    store_at[idx_split]['run_cnt'] += 1\n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "    store_at[idx_split]['overall']['precision'].append(_precision)\n",
    "    store_at[idx_split]['overall']['recall'].append(_recall)\n",
    "    store_at[idx_split]['overall']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(api_metrics)\n",
    "    store_at[idx_split]['api']['precision'].append(_precision)\n",
    "    store_at[idx_split]['api']['recall'].append(_recall)\n",
    "    store_at[idx_split]['api']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(so_metrics)\n",
    "    store_at[idx_split]['so']['precision'].append(_precision)\n",
    "    store_at[idx_split]['so']['recall'].append(_recall)\n",
    "    store_at[idx_split]['so']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(git_metrics)\n",
    "    store_at[idx_split]['git']['precision'].append(_precision)\n",
    "    store_at[idx_split]['git']['recall'].append(_recall)\n",
    "    store_at[idx_split]['git']['fscore'].append(_f1score)  \n",
    "    \n",
    "    _precision, _recall, _f1score = avg_macro_metric_for(misc_metrics)\n",
    "    store_at[idx_split]['misc']['precision'].append(_precision)\n",
    "    store_at[idx_split]['misc']['recall'].append(_recall)\n",
    "    store_at[idx_split]['misc']['fscore'].append(_f1score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TFBertForSequenceClassification.from_pretrained(model_id, cache_dir='/home/msarthur/scratch', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "03ddd131c9f0446eb83bb6dabee9a832",
      "3518f71b0e4540be8b17a3fe72182cb4",
      "a5ccb838d3704546937e925e456830be",
      "8181fd24b3624c1b9c6a9d0302f43a56",
      "f02cf8090f8d463eb7eeb59743a87276",
      "c9ef3ce0ace649c5a53e2244ba0dbb32",
      "702a74b6e6e44d6b8ad68347f1a4b5fb",
      "3d84c022c44141268ef2c8d5e0190404",
      "40c212c9b352401697860624a6c54b1c",
      "1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "911177bb86c749a0bd774cd3b7f9d302"
     ]
    },
    "id": "1oZGDUKnB1gw",
    "outputId": "21690a29-4add-4780-f87f-fa497b87d5e1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31mFold 0\u001b[0m\n",
      "how can i get the value of text view in recyclerview item?\n",
      "Hide MarkerView when nothing selected\n",
      "How to check programmatically whether app is running in debug mode or not?\n",
      "JSONObject parse dictionary objects\n",
      "Want to add drawable icons insteadof colorful dots\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7916/7916 [00:00<00:00, 861273.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1656\n",
      "1     828\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    664\n",
      "1     71\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2b872c29a3d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x2b872c29a3d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9022 - sparse_categorical_accuracy: 0.5853The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66598, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 20s 514ms/step - loss: 0.9022 - sparse_categorical_accuracy: 0.5853 - val_loss: 0.6660 - val_sparse_categorical_accuracy: 0.5616\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8077 - sparse_categorical_accuracy: 0.6622\n",
      "Epoch 00002: val_loss improved from 0.66598 to 0.59493, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 0.8077 - sparse_categorical_accuracy: 0.6622 - val_loss: 0.5949 - val_sparse_categorical_accuracy: 0.6486\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7093 - sparse_categorical_accuracy: 0.7287\n",
      "Epoch 00003: val_loss did not improve from 0.59493\n",
      "39/39 [==============================] - 10s 257ms/step - loss: 0.7093 - sparse_categorical_accuracy: 0.7287 - val_loss: 0.6362 - val_sparse_categorical_accuracy: 0.6630\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6070 - sparse_categorical_accuracy: 0.7786\n",
      "Epoch 00004: val_loss did not improve from 0.59493\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.6070 - sparse_categorical_accuracy: 0.7786 - val_loss: 0.6673 - val_sparse_categorical_accuracy: 0.6739\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5190 - sparse_categorical_accuracy: 0.8237\n",
      "Epoch 00005: val_loss did not improve from 0.59493\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.5190 - sparse_categorical_accuracy: 0.8237 - val_loss: 0.6629 - val_sparse_categorical_accuracy: 0.6884\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4420 - sparse_categorical_accuracy: 0.8623Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.59493\n",
      "39/39 [==============================] - 10s 261ms/step - loss: 0.4420 - sparse_categorical_accuracy: 0.8623 - val_loss: 0.6700 - val_sparse_categorical_accuracy: 0.6993\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/reference/org/json/JSONObject\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 82 [1s] 22\n",
      "predicted\n",
      "[0s] 89 [1s] 15\n",
      "--------------------\n",
      "Accuracy: 0.7019\n",
      "macro_f1: 0.4904\n",
      "Precision: 0.4933\n",
      "Recall: 0.4950\n",
      "F1: 0.4904\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://developer.android.com/codelabs/basic-android-kotlin-training-recyclerview-scrollable-list\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 276 [1s] 7\n",
      "predicted\n",
      "[0s] 241 [1s] 42\n",
      "--------------------\n",
      "Accuracy: 0.8269\n",
      "macro_f1: 0.4526\n",
      "Precision: 0.4855\n",
      "Recall: 0.4239\n",
      "F1: 0.4526\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/using-the-recyclerview\n",
      "--------------------\n",
      "Y\n",
      "[0s] 172 [1s] 7\n",
      "predicted\n",
      "[0s] 153 [1s] 26\n",
      "--------------------\n",
      "Accuracy: 0.8268\n",
      "macro_f1: 0.4826\n",
      "Precision: 0.4996\n",
      "Recall: 0.4988\n",
      "F1: 0.4826\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/flutter/flutter/issues/11392\n",
      "--------------------\n",
      "Y\n",
      "[0s] 40 [1s] 5\n",
      "predicted\n",
      "[0s] 37 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.7111\n",
      "macro_f1: 0.4156\n",
      "Precision: 0.4324\n",
      "Recall: 0.4000\n",
      "F1: 0.4156\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/23844667\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 5\n",
      "predicted\n",
      "[0s] 18 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6786\n",
      "macro_f1: 0.5902\n",
      "Precision: 0.5944\n",
      "Recall: 0.6478\n",
      "F1: 0.5902\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/37096547\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 12 [1s] 5\n",
      "predicted\n",
      "[0s] 9 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.4706\n",
      "macro_f1: 0.4396\n",
      "Precision: 0.4583\n",
      "Recall: 0.4500\n",
      "F1: 0.4396\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/converting-json-to-models\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 8\n",
      "predicted\n",
      "[0s] 21 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6774\n",
      "macro_f1: 0.6086\n",
      "Precision: 0.6048\n",
      "Recall: 0.6196\n",
      "F1: 0.6086\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://github.com/SundeepK/CompactCalendarView/issues/181\n",
      "--------------------\n",
      "Y\n",
      "[0s] 28 [1s] 8\n",
      "predicted\n",
      "[0s] 26 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6111\n",
      "macro_f1: 0.4815\n",
      "Precision: 0.4846\n",
      "Recall: 0.4821\n",
      "F1: 0.4815\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/33241952\n",
      "--------------------\n",
      "Y\n",
      "[0s] 8 [1s] 4\n",
      "predicted\n",
      "[0s] 8 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.6250\n",
      "Precision: 0.6250\n",
      "Recall: 0.6250\n",
      "F1: 0.6250\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.520\u001b[0m\n",
      "recall:    \u001b[31m0.516\u001b[0m\n",
      "f1-score:  \u001b[31m0.510\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.489\u001b[0m\n",
      "recall:    \u001b[31m0.459\u001b[0m\n",
      "f1-score:  \u001b[31m0.472\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.559\u001b[0m\n",
      "recall:    \u001b[31m0.574\u001b[0m\n",
      "f1-score:  \u001b[31m0.552\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.459\u001b[0m\n",
      "recall:    \u001b[31m0.441\u001b[0m\n",
      "f1-score:  \u001b[31m0.449\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.552\u001b[0m\n",
      "recall:    \u001b[31m0.559\u001b[0m\n",
      "f1-score:  \u001b[31m0.546\u001b[0m\n",
      "next 1\n",
      "\n",
      "\u001b[31mFold 1\u001b[0m\n",
      " height must be > 0\n",
      "Write and Read a json data to internal storage android\n",
      "Android PDF Rendering\n",
      "How can I hide a fragment on start of my MainActivity( or the application)?\n",
      "polymorphic deserialization of JSON with jackson, property type becomes &quot;null&quot;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7916/7916 [00:00<00:00, 750092.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1613\n",
      "1     806\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    622\n",
      "1     95\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.9005 - sparse_categorical_accuracy: 0.5672The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64660, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.9005 - sparse_categorical_accuracy: 0.5672 - val_loss: 0.6466 - val_sparse_categorical_accuracy: 0.6171\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.8036 - sparse_categorical_accuracy: 0.6577\n",
      "Epoch 00002: val_loss improved from 0.64660 to 0.58518, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 14s 360ms/step - loss: 0.8036 - sparse_categorical_accuracy: 0.6577 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.6729\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.7218 - sparse_categorical_accuracy: 0.7276\n",
      "Epoch 00003: val_loss improved from 0.58518 to 0.52367, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 13s 341ms/step - loss: 0.7218 - sparse_categorical_accuracy: 0.7276 - val_loss: 0.5237 - val_sparse_categorical_accuracy: 0.7286\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6157 - sparse_categorical_accuracy: 0.7821\n",
      "Epoch 00004: val_loss did not improve from 0.52367\n",
      "38/38 [==============================] - 10s 256ms/step - loss: 0.6157 - sparse_categorical_accuracy: 0.7821 - val_loss: 0.5669 - val_sparse_categorical_accuracy: 0.7398\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5235 - sparse_categorical_accuracy: 0.8177\n",
      "Epoch 00005: val_loss did not improve from 0.52367\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 0.5235 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.5884 - val_sparse_categorical_accuracy: 0.7286\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4259 - sparse_categorical_accuracy: 0.8690\n",
      "Epoch 00006: val_loss did not improve from 0.52367\n",
      "38/38 [==============================] - 10s 257ms/step - loss: 0.4259 - sparse_categorical_accuracy: 0.8690 - val_loss: 0.6073 - val_sparse_categorical_accuracy: 0.7398\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.3637 - sparse_categorical_accuracy: 0.8876Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.52367\n",
      "38/38 [==============================] - 10s 262ms/step - loss: 0.3637 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.6311 - val_sparse_categorical_accuracy: 0.7323\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://github.com/FasterXML/jackson-databind/issues/1538\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 26 [1s] 10\n",
      "predicted\n",
      "[0s] 26 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7222\n",
      "macro_f1: 0.6538\n",
      "Precision: 0.6538\n",
      "Recall: 0.6538\n",
      "F1: 0.6538\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "--------------------\n",
      "Y\n",
      "[0s] 242 [1s] 7\n",
      "predicted\n",
      "[0s] 212 [1s] 37\n",
      "--------------------\n",
      "Accuracy: 0.8394\n",
      "macro_f1: 0.5014\n",
      "Precision: 0.5152\n",
      "Recall: 0.5705\n",
      "F1: 0.5014\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/creating-and-using-fragments\n",
      "--------------------\n",
      "Y\n",
      "[0s] 132 [1s] 31\n",
      "predicted\n",
      "[0s] 139 [1s] 24\n",
      "--------------------\n",
      "Accuracy: 0.7853\n",
      "macro_f1: 0.6172\n",
      "Precision: 0.6328\n",
      "Recall: 0.6083\n",
      "F1: 0.6172\n",
      "\u001b[31m10\u001b[0m entries logged\n",
      "https://developer.android.com/training/basics/firstapp/starting-activity\n",
      "--------------------\n",
      "Y\n",
      "[0s] 66 [1s] 6\n",
      "predicted\n",
      "[0s] 62 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8611\n",
      "macro_f1: 0.6484\n",
      "Precision: 0.6258\n",
      "Recall: 0.6970\n",
      "F1: 0.6484\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://medium.com/@david.truong510/jackson-polymorphic-deserialization-91426e39b96a\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 5\n",
      "predicted\n",
      "[0s] 6 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5625\n",
      "macro_f1: 0.5608\n",
      "Precision: 0.6167\n",
      "Recall: 0.6273\n",
      "F1: 0.5608\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://medium.com/android-dev-hacks/rendering-pdf-documents-in-android-using-pdfrenderer-f6d4f730b18\n",
      "--------------------\n",
      "Y\n",
      "[0s] 33 [1s] 4\n",
      "predicted\n",
      "[0s] 27 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6757\n",
      "macro_f1: 0.4714\n",
      "Precision: 0.4944\n",
      "Recall: 0.4886\n",
      "F1: 0.4714\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2883355\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 19 [1s] 5\n",
      "predicted\n",
      "[0s] 14 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7083\n",
      "macro_f1: 0.6606\n",
      "Precision: 0.6643\n",
      "Recall: 0.7421\n",
      "F1: 0.6606\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/graphics/pdf/PdfRenderer\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 8\n",
      "predicted\n",
      "[0s] 34 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8182\n",
      "macro_f1: 0.7206\n",
      "Precision: 0.7059\n",
      "Recall: 0.7431\n",
      "F1: 0.7206\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30362446\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 8\n",
      "predicted\n",
      "[0s] 32 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7619\n",
      "macro_f1: 0.6465\n",
      "Precision: 0.6375\n",
      "Recall: 0.6618\n",
      "F1: 0.6465\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/14347588\n",
      "--------------------\n",
      "Y\n",
      "[0s] 20 [1s] 5\n",
      "predicted\n",
      "[0s] 15 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7200\n",
      "macro_f1: 0.6667\n",
      "Precision: 0.6667\n",
      "Recall: 0.7500\n",
      "F1: 0.6667\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/40168601\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 1 [1s] 3\n",
      "predicted\n",
      "[0s] 1 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 1.0000\n",
      "macro_f1: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1: 1.0000\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/38980595\n",
      "--------------------\n",
      "Y\n",
      "[0s] 2 [1s] 3\n",
      "predicted\n",
      "[0s] 0 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.6000\n",
      "macro_f1: 0.3750\n",
      "Precision: 0.3000\n",
      "Recall: 0.5000\n",
      "F1: 0.3750\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.626\u001b[0m\n",
      "recall:    \u001b[31m0.670\u001b[0m\n",
      "f1-score:  \u001b[31m0.627\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.616\u001b[0m\n",
      "recall:    \u001b[31m0.670\u001b[0m\n",
      "f1-score:  \u001b[31m0.623\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.654\u001b[0m\n",
      "recall:    \u001b[31m0.731\u001b[0m\n",
      "f1-score:  \u001b[31m0.670\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.654\u001b[0m\n",
      "recall:    \u001b[31m0.654\u001b[0m\n",
      "f1-score:  \u001b[31m0.654\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.581\u001b[0m\n",
      "recall:    \u001b[31m0.575\u001b[0m\n",
      "f1-score:  \u001b[31m0.550\u001b[0m\n",
      "next 2\n",
      "\n",
      "\u001b[31mFold 2\u001b[0m\n",
      "How to Integrate reCAPTCHA 2.0 in Android\n",
      "How can I make this rxjava zip to run in parallel?\n",
      "Permission Denial when trying to access contacts in Android\n",
      "keyUp called when key is still pressed\n",
      "Donâ€™t leak MockWebServer ports across tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7916/7916 [00:00<00:00, 352602.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1459\n",
      "1     730\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1178\n",
      "1     180\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9417 - sparse_categorical_accuracy: 0.5386The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68853, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 18s 508ms/step - loss: 0.9417 - sparse_categorical_accuracy: 0.5386 - val_loss: 0.6885 - val_sparse_categorical_accuracy: 0.6311\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9119 - sparse_categorical_accuracy: 0.5614\n",
      "Epoch 00002: val_loss improved from 0.68853 to 0.68054, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 13s 365ms/step - loss: 0.9119 - sparse_categorical_accuracy: 0.5614 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.6393\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8614 - sparse_categorical_accuracy: 0.6300\n",
      "Epoch 00003: val_loss improved from 0.68054 to 0.62176, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 16s 447ms/step - loss: 0.8614 - sparse_categorical_accuracy: 0.6300 - val_loss: 0.6218 - val_sparse_categorical_accuracy: 0.7131\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7821 - sparse_categorical_accuracy: 0.7254\n",
      "Epoch 00004: val_loss did not improve from 0.62176\n",
      "35/35 [==============================] - 9s 252ms/step - loss: 0.7821 - sparse_categorical_accuracy: 0.7254 - val_loss: 0.6593 - val_sparse_categorical_accuracy: 0.6639\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6837 - sparse_categorical_accuracy: 0.7656\n",
      "Epoch 00005: val_loss did not improve from 0.62176\n",
      "35/35 [==============================] - 9s 251ms/step - loss: 0.6837 - sparse_categorical_accuracy: 0.7656 - val_loss: 0.6248 - val_sparse_categorical_accuracy: 0.7090\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6208 - sparse_categorical_accuracy: 0.8072\n",
      "Epoch 00006: val_loss improved from 0.62176 to 0.55040, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 12s 348ms/step - loss: 0.6208 - sparse_categorical_accuracy: 0.8072 - val_loss: 0.5504 - val_sparse_categorical_accuracy: 0.7418\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4816 - sparse_categorical_accuracy: 0.8712\n",
      "Epoch 00007: val_loss did not improve from 0.55040\n",
      "35/35 [==============================] - 9s 251ms/step - loss: 0.4816 - sparse_categorical_accuracy: 0.8712 - val_loss: 0.5880 - val_sparse_categorical_accuracy: 0.7295\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.3857 - sparse_categorical_accuracy: 0.9054\n",
      "Epoch 00008: val_loss did not improve from 0.55040\n",
      "35/35 [==============================] - 9s 253ms/step - loss: 0.3857 - sparse_categorical_accuracy: 0.9054 - val_loss: 0.6168 - val_sparse_categorical_accuracy: 0.7459\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.3516 - sparse_categorical_accuracy: 0.9109\n",
      "Epoch 00009: val_loss did not improve from 0.55040\n",
      "35/35 [==============================] - 9s 253ms/step - loss: 0.3516 - sparse_categorical_accuracy: 0.9109 - val_loss: 0.7373 - val_sparse_categorical_accuracy: 0.6926\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.2811 - sparse_categorical_accuracy: 0.9296Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.55040\n",
      "35/35 [==============================] - 9s 258ms/step - loss: 0.2811 - sparse_categorical_accuracy: 0.9296 - val_loss: 0.6636 - val_sparse_categorical_accuracy: 0.7582\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://www.raywenderlich.com/10091980-testing-rest-apis-using-mockwebserver\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 201 [1s] 18\n",
      "predicted\n",
      "[0s] 206 [1s] 13\n",
      "--------------------\n",
      "Accuracy: 0.8767\n",
      "macro_f1: 0.5313\n",
      "Precision: 0.5381\n",
      "Recall: 0.5282\n",
      "F1: 0.5313\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/training/permissions/requesting\n",
      "--------------------\n",
      "Y\n",
      "[0s] 90 [1s] 39\n",
      "predicted\n",
      "[0s] 110 [1s] 19\n",
      "--------------------\n",
      "Accuracy: 0.7054\n",
      "macro_f1: 0.5774\n",
      "Precision: 0.6313\n",
      "Recall: 0.5782\n",
      "F1: 0.5774\n",
      "\u001b[31m10\u001b[0m entries logged\n",
      "https://dzone.com/articles/rxjava-idiomatic-concurrency-flatmap-vs-parallel\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 106 [1s] 11\n",
      "predicted\n",
      "[0s] 109 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.8718\n",
      "macro_f1: 0.5704\n",
      "Precision: 0.5837\n",
      "Recall: 0.5626\n",
      "F1: 0.5704\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://www.avg.com/en/signal/guide-to-android-app-permissions-how-to-use-them-smartly\n",
      "--------------------\n",
      "Y\n",
      "[0s] 152 [1s] 9\n",
      "predicted\n",
      "[0s] 153 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.9068\n",
      "macro_f1: 0.5342\n",
      "Precision: 0.5364\n",
      "Recall: 0.5325\n",
      "F1: 0.5342\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/5233543\n",
      "--------------------\n",
      "Y\n",
      "[0s] 7 [1s] 14\n",
      "predicted\n",
      "[0s] 13 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.6190\n",
      "macro_f1: 0.6182\n",
      "Precision: 0.6683\n",
      "Recall: 0.6786\n",
      "F1: 0.6182\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/27297067\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 10 [1s] 11\n",
      "predicted\n",
      "[0s] 13 [1s] 8\n",
      "--------------------\n",
      "Accuracy: 0.6667\n",
      "macro_f1: 0.6636\n",
      "Precision: 0.6827\n",
      "Recall: 0.6727\n",
      "F1: 0.6636\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://medium.com/mindorks/instrumentation-testing-with-mockwebserver-and-dagger2-56778477f0cf\n",
      "--------------------\n",
      "Y\n",
      "[0s] 69 [1s] 3\n",
      "predicted\n",
      "[0s] 65 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.8611\n",
      "macro_f1: 0.4627\n",
      "Precision: 0.4769\n",
      "Recall: 0.4493\n",
      "F1: 0.4627\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/codelabs/advanced-kotlin-coroutines#7\n",
      "--------------------\n",
      "Y\n",
      "[0s] 368 [1s] 5\n",
      "predicted\n",
      "[0s] 326 [1s] 47\n",
      "--------------------\n",
      "Accuracy: 0.8606\n",
      "macro_f1: 0.4625\n",
      "Precision: 0.4923\n",
      "Recall: 0.4361\n",
      "F1: 0.4625\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24952513\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 4\n",
      "predicted\n",
      "[0s] 23 [1s] 4\n",
      "--------------------\n",
      "Accuracy: 0.7037\n",
      "macro_f1: 0.4130\n",
      "Precision: 0.4130\n",
      "Recall: 0.4130\n",
      "F1: 0.4130\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Understanding-App-Permissions\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 27\n",
      "predicted\n",
      "[0s] 53 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6032\n",
      "macro_f1: 0.5217\n",
      "Precision: 0.6019\n",
      "Recall: 0.5556\n",
      "F1: 0.5217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://developer.android.com/training/keyboard-input/commands\n",
      "--------------------\n",
      "Y\n",
      "[0s] 11 [1s] 3\n",
      "predicted\n",
      "[0s] 4 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.3571\n",
      "macro_f1: 0.3538\n",
      "Precision: 0.4750\n",
      "Recall: 0.4697\n",
      "F1: 0.3538\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://github.com/morenoh149/react-native-contacts/issues/516\n",
      "--------------------\n",
      "Y\n",
      "[0s] 30 [1s] 4\n",
      "predicted\n",
      "[0s] 29 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.7353\n",
      "macro_f1: 0.4237\n",
      "Precision: 0.4310\n",
      "Recall: 0.4167\n",
      "F1: 0.4237\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/training/safetynet/recaptcha\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 20\n",
      "predicted\n",
      "[0s] 44 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5926\n",
      "macro_f1: 0.4923\n",
      "Precision: 0.5182\n",
      "Recall: 0.5118\n",
      "F1: 0.4923\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/35357919\n",
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 12\n",
      "predicted\n",
      "[0s] 47 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.7358\n",
      "macro_f1: 0.5316\n",
      "Precision: 0.5603\n",
      "Recall: 0.5346\n",
      "F1: 0.5316\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.544\u001b[0m\n",
      "recall:    \u001b[31m0.524\u001b[0m\n",
      "f1-score:  \u001b[31m0.511\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.529\u001b[0m\n",
      "recall:    \u001b[31m0.499\u001b[0m\n",
      "f1-score:  \u001b[31m0.472\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.581\u001b[0m\n",
      "recall:    \u001b[31m0.575\u001b[0m\n",
      "f1-score:  \u001b[31m0.557\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.431\u001b[0m\n",
      "recall:    \u001b[31m0.417\u001b[0m\n",
      "f1-score:  \u001b[31m0.424\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.547\u001b[0m\n",
      "recall:    \u001b[31m0.526\u001b[0m\n",
      "f1-score:  \u001b[31m0.524\u001b[0m\n",
      "next 3\n",
      "\n",
      "\u001b[31mFold 3\u001b[0m\n",
      "Is there an accepted best-practice on making asynchronous HTTP requests in Android?\n",
      "How to set a minimum crop window ?\n",
      "Camera API: Cross device issues\n",
      "Quick Actions don't get displayed on Android 7.0\n",
      "Application icon doesn&#39;t show up in Android action bar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7916/7916 [00:00<00:00, 825143.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1596\n",
      "1     798\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    714\n",
      "1    104\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.9155 - sparse_categorical_accuracy: 0.5606The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62396, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 19s 505ms/step - loss: 0.9155 - sparse_categorical_accuracy: 0.5606 - val_loss: 0.6240 - val_sparse_categorical_accuracy: 0.6854\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.8078 - sparse_categorical_accuracy: 0.6775\n",
      "Epoch 00002: val_loss improved from 0.62396 to 0.56062, saving model to /home/msarthur/scratch/best_model\n",
      "38/38 [==============================] - 13s 344ms/step - loss: 0.8078 - sparse_categorical_accuracy: 0.6775 - val_loss: 0.5606 - val_sparse_categorical_accuracy: 0.7154\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.7311 - sparse_categorical_accuracy: 0.7277\n",
      "Epoch 00003: val_loss did not improve from 0.56062\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 0.7311 - sparse_categorical_accuracy: 0.7277 - val_loss: 0.5694 - val_sparse_categorical_accuracy: 0.6929\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.6322 - sparse_categorical_accuracy: 0.7886\n",
      "Epoch 00004: val_loss did not improve from 0.56062\n",
      "38/38 [==============================] - 10s 253ms/step - loss: 0.6322 - sparse_categorical_accuracy: 0.7886 - val_loss: 0.5728 - val_sparse_categorical_accuracy: 0.7303\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5615 - sparse_categorical_accuracy: 0.8195\n",
      "Epoch 00005: val_loss did not improve from 0.56062\n",
      "38/38 [==============================] - 10s 255ms/step - loss: 0.5615 - sparse_categorical_accuracy: 0.8195 - val_loss: 0.5999 - val_sparse_categorical_accuracy: 0.7116\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.4867 - sparse_categorical_accuracy: 0.8475Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.56062\n",
      "38/38 [==============================] - 10s 260ms/step - loss: 0.4867 - sparse_categorical_accuracy: 0.8475 - val_loss: 0.6088 - val_sparse_categorical_accuracy: 0.7378\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/26838730\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 14 [1s] 11\n",
      "predicted\n",
      "[0s] 15 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5600\n",
      "macro_f1: 0.5484\n",
      "Precision: 0.5500\n",
      "Recall: 0.5487\n",
      "F1: 0.5484\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://developer.android.com/training/notify-user/build-notification\n",
      "--------------------\n",
      "Y\n",
      "[0s] 139 [1s] 8\n",
      "predicted\n",
      "[0s] 125 [1s] 22\n",
      "--------------------\n",
      "Accuracy: 0.8367\n",
      "macro_f1: 0.5545\n",
      "Precision: 0.5482\n",
      "Recall: 0.6192\n",
      "F1: 0.5545\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://www.twilio.com/blog/5-ways-to-make-http-requests-in-java\n",
      "--------------------\n",
      "Y\n",
      "[0s] 92 [1s] 5\n",
      "predicted\n",
      "[0s] 83 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.8660\n",
      "macro_f1: 0.6208\n",
      "Precision: 0.5951\n",
      "Recall: 0.7402\n",
      "F1: 0.6208\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/8/javafx/layout-tutorial/size_align.htm\n",
      "--------------------\n",
      "Y\n",
      "[0s] 87 [1s] 8\n",
      "predicted\n",
      "[0s] 81 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.8105\n",
      "macro_f1: 0.5373\n",
      "Precision: 0.5344\n",
      "Recall: 0.5560\n",
      "F1: 0.5373\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/Defining-The-ActionBar\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 7\n",
      "predicted\n",
      "[0s] 38 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7292\n",
      "macro_f1: 0.5354\n",
      "Precision: 0.5342\n",
      "Recall: 0.5453\n",
      "F1: 0.5354\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/media/camera\n",
      "--------------------\n",
      "Y\n",
      "[0s] 231 [1s] 19\n",
      "predicted\n",
      "[0s] 213 [1s] 37\n",
      "--------------------\n",
      "Accuracy: 0.7920\n",
      "macro_f1: 0.4772\n",
      "Precision: 0.4871\n",
      "Recall: 0.4769\n",
      "F1: 0.4772\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://medium.com/@JasonCromer/android-asynctask-http-request-tutorial-6b429d833e28\n",
      "--------------------\n",
      "Y\n",
      "[0s] 39 [1s] 20\n",
      "predicted\n",
      "[0s] 49 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5254\n",
      "macro_f1: 0.3742\n",
      "Precision: 0.3561\n",
      "Recall: 0.4096\n",
      "F1: 0.3742\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/28504524\n",
      "--------------------\n",
      "Y\n",
      "[0s] 51 [1s] 14\n",
      "predicted\n",
      "[0s] 55 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6615\n",
      "macro_f1: 0.4379\n",
      "Precision: 0.4318\n",
      "Recall: 0.4475\n",
      "F1: 0.4379\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/3059155\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 14 [1s] 3\n",
      "predicted\n",
      "[0s] 8 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.4118\n",
      "macro_f1: 0.3561\n",
      "Precision: 0.4306\n",
      "Recall: 0.3810\n",
      "F1: 0.3561\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/training/volley/request\n",
      "--------------------\n",
      "Y\n",
      "[0s] 6 [1s] 9\n",
      "predicted\n",
      "[0s] 5 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5333\n",
      "macro_f1: 0.4976\n",
      "Precision: 0.5000\n",
      "Recall: 0.5000\n",
      "F1: 0.4976\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.497\u001b[0m\n",
      "recall:    \u001b[31m0.522\u001b[0m\n",
      "f1-score:  \u001b[31m0.494\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.517\u001b[0m\n",
      "recall:    \u001b[31m0.538\u001b[0m\n",
      "f1-score:  \u001b[31m0.517\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.471\u001b[0m\n",
      "recall:    \u001b[31m0.459\u001b[0m\n",
      "f1-score:  \u001b[31m0.447\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.495\u001b[0m\n",
      "recall:    \u001b[31m0.565\u001b[0m\n",
      "f1-score:  \u001b[31m0.510\u001b[0m\n",
      "next 4\n",
      "\n",
      "\u001b[31mFold 4\u001b[0m\n",
      "Android: rotate canvas around the center of the screen\n",
      "TS shows numbers instead of contact names in notifications\n",
      "No lock screen controls ever\n",
      "Enums support with Realm?\n",
      "Sound panning should work for stereo files (and if not, add it to the docs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7916/7916 [00:00<00:00, 845461.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1710\n",
      "1     855\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    235\n",
      "1     41\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.9313 - sparse_categorical_accuracy: 0.5789The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68552, saving model to /home/msarthur/scratch/best_model\n",
      "41/41 [==============================] - 21s 505ms/step - loss: 0.9310 - sparse_categorical_accuracy: 0.5789 - val_loss: 0.6855 - val_sparse_categorical_accuracy: 0.5754\n",
      "Epoch 2/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.8633 - sparse_categorical_accuracy: 0.6191\n",
      "Epoch 00002: val_loss improved from 0.68552 to 0.67903, saving model to /home/msarthur/scratch/best_model\n",
      "41/41 [==============================] - 14s 349ms/step - loss: 0.8631 - sparse_categorical_accuracy: 0.6195 - val_loss: 0.6790 - val_sparse_categorical_accuracy: 0.6351\n",
      "Epoch 3/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.7580 - sparse_categorical_accuracy: 0.7230\n",
      "Epoch 00003: val_loss improved from 0.67903 to 0.60289, saving model to /home/msarthur/scratch/best_model\n",
      "41/41 [==============================] - 17s 410ms/step - loss: 0.7582 - sparse_categorical_accuracy: 0.7228 - val_loss: 0.6029 - val_sparse_categorical_accuracy: 0.6947\n",
      "Epoch 4/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.6658 - sparse_categorical_accuracy: 0.7707\n",
      "Epoch 00004: val_loss did not improve from 0.60289\n",
      "41/41 [==============================] - 10s 252ms/step - loss: 0.6672 - sparse_categorical_accuracy: 0.7700 - val_loss: 0.6695 - val_sparse_categorical_accuracy: 0.6702\n",
      "Epoch 5/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5967 - sparse_categorical_accuracy: 0.8059\n",
      "Epoch 00005: val_loss did not improve from 0.60289\n",
      "41/41 [==============================] - 10s 253ms/step - loss: 0.5964 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.6221 - val_sparse_categorical_accuracy: 0.7158\n",
      "Epoch 6/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.4960 - sparse_categorical_accuracy: 0.8555\n",
      "Epoch 00006: val_loss did not improve from 0.60289\n",
      "41/41 [==============================] - 10s 253ms/step - loss: 0.4952 - sparse_categorical_accuracy: 0.8558 - val_loss: 0.6392 - val_sparse_categorical_accuracy: 0.7228\n",
      "Epoch 7/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.3981 - sparse_categorical_accuracy: 0.8926Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.60289\n",
      "41/41 [==============================] - 11s 257ms/step - loss: 0.3979 - sparse_categorical_accuracy: 0.8928 - val_loss: 0.6424 - val_sparse_categorical_accuracy: 0.7263\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://github.com/signalapp/Signal-Android/issues/3376\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 52 [1s] 5\n",
      "predicted\n",
      "[0s] 51 [1s] 6\n",
      "--------------------\n",
      "Accuracy: 0.8421\n",
      "macro_f1: 0.5472\n",
      "Precision: 0.5441\n",
      "Recall: 0.5519\n",
      "F1: 0.5472\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://dzone.com/articles/android-rotate-and-scale\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 51 [1s] 8\n",
      "predicted\n",
      "[0s] 49 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8305\n",
      "macro_f1: 0.6722\n",
      "Precision: 0.6592\n",
      "Recall: 0.6912\n",
      "F1: 0.6722\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24652078\n",
      "--------------------\n",
      "Y\n",
      "[0s] 6 [1s] 5\n",
      "predicted\n",
      "[0s] 9 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.5455\n",
      "macro_f1: 0.4762\n",
      "Precision: 0.5278\n",
      "Recall: 0.5167\n",
      "F1: 0.4762\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/work/dpc/dedicated-devices/lock-task-mode\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 56 [1s] 9\n",
      "predicted\n",
      "[0s] 55 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7385\n",
      "macro_f1: 0.4761\n",
      "Precision: 0.4773\n",
      "Recall: 0.4752\n",
      "F1: 0.4761\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://github.com/realm/realm-java/issues/776\n",
      "--------------------\n",
      "Y\n",
      "[0s] 27 [1s] 6\n",
      "predicted\n",
      "[0s] 23 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6364\n",
      "macro_f1: 0.5050\n",
      "Precision: 0.5130\n",
      "Recall: 0.5185\n",
      "F1: 0.5050\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/8712652\n",
      "--------------------\n",
      "Y\n",
      "[0s] 14 [1s] 3\n",
      "predicted\n",
      "[0s] 10 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.7647\n",
      "macro_f1: 0.7167\n",
      "Precision: 0.7143\n",
      "Recall: 0.8571\n",
      "F1: 0.7167\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/media-apps/volume-and-earphones\n",
      "--------------------\n",
      "Y\n",
      "[0s] 29 [1s] 5\n",
      "predicted\n",
      "[0s] 25 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.7647\n",
      "macro_f1: 0.6402\n",
      "Precision: 0.6267\n",
      "Recall: 0.6966\n",
      "F1: 0.6402\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.580\u001b[0m\n",
      "recall:    \u001b[31m0.615\u001b[0m\n",
      "f1-score:  \u001b[31m0.576\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.552\u001b[0m\n",
      "recall:    \u001b[31m0.586\u001b[0m\n",
      "f1-score:  \u001b[31m0.558\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.621\u001b[0m\n",
      "recall:    \u001b[31m0.687\u001b[0m\n",
      "f1-score:  \u001b[31m0.596\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.529\u001b[0m\n",
      "recall:    \u001b[31m0.535\u001b[0m\n",
      "f1-score:  \u001b[31m0.526\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.659\u001b[0m\n",
      "recall:    \u001b[31m0.691\u001b[0m\n",
      "f1-score:  \u001b[31m0.672\u001b[0m\n",
      "next 5\n",
      "\n",
      "\u001b[31mFold 5\u001b[0m\n",
      "Different actions from contact info depending on whether hitting back key or back arrow in top left\n",
      "Unlimited/Dynamic ViewPager in both directions\n",
      "Java: Efficient ArrayList filtering?\n",
      "shouldn't snackbar DSL helpers take CharSequence?\n",
      "Not receiving notifications when phone is locked and connected through WIFI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7916/7916 [00:00<00:00, 776185.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1577\n",
      "1     788\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    752\n",
      "1    115\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.9208 - sparse_categorical_accuracy: 0.5632The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69975, saving model to /home/msarthur/scratch/best_model\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.9208 - sparse_categorical_accuracy: 0.5632 - val_loss: 0.6997 - val_sparse_categorical_accuracy: 0.5399\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.8614 - sparse_categorical_accuracy: 0.6207\n",
      "Epoch 00002: val_loss improved from 0.69975 to 0.63259, saving model to /home/msarthur/scratch/best_model\n",
      "37/37 [==============================] - 13s 358ms/step - loss: 0.8614 - sparse_categorical_accuracy: 0.6207 - val_loss: 0.6326 - val_sparse_categorical_accuracy: 0.6502\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.7981 - sparse_categorical_accuracy: 0.6820\n",
      "Epoch 00003: val_loss improved from 0.63259 to 0.63013, saving model to /home/msarthur/scratch/best_model\n",
      "37/37 [==============================] - 14s 381ms/step - loss: 0.7981 - sparse_categorical_accuracy: 0.6820 - val_loss: 0.6301 - val_sparse_categorical_accuracy: 0.6616\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.7401 - sparse_categorical_accuracy: 0.7260\n",
      "Epoch 00004: val_loss improved from 0.63013 to 0.60750, saving model to /home/msarthur/scratch/best_model\n",
      "37/37 [==============================] - 13s 352ms/step - loss: 0.7401 - sparse_categorical_accuracy: 0.7260 - val_loss: 0.6075 - val_sparse_categorical_accuracy: 0.6768\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.6588 - sparse_categorical_accuracy: 0.7751\n",
      "Epoch 00005: val_loss improved from 0.60750 to 0.59519, saving model to /home/msarthur/scratch/best_model\n",
      "37/37 [==============================] - 19s 523ms/step - loss: 0.6588 - sparse_categorical_accuracy: 0.7751 - val_loss: 0.5952 - val_sparse_categorical_accuracy: 0.6882\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.5915 - sparse_categorical_accuracy: 0.8055\n",
      "Epoch 00006: val_loss improved from 0.59519 to 0.56983, saving model to /home/msarthur/scratch/best_model\n",
      "37/37 [==============================] - 13s 350ms/step - loss: 0.5915 - sparse_categorical_accuracy: 0.8055 - val_loss: 0.5698 - val_sparse_categorical_accuracy: 0.6806\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4823 - sparse_categorical_accuracy: 0.8562\n",
      "Epoch 00007: val_loss did not improve from 0.56983\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.4823 - sparse_categorical_accuracy: 0.8562 - val_loss: 0.6297 - val_sparse_categorical_accuracy: 0.6806\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4257 - sparse_categorical_accuracy: 0.8727\n",
      "Epoch 00008: val_loss did not improve from 0.56983\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.4257 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.5890 - val_sparse_categorical_accuracy: 0.7186\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3114 - sparse_categorical_accuracy: 0.9197\n",
      "Epoch 00009: val_loss did not improve from 0.56983\n",
      "37/37 [==============================] - 10s 257ms/step - loss: 0.3114 - sparse_categorical_accuracy: 0.9197 - val_loss: 0.6388 - val_sparse_categorical_accuracy: 0.7376\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2553 - sparse_categorical_accuracy: 0.9340Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.56983\n",
      "37/37 [==============================] - 10s 263ms/step - loss: 0.2553 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.7368 - val_sparse_categorical_accuracy: 0.7186\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/guide/topics/ui/notifiers/notifications\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 139 [1s] 7\n",
      "predicted\n",
      "[0s] 125 [1s] 21\n",
      "--------------------\n",
      "Accuracy: 0.8356\n",
      "macro_f1: 0.5260\n",
      "Precision: 0.5276\n",
      "Recall: 0.5745\n",
      "F1: 0.5260\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html\n",
      "--------------------\n",
      "Y\n",
      "[0s] 57 [1s] 7\n",
      "predicted\n",
      "[0s] 54 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7969\n",
      "macro_f1: 0.5591\n",
      "Precision: 0.5537\n",
      "Recall: 0.5727\n",
      "F1: 0.5591\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/324-viewpager-tutorial-getting-started-in-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 135 [1s] 42\n",
      "predicted\n",
      "[0s] 151 [1s] 26\n",
      "--------------------\n",
      "Accuracy: 0.7740\n",
      "macro_f1: 0.6360\n",
      "Precision: 0.6765\n",
      "Recall: 0.6222\n",
      "F1: 0.6360\n",
      "\u001b[31m14\u001b[0m entries logged\n",
      "https://www.hongkiat.com/blog/solve-android-delayed-notifications\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 65 [1s] 12\n",
      "predicted\n",
      "[0s] 66 [1s] 11\n",
      "--------------------\n",
      "Accuracy: 0.7792\n",
      "macro_f1: 0.5655\n",
      "Precision: 0.5682\n",
      "Recall: 0.5635\n",
      "F1: 0.5655\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/122105\n",
      "--------------------\n",
      "Y\n",
      "[0s] 127 [1s] 4\n",
      "predicted\n",
      "[0s] 112 [1s] 19\n",
      "--------------------\n",
      "Accuracy: 0.8550\n",
      "macro_f1: 0.5472\n",
      "Precision: 0.5437\n",
      "Recall: 0.6831\n",
      "F1: 0.5472\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/10108774\n",
      "--------------------\n",
      "Y\n",
      "[0s] 49 [1s] 6\n",
      "predicted\n",
      "[0s] 45 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7818\n",
      "macro_f1: 0.5612\n",
      "Precision: 0.5556\n",
      "Recall: 0.5850\n",
      "F1: 0.5612\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/reference/com/google/android/material/snackbar/Snackbar\n",
      "--------------------\n",
      "Y\n",
      "[0s] 34 [1s] 4\n",
      "predicted\n",
      "[0s] 28 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6842\n",
      "macro_f1: 0.4747\n",
      "Precision: 0.4964\n",
      "Recall: 0.4926\n",
      "F1: 0.4747\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/24313539\n",
      "--------------------\n",
      "Y\n",
      "[0s] 50 [1s] 5\n",
      "predicted\n",
      "[0s] 45 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8000\n",
      "macro_f1: 0.5754\n",
      "Precision: 0.5667\n",
      "Recall: 0.6200\n",
      "F1: 0.5754\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/36275986\n",
      "--------------------\n",
      "Y\n",
      "[0s] 19 [1s] 5\n",
      "predicted\n",
      "[0s] 14 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7083\n",
      "macro_f1: 0.6606\n",
      "Precision: 0.6643\n",
      "Recall: 0.7421\n",
      "F1: 0.6606\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://dzone.com/articles/iteration-over-java-collections-with-high-performa\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 45 [1s] 3\n",
      "predicted\n",
      "[0s] 38 [1s] 10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7708\n",
      "macro_f1: 0.5107\n",
      "Precision: 0.5237\n",
      "Recall: 0.5667\n",
      "F1: 0.5107\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/guide/navigation/navigation-swipe-view-2\n",
      "--------------------\n",
      "Y\n",
      "[0s] 16 [1s] 3\n",
      "predicted\n",
      "[0s] 10 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.5789\n",
      "macro_f1: 0.5128\n",
      "Precision: 0.5611\n",
      "Recall: 0.6146\n",
      "F1: 0.5128\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/guide/navigation/navigation-custom-back\n",
      "--------------------\n",
      "Y\n",
      "[0s] 16 [1s] 17\n",
      "predicted\n",
      "[0s] 23 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5455\n",
      "macro_f1: 0.5299\n",
      "Precision: 0.5609\n",
      "Recall: 0.5515\n",
      "F1: 0.5299\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.567\u001b[0m\n",
      "recall:    \u001b[31m0.599\u001b[0m\n",
      "f1-score:  \u001b[31m0.555\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.540\u001b[0m\n",
      "recall:    \u001b[31m0.561\u001b[0m\n",
      "f1-score:  \u001b[31m0.520\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.583\u001b[0m\n",
      "recall:    \u001b[31m0.658\u001b[0m\n",
      "f1-score:  \u001b[31m0.586\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.589\u001b[0m\n",
      "recall:    \u001b[31m0.584\u001b[0m\n",
      "f1-score:  \u001b[31m0.571\u001b[0m\n",
      "next 6\n",
      "\n",
      "\u001b[31mFold 6\u001b[0m\n",
      "Generating an error when using Provider for scoped instances\n",
      "Why settings.xml layout is overlapping the ActionBar/Toolbar?\n",
      "Explanation of the getView() method of an ArrayAdapter\n",
      "Dagger 2 doesn't implement some of the component methods in Android project with custom annotation processor\n",
      "Android - Jackson JSON parser returns null value in &#39;release&#39; builds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7916/7916 [00:00<00:00, 773455.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1492\n",
      "1     746\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    1119\n",
      "1     162\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9297 - sparse_categorical_accuracy: 0.5451The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70491, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.9297 - sparse_categorical_accuracy: 0.5451 - val_loss: 0.7049 - val_sparse_categorical_accuracy: 0.4739\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.8679 - sparse_categorical_accuracy: 0.5818\n",
      "Epoch 00002: val_loss improved from 0.70491 to 0.62071, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 13s 358ms/step - loss: 0.8679 - sparse_categorical_accuracy: 0.5818 - val_loss: 0.6207 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7944 - sparse_categorical_accuracy: 0.6801\n",
      "Epoch 00003: val_loss did not improve from 0.62071\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.7944 - sparse_categorical_accuracy: 0.6801 - val_loss: 0.6257 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.7356 - sparse_categorical_accuracy: 0.7234\n",
      "Epoch 00004: val_loss improved from 0.62071 to 0.59006, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 25s 710ms/step - loss: 0.7356 - sparse_categorical_accuracy: 0.7234 - val_loss: 0.5901 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6645 - sparse_categorical_accuracy: 0.7632\n",
      "Epoch 00005: val_loss did not improve from 0.59006\n",
      "35/35 [==============================] - 9s 256ms/step - loss: 0.6645 - sparse_categorical_accuracy: 0.7632 - val_loss: 0.5970 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.5815 - sparse_categorical_accuracy: 0.7976\n",
      "Epoch 00006: val_loss improved from 0.59006 to 0.56821, saving model to /home/msarthur/scratch/best_model\n",
      "35/35 [==============================] - 21s 594ms/step - loss: 0.5815 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.5682 - val_sparse_categorical_accuracy: 0.7390\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4880 - sparse_categorical_accuracy: 0.8369\n",
      "Epoch 00007: val_loss did not improve from 0.56821\n",
      "35/35 [==============================] - 9s 256ms/step - loss: 0.4880 - sparse_categorical_accuracy: 0.8369 - val_loss: 0.7071 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.3999 - sparse_categorical_accuracy: 0.8713\n",
      "Epoch 00008: val_loss did not improve from 0.56821\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.3999 - sparse_categorical_accuracy: 0.8713 - val_loss: 0.6027 - val_sparse_categorical_accuracy: 0.7269\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.2966 - sparse_categorical_accuracy: 0.9191\n",
      "Epoch 00009: val_loss did not improve from 0.56821\n",
      "35/35 [==============================] - 9s 257ms/step - loss: 0.2966 - sparse_categorical_accuracy: 0.9191 - val_loss: 0.6843 - val_sparse_categorical_accuracy: 0.7510\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.2237 - sparse_categorical_accuracy: 0.9410Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.56821\n",
      "35/35 [==============================] - 9s 262ms/step - loss: 0.2237 - sparse_categorical_accuracy: 0.9410 - val_loss: 0.7446 - val_sparse_categorical_accuracy: 0.7550\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://guides.codepath.com/android/Using-an-ArrayAdapter-with-ListView\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 38 [1s] 21\n",
      "predicted\n",
      "[0s] 49 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6102\n",
      "macro_f1: 0.4968\n",
      "Precision: 0.5265\n",
      "Recall: 0.5163\n",
      "F1: 0.4968\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://guides.codepath.com/android/dependency-injection-with-dagger-2\n",
      "--------------------\n",
      "Y\n",
      "[0s] 97 [1s] 24\n",
      "predicted\n",
      "[0s] 103 [1s] 18\n",
      "--------------------\n",
      "Accuracy: 0.7521\n",
      "macro_f1: 0.5679\n",
      "Precision: 0.5793\n",
      "Recall: 0.5631\n",
      "F1: 0.5679\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/57235136\n",
      "--------------------\n",
      "Y\n",
      "[0s] 38 [1s] 6\n",
      "predicted\n",
      "[0s] 34 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7273\n",
      "macro_f1: 0.5417\n",
      "Precision: 0.5412\n",
      "Recall: 0.5614\n",
      "F1: 0.5417\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/11064244\n",
      "--------------------\n",
      "Y\n",
      "[0s] 42 [1s] 9\n",
      "predicted\n",
      "[0s] 41 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7451\n",
      "macro_f1: 0.5796\n",
      "Precision: 0.5768\n",
      "Recall: 0.5833\n",
      "F1: 0.5796\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://www.raywenderlich.com/155-android-listview-tutorial-with-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 189 [1s] 22\n",
      "predicted\n",
      "[0s] 180 [1s] 31\n",
      "--------------------\n",
      "Accuracy: 0.8152\n",
      "macro_f1: 0.5792\n",
      "Precision: 0.5712\n",
      "Recall: 0.5956\n",
      "F1: 0.5792\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://github.com/quarkusio/quarkus/issues/3954\n",
      "--------------------\n",
      "Y\n",
      "[0s] 131 [1s] 7\n",
      "predicted\n",
      "[0s] 118 [1s] 20\n",
      "--------------------\n",
      "Accuracy: 0.8478\n",
      "macro_f1: 0.5689\n",
      "Precision: 0.5581\n",
      "Recall: 0.6494\n",
      "F1: 0.5689\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://www.i-programmer.info/programming/android/8521-android-adventures-menus-a-the-action-bar.html?start=1\n",
      "--------------------\n",
      "Y\n",
      "[0s] 49 [1s] 5\n",
      "predicted\n",
      "[0s] 47 [1s] 7\n",
      "--------------------\n",
      "Accuracy: 0.8519\n",
      "macro_f1: 0.6250\n",
      "Precision: 0.6109\n",
      "Recall: 0.6490\n",
      "F1: 0.6250\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/widget/ArrayAdapter\n",
      "--------------------\n",
      "Y\n",
      "[0s] 42 [1s] 5\n",
      "predicted\n",
      "[0s] 37 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8085\n",
      "macro_f1: 0.6430\n",
      "Precision: 0.6230\n",
      "Recall: 0.7167\n",
      "F1: 0.6430\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://github.com/nostra13/Android-Universal-Image-Loader/issues/462\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 19 [1s] 3\n",
      "predicted\n",
      "[0s] 12 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5909\n",
      "macro_f1: 0.5087\n",
      "Precision: 0.5583\n",
      "Recall: 0.6228\n",
      "F1: 0.5087\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/training/dependency-injection/dagger-android\n",
      "--------------------\n",
      "Y\n",
      "[0s] 176 [1s] 20\n",
      "predicted\n",
      "[0s] 167 [1s] 29\n",
      "--------------------\n",
      "Accuracy: 0.8112\n",
      "macro_f1: 0.5685\n",
      "Precision: 0.5615\n",
      "Recall: 0.5847\n",
      "F1: 0.5685\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/providers/content-provider-creating\n",
      "--------------------\n",
      "Y\n",
      "[0s] 242 [1s] 7\n",
      "predicted\n",
      "[0s] 212 [1s] 37\n",
      "--------------------\n",
      "Accuracy: 0.8313\n",
      "macro_f1: 0.4765\n",
      "Precision: 0.4994\n",
      "Recall: 0.4970\n",
      "F1: 0.4765\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/29923376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Y\n",
      "[0s] 16 [1s] 16\n",
      "predicted\n",
      "[0s] 22 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5625\n",
      "macro_f1: 0.5466\n",
      "Precision: 0.5727\n",
      "Recall: 0.5625\n",
      "F1: 0.5466\n",
      "\u001b[31m6\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/29738510\n",
      "--------------------\n",
      "Y\n",
      "[0s] 19 [1s] 4\n",
      "predicted\n",
      "[0s] 21 [1s] 2\n",
      "--------------------\n",
      "Accuracy: 0.8261\n",
      "macro_f1: 0.6167\n",
      "Precision: 0.6786\n",
      "Recall: 0.5987\n",
      "F1: 0.6167\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/6442054\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 12 [1s] 9\n",
      "predicted\n",
      "[0s] 11 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5714\n",
      "macro_f1: 0.5675\n",
      "Precision: 0.5682\n",
      "Recall: 0.5694\n",
      "F1: 0.5675\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://github.com/google/dagger/issues/671\n",
      "--------------------\n",
      "Y\n",
      "[0s] 9 [1s] 4\n",
      "predicted\n",
      "[0s] 3 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5385\n",
      "macro_f1: 0.5357\n",
      "Precision: 0.7000\n",
      "Recall: 0.6667\n",
      "F1: 0.5357\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.582\u001b[0m\n",
      "recall:    \u001b[31m0.596\u001b[0m\n",
      "f1-score:  \u001b[31m0.561\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.561\u001b[0m\n",
      "recall:    \u001b[31m0.599\u001b[0m\n",
      "f1-score:  \u001b[31m0.563\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.587\u001b[0m\n",
      "recall:    \u001b[31m0.575\u001b[0m\n",
      "f1-score:  \u001b[31m0.570\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.605\u001b[0m\n",
      "recall:    \u001b[31m0.646\u001b[0m\n",
      "f1-score:  \u001b[31m0.538\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.572\u001b[0m\n",
      "recall:    \u001b[31m0.581\u001b[0m\n",
      "f1-score:  \u001b[31m0.567\u001b[0m\n",
      "next 7\n",
      "\n",
      "\u001b[31mFold 7\u001b[0m\n",
      "Doesn't scroll properly inside ViewPager\n",
      "The gravity is not working on the TextView in some situation.\n",
      "Support for GoogleApiClient and new FusedLocationProviderApi\n",
      "How to record phone calls in Android\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7916/7916 [00:00<00:00, 859690.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1634\n",
      "1     817\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    815\n",
      "1     83\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9195 - sparse_categorical_accuracy: 0.5508The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65287, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 18s 459ms/step - loss: 0.9195 - sparse_categorical_accuracy: 0.5508 - val_loss: 0.6529 - val_sparse_categorical_accuracy: 0.6154\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8472 - sparse_categorical_accuracy: 0.6446\n",
      "Epoch 00002: val_loss improved from 0.65287 to 0.57749, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 14s 355ms/step - loss: 0.8472 - sparse_categorical_accuracy: 0.6446 - val_loss: 0.5775 - val_sparse_categorical_accuracy: 0.7070\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7841 - sparse_categorical_accuracy: 0.7075\n",
      "Epoch 00003: val_loss improved from 0.57749 to 0.55296, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 0.7841 - sparse_categorical_accuracy: 0.7075 - val_loss: 0.5530 - val_sparse_categorical_accuracy: 0.7253\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7089 - sparse_categorical_accuracy: 0.7519\n",
      "Epoch 00004: val_loss improved from 0.55296 to 0.53328, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 0.7089 - sparse_categorical_accuracy: 0.7519 - val_loss: 0.5333 - val_sparse_categorical_accuracy: 0.7473\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6410 - sparse_categorical_accuracy: 0.7878\n",
      "Epoch 00005: val_loss improved from 0.53328 to 0.52943, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 334ms/step - loss: 0.6410 - sparse_categorical_accuracy: 0.7878 - val_loss: 0.5294 - val_sparse_categorical_accuracy: 0.7399\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5659 - sparse_categorical_accuracy: 0.8242\n",
      "Epoch 00006: val_loss improved from 0.52943 to 0.51907, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 340ms/step - loss: 0.5659 - sparse_categorical_accuracy: 0.8242 - val_loss: 0.5191 - val_sparse_categorical_accuracy: 0.7729\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5006 - sparse_categorical_accuracy: 0.8523\n",
      "Epoch 00007: val_loss did not improve from 0.51907\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.5006 - sparse_categorical_accuracy: 0.8523 - val_loss: 0.5620 - val_sparse_categorical_accuracy: 0.7509\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4428 - sparse_categorical_accuracy: 0.8821\n",
      "Epoch 00008: val_loss did not improve from 0.51907\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 0.4428 - sparse_categorical_accuracy: 0.8821 - val_loss: 0.5242 - val_sparse_categorical_accuracy: 0.7875\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4052 - sparse_categorical_accuracy: 0.8915\n",
      "Epoch 00009: val_loss improved from 0.51907 to 0.50154, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 17s 440ms/step - loss: 0.4052 - sparse_categorical_accuracy: 0.8915 - val_loss: 0.5015 - val_sparse_categorical_accuracy: 0.8022\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.3500 - sparse_categorical_accuracy: 0.9094\n",
      "Epoch 00010: val_loss did not improve from 0.50154\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.3500 - sparse_categorical_accuracy: 0.9094 - val_loss: 0.5327 - val_sparse_categorical_accuracy: 0.7912\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://stackoverflow.com/questions/46481789\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 30 [1s] 5\n",
      "predicted\n",
      "[0s] 26 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.6571\n",
      "macro_f1: 0.4643\n",
      "Precision: 0.4786\n",
      "Recall: 0.4667\n",
      "F1: 0.4643\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://www.toptal.com/android/android-developers-guide-to-google-location-services-api\n",
      "--------------------\n",
      "Y\n",
      "[0s] 97 [1s] 22\n",
      "predicted\n",
      "[0s] 102 [1s] 17\n",
      "--------------------\n",
      "Accuracy: 0.7563\n",
      "macro_f1: 0.5553\n",
      "Precision: 0.5637\n",
      "Recall: 0.5518\n",
      "F1: 0.5553\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://developer.android.com/reference/android/widget/TextView\n",
      "--------------------\n",
      "Y\n",
      "[0s] 465 [1s] 5\n",
      "predicted\n",
      "[0s] 400 [1s] 70\n",
      "--------------------\n",
      "Accuracy: 0.8447\n",
      "macro_f1: 0.4711\n",
      "Precision: 0.5021\n",
      "Recall: 0.5258\n",
      "F1: 0.4711\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/training/gestures/scroll\n",
      "--------------------\n",
      "Y\n",
      "[0s] 50 [1s] 4\n",
      "predicted\n",
      "[0s] 44 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7407\n",
      "macro_f1: 0.4255\n",
      "Precision: 0.4545\n",
      "Recall: 0.4000\n",
      "F1: 0.4255\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/guide/topics/media/mediarecorder\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 41 [1s] 8\n",
      "predicted\n",
      "[0s] 39 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.8367\n",
      "macro_f1: 0.7278\n",
      "Precision: 0.7115\n",
      "Recall: 0.7515\n",
      "F1: 0.7278\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://javapapers.com/android/android-location-fused-provider\n",
      "--------------------\n",
      "Y\n",
      "[0s] 84 [1s] 15\n",
      "predicted\n",
      "[0s] 85 [1s] 14\n",
      "--------------------\n",
      "Accuracy: 0.8081\n",
      "macro_f1: 0.6162\n",
      "Precision: 0.6197\n",
      "Recall: 0.6131\n",
      "F1: 0.6162\n",
      "\u001b[31m5\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/19025301\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 4 [1s] 7\n",
      "predicted\n",
      "[0s] 2 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.8182\n",
      "macro_f1: 0.7708\n",
      "Precision: 0.8889\n",
      "Recall: 0.7500\n",
      "F1: 0.7708\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://developer.android.com/training/location/retrieve-current\n",
      "--------------------\n",
      "Y\n",
      "[0s] 27 [1s] 9\n",
      "predicted\n",
      "[0s] 26 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5833\n",
      "macro_f1: 0.4638\n",
      "Precision: 0.4654\n",
      "Recall: 0.4630\n",
      "F1: 0.4638\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/39588322\n",
      "--------------------\n",
      "Y\n",
      "[0s] 12 [1s] 4\n",
      "predicted\n",
      "[0s] 13 [1s] 3\n",
      "--------------------\n",
      "Accuracy: 0.6875\n",
      "macro_f1: 0.5429\n",
      "Precision: 0.5513\n",
      "Recall: 0.5417\n",
      "F1: 0.5429\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/6688444\n",
      "--------------------\n",
      "Y\n",
      "[0s] 5 [1s] 4\n",
      "predicted\n",
      "[0s] 0 [1s] 9\n",
      "--------------------\n",
      "Accuracy: 0.4444\n",
      "macro_f1: 0.3077\n",
      "Precision: 0.2222\n",
      "Recall: 0.5000\n",
      "F1: 0.3077\n",
      "\u001b[31m4\u001b[0m entries logged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.546\u001b[0m\n",
      "recall:    \u001b[31m0.556\u001b[0m\n",
      "f1-score:  \u001b[31m0.535\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.533\u001b[0m\n",
      "recall:    \u001b[31m0.535\u001b[0m\n",
      "f1-score:  \u001b[31m0.522\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.535\u001b[0m\n",
      "recall:    \u001b[31m0.565\u001b[0m\n",
      "f1-score:  \u001b[31m0.521\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31mnan\u001b[0m\n",
      "recall:    \u001b[31mnan\u001b[0m\n",
      "f1-score:  \u001b[31mnan\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.592\u001b[0m\n",
      "recall:    \u001b[31m0.582\u001b[0m\n",
      "f1-score:  \u001b[31m0.586\u001b[0m\n",
      "next 8\n",
      "\n",
      "\u001b[31mFold 8\u001b[0m\n",
      "SeekTo Position of cutted song not working\n",
      "Android Gallery with pinch zoom\n",
      "Wait for 2 async REST calls to result in success or error\n",
      "how  to set Screenshot frame size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msarthur/hface/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/msarthur/hface/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7916/7916 [00:00<00:00, 818108.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1685\n",
      "1     842\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    333\n",
      "1     55\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{1: 2.0, 0: 1.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.8875 - sparse_categorical_accuracy: 0.6197The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62975, saving model to /home/msarthur/scratch/best_model\n",
      "40/40 [==============================] - 19s 471ms/step - loss: 0.8875 - sparse_categorical_accuracy: 0.6197 - val_loss: 0.6297 - val_sparse_categorical_accuracy: 0.6441\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.8076 - sparse_categorical_accuracy: 0.6628\n",
      "Epoch 00002: val_loss improved from 0.62975 to 0.58528, saving model to /home/msarthur/scratch/best_model\n",
      "40/40 [==============================] - 16s 392ms/step - loss: 0.8076 - sparse_categorical_accuracy: 0.6628 - val_loss: 0.5853 - val_sparse_categorical_accuracy: 0.6904\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7151 - sparse_categorical_accuracy: 0.7198\n",
      "Epoch 00003: val_loss improved from 0.58528 to 0.56272, saving model to /home/msarthur/scratch/best_model\n",
      "40/40 [==============================] - 14s 348ms/step - loss: 0.7151 - sparse_categorical_accuracy: 0.7198 - val_loss: 0.5627 - val_sparse_categorical_accuracy: 0.7224\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6303 - sparse_categorical_accuracy: 0.7689\n",
      "Epoch 00004: val_loss did not improve from 0.56272\n",
      "40/40 [==============================] - 10s 260ms/step - loss: 0.6303 - sparse_categorical_accuracy: 0.7689 - val_loss: 0.6004 - val_sparse_categorical_accuracy: 0.6904\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5381 - sparse_categorical_accuracy: 0.8108\n",
      "Epoch 00005: val_loss did not improve from 0.56272\n",
      "40/40 [==============================] - 11s 263ms/step - loss: 0.5381 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.5990 - val_sparse_categorical_accuracy: 0.7295\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4488 - sparse_categorical_accuracy: 0.8536\n",
      "Epoch 00006: val_loss did not improve from 0.56272\n",
      "40/40 [==============================] - 10s 257ms/step - loss: 0.4488 - sparse_categorical_accuracy: 0.8536 - val_loss: 0.7080 - val_sparse_categorical_accuracy: 0.6868\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3783 - sparse_categorical_accuracy: 0.8773Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.56272\n",
      "40/40 [==============================] - 10s 262ms/step - loss: 0.3783 - sparse_categorical_accuracy: 0.8773 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.7295\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://developer.android.com/guide/background/threading\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 66 [1s] 15\n",
      "predicted\n",
      "[0s] 69 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.7654\n",
      "macro_f1: 0.5778\n",
      "Precision: 0.5870\n",
      "Recall: 0.5727\n",
      "F1: 0.5778\n",
      "\u001b[31m4\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2993085\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 47 [1s] 6\n",
      "predicted\n",
      "[0s] 43 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7736\n",
      "macro_f1: 0.5583\n",
      "Precision: 0.5535\n",
      "Recall: 0.5816\n",
      "F1: 0.5583\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/2661536\n",
      "--------------------\n",
      "Y\n",
      "[0s] 96 [1s] 4\n",
      "predicted\n",
      "[0s] 85 [1s] 15\n",
      "--------------------\n",
      "Accuracy: 0.8500\n",
      "macro_f1: 0.5638\n",
      "Precision: 0.5549\n",
      "Recall: 0.6823\n",
      "F1: 0.5638\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://developer.android.com/training/gestures/scale\n",
      "--------------------\n",
      "Y\n",
      "[0s] 36 [1s] 4\n",
      "predicted\n",
      "[0s] 30 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7500\n",
      "macro_f1: 0.5671\n",
      "Precision: 0.5667\n",
      "Recall: 0.6389\n",
      "F1: 0.5671\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://www.twilio.com/blog/asynchronous-api-requests-java-completablefutures\n",
      "--------------------\n",
      "Y\n",
      "[0s] 39 [1s] 11\n",
      "predicted\n",
      "[0s] 40 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6200\n",
      "macro_f1: 0.4274\n",
      "Precision: 0.4250\n",
      "Recall: 0.4301\n",
      "F1: 0.4274\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/10630373\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 26 [1s] 6\n",
      "predicted\n",
      "[0s] 22 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6875\n",
      "macro_f1: 0.5833\n",
      "Precision: 0.5818\n",
      "Recall: 0.6154\n",
      "F1: 0.5833\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://github.com/google/ExoPlayer/issues/8387\n",
      "--------------------\n",
      "Y\n",
      "[0s] 23 [1s] 9\n",
      "predicted\n",
      "[0s] 22 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.5938\n",
      "macro_f1: 0.5135\n",
      "Precision: 0.5136\n",
      "Recall: 0.5145\n",
      "F1: 0.5135\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.540\u001b[0m\n",
      "recall:    \u001b[31m0.576\u001b[0m\n",
      "f1-score:  \u001b[31m0.542\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.577\u001b[0m\n",
      "recall:    \u001b[31m0.606\u001b[0m\n",
      "f1-score:  \u001b[31m0.572\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.563\u001b[0m\n",
      "recall:    \u001b[31m0.626\u001b[0m\n",
      "f1-score:  \u001b[31m0.568\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.514\u001b[0m\n",
      "recall:    \u001b[31m0.514\u001b[0m\n",
      "f1-score:  \u001b[31m0.513\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.425\u001b[0m\n",
      "recall:    \u001b[31m0.430\u001b[0m\n",
      "f1-score:  \u001b[31m0.427\u001b[0m\n",
      "next 9\n",
      "\n",
      "\u001b[31mFold 9\u001b[0m\n",
      "Android SQLite performance in complex queries\n",
      "Custom Annotations in Retrofit 2.0\n",
      "Android App Retrieve Data from Server but in a Secure way\n",
      "Hilt: How to prevent Hilt from picking dependency from a library?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7916/7916 [00:00<00:00, 788648.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\u001b[31mtrain\u001b[0m\n",
      "0    1631\n",
      "1     815\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mtest\u001b[0m\n",
      "0    493\n",
      "1     85\n",
      "Name: category_index, dtype: int64\n",
      "\n",
      "\u001b[31mweights\u001b[0m\n",
      "{0: 1.0, 1: 2.0}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.9153 - sparse_categorical_accuracy: 0.5822The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67497, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 17s 426ms/step - loss: 0.9153 - sparse_categorical_accuracy: 0.5822 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.5735\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7849 - sparse_categorical_accuracy: 0.6807\n",
      "Epoch 00002: val_loss improved from 0.67497 to 0.62412, saving model to /home/msarthur/scratch/best_model\n",
      "39/39 [==============================] - 13s 341ms/step - loss: 0.7849 - sparse_categorical_accuracy: 0.6807 - val_loss: 0.6241 - val_sparse_categorical_accuracy: 0.6618\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7113 - sparse_categorical_accuracy: 0.7355\n",
      "Epoch 00003: val_loss did not improve from 0.62412\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.7113 - sparse_categorical_accuracy: 0.7355 - val_loss: 0.6416 - val_sparse_categorical_accuracy: 0.6691\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.6117 - sparse_categorical_accuracy: 0.7866\n",
      "Epoch 00004: val_loss did not improve from 0.62412\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 0.6117 - sparse_categorical_accuracy: 0.7866 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.6544\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.5505 - sparse_categorical_accuracy: 0.8115\n",
      "Epoch 00005: val_loss did not improve from 0.62412\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 0.5505 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.6490 - val_sparse_categorical_accuracy: 0.7059\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4588 - sparse_categorical_accuracy: 0.8508Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.62412\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 0.4588 - sparse_categorical_accuracy: 0.8508 - val_loss: 0.6852 - val_sparse_categorical_accuracy: 0.6949\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "\u001b[31mTesting model\u001b[0m\n",
      "https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 47 [1s] 3\n",
      "predicted\n",
      "[0s] 40 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7400\n",
      "macro_f1: 0.4253\n",
      "Precision: 0.4625\n",
      "Recall: 0.3936\n",
      "F1: 0.4253\n",
      "\u001b[31m0\u001b[0m entries logged\n",
      "https://developer.android.com/training/dependency-injection/hilt-android\n",
      "--------------------\n",
      "Y\n",
      "[0s] 125 [1s] 20\n",
      "predicted\n",
      "[0s] 124 [1s] 21\n",
      "--------------------\n",
      "Accuracy: 0.8138\n",
      "macro_f1: 0.6165\n",
      "Precision: 0.6142\n",
      "Recall: 0.6190\n",
      "F1: 0.6165\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://github.com/google/dagger/issues/1991\n",
      "--------------------\n",
      "Y\n",
      "[0s] 77 [1s] 4\n",
      "predicted\n",
      "[0s] 69 [1s] 12\n",
      "--------------------\n",
      "Accuracy: 0.8272\n",
      "macro_f1: 0.5146\n",
      "Precision: 0.5199\n",
      "Recall: 0.5536\n",
      "F1: 0.5146\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://developer.android.com/training/data-storage/sqlite\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 56 [1s] 13\n",
      "predicted\n",
      "[0s] 59 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6957\n",
      "macro_f1: 0.4522\n",
      "Precision: 0.4483\n",
      "Recall: 0.4581\n",
      "F1: 0.4522\n",
      "\u001b[31m1\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/8184492\n",
      "--------------------\n",
      "Y\n",
      "[0s] 46 [1s] 7\n",
      "predicted\n",
      "[0s] 43 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7547\n",
      "macro_f1: 0.5446\n",
      "Precision: 0.5419\n",
      "Recall: 0.5559\n",
      "F1: 0.5446\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/47760861\n",
      "--------------------\n",
      "Y\n",
      "[0s] 28 [1s] 3\n",
      "predicted\n",
      "[0s] 21 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7742\n",
      "macro_f1: 0.6593\n",
      "Precision: 0.6500\n",
      "Recall: 0.8750\n",
      "F1: 0.6593\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "--------------------\n",
      "Y\n",
      "[0s] 39 [1s] 9\n",
      "predicted\n",
      "[0s] 38 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6875\n",
      "macro_f1: 0.5079\n",
      "Precision: 0.5079\n",
      "Recall: 0.5085\n",
      "F1: 0.5079\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/4015026\n",
      "--------------------\n",
      "Y\n",
      "[0s] 20 [1s] 15\n",
      "predicted\n",
      "[0s] 25 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.6857\n",
      "macro_f1: 0.6578\n",
      "Precision: 0.6900\n",
      "Recall: 0.6583\n",
      "F1: 0.6578\n",
      "\u001b[31m7\u001b[0m entries logged\n",
      "https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "--------------------\n",
      "Y\n",
      "[0s] 51 [1s] 7\n",
      "predicted\n",
      "[0s] 48 [1s] 10\n",
      "--------------------\n",
      "Accuracy: 0.7759\n",
      "macro_f1: 0.5520\n",
      "Precision: 0.5479\n",
      "Recall: 0.5644\n",
      "F1: 0.5520\n",
      "\u001b[31m2\u001b[0m entries logged\n",
      "https://stackoverflow.com/questions/30648172\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "--------------------\n",
      "Y\n",
      "[0s] 4 [1s] 4\n",
      "predicted\n",
      "[0s] 3 [1s] 5\n",
      "--------------------\n",
      "Accuracy: 0.6250\n",
      "macro_f1: 0.6190\n",
      "Precision: 0.6333\n",
      "Recall: 0.6250\n",
      "F1: 0.6190\n",
      "\u001b[31m3\u001b[0m entries logged\n",
      "\n",
      "\u001b[33mModel metrics\u001b[0m\n",
      "precision: \u001b[31m0.562\u001b[0m\n",
      "recall:    \u001b[31m0.581\u001b[0m\n",
      "f1-score:  \u001b[31m0.555\u001b[0m\n",
      "\n",
      "\u001b[33mapi_metrics\u001b[0m\n",
      "precision: \u001b[31m0.531\u001b[0m\n",
      "recall:    \u001b[31m0.539\u001b[0m\n",
      "f1-score:  \u001b[31m0.534\u001b[0m\n",
      "\n",
      "\u001b[33mso_metrics\u001b[0m\n",
      "precision: \u001b[31m0.629\u001b[0m\n",
      "recall:    \u001b[31m0.679\u001b[0m\n",
      "f1-score:  \u001b[31m0.620\u001b[0m\n",
      "\n",
      "\u001b[33mgit_metrics\u001b[0m\n",
      "precision: \u001b[31m0.520\u001b[0m\n",
      "recall:    \u001b[31m0.554\u001b[0m\n",
      "f1-score:  \u001b[31m0.515\u001b[0m\n",
      "\n",
      "\u001b[33mmisc_metrics\u001b[0m\n",
      "precision: \u001b[31m0.506\u001b[0m\n",
      "recall:    \u001b[31m0.489\u001b[0m\n",
      "f1-score:  \u001b[31m0.495\u001b[0m\n",
      "next 10\n"
     ]
    }
   ],
   "source": [
    "# @title 10-fold cross validation WIP\n",
    "CORPUS = raw_data\n",
    "\n",
    "all_tasks = sorted(list(set([d['question'] for d in raw_data])))\n",
    "rseed = 20210343\n",
    "random.seed(rseed)\n",
    "random.shuffle(all_tasks)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "file_handler = logging.FileHandler('/home/msarthur/scratch/LOG-bert_ds_android.ans')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, random_state=rseed)\n",
    "np_tasks_arr = np.array(all_tasks)\n",
    "\n",
    "\n",
    "\n",
    "idx_split = 0\n",
    "for train_index, test_index in kf.split(np_tasks_arr):\n",
    "\n",
    "    idx_split = str(idx_split)\n",
    "    eval_fold = True\n",
    "    # 10 runs per fold to avoid reporting peek results in a given fold\n",
    "    if idx_split in fold_results and fold_results[idx_split]['run_cnt'] >= 10:\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split} FULLY TESTED\" + Style.RESET_ALL)\n",
    "        eval_fold = False\n",
    "\n",
    "\n",
    "    if eval_fold:\n",
    "        # <------------------------------------------------------------------------- EVAL VARIABLES\n",
    "        recommendation_metrics = defaultdict(list)\n",
    "        prediction_metrics = defaultdict(list)\n",
    "        api_metrics = defaultdict(list)\n",
    "        so_metrics = defaultdict(list)\n",
    "        git_metrics = defaultdict(list)\n",
    "        misc_metrics = defaultdict(list)\n",
    "        random_prediction_metrics = defaultdict(list)\n",
    "        clz_report_lst = defaultdict(list)\n",
    "\n",
    "        classification_report_lst = []\n",
    "        log_examples_lst = []\n",
    "        source_lst = []\n",
    "        venn_diagram_set = []\n",
    "        # <------------------------------------------------------------------------- EVAL VARIABLES\n",
    "\n",
    "\n",
    "        test_tasks_lst = np_tasks_arr[test_index].tolist()\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Fold {idx_split}\" + Style.RESET_ALL)\n",
    "        logger.info('\\n'.join(test_tasks_lst))\n",
    "\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "        df_train, df_val, df_test, weights = get_train_val_test(\n",
    "            test_tasks_lst,\n",
    "            aug=USE_DS_SYNTHETIC,\n",
    "            undersample=UNDERSAMPLING, \n",
    "            undersample_n=N_UNDERSAMPLING\n",
    "        )\n",
    "        # <------------------------------------------------------------------------- INPUT\n",
    "\n",
    "        logger.info('-' * 10)\n",
    "        logger.info(Fore.RED + 'train'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_train.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'test'+ Style.RESET_ALL)\n",
    "        logger.info(str(df_test.category_index.value_counts()))\n",
    "        logger.info(\"\")\n",
    "\n",
    "        logger.info(Fore.RED + 'weights'+ Style.RESET_ALL)\n",
    "        logger.info(str(weights))\n",
    "        logger.info('-' * 10)\n",
    "\n",
    "\n",
    "        # Encode X_train\n",
    "        train_encodings = _encode(tokenizer, df_train)\n",
    "        train_labels = df_train['category_index'].tolist()\n",
    "\n",
    "        # Encode X_valid\n",
    "        val_encodings = _encode(tokenizer, df_val)\n",
    "        val_labels = df_val['category_index'].tolist()\n",
    "\n",
    "\n",
    "        # https://huggingface.co/transformers/custom_datasets.html\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(train_encodings),\n",
    "            train_labels\n",
    "        ))\n",
    "\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "            dict(val_encodings),\n",
    "            val_labels\n",
    "        ))\n",
    "\n",
    "\n",
    "        if model_id == 'distilbert-base-uncased':\n",
    "            model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "                model_id, cache_dir='/home/msarthur/scratch'\n",
    "            )\n",
    "        else:\n",
    "            model = TFBertForSequenceClassification.from_pretrained(\n",
    "                model_id, cache_dir='/home/msarthur/scratch', local_files_only=True\n",
    "            )\n",
    "\n",
    "        # freeze all the parameters\n",
    "        # for param in model.parameters():\n",
    "        #   param.requires_grad = False\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "        METRICS = [\n",
    "            tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        ]\n",
    "\n",
    "        early_stopper = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', mode='min', patience=4, \n",
    "            verbose=1, restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
    "        checkpoint_filepath = '/home/msarthur/scratch/best_model'\n",
    "\n",
    "        mc = tf.keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath, \n",
    "            monitor='val_loss', mode='min', verbose=1, \n",
    "            save_best_only=True,\n",
    "            save_weights_only=True\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_fn,\n",
    "            metrics=METRICS\n",
    "        )\n",
    "\n",
    "        # https://discuss.huggingface.co/t/how-to-dealing-with-data-imbalance/393/3\n",
    "        # https://wandb.ai/ayush-thakur/huggingface/reports/Early-Stopping-in-HuggingFace-Examples--Vmlldzo0MzE2MTM\n",
    "        model.fit(\n",
    "            train_dataset.shuffle(1000).batch(BATCH_SIZE), \n",
    "            epochs=EPOCHS, \n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_weight=weights,\n",
    "            validation_data=val_dataset.shuffle(1000).batch(BATCH_SIZE),\n",
    "            callbacks=[early_stopper, mc]\n",
    "        )\n",
    "\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "        \n",
    "        most_common_frame_relationships = None\n",
    "        if MATCH_FRAME_FROM_TASK:\n",
    "            most_common_frame_relationships = get_most_common_frame_relationships(df_train)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.RED + f\"Testing model\" + Style.RESET_ALL)\n",
    "        for source in df_test[\"source\"].unique():\n",
    "            df_source = df_test[df_test[\"source\"] == source]   \n",
    "            logger.info(source)\n",
    "            test_model(source, df_source, model, tokenizer, pos_filter=USE_FRAME_FILTERING, task_filter=most_common_frame_relationships)\n",
    "\n",
    "        add_idx_fold_results(idx_split, fold_results)\n",
    "        if 'venn_diagram_set' not in fold_results:\n",
    "            fold_results['venn_diagram_set'] = []\n",
    "\n",
    "        fold_results['venn_diagram_set'] += venn_diagram_set\n",
    "        fold_results['venn_diagram_set'] = list(set(fold_results['venn_diagram_set']))\n",
    "\n",
    "\n",
    "        _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "        logger.info(\"\")\n",
    "        logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "        logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "        logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "        logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        log_sources_data = [api_metrics, so_metrics, git_metrics, misc_metrics]\n",
    "        log_sources_ids = ['api_metrics', 'so_metrics', 'git_metrics', 'misc_metrics']\n",
    "\n",
    "        for _id, __data in zip(log_sources_ids, log_sources_data):\n",
    "            _precision, _recall, _f1score = avg_macro_metric_for(__data)\n",
    "\n",
    "            logger.info(\"\")\n",
    "            logger.info(Fore.YELLOW + f\"{_id}\" + Style.RESET_ALL)\n",
    "            logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "            logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "            logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "    idx_split = int(idx_split)\n",
    "    idx_split += 1\n",
    "    logger.info(f\"next {idx_split}\")\n",
    "#     break\n",
    "#     if idx_split >= 2:\n",
    "#         logger.info(f\"breaking at {idx_split}\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for source in df_test[\"source\"].unique():\n",
    "#     df_source = df_test[df_test[\"source\"] == source]   \n",
    "#     logger.info(source)\n",
    "#     test_model(source, df_source, model, tokenizer, pos_filter=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m0\u001b[0m\n",
      "precision: \u001b[31m0.520\u001b[0m [0.52]\n",
      "recall:    \u001b[31m0.516\u001b[0m [0.52]\n",
      "f1-score:  \u001b[31m0.510\u001b[0m [0.51]\n",
      "\u001b[33m1\u001b[0m\n",
      "precision: \u001b[31m0.626\u001b[0m [0.63]\n",
      "recall:    \u001b[31m0.670\u001b[0m [0.67]\n",
      "f1-score:  \u001b[31m0.627\u001b[0m [0.63]\n",
      "\u001b[33m2\u001b[0m\n",
      "precision: \u001b[31m0.544\u001b[0m [0.54]\n",
      "recall:    \u001b[31m0.524\u001b[0m [0.52]\n",
      "f1-score:  \u001b[31m0.511\u001b[0m [0.51]\n",
      "\u001b[33m3\u001b[0m\n",
      "precision: \u001b[31m0.497\u001b[0m [0.5]\n",
      "recall:    \u001b[31m0.522\u001b[0m [0.52]\n",
      "f1-score:  \u001b[31m0.494\u001b[0m [0.49]\n",
      "\u001b[33m4\u001b[0m\n",
      "precision: \u001b[31m0.580\u001b[0m [0.58]\n",
      "recall:    \u001b[31m0.615\u001b[0m [0.62]\n",
      "f1-score:  \u001b[31m0.576\u001b[0m [0.58]\n",
      "\u001b[33m5\u001b[0m\n",
      "precision: \u001b[31m0.567\u001b[0m [0.57]\n",
      "recall:    \u001b[31m0.599\u001b[0m [0.6]\n",
      "f1-score:  \u001b[31m0.555\u001b[0m [0.55]\n",
      "\u001b[33m6\u001b[0m\n",
      "precision: \u001b[31m0.582\u001b[0m [0.58]\n",
      "recall:    \u001b[31m0.596\u001b[0m [0.6]\n",
      "f1-score:  \u001b[31m0.561\u001b[0m [0.56]\n",
      "\u001b[33m7\u001b[0m\n",
      "precision: \u001b[31m0.546\u001b[0m [0.55]\n",
      "recall:    \u001b[31m0.556\u001b[0m [0.56]\n",
      "f1-score:  \u001b[31m0.535\u001b[0m [0.53]\n",
      "\u001b[33m8\u001b[0m\n",
      "precision: \u001b[31m0.540\u001b[0m [0.54]\n",
      "recall:    \u001b[31m0.576\u001b[0m [0.58]\n",
      "f1-score:  \u001b[31m0.542\u001b[0m [0.54]\n",
      "\u001b[33m9\u001b[0m\n",
      "precision: \u001b[31m0.562\u001b[0m [0.56]\n",
      "recall:    \u001b[31m0.581\u001b[0m [0.58]\n",
      "f1-score:  \u001b[31m0.555\u001b[0m [0.55]\n",
      "\n",
      "\n",
      "\u001b[31mAGGREGATED METRICS\u001b[0m\n",
      "\n",
      "precision: \u001b[31m0.556\u001b[0m\n",
      "recall:    \u001b[31m0.576\u001b[0m\n",
      "f1-score:  \u001b[31m0.547\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "__precision, __recall, __fscore = [], [], []\n",
    "\n",
    "for key_i, value in fold_results.items():\n",
    "    if isinstance(value, dict):\n",
    "        for key_j, __data in value.items():\n",
    "            if key_j == 'overall':\n",
    "                logger.info(Fore.YELLOW + f\"{key_i}\" + Style.RESET_ALL)\n",
    "                logger.info(\"precision: \" + Fore.RED +\n",
    "                            \"{:.3f}\".format(np.mean(__data['precision'])) + Style.RESET_ALL +\n",
    "                           f\" {str([round(x, 2) for x in __data['precision']])}\")\n",
    "                logger.info(\"recall:    \" + Fore.RED +\n",
    "                            \"{:.3f}\".format(np.mean(__data['recall'])) + Style.RESET_ALL+\n",
    "                           f\" {str([round(x, 2) for x in __data['recall']])}\")\n",
    "                logger.info(\"f1-score:  \" + \n",
    "                            Fore.RED + \"{:.3f}\".format(np.mean(__data['fscore'])) + Style.RESET_ALL+\n",
    "                           f\" {str([round(x, 2) for x in __data['fscore']])}\")\n",
    "                \n",
    "                __precision += __data['precision']\n",
    "                __recall += __data['recall']\n",
    "                __fscore += __data['fscore']\n",
    "                \n",
    "__precision = [x for x in __precision if str(x) != 'nan']\n",
    "__recall = [x for x in __recall if str(x) != 'nan']\n",
    "__fscore = [x for x in __fscore if str(x) != 'nan']\n",
    "\n",
    "\n",
    "logger.info(\"\\n\")\n",
    "logger.info(Fore.RED + \"AGGREGATED METRICS\" + Style.RESET_ALL)\n",
    "logger.info(\"\\nprecision: \" + Fore.RED + \"{:.3f}\".format(np.mean(__precision)) + Style.RESET_ALL)\n",
    "logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(np.mean(__recall)) + Style.RESET_ALL)\n",
    "logger.info(\"f1-score:  \" +  Fore.RED + \"{:.3f}\".format(np.mean(__fscore)) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCaching results\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(Fore.YELLOW + \"Caching results\" + Style.RESET_ALL)\n",
    "with open('bert_ds_android_best_config.json', 'w') as fo:\n",
    "    json.dump(fold_results, fo, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', 'venn_diagram_set', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for source in df_test[\"source\"].unique():\n",
    "#     df_source = df_test[df_test[\"source\"] == source]   \n",
    "#     logger.info(source)\n",
    "#     test_model(source, df_source, model, tokenizer, pos_filter=True)\n",
    "#     cnt += 1\n",
    "#     if cnt >= 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cYVkKLe-B1j0"
   },
   "outputs": [],
   "source": [
    "#@title Metrics report\n",
    "# logger.info(json.dumps(fold_results, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _precision, _recall, _f1score = avg_macro_metric_for(prediction_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"Model metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(api_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"API metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(so_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"SO metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(git_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"GIT metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)\n",
    "\n",
    "# _precision, _recall, _f1score = avg_macro_metric_for(misc_metrics)\n",
    "\n",
    "# logger.info(\"\")\n",
    "# logger.info(Fore.YELLOW + \"MISC metrics\" + Style.RESET_ALL)\n",
    "# logger.info(\"precision: \" + Fore.RED + \"{:.3f}\".format(_precision) + Style.RESET_ALL)\n",
    "# logger.info(\"recall:    \" + Fore.RED + \"{:.3f}\".format(_recall) + Style.RESET_ALL)\n",
    "# logger.info(\"f1-score:  \" + Fore.RED + \"{:.3f}\".format(_f1score) + Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "zUOGnWgIMYLN"
   },
   "outputs": [],
   "source": [
    "def examples_per_source_type(source_type='misc', n_samples=None):\n",
    "    _sources = list(set([x[0] for x in log_examples_lst]))\n",
    "\n",
    "    _template = \"[w={}]\" + Fore.RED + \"[y={}]\" + Fore.YELLOW + \"[p={:.4f}]\" + Style.RESET_ALL + \" {}\"\n",
    "\n",
    "    idx = 0\n",
    "    for s in _sources:\n",
    "        examples_in_source = []\n",
    "        if source_type == 'api' and ('docs.oracle' in s or 'developer.android' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'so' and ('stackoverflow.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]            \n",
    "            idx += 1\n",
    "        elif source_type == 'git' and ('github.com' in s):\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        elif source_type == 'misc' and 'github.com' not in s and 'docs.oracle' not in s and 'developer.android' not in s and 'stackoverflow.com' not in s:\n",
    "            examples_in_source = list(filter(lambda k: k[0] == s, log_examples_lst))\n",
    "            task_title = examples_in_source[0][1]\n",
    "            idx += 1\n",
    "        if not examples_in_source:\n",
    "            continue\n",
    "        logger.info('')\n",
    "        logger.info(Fore.RED + f\"{task_title}\" + Style.RESET_ALL)    \n",
    "        logger.info(s)\n",
    "        logger.info('')\n",
    "\n",
    "        for _, _, pweights, y_predict, y_probs, text in examples_in_source:\n",
    "            logger.info(_template.format(pweights, y_predict, y_probs, text))\n",
    "            logger.info('')\n",
    "        logger.info('-' * 20)\n",
    "      \n",
    "        if n_samples and idx >= n_samples:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Fjg9kKaDM0fo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAPI\u001b[0m\n",
      "\n",
      "\u001b[31mHilt: How to prevent Hilt from picking dependency from a library?\u001b[0m\n",
      "https://developer.android.com/training/dependency-injection/hilt-android\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7922]\u001b[0m For example, as you might need the Context class from either the application or the activity, Hilt provides the @ApplicationContext and @ActivityContext qualifiers.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7892]\u001b[0m The following example demonstrates how to scope a binding to a component in a Hilt module.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7829]\u001b[0m However, in most cases it is best to use Hilt to manage all of your usage of Dagger on Android.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7786]\u001b[0m Instead, provide Hilt with the binding information by creating an abstract function annotated with @Binds inside a Hilt module.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7770]\u001b[0m Hilt automatically generates and provides the following:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7759]\u001b[0m One way to provide binding information to Hilt is constructor injection.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7750]\u001b[0m The function parameters tell Hilt the dependencies of the corresponding type.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7736]\u001b[0m Hilt automatically creates and destroys instances of generated component classes following the lifecycle of the corresponding Android classes.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7616]\u001b[0m The previous examples demonstrated the use of ActivityComponent in Hilt modules.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7498]\u001b[0m Scope annotations to use with the components that Hilt generates automatically.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mAndroid SQLite performance in complex queries\u001b[0m\n",
      "https://developer.android.com/training/data-storage/sqlite\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7198]\u001b[0m There is no compile-time verification of raw SQL queries.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7151]\u001b[0m For example, here's an implementation of SQLiteOpenHelper that uses some of the commands shown above:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6740]\u001b[0m To access your database, instantiate your subclass of SQLiteOpenHelper:\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.6587]\u001b[0m The results of the query are returned to you in a Cursor object.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.5817]\u001b[0m When you use this class to obtain references to your database, the system performs the potentially long-running operations of creating and updating the database only when needed and not during app startup.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5484]\u001b[0m This can happen if you have a conflict with pre-existing data in the database.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5361]\u001b[0m The method combines elements of insert ( ) and update ( ), except the column list defines the data you want to fetch ( the `` projection'' ), rather than the data to insert.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4827]\u001b[0m The insert ( ) methods returns the ID for the newly created row, or it will return -1 if there was an error inserting the data.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4799]\u001b[0m You may also want to implement the onDowngrade ( ) or onOpen ( ) methods, but they are not required.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.3053]\u001b[0m A contract class is a container for constants that define names for URIs, tables, and columns.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for API sources\n",
    "\n",
    "logger.info(Fore.RED + \"API\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='api', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "FDBgOWQXNW1i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mGIT\u001b[0m\n",
      "\n",
      "\u001b[31mHilt: How to prevent Hilt from picking dependency from a library?\u001b[0m\n",
      "https://github.com/google/dagger/issues/1991\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7481]\u001b[0m Hilt gradle plugin doesn't pick classes from custom android sdk-addon\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.5822]\u001b[0m In your case, you can add Retrofit and OkHttp dependency in app's build.gradle.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5753]\u001b[0m The workaround in the issue mentioned by Dany was working the last time I checked it.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5584]\u001b[0m We are aware of the implications this causes, such as leaking classes into other Gradle modules and possibly build performance impact with regards to compile avoidance.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5574]\u001b[0m I was surprised by this since I haven't really run into errors like this on my real project.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5287]\u001b[0m If you have build variants, this approach makes it easy to have different features in different variants.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5101]\u001b[0m In my sample app I have created a separate library module called core.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4866]\u001b[0m One way to mitigate this problem is to have your application gradle module be tiny.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4251]\u001b[0m But I am not sure why app module should be aware of these dependencies ( Retrofit + Okhttp )\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.3823]\u001b[0m It would be great if you could share one.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for GIT sources\n",
    "\n",
    "logger.info(Fore.RED + \"GIT\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='git', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "G4Bqx8AbNoV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSO\u001b[0m\n",
      "\n",
      "\u001b[31mAndroid SQLite performance in complex queries\u001b[0m\n",
      "https://stackoverflow.com/questions/4015026\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.7519]\u001b[0m If you have more complex queries that can't make use of any indexes that you might create, you can de-normalize your schema, structuring your data in such a way that the queries are simpler and can be answered using indexes.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7025]\u001b[0m I dropped this into my ContentProvider.query -LRB- -RRB- and now I can see exactly how all the queries are getting performed.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7002]\u001b[0m You can have indexes that contain multiple columns -LRB- to assist queries with multiple predicates -RRB-.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6660]\u001b[0m Only one index will be used on any given query.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.6300]\u001b[0m Here's a bit of code to get EXPLAIN QUERY PLAN results into Android logcat from a running Android app.\n",
      "\n",
      "[w=3]\u001b[31m[y=1]\u001b[33m[p=0.5909]\u001b[0m If you have a lot of string / text type data, consider creating Virtual tables using full text search -LRB- FTS3 -RRB-, which can run faster query.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5722]\u001b[0m off course it is a little tedious to write raw query.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5579]\u001b[0m If you have indexes with multiple columns, they are usable only if the predicates fit the index from left to right with no gaps -LRB- but unused columns at the end are fine -RRB-.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.5465]\u001b[0m If you use an ordering predicate -LRB- <, < =, > etc -RRB- then that needs to be in the last used column of the index.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1903]\u001b[0m I would add these:\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mHilt: How to prevent Hilt from picking dependency from a library?\u001b[0m\n",
      "https://stackoverflow.com/questions/30648172\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6924]\u001b[0m To find duplicate dependencies or its required dependencies, you can visualize library dependencies in tree.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4497]\u001b[0m Note that, run gradlew in Windows as below.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.2666]\u001b[0m Execute gradle command as below.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.2269]\u001b[0m For more information, you can see the tutorial at LINK\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1509]\u001b[0m In above example, last line com.android.support: support-annotations presents overriden from 22.1.1 to 22.2.0 internally.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mAndroid App Retrieve Data from Server but in a Secure way\u001b[0m\n",
      "https://stackoverflow.com/questions/8184492\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5858]\u001b[0m But still there are many vulnerabilities are possible by poor design of the apps.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5144]\u001b[0m If you are really concerned about the data then further encrypt it with a unique algorithm before sending and decrypt it when it reaches the app.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5000]\u001b[0m If you want to pretty much ensure the user can not see the data other than by looking at your app then encryption is really the only way.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4563]\u001b[0m You can obfuscate as much as you want, if a hacker is really determined to get to your data, he will be able to so by decompiling your application and spending many sleepless nights passing through your code and figuring out how the requests are formed.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.3698]\u001b[0m LINK http://developer.android.com/reference/javax/net/ssl/package-summary.html LINK\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.2342]\u001b[0m Google recently announced a cloud-based storage solution for apps, so you could consider storing the key there if the situation allows.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1588]\u001b[0m maybe that'll help\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1569]\u001b[0m Whether or not to trust the master-key method, I'll leave to you.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1539]\u001b[0m A few things to think about:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1535]\u001b[0m .\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mCustom Annotations in Retrofit 2.0\u001b[0m\n",
      "https://stackoverflow.com/questions/47760861\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7733]\u001b[0m We read the annotation in the CallAdapter.Factory and when the request gets created in the CallAdapter, we will store some information for this kind of request within some map, to identify it later in some interceptor.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.7478]\u001b[0m Retrofit Changelog:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7236]\u001b[0m I have similar requirement, what I found is Annotation can be read in LINK, LINK and LINK.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7109]\u001b[0m getAnnotation -LRB- annotationClass -RRB-\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6503]\u001b[0m header -LRB- `` needauth'' -RRB- to get the value.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5829]\u001b[0m And you can use then like that:\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5078]\u001b[0m = this.tag -LRB- Invocation:: class.java -RRB- ?\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4813]\u001b[0m In GsonCacheableConverter, it overrides responseBodyConverter -LRB- -RRB- to persist response tagged with @Cacheable.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4672]\u001b[0m method -LRB- -RRB- ?\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4579]\u001b[0m Based on LINK.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for SO sources\n",
    "\n",
    "logger.info(Fore.RED + \"SO\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='so', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "2_mgLqe0N-hs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mMISC\u001b[0m\n",
      "\n",
      "\u001b[31mAndroid App Retrieve Data from Server but in a Secure way\u001b[0m\n",
      "https://medium.com/mindorks/how-to-pass-large-data-between-server-and-client-android-securely-345fed551651\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6295]\u001b[0m How to pass large data between server and client ( android ) securely?Using RSA and AES ( Hybrid ) encryption techniqueMayank Mohan UpadhyayFollowJun 14, 2017 Â· 5 min readHello guys, Most of the times, we pass sensitive data from our Android app to our server.\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.5248]\u001b[0m Client will use this passcode to encrypt user's email ID and send to the server.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4767]\u001b[0m You can't ship the passcode in your app.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4020]\u001b[0m Also, it is impractical to use asymmetric encryption because 99 % of the times the data that you'd want to transfer would be of more than 128 bytes in size !\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.3129]\u001b[0m 1 public key and 1 private key.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.2585]\u001b[0m What to do?Hybrid solution to the rescue!Consider this: Using an asymmetric encryption ( say RSA ), the server generates a key pair consisting of a public key and a private key.Server saves these keys in a secure location.We take public key and ship it in our app ( client ).\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.2316]\u001b[0m This is just wonderful!This kind of encryption technique is called asymmetric encryption.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.2265]\u001b[0m Public key is visible publicly and anyone can use that key to encrypt sensitive data.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1971]\u001b[0m \n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1477]\u001b[0m Learn moreMake Medium yours.Follow the writers, publications, and topics that matter to you, and you'll see them on your homepage and in your inbox.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mHilt: How to prevent Hilt from picking dependency from a library?\u001b[0m\n",
      "https://prog.world/a-practical-guide-to-using-hilt-with-kotlin\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7898]\u001b[0m Setting up Hilt To set up Hilt in your application, first follow the directions from the guide: Installing Gradle Build ...\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7880]\u001b[0m â®• As constructor parameters If you mark the constructor with annotation @Inject, Hilt will implement all the parameters according to the bindings you define for these types.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7858]\u001b[0m You don't need to do anything else, and you don't need to call Hilt directly.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7510]\u001b[0m The modules are installed in Hilt componentwhich is indicated by annotation @InstallIn ... I'll give a more detailed explanation below.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.7470]\u001b[0m A practical guide to using Hilt with Kotlin\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.6491]\u001b[0m Dependency Definition and Injection When writing code that uses Dependency Injection, there are two main components to consider:\n",
      "\n",
      "[w=1]\u001b[31m[y=1]\u001b[33m[p=0.5753]\u001b[0m Classes that can be injected as dependencies.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.5286]\u001b[0m For example, this makes it easy to replace interface implementations with mock objects.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4506]\u001b[0m Four easy Kubernetes terminal settings to improve your productivity\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1397]\u001b[0m NextContinue How the search for black cat in dark Kubernetes has changed\n",
      "\n",
      "--------------------\n",
      "\n",
      "\u001b[31mAndroid App Retrieve Data from Server but in a Secure way\u001b[0m\n",
      "https://medium.com/@rezabigdeli6/how-to-send-a-semi-secure-request-to-a-server-in-android-359b11b4e873\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.6600]\u001b[0m So this way the hacker who is sniffing our requests wouldn't know what we are doing and what information are we sending so they can't go ahead and make fake requests.But the new problem here is that decompiling an Android application isn't that hard, actually it's pretty easy.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4712]\u001b[0m Also you can check the package name in your native code and a lot of other things.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.4370]\u001b[0m For example to counteract the for loop we can send the encrypted data back to the java code with a little of delay.\n",
      "\n",
      "[w=2]\u001b[31m[y=1]\u001b[33m[p=0.3596]\u001b[0m Well we can put some kind of encryption into our requests, for example using RSA we can have a private key, put it into the application, and encrypt the requests.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.2285]\u001b[0m Of course there are some solutions for this type of attack, for example CAPTCHAS, but again the problem is CAPTCHAS will ruin the UX of your application.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1990]\u001b[0m But the advantage of using native code is that we can be, to some extend, sure that: First: They don't have access to our private key so if they want to create requests they have to use our library.Second: They can't see or manipulate our native code and logic.So we can use and check a lot of factors and bring in a lot of checking in our native code.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1752]\u001b[0m Step three: Use Other FactorsWe know that they can use our library just like we are using it.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1710]\u001b[0m And at the same time, delaying for half a second wouldn't be as annoying as CAPTCHAS for someone who is trying to register.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1590]\u001b[0m We did a lot of things and used a lot of methods to make the things hard for the hacker but as I said a determined hacker can do anything.\n",
      "\n",
      "[w=0]\u001b[31m[y=1]\u001b[33m[p=0.1505]\u001b[0m But making things hard for them can dissuade them from doing their job or at least gives you some time to change your approach or find a better way in your next release.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#@title Sample prediction outputs for MISC sources\n",
    "\n",
    "logger.info(Fore.RED + \"MISC\" + Style.RESET_ALL)\n",
    "examples_per_source_type(source_type='misc', n_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m317 entries VENN SET\u001b[0m\n",
      "\n",
      "It also helps simplify refactoring, since you can focus on what modules to build rather than focusing on the order in which they need to be created.\n",
      "My answer builds on that from Kevin Wong, here as a one-liner using CollectionUtils from spring and a Java 8 lambda expression.\n",
      "I've seen this cause a crash on Android 5.1.\n",
      "The example code above will access the first, back-facing camera on a device with more than one camera.\n",
      "The model in this case is Business and for our application, let's suppose we just need the name, phone, and image of the business which are all provided by the Search API.\n",
      "To handle an individual key press, implement onKeyDown ( ) or onKeyUp ( ) as appropriate.\n",
      "I spent some time thinking about it.\n",
      "Encodes this object as a compact JSON string, such as:\n",
      "bt when i load the list, it load wrong list items time to time.\n",
      "There have been reports that this value is not 100 % reliable from Eclipse-based builds, though I personally have not encountered a problem, so I can not say how much of an issue it really is.\n",
      "I simply reorder the fragment list, update the viewPager and move to the new page without animation, the result is an endless loop in both directions:\n",
      "@ahamrani If I were you I would go ask on Huawei/EmUI related forums before voiding my warranty ...\n",
      "Make sure you don't have something like that hanging around\n",
      "If you run the app now you won't be able to see any movies:\n",
      "But I dont understand what difference they made ?\n",
      "For example, here's an implementation of SQLiteOpenHelper that uses some of the commands shown above:\n",
      "parent\n",
      "After that override getView -LRB- -RRB- method and make sure to return your custom View there.\n",
      "Specify a URL and receive a raw string in response.\n",
      "When using the verifyWithRecaptcha ( ) method in your app, you must do the following:\n",
      "In human speech it would be like,\n",
      "- processor class1 -LSB-, class2, class3 ... -RSB-\n",
      "For me, the problem was that I copied something from an example and used\n",
      "For other services, you might need to intercept calls in a different way.\n",
      "It is worth noting that apparently Dagger2 creates a single instance per scoped provider in a module per component.\n",
      "EXAMPLE:\n",
      "Create a PendingIntent for the reply action.\n",
      "You should only declare modules once in a component.\n",
      "inject.Scope annotation - Dependencies declared with that scope with have caching Provider with double-check lock generated and only single instance will be created for it within component declared with the same scope and its creation will be thread safe.\n",
      "Specify a URL and get a JSON object or array ( respectively ) in response.\n",
      "You can either rotate your bitmap when you draw it by using a matrix:\n",
      "In your activity's onCreate ( ) method, create an instance of the Fused Location Provider Client as the following code snippet shows.\n",
      "I haven't tried recording phone call's but there is a option in LINK for:\n",
      "and in the LinearLayout, the default gravity -LRB- used here -RRB- is ` center'\n",
      "Your app can then access the related data for a period of time that depends on your app's behavior and the user's actions:\n",
      "For those who want to capture a GLSurfaceView, the getDrawingCache or drawing to canvas method won't work.\n",
      "Validating the response is really easy.\n",
      "Volley provides the following classes for JSON requests:\n",
      "For example, you can not constructor-inject an interface.\n",
      "I would add these:\n",
      "Hope it helps !\n",
      "The following code snippet shows how to invoke this method:\n",
      "You don't need to use so many lists, just create a class that will contain all the data of single item, there is no need for buttons, use just text change listener instead.\n",
      "You can also add one or more metadata tracks with custom information for each frame, but only to MP4 containers.\n",
      "Having an interface like this helps with mocking the client for tests, which I appreciate.\n",
      "Update Note: This tutorial is now up to date with the latest version of Android Studio version 3.0.1, and uses Kotlin for app development.\n",
      "I didn't see a specific issue opened for this, but looking at the code for DrawableWrapperDonut/DrawableWrapperGingerbread, I can see that the problem was introduced around 23.4.0 and later fixed, so if you were using the buggy version, switching to a good version should fix this crash.\n",
      "Initial and maximum pool size.\n",
      "Runtime permissions are permissions that are requested as they are needed while the app is running.\n",
      "Check this tutorial you will get information about how to draw bitmap and how to rotate canvas\n",
      "As discussed in Detecting Common Gestures, GestureDetector helps you detect common gestures used by Android such as scrolling, flinging, and long press.\n",
      "If the user granted the permission to your app, you can access the private user data.\n",
      "Only one index will be used on any given query.\n",
      "For example, this makes it easy to replace interface implementations with mock objects.\n",
      "Anyway, I don't really like this solution, setting getCount to return Integer.MAX _ VALUE can have huge impact on application performance.\n",
      "See this example code for a working example.\n",
      "Scoped generic class fails to build Â· Issue # 671 Â· google/dagger Â· GitHub\n",
      "The user has now plenty of swiping to do in either direction before they reach an end.\n",
      "SQLiteDatabase databases you create are private to your application and provider.\n",
      "An application icon An `` upward'' navigation to logical parent An application or activity-specific title Primary action icons for an activity Consistent navigation ( including navigation drawer )\n",
      "Kotlin\n",
      "Traditionally, you manage a request code yourself as part of the permission request and include this request code in your permission callback logic.\n",
      "This will automatically show the HomeFragment and hide any other fragment in the list.\n",
      "You annotate a class with @RunWith ( AndroidJUnit4:: class ) to specify that AndroidJUnit4 is the runner for this test.\n",
      "You'll have to add 8 more items to the JSON file.\n",
      "Mark Complete ( All Chapters ) Clear Progress ( All Chapters )\n",
      "Screen Orientation - Often within apps, the portrait version of an activity has a substantially different layout from the landscape version.\n",
      "Go back to MainActivity.kt and first import the ViewPager to be able to use it with this line:\n",
      "This answer is a modification to mangu23 LINK I only added a for loop to avoid repetition and to easily add more fragments without boilerplate code.\n",
      "JsonArrayRequest -- A request for retrieving a JSONArray response body at a given URL.\n",
      "When I updated your sample with these annotations, Jackson correctly deserialized each object to the expected subclass.\n",
      "When the app needs to use any of the protected features of the device ( sending network requests, accessing the camera, sending an SMS, etc ) it must obtain the appropriate permission from the user to do so.\n",
      "At the time I am writing this article, the latest version of Google Play Services available is 6.5.87.\n",
      "Based on LINK.\n",
      "And replace the response_string with the value that you earlier got by the g-recaptcha-response field.\n",
      "And you can get the json object by passing index value like,\n",
      "I believe I had a similar problem.\n",
      "Press Alt + Enter, or Option + Return on a Mac, to import these other needed classes:\n",
      "It introduced the concept of runtime permissions.\n",
      "Before you pull your hairs out make sure you are using:\n",
      "now you can do what you want with the bitmap.\n",
      "To be able to record, your app must tell the user that it will access the device's audio input.\n",
      "Create a new class by right-clicking on the com.raywenderlich.alltherecipes package and selecting New > Kotlin File/Class.\n",
      "Here is a LINK on how to record audio using the LINK.\n",
      "However, in most cases it is best to use Hilt to manage all of your usage of Dagger on Android.\n",
      "This connects the volume controls to STREAM_MUSIC whenever the target activity or fragment is visible.\n",
      "If your app isn't currently playing anything, hitting the volume keys adjusts the music volume ( or the ringer volume before Android 9 ).\n",
      "When a event arrives that specific state is changed, and we check if all the states are as desired.\n",
      "Now, we just need to connect this adapter to a ListView to be populated:\n",
      "Hilt automatically creates and destroys instances of generated component classes following the lifecycle of the corresponding Android classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Intent is an object that provides runtime binding between separate components, such as two activities.\n",
      "However, I'm somewhat new to Jackson, so perhaps I'm missing something here.\n",
      "This nested fragment is known as a child fragment.\n",
      "If you run the app and tap the button on the first activity, the second activity starts but is empty.\n",
      "Get news and tips by email Subscribe\n",
      "Please see LINK for more info.\n",
      "Java 7\n",
      "If you try any of this out then there is a chance that you will do everything correct and yet your action bar will not show.\n",
      "It is also working on a real device and I tested it in Panasonic P81.\n",
      "custom event icon/add small icon to event Â· Issue # 181 Â· SundeepK/CompactCalendarView Â· GitHub\n",
      "the final action in the ondraw method is the drawing of the bitmap.\n",
      "Defining the Adapter Next, we need to define the adapter to describe the process of converting the Java object to a View ( in the getView method ).\n",
      "- proc: only means that only annotation processing is done, without any subsequent compilation.\n",
      "Previously it would have added an App Bar but Google recommends that we change to using the Toolbar widget.\n",
      "To model the response of the network request, we have our own Result class.\n",
      "I suspect the version of Jackson are you using explains the difference.\n",
      "Next, we need to add method that would manage the deserialization of a JSON dictionary into a populated Business object:\n",
      "If you have a lot of string / text type data, consider creating Virtual tables using full text search -LRB- FTS3 -RRB-, which can run faster query.\n",
      "off course it is a little tedious to write raw query.\n",
      "This is usually not necessary, however, because callbacks are automatically removed when their associated LifecycleOwner is destroyed.\n",
      "More than just text ?\n",
      "ViewPager - Swiping between fragments\n",
      "This will ensure that the ViewPager doesn't request the element at an index larger than movies.size because the remainder after you divide the position by movies.size will always be greater than or equal to 0 and less than movies.size.\n",
      "and dont forget to set scaleType property to matrix of ImageView tag like:\n",
      "The content of the array is obtained through Resources.getTextArray ( int ).\n",
      "Yes, it is possible ` to receive notifications from google cloud message when the application is fully closed'.\n",
      "Generates the classes that it uses at runtime to create the actual objects and their dependencies.\n",
      "reference LINK\n",
      "Whether or not to trust the master-key method, I'll leave to you.\n",
      "Pardon the misspelling, I meant polling.\n",
      "Unless your JSON structure is complicated, you won't have to deal with deserializing your JSON into a polymorphic data type.\n",
      "Using a Custom ArrayAdapter When we want to display a series of items from a list using a custom representation of the items, we need to use our own custom XML layout for each item.\n",
      "The function parameters tell Hilt the dependencies of the corresponding type.\n",
      "In the desired layout, the labels are right-justified and the fields are left-justified.\n",
      "If the user presses and holds the button, then onKeyDown ( ) is called multiple times.\n",
      "Your task is to populate each element of the row view with the relevant recipe data, hence, you'll define what text goes in the `` title'' element, the `` subtitle'' element and so on.\n",
      "A Toolbar is a generalization of action bars for use within application layouts.\n",
      "Core Java APIs for making Java http requests Since Java 1.1 there has been an HTTP client in the core libraries provided with the JDK.\n",
      "ArrayAdapter is a subclass of BaseAdapter which takes ArrayList -LRB- or array -RRB- in constructor.\n",
      "If using the fasterxml then,\n",
      "If the action accesses shared state, it is responsible for providing the required synchronization.\n",
      "Add the calling app's package name to the site key on the reCAPTCHA Admin Console, or disable package name validation for your site key.\n",
      "You are mistaking gravity and layout_gravity.\n",
      "Note: Most of the audio sources ( including DEFAULT ) apply processing to the audio signal.\n",
      "I figured out a solution in order to avoid this problem using the:\n",
      "After the user responds to the system permissions dialog, the system then invokes your app's implementation of onRequestPermissionsResult ( ).\n",
      "Change the android: label or android: icon to modify the ActionBar title or icon for a given activity or for the application as a whole.\n",
      "Create a face detection listener\n",
      "Please also check this developer app given for how to integrate RemoteControlClient: LINK However UI for the RemoteControlClient defer as per the device you can not updates its UI to your own but you have control to show and display the component and control of the Music app.\n",
      "It provides the best accuracy based on our needs.\n",
      "How to pass large data between server and client ( android ) securely?Using RSA and AES ( Hybrid ) encryption techniqueMayank Mohan UpadhyayFollowJun 14, 2017 Â· 5 min readHello guys, Most of the times, we pass sensitive data from our Android app to our server.\n",
      "Make sure you add it outside of the application tag.\n",
      "I had the same error and traced it to a bug with DrawableCompat.wrap -LRB- -RRB- in 23.4.0 that doesn't exist in earlier & later versions of the support library.\n",
      "Adds the specified Collection at the end of the array.\n",
      "Notice that the starter project contains a Recipe class that models and stores the information about the recipes that will be displayed.\n",
      "The last thing you have to do is let the RecyclerTabLayout know what titles to display on the Tabs.\n",
      "Dedicated devices cookbook with further examples to restrict the dedicated devices and enhance the user experience.\n",
      "Note: Your app can not customize the dialog that appears when you call launch ( ).\n",
      "In case you want to switch back to default heartbeat interval, either uninstall the app or set the default interval right from the app.\n",
      "Creates a new ArrayAdapter from external resources.\n",
      "Runtime Permissions If the permission you need to add isn't listed under the normal permissions, you'll need to deal with `` Runtime Permissions''.\n",
      "Getting locked out of your own Android phone can be really frustrating and quite embarrassing.\n",
      "The bad: A malicious app can secretly turn on your camera and record what's going on around you.\n",
      "Presenting navigational components such as the navigation drawer or the viewpager.\n",
      "In you case, you first want to check if you such file exist before creating one.\n",
      "I think that's done in `` Contacts/src/com/android/contacts/ui/QuickContactWindow.java'', but I am not completely sure.\n",
      "Sets the TextClassifier for this TextView.\n",
      "And if you are building a media player, also read Using MediaStyle notifications with a foreground service.\n",
      "getAnnotation -LRB- annotationClass -RRB-\n",
      "Users can swipe down on the status bar to open the notification drawer, where they can view more details and take actions with the notification.\n",
      "For more information, you can see the tutorial at LINK\n",
      "The workaround in the issue mentioned by Dany was working the last time I checked it.\n",
      "This usually allows Android to properly navigate to previous destinations when the Back button is pressed.\n",
      ":] Where to Go From Here ?\n",
      "It returns the title of the movie that corresponds with the fragment created inside getItem ( position: Int ).\n",
      "@geoand you're correct, it still works if I remove @RegisterForReflection.\n",
      "When the user makes a choice, the system asynchronously invokes your implementation of ActivityResultCallback, which you defined in the previous step.\n",
      "Set the output file format using setOutputFormat ( ).\n",
      "You can download the solution here.\n",
      "I have seen Android location access tutorial examples giving all the available permission in the world.\n",
      "Attach the RemoteInput object to an action using addRemoteInput ( ).\n",
      "In addition to Stream, which is a stream of object references, there are primitive specializations for IntStream, LongStream, and DoubleStream, all of which are referred to as `` streams'' and conform to the characteristics and restrictions described here.\n",
      "And you can use then like that:\n",
      "the second step is to translate the view up and left by half the width and half the height.\n",
      "For example:\n",
      "note that the 2 null args may allow you to clip some portion in the page and perform a transformation -LRB- using a LINK -RRB- of the clip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns the value mapped by name if it exists and is a boolean or can be coerced to a boolean, or fallback otherwise.\n",
      "Notice that there's a FrameLayout with the id of @ + id/child _ fragment_container in which the child fragment will be inserted.\n",
      "Returns the API response in a JsonObject.\n",
      "I dropped this into my ContentProvider.query -LRB- -RRB- and now I can see exactly how all the queries are getting performed.\n",
      "Wont help you in this case.\n",
      "with the api 23, permission <uses-permissionÂ android:name=\"android.pemission.READ_CONTACTS\"/> dont work, change the api level in the emulator for api 22 -LRB- lollipop -RRB- or lower\n",
      "The system passes in the user response to the permission dialog, as well as the request code that you defined, as shown in the following code snippet:\n",
      "Connecting the PagerAdapter and the ViewPager Open MainActivity.kt and add the following line at the top to declare your MoviesPagerAdapter:\n",
      "If you launch a foreground service while the activity is visible, and the user then moves your app to the background, your app can continue to access the data until that foreground service stops.\n",
      "getView going to be called for each position every time it is displayed.\n",
      "What to do?Hybrid solution to the rescue!Consider this: Using an asymmetric encryption ( say RSA ), the server generates a key pair consisting of a public key and a private key.Server saves these keys in a secure location.We take public key and ship it in our app ( client ).\n",
      "Here was my approach to this in kotlin\n",
      "Subcomponent Builders Available starting in v2 .7\n",
      "Any thread in your app can run in parallel to other threads, including the main thread, so you should ensure that your code is thread-safe.\n",
      "I think we will know more about your issue after you make either one or both of the above changes: -RRB-\n",
      "The @Singleton annotation also signals to the Dagger compiler that the instance should be created only once in the application.\n",
      "I hope this tutorial is of some use to you, and helps you on your way to creating an awesome Android application.\n",
      "layout_gravity is the way the TextView will align itself in its parent, in your case in the vertical LinearLayout\n",
      "If you want to take screenshot from fragment than follow this:\n",
      "You can use the ApplicationComponent to get a reference to LoginComponent and then inject LoginActivity as follows:\n",
      "Please give your suggestions in a detailed manner.\n",
      "The user can grant or deny each permission, and the app can continue to run with limited capabilities even if the user denies a permission request.\n",
      "onCreate of the Activity, you can use do the following\n",
      "Reference: LINK\n",
      "You might expect the Location object that's contained in the most recent call to getLastLocation ( ) to be the most accurate.\n",
      "You may also find useful LINK and LINK.\n",
      "and successfully create a Business with Business.fromJson ( json ).\n",
      "Here is how I apply offset and length.\n",
      "LINK http://developer.android.com/reference/javax/net/ssl/package-summary.html LINK\n",
      "Embedding a Fragment in an Activity There are two ways to add a fragment to an activity: dynamically using Java and statically using XML.\n",
      "All callbacks registered via addCallback are evaluated when you call super.onBackPressed ( ).\n",
      "I am using this solution in case to find out that my app is running on debug version.\n",
      "If you want to render a PDF, you create a renderer and for every page you want to render, you open the page, render it, and close the page.\n",
      "Try this:\n",
      "Please let me know your suggestions and comments.You can find me on Medium and LinkedIn ... Thanks for reading ...\n",
      "The activity also removes registered callbacks when their associated LifecycleOwner is destroyed, which prevents memory leaks and makes it suitable for use in fragments or other lifecycle owners that have a shorter lifetime than the activity.\n",
      "gravity is the way the text will align itself in the TextView.\n",
      "Maven depenendency for pretius-jddl -LRB- check newest version at LINK:\n",
      "In the question, all that was wanted was execution of each of the operations, either one-by-one or in parallel -LRB- which was not specified, but linked Bolts example was about parallel execution -RRB-.\n",
      "The SafetyNet service includes a reCAPTCHA API that you can use to protect your app from malicious traffic.\n",
      "Reusing View and Logic Components - Fragments enable re-use of parts of your screen including views and event logic over and over in different ways across many disparate activities.\n",
      "Ah, thanks @oztimpower, I had forgot !\n",
      "Next, you'll need to initiate the permission request and handle the result.\n",
      "to subscribe to this conversation on GitHub.\n",
      "From the OnCreateView method ?\n",
      "To enable Smart Reply, call setAllowGeneratedResponses ( true ) on the reply action.\n",
      "notice that the drawbitmap method uses the matrix with the various transformations encoded in it.\n",
      "It wasn't until I moved the * uses-permission ... READ_CONTACTS * line to outside the application tag that things worked.\n",
      "If that is how you wish to distinguish a `` debug'' build from a `` release'' build, then by definition, that's the best solution.\n",
      "so user can drag the image off the screen and zoom-In, zoom-out the image.\n",
      "Note: This class takes ownership of the passed in file descriptor and is responsible for closing it when the renderer is closed.\n",
      "This ensures that the OnBackPressedCallback is only added when the LifecycleOwner is Lifecycle.State.STARTED.\n",
      "If you use an ordering predicate -LRB- <, < =, > etc -RRB- then that needs to be in the last used column of the index.\n",
      "This topic provides simple examples for sizing and aligning nodes in a pane.\n",
      "Joe Howard Joe's path to software development began in the fields of computational physics and systems engineering.\n",
      "Also, all example on developer.android.com are terrible, any one of them really works.Olaoye OluwapelumiThanks, really helpful.\n",
      "Before Marshmallow, permissions were handled at install-time and specified in the AndroidManifest.xml within the project.\n",
      "onScroll ( ) is only called when a finger is down ; as soon as the finger is lifted from the screen, the gesture either ends, or a fling gesture is started ( if the finger was moving with some speed just before it was lifted ).\n",
      "What if you then decide to add your favorite TV series as well ?\n",
      "Level up your Twilio API skills in TwilioQuest, an educational game for Mac, Windows, and Linux.\n",
      "An intent may also contain `` extras'' data that the destination activity displays in the UI ; the user then has the option of changing this data before using it to modify the data in the provider.\n",
      "Note that, run gradlew in Windows as below.\n",
      "For example, if each page in the swipe view should consume the entire layout, then your layout should look like this:\n",
      "get the LINK to render\n",
      "In fact components can declare many scopes -LRB- e.g. @ActivityScope and @UiScope -RRB- and Dagger will treat both of them as single scope - it's called scope aliasing.\n",
      "So the first thing you should do its to create your custom adapter.\n",
      "If you need this mode there are some guidelines to use it properly: here are LINK.\n",
      "On the other hand, if your application is about sharing user location with his friend, you maybe just need to request the location once in a while.\n",
      "MockWebServer makes it possible to easily test how your apps behave when making HTTP/HTTPS calls.\n",
      "The TextView being in wrap_content this does nothing, as the TextView is exactly the size of the text.\n",
      "Open activity_main.xml and paste the following snippet above the ViewPager:\n",
      "you have to use the matrix to rotate image look the lines\n",
      "Read more about getters and setters in Kotlin here.\n",
      "Sometimes, this is not possible and you have to use Dagger modules.\n",
      "Check the success field for true or false\n",
      "Returns the value mapped by name if it exists and is an int or can be coerced to an int, or 0 otherwise.\n",
      "You will probably want to add more functionality later, but it will help you get started.\n",
      "Short battery life is one of the biggest downfalls of Android phones, and there are times when you ... Read more\n",
      "For additional design guidance for tab layouts, see the Material Design documentation for tabs.\n",
      "I dont know how its was worked in android 4.0.\n",
      "As you can read LINK:\n",
      "You can have indexes that contain multiple columns -LRB- to assist queries with multiple predicates -RRB-.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An audio app should provide the ability to balance its output volume with other apps that might be playing on the same stream.\n",
      "Set the audio encoder using setAudioEncoder ( ).\n",
      "Anyone with HTTP POST knowledge could put random data inside of the g-recaptcha-response form field, and foll your site to make it think that this field was provided by the google widget.\n",
      "Next, we define the parent component:\n",
      "If the holder holds the view you want, you can reuse it.\n",
      "A practical guide to using Hilt with Kotlin\n",
      "The JSON structure was quite complex, with multiple levels and even an array.\n",
      "If an uncaught exception is thrown by the finalize method, the exception is ignored and finalization of that object terminates.\n",
      "David TruongJan 9, 2019 Â· 2 min read\n",
      "1 - Enable touch in the chart\n",
      "More information LINK\n",
      "So in order to get a scoped provider in a module, you need to specify the scope for your module's provider method.\n",
      "after that, you can easily start recording anywhere you want\n",
      "the zip is attached at the bottom of that page.\n",
      "Jackson Polymorphic DeserializationHow to Use Jackson to Deserialize Json Fields into Polymorphic TypesDavid TruongJan 9, 2019 Â· 2 min readPhoto by Markus Spiske on UnsplashJackson deserialization/serialization works out of the box most of the time.\n",
      "The Action Bar follows the material design guidelines and uses a LINK.\n",
      "In the fragment, add a method:\n",
      "Snackbars should still work with AppCompat themes, which don't specify a snackbarButtonStyle.\n",
      "What the ViewHolder class does is cache the call to findViewById ( ).\n",
      "To find duplicate dependencies or its required dependencies, you can visualize library dependencies in tree.\n",
      "So let me do it for you: the correct hierarchy as suggested by google blogspot it is working fine for me: Check this out\n",
      "Let me know if you guys need anything more in this tutorial.\n",
      "Unscoped dependency will have simple Provider generated without any caching and any instance of that dependency created in component will be new for every new injection -LRB- as in constructor, or in module provision method, or just as a field -RRB-.\n",
      "TabLayout - Tabs at the top\n",
      "you should try this:\n",
      "Suppose that AnalyticsService has an internal state that requires the same instance to be used every time -- not only in ExampleActivity, but anywhere in the app.\n",
      "Example code for LoginUserNameFragment appears in the following code snippet:\n",
      "I don't know if it can help anybody, but here is what I use as a workaround:\n",
      "Use a raw framework class to avoid Java 7's poor type inference when ...\n",
      "create two class to achieve this goal: GcmBroadcastReceiver and GcnIntentService.\n",
      "Any exception thrown by the finalize method causes the finalization of this object to be halted, but is otherwise ignored.\n",
      "Reduce the amount of time that the system waits to reset the permissions.\n",
      "It is up to you which road you take, but I found the solution helpful, especially if you use a base class for all of your activities.\n",
      "There are several considerations when using these approaches:\n",
      "Preparing the ViewPager For step one, open MainActivity.kt and remove everything inside onCreate ( ), below this line:\n",
      "Creating an instance of UserRemoteDataSource is not that expensive, so scoping it to the component's lifecycle is not necessary.\n",
      "and not:\n",
      "This can be done by adding an onCreateOptionsMenu method to the fragment directly.\n",
      "Also, if you're only interested in the completion of your task, not return values, you should probably look into LINK instead of LINK.\n",
      "In Android, this pattern is common in details screens where the id of the element to show is only known at runtime, not at compile time when Dagger generates the DI graph.\n",
      "If you haven't done so already, read the topic Content provider basics to learn more about providers and how they work.\n",
      "If the user denied the permission instead, gracefully degrade your app experience so that it provides functionality to the user, even without the information that's protected by that permission.\n",
      "When an event appears upstream ( UUID ), it is delegated to one of 10 `` rails'' -- concurrent, independent pipelines.\n",
      "So ideally we also would have an easy way of processing an array of businesses into an ArrayList of Business objects.\n",
      "Back navigation is how users move backward through the history of screens they previously visited.\n",
      "From version 8.0.0 of the Twilio Helper Library, the type of future returned is now a CompletableFuture which has a.\n",
      "How to Post to DZone\n",
      "- the explicit creation of multiple threads\n",
      "The steps are explained in more detail below.\n",
      "Granting and revoking runtime permissions:\n",
      "A good implementation that never crashes your app would be:\n",
      "This lesson describes how to use these standard request types.\n",
      "As long as the audio source options work, you should be good to go.\n",
      "About the authorDanny is a full-stack software engineer with 7 + years of experience doing project management and building web and mobile applications.\n",
      "The problem in the first case is that Dagger is overeager to use a single static factory instance for generating instances of scoped generic classes.\n",
      "I guess all that's really missing in the generated code is a typecast to Provider to achieve erasure bliss.\n",
      "That's all there was to it.\n",
      "Creating threads is expensive, so you should create a thread pool only once as your app initializes.\n"
     ]
    }
   ],
   "source": [
    "logger.info(Fore.RED + f\"{len(fold_results['venn_diagram_set'])} entries VENN SET\" + Style.RESET_ALL)\n",
    "for _t in fold_results['venn_diagram_set']:\n",
    "    logger.info(_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM51gMzrDUJf4OiiaquqBe4",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "hugging-face-keras-bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7 Arthur hugging",
   "language": "python",
   "name": "msarthur-hface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03ddd131c9f0446eb83bb6dabee9a832": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3518f71b0e4540be8b17a3fe72182cb4",
       "IPY_MODEL_a5ccb838d3704546937e925e456830be",
       "IPY_MODEL_8181fd24b3624c1b9c6a9d0302f43a56"
      ],
      "layout": "IPY_MODEL_f02cf8090f8d463eb7eeb59743a87276"
     }
    },
    "0466163ff4a945798423387d1ac900c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0efe94b613f44c029f2e9bd05696ad32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3e13535de4b44bb9139c3911684cee8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6ccdfb754c12418c9438ac218a172e63",
      "value": "Downloading: 100%"
     }
    },
    "153c3ed5c6314a49a5a37ad976417142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_262cc50dd08f49f78b781c2ce96a4ad7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f305b344487a4b598a7d41b007e49abd",
      "value": " 232k/232k [00:00&lt;00:00, 286kB/s]"
     }
    },
    "16b6cfa829ad43778c079452df231a3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17cfaa41c53842618c728987a81a44da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fc2d9969ea34bb3bb6e9f0260c2a75c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23531989ef014d7db16b220bb807c8fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "262cc50dd08f49f78b781c2ce96a4ad7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3518f71b0e4540be8b17a3fe72182cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9ef3ce0ace649c5a53e2244ba0dbb32",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_702a74b6e6e44d6b8ad68347f1a4b5fb",
      "value": "Downloading: 100%"
     }
    },
    "35a9eeb0acdb44738a6ad7fbf6d99b2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3950e2a7832c4dce8fd8209d6322a1f7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d32667132d604faeb419bbf9851c1bd8",
      "value": 231508
     }
    },
    "394b7988d36849b7b2c82872ae8d489d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3950e2a7832c4dce8fd8209d6322a1f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ccd384305c44ee3a86f47a2b994fbf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d84c022c44141268ef2c8d5e0190404": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40c212c9b352401697860624a6c54b1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4bd0f4c575714ad7848e818a576ee00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a38bc7017d545e2b44ad6ab0b2d937b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_929799bd24fb411bb4686988f2ae8996",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bd0f4c575714ad7848e818a576ee00a",
      "value": 570
     }
    },
    "5c6bfb038756422bb00be1349db7750b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c586016d3b594c6299cab2384f4c10aa",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d03c894896ad4ed6b48f19a70fbdf2af",
      "value": 466062
     }
    },
    "67f208ba489343dfa195c1dd915f3efe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16b6cfa829ad43778c079452df231a3d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a2a36eb594654c65acd584d9d4ebea20",
      "value": "Downloading: 100%"
     }
    },
    "6ccdfb754c12418c9438ac218a172e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cf29b5d508a4e2082751ccc7fa2f625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ccd384305c44ee3a86f47a2b994fbf9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_23531989ef014d7db16b220bb807c8fd",
      "value": " 466k/466k [00:00&lt;00:00, 637kB/s]"
     }
    },
    "702a74b6e6e44d6b8ad68347f1a4b5fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71a15c5a038f451f8ee64ce046488f71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8181fd24b3624c1b9c6a9d0302f43a56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fc2d9969ea34bb3bb6e9f0260c2a75c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_911177bb86c749a0bd774cd3b7f9d302",
      "value": " 536M/536M [00:12&lt;00:00, 40.9MB/s]"
     }
    },
    "82b7fc20b50c44b2bd84b3bf882cdd43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c2b37becdef45bba205dfb20f8e37b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4276b6a5eac4023955218db6f78c84a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c4b0a1b67d304afda6ee4e52095584cc",
      "value": " 28.0/28.0 [00:00&lt;00:00, 631B/s]"
     }
    },
    "8c7cf993674145ffb7bb876e5591f6ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67f208ba489343dfa195c1dd915f3efe",
       "IPY_MODEL_35a9eeb0acdb44738a6ad7fbf6d99b2b",
       "IPY_MODEL_153c3ed5c6314a49a5a37ad976417142"
      ],
      "layout": "IPY_MODEL_82b7fc20b50c44b2bd84b3bf882cdd43"
     }
    },
    "901557318fb947dfa082f0cbf2d7365b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0efe94b613f44c029f2e9bd05696ad32",
       "IPY_MODEL_5a38bc7017d545e2b44ad6ab0b2d937b",
       "IPY_MODEL_b3db733aacf94a3c94519d70a7a56d7a"
      ],
      "layout": "IPY_MODEL_394b7988d36849b7b2c82872ae8d489d"
     }
    },
    "911177bb86c749a0bd774cd3b7f9d302": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "929799bd24fb411bb4686988f2ae8996": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "997b8c940317448c9409a2dee15fc519": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e99fb1211ba43459ee78dd64ab8c30e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2a36eb594654c65acd584d9d4ebea20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5ccb838d3704546937e925e456830be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d84c022c44141268ef2c8d5e0190404",
      "max": 536063208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40c212c9b352401697860624a6c54b1c",
      "value": 536063208
     }
    },
    "a66943be0fc0423880cb2bd63a1ea2d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6d9e21208294428a3f5572bbbd8b0b9",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d15e557fc621427a8295eecdc1e781a8",
      "value": 28
     }
    },
    "a8fd8b38a6b84be7b83b2f4df590fada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e99fb1211ba43459ee78dd64ab8c30e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_71a15c5a038f451f8ee64ce046488f71",
      "value": "Downloading: 100%"
     }
    },
    "b12b35cc52454a249c97f695409d24ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3db733aacf94a3c94519d70a7a56d7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0466163ff4a945798423387d1ac900c8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_17cfaa41c53842618c728987a81a44da",
      "value": " 570/570 [00:00&lt;00:00, 17.0kB/s]"
     }
    },
    "b4276b6a5eac4023955218db6f78c84a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d9e21208294428a3f5572bbbd8b0b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baffabe6cabf48f5b0b6523ea92aee78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18a3a9fc6d54b9f848e4454e1e36c21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a8fd8b38a6b84be7b83b2f4df590fada",
       "IPY_MODEL_5c6bfb038756422bb00be1349db7750b",
       "IPY_MODEL_6cf29b5d508a4e2082751ccc7fa2f625"
      ],
      "layout": "IPY_MODEL_c4c410ab0c994a229a49b8baee221de4"
     }
    },
    "c4b0a1b67d304afda6ee4e52095584cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4c410ab0c994a229a49b8baee221de4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c586016d3b594c6299cab2384f4c10aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5b9bf1f3ae343ce97982c7802cfdc94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_997b8c940317448c9409a2dee15fc519",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b12b35cc52454a249c97f695409d24ce",
      "value": "Downloading: 100%"
     }
    },
    "c9ef3ce0ace649c5a53e2244ba0dbb32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d03c894896ad4ed6b48f19a70fbdf2af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d15e557fc621427a8295eecdc1e781a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d32667132d604faeb419bbf9851c1bd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3e13535de4b44bb9139c3911684cee8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0e88103f9684ffdb957357222bbaaf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5b9bf1f3ae343ce97982c7802cfdc94",
       "IPY_MODEL_a66943be0fc0423880cb2bd63a1ea2d2",
       "IPY_MODEL_8c2b37becdef45bba205dfb20f8e37b2"
      ],
      "layout": "IPY_MODEL_baffabe6cabf48f5b0b6523ea92aee78"
     }
    },
    "f02cf8090f8d463eb7eeb59743a87276": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f305b344487a4b598a7d41b007e49abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
